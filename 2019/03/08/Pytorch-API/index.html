

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhichao zhao">
  <meta name="keywords" content="">
  <title>pytorch API - å‡æ¬¢ç•… åˆä½•å¦¨ æ— äººå…±äº«</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />
    
  

  


<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- è‡ªå®šä¹‰æ ·å¼ä¿æŒåœ¨æœ€åº•éƒ¨ -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>å‡æ¬¢ç•…ï¼Œåˆä½•å¦¨ï¼Œæ— äººå…±äº«</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2019-03-08 18:46" pubdate>
        March 8, 2019 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.7k å­—
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      75
       åˆ†é’Ÿ
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">pytorch API</h1>
            
            <div class="markdown-body" id="post-body">
              <p>Pytorch API æ±‡æ€»æ•´ç†</p>
<a id="more"></a>
<h3 id="1-import-torch"><a href="#1-import-torch" class="headerlink" title="1. import torch"></a>1. import torch</h3><p>import &amp; vision</p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> torch 
print(torch.__version__)</code></pre>
<h3 id="2-Tensor-type-ğŸŒŸ"><a href="#2-Tensor-type-ğŸŒŸ" class="headerlink" title="2. Tensor type ğŸŒŸ"></a>2. Tensor type ğŸŒŸ</h3><p>Pytorch ç»™å‡ºäº† 9 ç§ CPU Tensor ç±»å‹å’Œ 9 ç§ GPU Tensor ç±»å‹ã€‚Pytorch ä¸­é»˜è®¤çš„æ•°æ®ç±»å‹æ˜¯ torch.FloatTensor, å³ torch.Tensor ç­‰åŒäº torch.FloatTensorã€‚</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Data type</th>
<th>dtype</th>
<th>CPU tensor</th>
<th>GPU tensor</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit floating point</td>
<td>torch.float32 or torch.float</td>
<td>torch.FloatTensor</td>
<td>torch.cuda.FloatTensor</td>
</tr>
<tr>
<td>64-bit floating point</td>
<td>torch.float64 or torch.double</td>
<td>torch.DoubleTensor</td>
<td>torch.cuda.DoubleTensor</td>
</tr>
<tr>
<td>16-bit floating point</td>
<td>torch.float16 or torch.half</td>
<td>torch.HalfTensor</td>
<td>torch.cuda.HalfTensor</td>
</tr>
<tr>
<td>8-bit integer (unsigned)</td>
<td>torch.uint8</td>
<td>torch.ByteTensor</td>
<td>torch.cuda.ByteTensor</td>
</tr>
<tr>
<td>8-bit integer (signed)</td>
<td>torch.int8</td>
<td>torch.CharTensor</td>
<td>torch.cuda.CharTensor</td>
</tr>
<tr>
<td>16-bit integer (signed)</td>
<td>torch.int16 or torch.short</td>
<td>torch.ShortTensor</td>
<td>torch.cuda.ShortTensor</td>
</tr>
<tr>
<td>32-bit integer (signed)</td>
<td>torch.int32 or torch.int</td>
<td>torch.IntTensor</td>
<td>torch.cuda.IntTensor</td>
</tr>
<tr>
<td>64-bit integer (signed)</td>
<td>torch.int64 or torch.long</td>
<td>torch.LongTensor</td>
<td>torch.cuda.LongTensor</td>
</tr>
<tr>
<td>Boolean</td>
<td>torch.bool</td>
<td>torch.BoolTensor</td>
<td>torch.cuda.BoolTensor</td>
</tr>
</tbody>
</table>
</div>
<h5 id="è®¾ç½®é»˜è®¤Tensor-ç±»å‹"><a href="#è®¾ç½®é»˜è®¤Tensor-ç±»å‹" class="headerlink" title="è®¾ç½®é»˜è®¤Tensor ç±»å‹"></a>è®¾ç½®é»˜è®¤Tensor ç±»å‹</h5><p>Pytorch å¯ä»¥é€šè¿‡ <code>set_default_tensor_type</code> å‡½æ•°<strong>è®¾ç½®é»˜è®¤ä½¿ç”¨çš„Tensorç±»å‹</strong>ï¼Œ åœ¨å±€éƒ¨ä½¿ç”¨å®Œåå¦‚æœéœ€è¦å…¶ä»–ç±»å‹ï¼Œåˆ™è¿˜éœ€è¦é‡æ–°è®¾ç½®ä¼šæ‰€éœ€çš„ç±»å‹ </p>
<pre><code class="hljs elm"><span class="hljs-title">torch</span>.set_default_tensor_<span class="hljs-keyword">type</span>(&#x27;torch.<span class="hljs-type">DoubleTensor</span>&#x27;)</code></pre>
<h5 id="CPU-GPU-äº’è½¬"><a href="#CPU-GPU-äº’è½¬" class="headerlink" title="CPU/GPU äº’è½¬"></a>CPU/GPU äº’è½¬</h5><p>CPU Tensor å’Œ GPU Tensor çš„åŒºåˆ«åœ¨äºï¼Œ å‰è€…å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè€Œåè€…å­˜å‚¨åœ¨æ˜¾å­˜ä¸­ã€‚ä¸¤è€…ä¹‹é—´çš„è½¬æ¢å¯ä»¥é€šè¿‡ <code>.cpu()</code>ã€<code>.cuda()</code>å’Œ <code>.to(device)</code> æ¥å®Œæˆ  </p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  
<span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.cuda() <span class="hljs-comment"># CPU -&gt; GPU</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()
<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.cpu() <span class="hljs-comment"># GPU -&gt; CPU</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()
<span class="hljs-string">&#x27;torch.FloatTensor&#x27;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.to(device) <span class="hljs-comment"># to device</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()
<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span></code></pre>
<h5 id="åˆ¤å®š-Tensor-ç±»å‹çš„å‡ ç§æ–¹å¼"><a href="#åˆ¤å®š-Tensor-ç±»å‹çš„å‡ ç§æ–¹å¼" class="headerlink" title="åˆ¤å®š Tensor ç±»å‹çš„å‡ ç§æ–¹å¼:"></a>åˆ¤å®š Tensor ç±»å‹çš„å‡ ç§æ–¹å¼:</h5><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],
        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a.is_cuda  <span class="hljs-comment"># å¯ä»¥æ˜¾ç¤ºæ˜¯å¦åœ¨æ˜¾å­˜ä¸­</span>
<span class="hljs-literal">True</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.dtype   <span class="hljs-comment"># Tensor å†…éƒ¨dataçš„ç±»å‹</span>
torch.float32
<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()
<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span>  <span class="hljs-comment"># å¯ä»¥ç›´æ¥æ˜¾ç¤º Tensor ç±»å‹ = is_cuda + dtype</span></code></pre>
<h5 id="ç±»å‹è½¬æ¢"><a href="#ç±»å‹è½¬æ¢" class="headerlink" title="ç±»å‹è½¬æ¢"></a>ç±»å‹è½¬æ¢</h5><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],
        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a.type(torch.DoubleTensor)   <span class="hljs-comment"># ä½¿ç”¨ type() å‡½æ•°è¿›è¡Œè½¬æ¢</span>
tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],
        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], dtype=torch.float64)
<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.double()  <span class="hljs-comment"># ç›´æ¥ä½¿ç”¨ int()ã€long() ã€float() ã€å’Œ double() ç­‰ç›´æ¥è¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢è¿›è¡Œ</span>
tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],
        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, dtype=torch.float64)
<span class="hljs-meta">&gt;&gt;&gt; </span>b = torch.randn(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>b.type_as(a)  <span class="hljs-comment"># ä½¿ç”¨ type_as å‡½æ•°, å¹¶ä¸éœ€è¦æ˜ç¡®å…·ä½“æ˜¯å“ªç§ç±»å‹</span>
tensor([[ <span class="hljs-number">0.2129</span>,  <span class="hljs-number">0.1877</span>, <span class="hljs-number">-0.0626</span>,  <span class="hljs-number">0.4607</span>, <span class="hljs-number">-1.0375</span>],
        [ <span class="hljs-number">0.7222</span>, <span class="hljs-number">-0.3502</span>,  <span class="hljs-number">0.1288</span>,  <span class="hljs-number">0.6786</span>,  <span class="hljs-number">0.5062</span>],
        [<span class="hljs-number">-0.4956</span>, <span class="hljs-number">-0.0793</span>,  <span class="hljs-number">0.7590</span>, <span class="hljs-number">-1.0932</span>, <span class="hljs-number">-0.1084</span>],
        [<span class="hljs-number">-2.2198</span>,  <span class="hljs-number">0.3827</span>,  <span class="hljs-number">0.2735</span>,  <span class="hljs-number">0.5642</span>,  <span class="hljs-number">0.6771</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,
       dtype=torch.float64)</code></pre>
<h5 id="numpy-array-ä¸-torch-Tensor-äº’è½¬"><a href="#numpy-array-ä¸-torch-Tensor-äº’è½¬" class="headerlink" title="numpy array ä¸ã€€torch Tensorã€€äº’è½¬"></a>numpy array ä¸ã€€torch Tensorã€€äº’è½¬</h5><pre><code class="hljs python">torch.Tensor ä¸ np.ndarray è½¬æ¢
<span class="hljs-comment"># torch.Tensor -&gt; np.ndarray.</span>
ndarray = tensor.cpu().numpy()

<span class="hljs-comment"># np.ndarray -&gt; torch.Tensor.</span>
tensor = torch.from_numpy(ndarray).float()
tensor = torch.from_numpy(ndarray.copy()).float()  <span class="hljs-comment"># If ndarray has negative stride</span></code></pre>
<h5 id="Tensor-ç›¸å…³ä¿¡æ¯è·å–"><a href="#Tensor-ç›¸å…³ä¿¡æ¯è·å–" class="headerlink" title="Tensor ç›¸å…³ä¿¡æ¯è·å–"></a>Tensor ç›¸å…³ä¿¡æ¯è·å–</h5><pre><code class="hljs python">t.size()/tã€.shape   <span class="hljs-comment"># ä¸¤è€…ç­‰ä»·ï¼Œ è¿”å› t çš„å½¢çŠ¶, å¯ä»¥ä½¿ç”¨ t.size()[1] æˆ– t.size(1) æŸ¥çœ‹åˆ—æ•°</span>
t.numel() / t.nelement()  <span class="hljs-comment"># ä¸¤è€…ç­‰ä»·, è¿”å› tensor ä¸­å…ƒç´ æ€»ä¸ªæ•°</span>
t.item()  <span class="hljs-comment"># å–å‡ºå•ä¸ª tensor çš„å€¼</span>
t.dim()  <span class="hljs-comment"># ç»´åº¦</span></code></pre>
<h3 id="3-Tensor-Create"><a href="#3-Tensor-Create" class="headerlink" title="3. Tensor Create"></a>3. Tensor Create</h3><h5 id="æœ€åŸºæœ¬çš„Tensoråˆ›å»ºæ–¹å¼"><a href="#æœ€åŸºæœ¬çš„Tensoråˆ›å»ºæ–¹å¼" class="headerlink" title="æœ€åŸºæœ¬çš„Tensoråˆ›å»ºæ–¹å¼"></a>æœ€åŸºæœ¬çš„Tensoråˆ›å»ºæ–¹å¼</h5><pre><code class="hljs python">troch.Tensor(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># ä¼šä½¿ç”¨é»˜è®¤çš„ç±»å‹åˆ›å»º Tensor, </span>
                   <span class="hljs-comment"># å¯ä»¥é€šè¿‡ torch.set_default_tensor_type(&#x27;torch.DoubleTensor&#x27;) è¿›è¡Œä¿®æ”¹</span>
torch.DoubleTensor(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># æŒ‡å®šç±»å‹åˆ›å»º Tensor</span>

torch.Tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])  <span class="hljs-comment"># é€šè¿‡ list åˆ›å»º Tensor</span>
                                <span class="hljs-comment"># å°† Tensorè½¬æ¢ä¸ºlistå¯ä»¥ä½¿ç”¨: t.tolist()</span>
torch.from_numpy(np.array([<span class="hljs-number">2</span>, <span class="hljs-number">3.3</span>]) ) <span class="hljs-comment"># é€šè¿‡ numpy array åˆ›å»º tensor</span></code></pre>
<h5 id="ç¡®å®šåˆå§‹å€¼çš„æ–¹å¼åˆ›å»º"><a href="#ç¡®å®šåˆå§‹å€¼çš„æ–¹å¼åˆ›å»º" class="headerlink" title="ç¡®å®šåˆå§‹å€¼çš„æ–¹å¼åˆ›å»º"></a>ç¡®å®šåˆå§‹å€¼çš„æ–¹å¼åˆ›å»º</h5><pre><code class="hljs python">torch.ones(sizes)  <span class="hljs-comment"># å…¨ 1 Tensor     </span>
torch.zeros(sizes)  <span class="hljs-comment"># å…¨ 0 Tensor</span>
torch.eye(sizes)  <span class="hljs-comment"># å¯¹è§’çº¿ä¸º1ï¼Œä¸è¦æ±‚è¡Œåˆ—ä¸€è‡´</span>
torch.full(sizes, value) <span class="hljs-comment"># æŒ‡å®š value</span></code></pre>
<h5 id="åˆ†å¸ƒ"><a href="#åˆ†å¸ƒ" class="headerlink" title="åˆ†å¸ƒ"></a>åˆ†å¸ƒ</h5><pre><code class="hljs python">torch.rand(sizes)  <span class="hljs-comment"># å‡åŒ€åˆ†å¸ƒ   </span>
torch.randn(sizes)   <span class="hljs-comment"># æ ‡å‡†åˆ†å¸ƒ</span>
<span class="hljs-comment"># æ­£æ€åˆ†å¸ƒ: è¿”å›ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«ä»ç»™å®šå‚æ•° means, std çš„ç¦»æ•£æ­£æ€åˆ†å¸ƒä¸­æŠ½å–éšæœºæ•°ã€‚ </span>
<span class="hljs-comment"># å‡å€¼ means æ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„å‡å€¼ -&gt; ä»¥æ­¤å¼ é‡çš„å‡å€¼ä½œä¸ºå‡å€¼</span>
<span class="hljs-comment"># æ ‡å‡†å·® std æ˜¯ä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«æ¯ä¸ªè¾“å‡ºå…ƒç´ ç›¸å…³çš„æ­£æ€åˆ†å¸ƒçš„æ ‡å‡†å·® -&gt; ä»¥æ­¤å¼ é‡çš„æ ‡å‡†å·®ä½œä¸ºæ ‡å‡†å·®ã€‚ </span>
<span class="hljs-comment"># å‡å€¼å’Œæ ‡å‡†å·®çš„å½¢çŠ¶ä¸é¡»åŒ¹é…ï¼Œä½†æ¯ä¸ªå¼ é‡çš„å…ƒç´ ä¸ªæ•°é¡»ç›¸åŒ</span>
torch.normal(mean=torch.arange(<span class="hljs-number">1.</span>, <span class="hljs-number">11.</span>), std=torch.arange(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-0.1</span>))
tensor([<span class="hljs-number">-0.1987</span>,  <span class="hljs-number">3.1957</span>,  <span class="hljs-number">3.5459</span>,  <span class="hljs-number">2.8150</span>,  <span class="hljs-number">5.5398</span>,  <span class="hljs-number">5.6116</span>,  <span class="hljs-number">7.5512</span>,  <span class="hljs-number">7.8650</span>,
         <span class="hljs-number">9.3151</span>, <span class="hljs-number">10.1827</span>])
torch.uniform(<span class="hljs-keyword">from</span>,to) <span class="hljs-comment"># å‡åŒ€åˆ†å¸ƒ </span>

torch.arange(s, e, steps)  <span class="hljs-comment"># ä» s åˆ° eï¼Œæ­¥é•¿ä¸º step</span>
torch.linspace(s, e, num)   <span class="hljs-comment"># ä» s åˆ° e, å‡åŒ€åˆ‡åˆ†ä¸º num ä»½</span>
<span class="hljs-comment"># ! æ³¨æ„linespaceå’Œarangeçš„åŒºåˆ«ï¼Œå‰è€…çš„æœ€åä¸€ä¸ªå‚æ•°æ˜¯ç”Ÿæˆçš„Tensorä¸­å…ƒç´ çš„æ•°é‡ï¼Œè€Œåè€…çš„æœ€åä¸€ä¸ªå‚æ•°æ˜¯æ­¥é•¿ã€‚</span>
torch.randperm(m) <span class="hljs-comment"># 0 åˆ° m-1 çš„éšæœºåºåˆ—</span>
<span class="hljs-comment"># ! shuffle æ“ä½œ</span>
tensor[torch.randperm(tensor.size(<span class="hljs-number">0</span>))]</code></pre>
<h5 id="å¤åˆ¶"><a href="#å¤åˆ¶" class="headerlink" title="å¤åˆ¶"></a>å¤åˆ¶</h5><p>Pytorch æœ‰å‡ ç§ä¸åŒçš„å¤åˆ¶æ–¹å¼ï¼Œæ³¨æ„åŒºåˆ†</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Operation</th>
<th>New/Shared memory</th>
<th>Still in computation graph</th>
</tr>
</thead>
<tbody>
<tr>
<td>tensor.clone()</td>
<td>New</td>
<td>Yes</td>
</tr>
<tr>
<td>tensor.detach()</td>
<td>Shared</td>
<td>No</td>
</tr>
<tr>
<td>tensor.detach.clone()</td>
<td>New</td>
<td>No</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-ç´¢å¼•ã€æ¯”è¾ƒã€æ’åº"><a href="#4-ç´¢å¼•ã€æ¯”è¾ƒã€æ’åº" class="headerlink" title="4. ç´¢å¼•ã€æ¯”è¾ƒã€æ’åº"></a>4. ç´¢å¼•ã€æ¯”è¾ƒã€æ’åº</h3><h5 id="ç´¢å¼•æ“ä½œ"><a href="#ç´¢å¼•æ“ä½œ" class="headerlink" title="ç´¢å¼•æ“ä½œ"></a>ç´¢å¼•æ“ä½œ</h5><pre><code class="hljs python">a.item() <span class="hljs-comment">#ã€€ä»åªåŒ…å«ä¸€ä¸ªå…ƒç´ çš„å¼ é‡ä¸­æå–å€¼</span>

a[row, column]   <span class="hljs-comment"># row è¡Œï¼Œ cloumn åˆ—</span>
a[index]   <span class="hljs-comment"># ç¬¬index è¡Œ</span>
a[:,index]   <span class="hljs-comment"># ç¬¬ index åˆ—</span>

a[<span class="hljs-number">0</span>, <span class="hljs-number">-1</span>]  <span class="hljs-comment"># ç¬¬é›¶è¡Œï¼Œ æœ€åä¸€ä¸ªå…ƒç´ </span>
a[:index]  <span class="hljs-comment"># å‰ index è¡Œ</span>
a[:row, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>]  <span class="hljs-comment"># å‰ row è¡Œï¼Œ 0å’Œ1åˆ—</span>

a[a&gt;<span class="hljs-number">1</span>]  <span class="hljs-comment"># é€‰æ‹© a &gt; 1çš„å…ƒç´ ï¼Œ ç­‰ä»·äº a.masked_select(a&gt;1)</span>
torch.nonzero(a) <span class="hljs-comment"># é€‰æ‹©éé›¶å…ƒç´ çš„åæ ‡ï¼Œå¹¶è¿”å›</span>
a.clamp(x, y)  <span class="hljs-comment"># å¯¹ Tensor å…ƒç´ è¿›è¡Œé™åˆ¶ï¼Œ å°äºxç”¨xä»£æ›¿ï¼Œ å¤§äºyç”¨yä»£æ›¿</span>
torch.where(condition, x, y)  <span class="hljs-comment"># æ»¡è¶³condition çš„ä½ç½®è¾“å‡ºxï¼Œ å¦åˆ™è¾“å‡ºy</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[ <span class="hljs-number">6.</span>, <span class="hljs-number">-2.</span>],
        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.where(a &gt; <span class="hljs-number">1</span>, torch.full_like(a, <span class="hljs-number">1</span>), a)  <span class="hljs-comment"># å¤§äº1 çš„éƒ¨åˆ†ç›´æ¥ç”¨1ä»£æ›¿ï¼Œ å…¶ä»–ä¿ç•™åŸå€¼</span>
tensor([[ <span class="hljs-number">1.</span>, <span class="hljs-number">-2.</span>],
        [ <span class="hljs-number">1.</span>,  <span class="hljs-number">0.</span>]])

<span class="hljs-comment">#ã€€å¾—åˆ°éé›¶å…ƒç´ </span>
torch.nonzero(tensor)               <span class="hljs-comment"># éé›¶å…ƒç´ çš„ç´¢å¼•</span>
torch.nonzero(tensor == <span class="hljs-number">0</span>)          <span class="hljs-comment"># é›¶å…ƒç´ çš„ç´¢å¼•</span>
torch.nonzero(tensor).size(<span class="hljs-number">0</span>)       <span class="hljs-comment"># éé›¶å…ƒç´ çš„ä¸ªæ•°</span>
torch.nonzero(tensor == <span class="hljs-number">0</span>).size(<span class="hljs-number">0</span>)  <span class="hljs-comment"># é›¶å…ƒç´ çš„ä¸ªæ•°</span></code></pre>
<h5 id="æ¯”è¾ƒæ“ä½œ"><a href="#æ¯”è¾ƒæ“ä½œ" class="headerlink" title="æ¯”è¾ƒæ“ä½œ"></a>æ¯”è¾ƒæ“ä½œ</h5><pre><code class="hljs python">gt &gt;    lt &lt;     ge &gt;=     le &lt;=   eq ==    ne != 
topk(input, k) -&gt; (Tensor, LongTensor)
sort(input) -&gt; (Tensor, LongTensor)
max/min =&gt; max(tensor)      max(tensor, dim)    max(tensor1, tensor2)</code></pre>
<p>sort å‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°, å…¶ä¸­ å‚æ•° 0 ä¸ºæŒ‰ç…§è¡Œæ’åºã€1ä¸ºæŒ‰ç…§åˆ—æ’åº: True ä¸ºé™åºï¼Œ False ä¸ºå‡åºï¼Œ è¿”å›å€¼æœ‰ä¸¤ä¸ªï¼Œ ç¬¬ä¸€ä¸ªæ˜¯æ’åºç»“æœï¼Œ ç¬¬äºŒä¸ªæ˜¯æ’åºåºå·</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[<span class="hljs-number">-1.8500</span>, <span class="hljs-number">-0.2005</span>,  <span class="hljs-number">1.4475</span>],
        [<span class="hljs-number">-1.7795</span>, <span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.8965</span>],
        [ <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>,  <span class="hljs-number">1.6395</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">0</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>] 
tensor([[ <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>,  <span class="hljs-number">1.6395</span>],
        [<span class="hljs-number">-1.7795</span>, <span class="hljs-number">-0.2005</span>,  <span class="hljs-number">1.4475</span>],
        [<span class="hljs-number">-1.8500</span>, <span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.8965</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">0</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]
tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],
        [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
        [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">1</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]
tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],
        [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],
        [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">1</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
tensor([[ <span class="hljs-number">1.4475</span>, <span class="hljs-number">-0.2005</span>, <span class="hljs-number">-1.8500</span>],
        [<span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.7795</span>, <span class="hljs-number">-1.8965</span>],
        [ <span class="hljs-number">1.6395</span>,  <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>]])</code></pre>
<h3 id="5-Element-wise-å’Œ-å½’å¹¶æ“ä½œ"><a href="#5-Element-wise-å’Œ-å½’å¹¶æ“ä½œ" class="headerlink" title="5. Element-wise å’Œ å½’å¹¶æ“ä½œ"></a>5. Element-wise å’Œ å½’å¹¶æ“ä½œ</h3><p>Element-wiseï¼šè¾“å‡ºçš„ Tensor å½¢çŠ¶ä¸åŸå§‹çš„å½¢çŠ¶ä¸€è‡´</p>
<pre><code class="hljs python">abs / sqrt / div / exp / fmod / log / pow...
cos / sin / asin / atan2 / cosh...
ceil / round / floor / trunc
clamp(input, min, max)
sigmoid / tanh...</code></pre>
<p>å½’å¹¶æ“ä½œï¼šè¾“å‡ºçš„ Tensor å½¢çŠ¶å°äºåŸå§‹çš„ Tensorå½¢çŠ¶</p>
<pre><code class="hljs python">mean/sum/median/mode   <span class="hljs-comment"># å‡å€¼/å’Œ/ ä¸­ä½æ•°/ä¼—æ•°</span>
norm/dist  <span class="hljs-comment"># èŒƒæ•°/è·ç¦»</span>
std/var  <span class="hljs-comment"># æ ‡å‡†å·®/æ–¹å·®</span>
cumsum/cumprd <span class="hljs-comment"># ç´¯åŠ /ç´¯ä¹˜</span></code></pre>
<h3 id="6-å˜å½¢æ“ä½œ"><a href="#6-å˜å½¢æ“ä½œ" class="headerlink" title="6. å˜å½¢æ“ä½œ"></a>6. å˜å½¢æ“ä½œ</h3><h5 id="view-resize-reshape-è°ƒæ•´Tensorçš„å½¢çŠ¶"><a href="#view-resize-reshape-è°ƒæ•´Tensorçš„å½¢çŠ¶" class="headerlink" title="view/resize/reshape  è°ƒæ•´Tensorçš„å½¢çŠ¶"></a>view/resize/reshape  è°ƒæ•´Tensorçš„å½¢çŠ¶</h5><ul>
<li>å…ƒç´ æ€»æ•°å¿…é¡»ç›¸åŒ  </li>
<li>view å’Œ reshape å¯ä»¥ä½¿ç”¨ -1 è‡ªåŠ¨è®¡ç®—ç»´åº¦</li>
<li>å…±äº«å†…å­˜</li>
</ul>
<p>!!!  <code>view()</code> æ“ä½œæ˜¯éœ€è¦ Tensor åœ¨å†…å­˜ä¸­è¿ç»­çš„ï¼Œ è¿™ç§æƒ…å†µä¸‹éœ€è¦ä½¿ç”¨ <code>contiguous()</code> æ“ä½œå…ˆå°†å†…å­˜å˜ä¸ºè¿ç»­ã€‚ å¯¹äºreshape æ“ä½œï¼Œ å¯ä»¥çœ‹åšæ˜¯ <code>Tensor.contiguous().view()</code>.   ğŸŒŸ</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.Tensor(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[<span class="hljs-number">6.0000e+00</span>, <span class="hljs-number">8.0000e+00</span>],
        [<span class="hljs-number">1.0000e+00</span>, <span class="hljs-number">1.8367e-40</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.resize(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)
tensor([[<span class="hljs-number">6.0000e+00</span>],
        [<span class="hljs-number">8.0000e+00</span>],
        [<span class="hljs-number">1.0000e+00</span>],
        [<span class="hljs-number">1.8367e-40</span>]])</code></pre>
<h5 id="transpose-permute-å„ç»´åº¦ä¹‹é—´çš„å˜æ¢"><a href="#transpose-permute-å„ç»´åº¦ä¹‹é—´çš„å˜æ¢" class="headerlink" title="transpose / permute  å„ç»´åº¦ä¹‹é—´çš„å˜æ¢"></a>transpose / permute  å„ç»´åº¦ä¹‹é—´çš„å˜æ¢</h5><p>transpose å¯ä»¥å°†æŒ‡å®šçš„ä¸¤ä¸ªç»´åº¦çš„å…ƒç´ è¿›è¡Œè½¬ç½®ï¼Œ permute åˆ™å¯ä»¥æŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œç»´åº¦å˜æ¢</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x
tensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>]],
        [[ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])

<span class="hljs-meta">&gt;&gt;&gt; </span>x.shape
torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>x.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 2, 3])</span>
tensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>],
         [ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])
<span class="hljs-meta">&gt;&gt;&gt; </span>x.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 2, 3])</span>
tensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>],
         [ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])
<span class="hljs-meta">&gt;&gt;&gt; </span></code></pre>
<h5 id="squeeze-dim-unsquence-dim-ğŸŒŸ"><a href="#squeeze-dim-unsquence-dim-ğŸŒŸ" class="headerlink" title="squeeze(dim) / unsquence(dim)   ğŸŒŸ"></a>squeeze(dim) / unsquence(dim)   ğŸŒŸ</h5><p>å¤„ç† size ä¸º 1 çš„ç»´åº¦ï¼Œ å‰è€…ç”¨äºå»é™¤ size ä¸º 1 çš„ç»´åº¦ï¼Œ è€Œåè€…åˆ™æ˜¯å°†æŒ‡å®šçš„ç»´åº¦çš„sizeå˜ä¸º1</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-comment"># shape =&gt; torch.Size([3])</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 3])</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a.unqueeze(<span class="hljs-number">0</span>).squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># shape =&gt; torch.Size([3])</span></code></pre>
<h5 id="expand-expand-as-repeatå¤åˆ¶å…ƒç´ æ¥æ‰©å±•ç»´åº¦"><a href="#expand-expand-as-repeatå¤åˆ¶å…ƒç´ æ¥æ‰©å±•ç»´åº¦" class="headerlink" title="expand / expand_as / repeatå¤åˆ¶å…ƒç´ æ¥æ‰©å±•ç»´åº¦"></a>expand / expand_as / repeatå¤åˆ¶å…ƒç´ æ¥æ‰©å±•ç»´åº¦</h5><p>æœ‰æ—¶éœ€è¦é‡‡ç”¨å¤åˆ¶çš„å½¢å¼æ¥æ‰©å±• Tensor çš„ç»´åº¦ï¼Œ è¿™æ—¶å¯ä»¥ä½¿ç”¨ <code>expand</code>ï¼Œ <code>expand()</code> å‡½æ•°å°† size ä¸º 1çš„ç»´åº¦å¤åˆ¶æ‰©å±•ä¸ºæŒ‡å®šå¤§å°ï¼Œ ä¹Ÿå¯ä»¥ç”¨ <code>expand_as()</code>å‡½æ•°æŒ‡å®šä¸º ç¤ºä¾‹ Tensor çš„ç»´åº¦ã€‚</p>
<p>!! <code>expand</code> æ‰©å¤§ tensor ä¸éœ€è¦åˆ†é…æ–°å†…å­˜ï¼Œåªæ˜¯ä»…ä»…æ–°å»ºä¸€ä¸ª tensor çš„è§†å›¾ï¼Œå…¶ä¸­é€šè¿‡å°† stride è®¾ä¸º0ï¼Œä¸€ç»´å°†ä¼šæ‰©å±•ä½æ›´é«˜ç»´ã€‚</p>
<p><code>repeat</code> æ²¿ç€æŒ‡å®šçš„ç»´åº¦é‡å¤ tensorã€‚ ä¸åŒäº <code>expand()</code>ï¼Œå¤åˆ¶çš„æ˜¯ tensor ä¸­çš„æ•°æ®ã€‚</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[[<span class="hljs-number">0.3094</span>],
         [<span class="hljs-number">0.4812</span>]],

        [[<span class="hljs-number">0.0950</span>],
         [<span class="hljs-number">0.8652</span>]]])
<span class="hljs-meta">&gt;&gt;&gt; </span>a.expand(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>) <span class="hljs-comment"># å°†ç¬¬2ç»´çš„ç»´åº¦ç”±1å˜ä¸º3ï¼Œ åˆ™å¤åˆ¶è¯¥ç»´çš„å…ƒç´ ï¼Œå¹¶æ‰©å±•ä¸º3</span>
tensor([[[<span class="hljs-number">0.3094</span>, <span class="hljs-number">0.3094</span>, <span class="hljs-number">0.3094</span>],
         [<span class="hljs-number">0.4812</span>, <span class="hljs-number">0.4812</span>, <span class="hljs-number">0.4812</span>]],

        [[<span class="hljs-number">0.0950</span>, <span class="hljs-number">0.0950</span>, <span class="hljs-number">0.0950</span>],
         [<span class="hljs-number">0.8652</span>, <span class="hljs-number">0.8652</span>, <span class="hljs-number">0.8652</span>]]])

<span class="hljs-meta">&gt;&gt;&gt; </span>a.repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># å°†ç¬¬äºŒä½å¤åˆ¶ä¸€æ¬¡</span>
tensor([[[<span class="hljs-number">0.3094</span>],
         [<span class="hljs-number">0.4812</span>],
         [<span class="hljs-number">0.3094</span>],
         [<span class="hljs-number">0.4812</span>]],

        [[<span class="hljs-number">0.0950</span>],
         [<span class="hljs-number">0.8652</span>],
         [<span class="hljs-number">0.0950</span>],
         [<span class="hljs-number">0.8652</span>]]])</code></pre>
<h5 id="ä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ‰©å±•å¤šä¸ªç»´åº¦-ğŸŒŸ"><a href="#ä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ‰©å±•å¤šä¸ªç»´åº¦-ğŸŒŸ" class="headerlink" title="ä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ‰©å±•å¤šä¸ªç»´åº¦ ğŸŒŸ"></a>ä½¿ç”¨åˆ‡ç‰‡æ“ä½œæ‰©å±•å¤šä¸ªç»´åº¦ ğŸŒŸ</h5><pre><code class="hljs fortran">b = a[:,<span class="hljs-keyword">None</span>, <span class="hljs-keyword">None</span>,:] # <span class="hljs-keyword">None</span> å¤„çš„ç»´åº¦ä¸ºï¼‘</code></pre>
<h3 id="7-ç»„åˆä¸åˆ†å—"><a href="#7-ç»„åˆä¸åˆ†å—" class="headerlink" title="7. ç»„åˆä¸åˆ†å—"></a>7. ç»„åˆä¸åˆ†å—</h3><p><strong>ç»„åˆæ“ä½œ</strong> æ˜¯å°†ä¸åŒçš„ Tensor å åŠ èµ·æ¥ã€‚ ä¸»è¦æœ‰ <code>cat()</code> å’Œ <code>torch.stack()</code> ä¸¤ä¸ªå‡½æ•°ï¼Œcat å³ concatenate çš„æ„æ€ï¼Œ æ˜¯æŒ‡æ²¿ç€å·²æœ‰çš„æ•°æ®çš„æŸä¸€ç»´åº¦è¿›è¡Œæ‹¼æ¥ï¼Œ æ“ä½œåçš„æ•°æ®çš„æ€»ç»´æ•°ä¸å˜ï¼Œ åœ¨è¿›è¡Œæ‹¼æ¥æ—¶ï¼Œ é™¤äº†æ‹¼æ¥çš„ç»´åº¦ä¹‹å¤–ï¼Œ å…¶ä»–ç»´åº¦å¿…é¡»ç›¸åŒã€‚ è€Œ<code>torch. stack()</code> å‡½æ•°ä¼šæ–°å¢ä¸€ä¸ªç»´åº¦ï¼Œ å¹¶æŒ‰ç…§æŒ‡å®šçš„ç»´åº¦è¿›è¡Œå åŠ ã€‚</p>
<pre><code class="hljs shell">torch.cat(list_of_tensors, dim=0)ã€€  # k ä¸ª (m,n) -&gt; (k*m, n)
torch.stack(list_of_tensors, dim=0)   # k ä¸ª (m,n) -&gt; (k*m*n)</code></pre>
<p><strong>åˆ†å—æ“ä½œ</strong> æ˜¯æŒ‡å°† Tensor åˆ†å‰²æˆä¸åŒçš„å­ Tensorï¼Œä¸»è¦æœ‰ <code>torch.chunk()</code> ä¸ <code>torch.split()</code> ä¸¤ä¸ªå‡½æ•°ï¼Œå‰è€…éœ€è¦æŒ‡å®šåˆ†å—çš„æ•°é‡ï¼Œè€Œåè€…åˆ™éœ€è¦æŒ‡å®šæ¯ä¸€å—çš„å¤§å°ï¼Œä»¥æ•´å½¢æˆ–è€…listæ¥è¡¨ç¤ºã€‚</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>]]), tensor([[<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],
        [<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>]]), tensor([[<span class="hljs-number">3.</span>],
        [<span class="hljs-number">6.</span>]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.split(a, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>],
        [<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]),)
<span class="hljs-meta">&gt;&gt;&gt; </span>torch.split(a, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-number">1</span>)
(tensor([[<span class="hljs-number">1.</span>],
        [<span class="hljs-number">4.</span>]]), tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>],
        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]))</code></pre>
<h3 id="8-èšåˆ-ä¸-åˆ†æ•£"><a href="#8-èšåˆ-ä¸-åˆ†æ•£" class="headerlink" title="8.  èšåˆ ä¸ åˆ†æ•£"></a>8.  èšåˆ ä¸ åˆ†æ•£</h3><pre><code class="hljs python">torch.gather(input, dim, index, out=<span class="hljs-literal">None</span>)  <span class="hljs-comment"># æ ¹æ® index å’Œ dim, å¯»æ‰¾ input å¯¹åº”çš„ç´¢å¼•ä½ç½®, å¾—åˆ° output</span>
Tensor.scatter_(dim, index, src)   <span class="hljs-comment"># æ ¹æ® dim å’Œ index, å°† src æŒ‡å®šä½ç½®ä¸Šçš„å€¼ï¼Œ åˆ†é…ç»™ output å¯¹åº”ç´¢å¼•ä½ç½®ã€‚</span></code></pre>
<h3 id="9-linear-algebra"><a href="#9-linear-algebra" class="headerlink" title="9. linear algebra"></a>9. linear algebra</h3><pre><code class="hljs python">trace  <span class="hljs-comment"># å¯¹è§’çº¿å…ƒç´ ä¹‹å’Œ(çŸ©é˜µçš„è¿¹)</span>
diag  <span class="hljs-comment"># å¯¹è§’çº¿å…ƒç´ </span>
triu/tril  <span class="hljs-comment"># çŸ©é˜µçš„ä¸Šä¸‰è§’/ä¸‹ä¸‰è§’</span>
addmm/addbmm/addmv/addr/badbmm...  <span class="hljs-comment"># çŸ©é˜µè¿ç®—</span>
t <span class="hljs-comment"># è½¬ç½®</span>
dor/cross <span class="hljs-comment"># å†…ç§¯/å¤–ç§¯</span>
inverse <span class="hljs-comment"># çŸ©é˜µæ±‚é€†</span>
svd  <span class="hljs-comment"># å¥‡å¼‚å€¼åˆ†è§£</span>

torch.mm(tensor1, tensor2)   <span class="hljs-comment"># çŸ©é˜µä¹˜æ³•  (m*n) * (n*p) -&gt; (m*p)</span>
torch.bmm(tensor1, tensor2) <span class="hljs-comment"># batchçš„çŸ©é˜µä¹˜æ³•: (b*m*n) * (b*n*p) -&gt; (b*m*p).</span>
torch.mv(tensor, vec) <span class="hljs-comment">#ã€€çŸ©é˜µå‘é‡ä¹˜æ³• (m*n) * (n) = (m)</span>
tensor1 * tensor2 <span class="hljs-comment"># Element-wise multiplication.</span></code></pre>
<h3 id="10-åŸºæœ¬æœºåˆ¶"><a href="#10-åŸºæœ¬æœºåˆ¶" class="headerlink" title="10. åŸºæœ¬æœºåˆ¶"></a>10. åŸºæœ¬æœºåˆ¶</h3><h5 id="å¹¿æ’­æœºåˆ¶"><a href="#å¹¿æ’­æœºåˆ¶" class="headerlink" title="å¹¿æ’­æœºåˆ¶"></a>å¹¿æ’­æœºåˆ¶</h5><p>ä¸åŒå½¢çŠ¶çš„ Tensor è¿›è¡Œè®¡ç®—æ—¶ï¼Œ å¯ä»¥è‡ªåŠ¨æ‰©å±•åˆ°è¾ƒå¤§çš„ç›¸åŒå½¢çŠ¶å†è¿›è¡Œè®¡ç®—ã€‚ å¹¿æ’­æœºåˆ¶çš„å‰ææ˜¯ä¸€ä¸ª Tensor  è‡³å°‘æœ‰ä¸€ä¸ªç»´åº¦ï¼Œä¸”ä»å°¾éƒ¨éå† Tensor æ—¶ï¼Œä¸¤è€…ç»´åº¦å¿…é¡»ç›¸ç­‰ï¼Œ å…¶ä¸­ä¸ƒä¸ªè¦ä¹ˆæ˜¯1ï¼Œ è¦ä¹ˆä¸å­˜åœ¨</p>
<h5 id="å‘é‡åŒ–æ“ä½œ"><a href="#å‘é‡åŒ–æ“ä½œ" class="headerlink" title="å‘é‡åŒ–æ“ä½œ"></a>å‘é‡åŒ–æ“ä½œ</h5><p>å¯ä»¥åœ¨åŒä¸€æ—¶é—´è¿›è¡Œæ‰¹é‡åœ°å¹¶è¡Œè®¡ç®—ï¼Œä¾‹å¦‚çŸ©é˜µè¿ç®—ï¼Œä»¥è¾¾åˆ°æ›´é«˜çš„è®¡ç®—æ•ˆç‡çš„ä¸€ç§æ–¹å¼:</p>
<h5 id="å…±äº«å†…å­˜æœºåˆ¶"><a href="#å…±äº«å†…å­˜æœºåˆ¶" class="headerlink" title="å…±äº«å†…å­˜æœºåˆ¶"></a>å…±äº«å†…å­˜æœºåˆ¶</h5><p>(1) ç›´æ¥é€šè¿‡ Tensor æ¥åˆå§‹åŒ–å¦ä¸€ä¸ª Tensorï¼Œ æˆ–è€…é€šè¿‡ Tensor çš„ç»„åˆã€åˆ†å—ã€ç´¢å¼•ã€å˜å½¢æ¥åˆå§‹åŒ–å¦ä¸€ä¸ªTensorï¼Œ åˆ™è¿™ä¸¤ä¸ª Tensor å…±äº«å†…å­˜:</p>
<pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>b = a
<span class="hljs-meta">&gt;&gt;&gt; </span>c = a.view(<span class="hljs-number">6</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>b[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = <span class="hljs-number">0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>c[<span class="hljs-number">3</span>] = <span class="hljs-number">4</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>a
tensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.3898</span>, <span class="hljs-number">-0.7641</span>],
        [ <span class="hljs-number">4.0000</span>,  <span class="hljs-number">0.6859</span>, <span class="hljs-number">-1.5179</span>]])</code></pre>
<p>(2) å¯¹äºä¸€äº›æ“ä½œé€šè¿‡åŠ åç¼€  â€œ_â€  å®ç° inplace æ“ä½œï¼Œ å¦‚ <code>add_()</code> å’Œ <code>resize_()</code> ç­‰ï¼Œ è¿™æ ·æ“ä½œåªè¦è¢«æ‰§è¡Œï¼Œ æœ¬èº«çš„ Tensor å°±ä¼šè¢«æ”¹å˜ã€‚</p>
<pre><code class="hljs angelscript">&gt;&gt;&gt; a
tensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.3898</span>, <span class="hljs-number">-0.7641</span>],
        [ <span class="hljs-number">4.0000</span>,  <span class="hljs-number">0.6859</span>, <span class="hljs-number">-1.5179</span>]])
&gt;&gt;&gt; a.add_(a)
tensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.7796</span>, <span class="hljs-number">-1.5283</span>],
        [ <span class="hljs-number">8.0000</span>,  <span class="hljs-number">1.3719</span>, <span class="hljs-number">-3.0358</span>]])</code></pre>
<p>(3) Tensorä¸ Numpy å¯ä»¥é«˜æ•ˆçš„å®Œæˆè½¬æ¢ï¼Œ å¹¶ä¸”è½¬æ¢å‰åçš„å˜é‡å…±äº«å†…å­˜ã€‚åœ¨è¿›è¡Œ Pytorch ä¸æ”¯æŒçš„æ“ä½œçš„æ—¶å€™ï¼Œ ç”šè‡³å¯ä»¥æ›²çº¿æ•‘å›½ï¼Œ å°† Tensor è½¬æ¢ä¸º Numpy ç±»å‹ï¼Œæ“ä½œåå†è½¬åŒ–ä¸º Tensor</p>
<pre><code class="hljs clean"># tensor &lt;--&gt; numpy
b = a.numpy() # tensor -&gt; numpy
a = torch.from_numpy(a) # numpy -&gt; tensor</code></pre>
<p>!!! éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ<code>torch.tensor()</code> æ€»æ˜¯ä¼šè¿›è¡Œæ•°æ®æ‹·è´ï¼Œæ–° tensor å’ŒåŸæ¥çš„æ•°æ®ä¸å†å…±äº«å†…å­˜ã€‚æ‰€ä»¥å¦‚æœä½ æƒ³å…±äº«å†…å­˜çš„è¯ï¼Œå»ºè®®ä½¿ç”¨ <code>torch.from_numpy()</code> æˆ–è€… <code>tensor.detach()</code> æ¥æ–°å»ºä¸€ä¸ª tensor, äºŒè€…å…±äº«å†…å­˜ã€‚</p>
<h3 id="11-nn"><a href="#11-nn" class="headerlink" title="11. nn"></a>11. nn</h3><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</code></pre>
<h5 id="pad-å¡«å……"><a href="#pad-å¡«å……" class="headerlink" title="pad å¡«å……"></a>pad å¡«å……</h5><pre><code class="hljs python">nn.ConstantPad2d(padding, value)</code></pre>
<h5 id="å·ç§¯å’Œåå·ç§¯"><a href="#å·ç§¯å’Œåå·ç§¯" class="headerlink" title="å·ç§¯å’Œåå·ç§¯"></a>å·ç§¯å’Œåå·ç§¯</h5><pre><code class="hljs python">nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)
nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, output_padding=<span class="hljs-number">0</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, dilation=<span class="hljs-number">1</span>)</code></pre>
<pre><code class="hljs python"><span class="hljs-comment">#ã€€æœ€å¸¸ç”¨çš„ä¸¤ç§å·ç§¯å±‚è®¾è®¡ 3x3 &amp; 1x1</span>
conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)
conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, bias=<span class="hljs-literal">True</span>)</code></pre>
<h5 id="æ± åŒ–å±‚"><a href="#æ± åŒ–å±‚" class="headerlink" title="æ± åŒ–å±‚"></a>æ± åŒ–å±‚</h5><pre><code class="hljs python">nn.MaxPool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, return_indices=<span class="hljs-literal">False</span>, ceil_mode=<span class="hljs-literal">False</span>)
nn.AvgPool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>, ceil_mode=<span class="hljs-literal">False</span>, count_include_pad=<span class="hljs-literal">True</span>)
nn.AdaptiveMaxPool2d(output_size, return_indices=<span class="hljs-literal">False</span>)
nn.AdaptiveAvgPool2d(output_size)  <span class="hljs-comment"># global avg pool: output_size=1</span>
nn.MaxUnpool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>)</code></pre>
<h5 id="å…¨è¿æ¥å±‚"><a href="#å…¨è¿æ¥å±‚" class="headerlink" title="å…¨è¿æ¥å±‚"></a>å…¨è¿æ¥å±‚</h5><pre><code class="hljs python">nn.Linear(in_features, out_features, bias=<span class="hljs-literal">True</span>)</code></pre>
<h5 id="é˜²æ­¢è¿‡æ‹Ÿåˆç›¸å…³å±‚"><a href="#é˜²æ­¢è¿‡æ‹Ÿåˆç›¸å…³å±‚" class="headerlink" title="é˜²æ­¢è¿‡æ‹Ÿåˆç›¸å…³å±‚"></a>é˜²æ­¢è¿‡æ‹Ÿåˆç›¸å…³å±‚</h5><pre><code class="hljs python">nn.Dropout2d(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)
nn.AlphaDropout(p=<span class="hljs-number">0.5</span>)
nn.BatchNorm2d(num_features, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)</code></pre>
<h5 id="æ¿€æ´»å‡½æ•°"><a href="#æ¿€æ´»å‡½æ•°" class="headerlink" title="æ¿€æ´»å‡½æ•°"></a>æ¿€æ´»å‡½æ•°</h5><pre><code class="hljs python">nn.Softplus(beta=<span class="hljs-number">1</span>, threshold=<span class="hljs-number">20</span>)
nn.Tanh()
nn.ReLU(inplace=<span class="hljs-literal">False</span>)    
nn.ReLU6(inplace=<span class="hljs-literal">False</span>)
nn.LeakyReLU(negative_slope=<span class="hljs-number">0.01</span>, inplace=<span class="hljs-literal">False</span>)
nn.PReLU(num_parameters=<span class="hljs-number">1</span>, init=<span class="hljs-number">0.25</span>)
nn.SELU(inplace=<span class="hljs-literal">False</span>)
nn.ELU(alpha=<span class="hljs-number">1.0</span>, inplace=<span class="hljs-literal">False</span>)</code></pre>
<h5 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h5><pre><code class="hljs python">nn.RNNCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>, nonlinearity=<span class="hljs-string">&#x27;tanh&#x27;</span>)
nn.RNN(*args, **kwargs)
nn.LSTMCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>)
nn.LSTM(*args, **kwargs)
nn.GRUCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>)
nn.GRU(*args, **kwargs)</code></pre>
<h5 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h5><pre><code class="hljs python">nn.Embedding(num_embeddings, embedding_dim, padding_idx=<span class="hljs-literal">None</span>, max_norm=<span class="hljs-literal">None</span>, norm_type=<span class="hljs-number">2</span>, scale_grad_by_freq=<span class="hljs-literal">False</span>, sparse=<span class="hljs-literal">False</span>, _weight=<span class="hljs-literal">None</span>)</code></pre>
<h5 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h5><pre><code class="hljs python">nn.Sequential(*args)</code></pre>
<h5 id="loss-functon"><a href="#loss-functon" class="headerlink" title="loss functon"></a>loss functon</h5><pre><code class="hljs python">nn.BCELoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.CrossEntropyLoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)
<span class="hljs-comment"># CrossEntropyLoss ç­‰ä»·äº log_softmax + NLLLoss</span>
nn.L1Loss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.KLDivLoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.MSELoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.NLLLoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)
nn.NLLLoss2d(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)
nn.SmoothL1Loss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.SoftMarginLoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.TripletMarginLoss(margin=<span class="hljs-number">1.0</span>, p=<span class="hljs-number">2</span>, eps=<span class="hljs-number">1e-06</span>, swap=<span class="hljs-literal">False</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)
nn.CosineEmbeddingLoss(margin=<span class="hljs-number">0</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)</code></pre>
<h5 id="functional-ğŸŒŸ"><a href="#functional-ğŸŒŸ" class="headerlink" title="functional    ğŸŒŸ"></a>functional    ğŸŒŸ</h5><pre><code class="hljs python">nn.functional <span class="hljs-comment"># nnä¸­çš„å¤§å¤šæ•°layerï¼Œåœ¨functionalä¸­éƒ½æœ‰ä¸€ä¸ªä¸ä¹‹ç›¸å¯¹åº”çš„å‡½æ•°ã€‚</span>
              <span class="hljs-comment"># nn.functionalä¸­çš„å‡½æ•°å’Œnn.Moduleçš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œ</span>
              <span class="hljs-comment"># ç”¨nn.Moduleå®ç°çš„layersæ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ç±»ï¼Œéƒ½æ˜¯ç”± class layer(nn.Module)å®šä¹‰ï¼Œ</span>
              <span class="hljs-comment"># ä¼šè‡ªåŠ¨æå–å¯å­¦ä¹ çš„å‚æ•°ã€‚è€Œnn.functionalä¸­çš„å‡½æ•°æ›´åƒæ˜¯çº¯å‡½æ•°ï¼Œ</span>
              <span class="hljs-comment"># ç”±def function(input)å®šä¹‰ã€‚</span></code></pre>
<h5 id="init"><a href="#init" class="headerlink" title="init"></a>init</h5><pre><code class="hljs python">torch.nn.init.uniform
torch.nn.init.normal
torch.nn.init.kaiming_uniform
torch.nn.init.kaiming_normal
torch.nn.init.xavier_normal
torch.nn.init.xavier_uniform
torch.nn.init.sparse</code></pre>
<h5 id="net"><a href="#net" class="headerlink" title="net"></a>net</h5><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">net_name</span>(<span class="hljs-params">nn.Module</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span>
        super(net_name, self).__init__()
        self.layer_name = xxxx

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span> 
        x = self.layer_name(x)        
        <span class="hljs-keyword">return</span> x

net.parameters()   <span class="hljs-comment"># è·å–å‚æ•° </span>
net.named_parameters  <span class="hljs-comment"># è·å–å‚æ•°åŠåç§°</span>
net.zero_grad()  <span class="hljs-comment"># ç½‘ç»œæ‰€æœ‰æ¢¯åº¦æ¸…é›¶, grad åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ˜¯ç´¯åŠ çš„(accumulated)ï¼Œ</span>
                 <span class="hljs-comment"># è¿™æ„å‘³ç€æ¯ä¸€æ¬¡è¿è¡Œåå‘ä¼ æ’­ï¼Œæ¢¯åº¦éƒ½ä¼šç´¯åŠ ä¹‹å‰çš„æ¢¯åº¦ï¼Œæ‰€ä»¥åå‘ä¼ æ’­ä¹‹å‰éœ€æŠŠæ¢¯åº¦æ¸…é›¶ã€‚</span></code></pre>
<h3 id="12-optim-gt-form-torch-import-optim"><a href="#12-optim-gt-form-torch-import-optim" class="headerlink" title="12. optim -&gt; form torch import optim"></a>12. optim -&gt; form torch import optim</h3><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim

optim.SGD(params, lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0</span>, dampening=<span class="hljs-number">0</span>, weight_decay=<span class="hljs-number">0</span>, nesterov=<span class="hljs-literal">False</span>)
optim.ASGD(params, lr=<span class="hljs-number">0.01</span>, lambd=<span class="hljs-number">0.0001</span>, alpha=<span class="hljs-number">0.75</span>, t0=<span class="hljs-number">1000000.0</span>, weight_decay=<span class="hljs-number">0</span>)
optim.LBFGS(params, lr=<span class="hljs-number">1</span>, max_iter=<span class="hljs-number">20</span>, max_eval=<span class="hljs-literal">None</span>, tolerance_grad=<span class="hljs-number">1e-05</span>, tolerance_change=<span class="hljs-number">1e-09</span>, history_size=<span class="hljs-number">100</span>, line_search_fn=<span class="hljs-literal">None</span>)
optim.RMSprop(params, lr=<span class="hljs-number">0.01</span>, alpha=<span class="hljs-number">0.99</span>, eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>, momentum=<span class="hljs-number">0</span>, centered=<span class="hljs-literal">False</span>)
optim.Rprop(params, lr=<span class="hljs-number">0.01</span>, etas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">1.2</span>), step_sizes=(<span class="hljs-number">1e-06</span>, <span class="hljs-number">50</span>))
optim.Adadelta(params, lr=<span class="hljs-number">1.0</span>, rho=<span class="hljs-number">0.9</span>, eps=<span class="hljs-number">1e-06</span>, weight_decay=<span class="hljs-number">0</span>)
optim.Adagrad(params, lr=<span class="hljs-number">0.01</span>, lr_decay=<span class="hljs-number">0</span>, weight_decay=<span class="hljs-number">0</span>, initial_accumulator_value=<span class="hljs-number">0</span>)
optim.Adam(params, lr=<span class="hljs-number">0.001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>, amsgrad=<span class="hljs-literal">False</span>)
optim.Adamax(params, lr=<span class="hljs-number">0.002</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>)
optim.SparseAdam(params, lr=<span class="hljs-number">0.001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>)
optim.Optimizer(params, defaults)

optimizer.zero_grad()  <span class="hljs-comment"># ç­‰ä»·äº net.zero_grad() </span>
optimizer.step()</code></pre>
<h3 id="13-learning-rate"><a href="#13-learning-rate" class="headerlink" title="13.  learning rate"></a>13.  learning rate</h3><pre><code class="hljs python"><span class="hljs-comment"># Reduce learning rate when validation accuarcy plateau.</span>
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="hljs-string">&#x27;max&#x27;</span>, patience=<span class="hljs-number">5</span>, verbose=<span class="hljs-literal">True</span>)
<span class="hljs-comment"># Cosine annealing learning rate.</span>
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class="hljs-number">80</span>)
<span class="hljs-comment"># Reduce learning rate by 10 at given epochs.</span>
scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="hljs-number">50</span>, <span class="hljs-number">70</span>], gamma=<span class="hljs-number">0.1</span>)
<span class="hljs-comment"># Learning rate warmup by 10 epochs.</span>
scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=<span class="hljs-keyword">lambda</span> t: t / <span class="hljs-number">10</span>)

<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>):
    scheduler.step()
    train(...); val(...)</code></pre>
<h3 id="14-save-and-load-model"><a href="#14-save-and-load-model" class="headerlink" title="14. save and load model"></a>14. save and load model</h3><pre><code class="hljs python">torch.save(model.state_dict(), <span class="hljs-string">&#x27;xxxx_params.pth&#x27;</span>)
model.load_state_dict(t.load(<span class="hljs-string">&#x27;xxxx_params.pth&#x27;</span>))

torch.save(model, <span class="hljs-string">&#x27;xxxx.pth&#x27;</span>)
model.torch.load(<span class="hljs-string">&#x27;xxxx.pth&#x27;</span>)

all_data = dict(
    optimizer = optimizer.state_dict(),
    model = model.state_dict(),
    info = <span class="hljs-string">u&#x27;model and optim parameter&#x27;</span>
)

t.save(all_data, <span class="hljs-string">&#x27;xxx.pth&#x27;</span>)
all_data = t.load(<span class="hljs-string">&#x27;xxx.pth&#x27;</span>)
all_data.keys()</code></pre>
<h3 id="15-torchvision"><a href="#15-torchvision" class="headerlink" title="15. torchvision"></a>15. torchvision</h3><h5 id="models"><a href="#models" class="headerlink" title="models"></a>models</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models
resnet34 = models.resnet34(pretrained=<span class="hljs-literal">True</span>, num_classes=<span class="hljs-number">1000</span>)</code></pre>
<h5 id="data-augmentation"><a href="#data-augmentation" class="headerlink" title="data augmentation"></a>data augmentation</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms

<span class="hljs-comment"># transforms.CenterCrop           transforms.Grayscale           transforms.ColorJitter          </span>
<span class="hljs-comment"># transforms.Lambda               transforms.Compose             transforms.LinearTransformation </span>
<span class="hljs-comment"># transforms.FiveCrop             transforms.Normalize           transforms.functional           </span>
<span class="hljs-comment"># transforms.Pad                  transforms.RandomAffine        transforms.RandomHorizontalFlip  </span>
<span class="hljs-comment"># transforms.RandomApply          transforms.RandomOrder         transforms.RandomChoice         </span>
<span class="hljs-comment"># transforms.RandomResizedCrop    transforms.RandomCrop          transforms.RandomRotation        </span>
<span class="hljs-comment"># transforms.RandomGrayscale      transforms.RandomSizedCrop     transforms.RandomVerticalFlip   </span>
<span class="hljs-comment"># transforms.ToTensor             transforms.Resize              transforms.transforms                                           </span>
<span class="hljs-comment"># transforms.TenCrop              transforms.Scale               transforms.ToPILImage</span></code></pre>
<h5 id="è‡ªå®šä¹‰-dataset"><a href="#è‡ªå®šä¹‰-dataset" class="headerlink" title="è‡ªå®šä¹‰ dataset"></a>è‡ªå®šä¹‰ dataset</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">my_data</span>(<span class="hljs-params">Dataset</span>):</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, image_path, annotation_path, transform=None</span>):</span>
        <span class="hljs-comment"># åˆå§‹åŒ–ï¼Œ è¯»å–æ•°æ®é›†  ğŸŒŸ</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span>  
        <span class="hljs-comment"># è·å–æ•°æ®é›†çš„æ€»å¤§å°  ğŸŒŸ</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, id</span>):</span>  ğŸŒŸ
        <span class="hljs-comment"># å¯¹äºåˆ¶å®šçš„ id, è¯»å–è¯¥æ•°æ®å¹¶è¿”å›    </span></code></pre>
<p><strong>datasets</strong></p>
<pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, Dataloader
<span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms

transform = transforms.Compose([
        transforms.ToTensor(), <span class="hljs-comment"># convert to Tensor</span>
        transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]) <span class="hljs-comment"># normalization</span>

dataset = ImageFolder(root, transform=transform, target_transform=<span class="hljs-literal">None</span>, loader=default_loader)
dataloader = DataLoader(dataset, <span class="hljs-number">2</span>, collate_fn=my_collate_fn, num_workers=<span class="hljs-number">1</span>,shuffle=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">for</span> batch_datas, batch_labels <span class="hljs-keyword">in</span> dataloader:
    ...</code></pre>
<h5 id="img-process"><a href="#img-process" class="headerlink" title="img process"></a>img process</h5><pre><code class="hljs python">img = make_grid(next(dataiter)[<span class="hljs-number">0</span>], <span class="hljs-number">4</span>) 
save_image(img, <span class="hljs-string">&#x27;a.png&#x27;</span>)</code></pre>
<h5 id="data-Visualization"><a href="#data-Visualization" class="headerlink" title="data Visualization"></a>data Visualization</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToPILImage

show = ToPILImage()  <span class="hljs-comment"># å¯ä»¥æŠŠTensorè½¬æˆImageï¼Œæ–¹ä¾¿å¯è§†åŒ–</span>

(data, label) = trainset[<span class="hljs-number">100</span>]
show((data + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>).resize((<span class="hljs-number">100</span>, <span class="hljs-number">100</span>))  <span class="hljs-comment"># åº”è¯¥ä¼šè‡ªåŠ¨ä¹˜ä»¥ 255 çš„</span></code></pre>
<h3 id="16-Code-Samples"><a href="#16-Code-Samples" class="headerlink" title="16. Code Samples"></a>16. Code Samples</h3><pre><code class="hljs python"><span class="hljs-comment"># torch.device object used throughout this script</span>
device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> use_cuda <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)

model = MyRNN().to(device)

<span class="hljs-comment"># train</span>
total_loss = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> input, target <span class="hljs-keyword">in</span> train_loader:
    input, target = input.to(device), target.to(device)
    hidden = input.new_zeros(*h_shape)  <span class="hljs-comment"># has the same device &amp; dtype as `input`</span>
    ...  <span class="hljs-comment"># get loss and optimize</span>
    total_loss += loss.item()           <span class="hljs-comment"># get Python number from 1-element Tensor</span>

<span class="hljs-comment"># evaluate</span>
<span class="hljs-keyword">with</span> torch.no_grad():                   <span class="hljs-comment"># operations inside don&#x27;t track history</span>
    <span class="hljs-keyword">for</span> input, target <span class="hljs-keyword">in</span> test_loader:
        ...</code></pre>
<h3 id="17-jit-amp-torchscript"><a href="#17-jit-amp-torchscript" class="headerlink" title="17. jit &amp; torchscript"></a>17. jit &amp; torchscript</h3><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.jit <span class="hljs-keyword">import</span> script, trace
torch.jit.trace(model, torch.rand(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">224</span>,<span class="hljs-number">224</span>)) ã€€<span class="hljs-comment"># export model</span>
<span class="hljs-meta">@torch.jit.script</span></code></pre>
<pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;torch/torch.h&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;torch/script.h&gt;</span></span>

<span class="hljs-meta"># img blob -&gt; img tensor</span>
torch::Tensor img_tensor = torch::from_blob(image.data, &#123;<span class="hljs-number">1</span>, image.rows, image.cols, <span class="hljs-number">3</span>&#125;, torch::kByte);
img_tensor = img_tensor.permute(&#123;<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;);
img_tensor = img_tensor.toType(torch::kFloat);
img_tensor = img_tensor.div(<span class="hljs-number">255</span>);
<span class="hljs-meta"># load model</span>
<span class="hljs-built_in">std</span>::<span class="hljs-built_in">shared_ptr</span>&lt;torch::jit::script::Module&gt; <span class="hljs-keyword">module</span> = torch::jit::load(<span class="hljs-string">&quot;resnet.pt&quot;</span>);
<span class="hljs-meta"># forward</span>
torch::Tensor output = <span class="hljs-keyword">module</span>-&gt;forward(&#123;img_tensor&#125;).toTensor();</code></pre>
<h3 id="18-onnx"><a href="#18-onnx" class="headerlink" title="18. onnx"></a>18. onnx</h3><pre><code class="hljs python">torch.onnx.export(model, dummy data, xxxx.proto) <span class="hljs-comment"># exports an ONNX formatted</span>

model = onnx.load(<span class="hljs-string">&quot;alexnet.proto&quot;</span>)               <span class="hljs-comment"># load an ONNX model</span>
onnx.checker.check_model(model)                  <span class="hljs-comment"># check that the model</span>

onnx.helper.printable_graph(model.graph)         <span class="hljs-comment"># print a human readableã€€representation of the graph</span></code></pre>
<h3 id="19-Distributed-Training"><a href="#19-Distributed-Training" class="headerlink" title="19. Distributed Training"></a>19. Distributed Training</h3><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist          <span class="hljs-comment"># distributed communication</span>
<span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process       <span class="hljs-comment"># memory sharing processes</span></code></pre>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AF%AD%E8%A8%80%E5%92%8C%E5%BA%93/">è¯­è¨€å’Œåº“</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/pytorch/">pytorch</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 åè®®</a> ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/03/10/model-evaluation/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">model_evaluation</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2019/03/08/The-next-step-of-machine-learning/">
                        <span class="hidden-mobile">The next step of machine learning</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "pytorch API&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
