

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhichao zhao">
  <meta name="keywords" content="">
  <title>pytorch分布式训练 - 假欢畅 又何妨 无人共享</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>假欢畅，又何妨，无人共享</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2019-05-17 00:08" pubdate>
        May 17, 2019 am
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      19
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">pytorch分布式训练</h1>
            
            <div class="markdown-body" id="post-body">
              <p>pytorch 分布式解决方案尝试: </p>
<ul>
<li>nn.Dataparallel 简单解决方案：适合于单节点多 GPU 并行</li>
<li>nn.parallel.DistributedDataParallel 并行 +  torch.utils.data.distributed.DistributedSampler 数据 + torch.distributed 配置</li>
<li>horovod： Uber 开源外部解决方案</li>
</ul>
<a id="more"></a>
<p>典型的两种方式： Map-reduce 和 Ring all reduce</p>
<p>几种通信方式：</p>
<h4 id="方式一-nn-DataParallel"><a href="#方式一-nn-DataParallel" class="headerlink" title="方式一: nn.DataParallel"></a>方式一: nn.DataParallel</h4><p>​    nn.DataParallel 为单进程，多线程。使用起来比较简单，相应的效率也较低， 适用于<strong>单节点多 GPU</strong> 的情况。nn.DataParallel 会将模型复制到不同的 GPU 上。 对于每个训练批次 batch， 会将其切分到不同的 GPU 上进行正向传播并将梯度汇总（默认是第一个 GPU）。其函数原型为：</p>
<pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">torch</span>.<span class="hljs-title">nn</span>.<span class="hljs-title">DataParallel</span>(<span class="hljs-params">module, device_ids=None, output_device=None, dim=<span class="hljs-number">0</span></span>)</span>
<span class="hljs-class"># <span class="hljs-title">device_ids</span>:</span> 指定参与训练的 GPU
<span class="hljs-comment">#  output_device: 用于梯度汇总的 GPU</span></code></pre>
<p>注意点：</p>
<p>（1）效率低下的原因：在每个训练批次（batch）中，会将梯度汇总然后分发到每个 GPU 上，所以网络通信就成为了一个瓶颈，并且会带来显存利用不平衡的问题。</p>
<p>（2）使用 nn.DataParallel 会在原有的模型外边包装一个 module， 加载模型的时候需要进行适当的拆包。</p>
<p>（2） 当没有指定 device_ids 的时候，程序会自动找到这个机器上面可以用的所有的显卡, 然后用于训练。可以通过：</p>
<p><code>os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;]</code> 事先指定可用 GPU， 防止 GPU 冲突。</p>
<h4 id="方式二：torch-nn-parallel-DistributedDataParallel"><a href="#方式二：torch-nn-parallel-DistributedDataParallel" class="headerlink" title="方式二：torch.nn.parallel.DistributedDataParallel"></a>方式二：torch.nn.parallel.DistributedDataParallel</h4><p>torch.nn.parallel.DistributedDataParallel 是 pytorch 推荐的并行方案。它支持多机多卡训练，显存分配更加均衡，且效率较高。</p>
<h5 id="Step1：-环境配置"><a href="#Step1：-环境配置" class="headerlink" title="Step1： 环境配置"></a>Step1： 环境配置</h5><p>确定网络的接口， 通常会自己寻找网络接口，当没有自己寻找到的时候，需要手动进行配置: </p>
<pre><code class="hljs python"><span class="hljs-keyword">import</span> os
os.environ[<span class="hljs-string">&#x27;NCCL_SOCKET_IFNAME&#x27;</span>] = <span class="hljs-string">&#x27;enp2s0&#x27;</span>   <span class="hljs-comment"># for NCCL</span>
os.environ[<span class="hljs-string">&#x27;GLOO_SOCKET_IFNAME&#x27;</span>] = <span class="hljs-string">&#x27;enp2s0&#x27;</span>   <span class="hljs-comment"># for GLOO</span></code></pre>
<h5 id="step2-确定相关配置"><a href="#step2-确定相关配置" class="headerlink" title="step2: 确定相关配置"></a>step2: 确定相关配置</h5><ul>
<li><p><strong>后端</strong>：  后端支持 gloo、nccl 和 mpi 三种方式。在使用 CPU 进行分布式训练的时候，优先选择 gloo， 在使用 GPU 进行分布式训练的时候， 优先选择 nccl。</p>
<p>   <strong>NCCL</strong>：NCCL 的全称为  NVIDIA Collective Communications Library ，是一个可以实现多个 GPU 、多个结点间聚合通信的库，在  PCIe、Nvlink、InfiniBand 上可以实现较高的通信速度。NCCL 对 GPU 均有较好支持，且  torch.distributed 对其也提供了原生支持。</p>
<p>MPI</p>
<p>​    <strong>MPI</strong>：即消息传递接口 (Message Passing Interface)，是一个来自于高性能计算领域的标准的工具。它支持点对点通信以及集体通信，并且是 torch.distributed 的 API 的灵感来源。MPI 后端的优势在于，在大型计算机集群上，MPI 应用广泛，且高度优化。 但是，torch.distributed 对 MPI 并不提供原生支持。因此，要使用 MPI，必须从源码编译 Pytorch。是否支持 GPU，视安装的 MPI 版本而定。</p>
<p>​    <strong>Gloo</strong>：Gloo后端支持 CPU 和 GPU，其支持集体通信（collective Communication），并对其进行了优化。torch.distributed 对 gloo 提供原生支持，无需进行额外操作。</p>
</li>
<li><p><strong>init_method: </strong> 初始化 <code>init_method</code> 的方法有两种，一种是使用 TCP 进行初始化，另外一种是使用 共享文件系统 进行初始化。并不推荐使用共享文件系统进行初始化。 TCP 初始化的格式为：<code>tcp://ip:端口号</code></p>
</li>
<li><p><strong>rank</strong> 和  <strong>world_size</strong></p>
<p>你需要确保, 不同机器的 <code>rank</code> 值不同， 并且需要注意： 主机的<code>rank</code>必须为0，而且使用 <code>init_method</code>的 ip 一定是 <code>rank</code>为 0 的主机，<code>world_size</code> 是你的主机数量,  不能随便设置这个数值, 当参与训练的主机数量达到 <code>world_size</code> 的设置值时, 代码才会执行的.</p>
</li>
</ul>
<pre><code class="hljs python">parser = argparse.ArgumentParser()
parser.add_argument(<span class="hljs-string">&#x27;-bk&#x27;</span>,
                    <span class="hljs-string">&#x27;--backend&#x27;</span>, type=str, default=<span class="hljs-string">&#x27;nccl&#x27;</span>, help=<span class="hljs-string">&#x27;Name of the backend to use.&#x27;</span>)
parser.add_argument(<span class="hljs-string">&#x27;-im&#x27;</span>,
                    <span class="hljs-string">&#x27;--init-method&#x27;</span>,
                    type=str,
                    default=<span class="hljs-string">&#x27;env://&#x27;</span>,
                    help=<span class="hljs-string">&#x27;URL specifying how to initialize the package.&#x27;</span>)
parser.add_argument(<span class="hljs-string">&#x27;-ws&#x27;</span>, <span class="hljs-string">&#x27;--world-size&#x27;</span>, type=int, default=<span class="hljs-number">1</span>, help=<span class="hljs-string">&#x27;Number of processes participating in the job.&#x27;</span>)
parser.add_argument(<span class="hljs-string">&#x27;-r&#x27;</span>, <span class="hljs-string">&#x27;--rank&#x27;</span>, type=int, default=<span class="hljs-number">0</span>, help=<span class="hljs-string">&#x27;Rank of the current process.&#x27;</span>)
args = parser.parse_args()

distributed.init_process_group(
    backend=args.backend,
    init_method=args.init_method,
    world_size=args.world_size,
    rank=args.rank,
)</code></pre>
<h5 id="step-3-加载数据，进行训练"><a href="#step-3-加载数据，进行训练" class="headerlink" title="step 3: 加载数据，进行训练"></a>step 3: 加载数据，进行训练</h5><pre><code class="hljs python">train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)

model = nn.parallel.DistributedDataParallel(model)

<span class="hljs-comment"># ...</span></code></pre>
<h5 id="step4-在命令行执行如下命令"><a href="#step4-在命令行执行如下命令" class="headerlink" title="step4: 在命令行执行如下命令:"></a>step4: 在命令行执行如下命令:</h5><p>机器1：</p>
<pre><code class="hljs shell">python3 -m torch.distributed.launch torch_ddp.py  -bk nccl -im tcp://10.10.10.1:12345 -rn 0 -ws 2</code></pre>
<p>机器2：</p>
<pre><code class="hljs shell">python3 -m torch.distributed.launch torch_ddp.py  -bk nccl -im tcp://10.10.10.1:12345 -rn 1 -ws 2</code></pre>
<h4 id="方式三-Horovod"><a href="#方式三-Horovod" class="headerlink" title="方式三: Horovod"></a>方式三: Horovod</h4><p>Horovod 是 Uber 开源的跨平台的分布式训练工具，名字来自于俄国传统民间舞蹈，舞者手牵手围成一个圈跳舞，与 Horovod 设备之间的通信模式很像，有以下几个特点：</p>
<ol>
<li>兼容 TensorFlow、Keras 和 PyTorch 机器学习框架。</li>
<li>使用 Ring-AllReduce 算法，对比 Parameter Server 算法，有着无需等待，负载均衡的优点。</li>
<li>实现简单，容易上手。（划重点）</li>
</ol>
<h5 id="step1-简单设置"><a href="#step1-简单设置" class="headerlink" title="step1:  简单设置"></a>step1:  简单设置</h5><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> horovod.torch <span class="hljs-keyword">as</span> hvd

<span class="hljs-comment"># init horovod</span>
hvd.init()
<span class="hljs-comment"># 给当前进程分配对应的 gpu，local_rank() 返回的是当前是第几个进程</span>
torch.cuda.set_device(hvd.local_rank())</code></pre>
<h5 id="step2-datasets、model、optimizer"><a href="#step2-datasets、model、optimizer" class="headerlink" title="step2: datasets、model、optimizer"></a>step2: datasets、model、optimizer</h5><pre><code class="hljs python"><span class="hljs-comment"># dataset ...</span>
train_dataset = ...
train_sampler = torch.utils.data.distributed.DistributedSampler(
    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)

<span class="hljs-comment"># model ...</span>
model = ...
model.cuda()

<span class="hljs-comment"># optimizer ...</span>
optimizer = optim.SGD(model.parameters())
optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())</code></pre>
<h5 id="step3-训练"><a href="#step3-训练" class="headerlink" title="step3: 训练"></a>step3: 训练</h5><pre><code class="hljs python"><span class="hljs-comment"># 初始化的时候广播参数，这个是为了在一开始的时候同步各个 gpu 之间的参数</span>
hvd.broadcast_parameters(model.state_dict(), root_rank=<span class="hljs-number">0</span>)

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):
   <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> enumerate(train_loader):
       optimizer.zero_grad()
       output = model(data)
       loss = F.nll_loss(output, target)
       loss.backward()
       optimizer.step()
       <span class="hljs-keyword">if</span> batch_idx % args.log_interval == <span class="hljs-number">0</span>:
           print(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125;]\tLoss: &#123;&#125;&#x27;</span>.format(
               epoch, batch_idx * len(data), len(train_sampler), loss.item()))</code></pre>
<h4 id="方式四：-混合精度-apex-搭配分布式"><a href="#方式四：-混合精度-apex-搭配分布式" class="headerlink" title="方式四： 混合精度 apex 搭配分布式"></a>方式四： 混合精度 apex 搭配分布式</h4><p>这样可以取得比较低的显存占比，同时训练时间也大幅缩减。</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AF%AD%E8%A8%80%E5%92%8C%E5%BA%93/">语言和库</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2019/05/17/pytorch%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">pytorch深入理解</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2019/05/17/pytorch%E5%8A%A0%E9%80%9F/">
                        <span class="hidden-mobile">pytorch加速</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "pytorch分布式训练&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
