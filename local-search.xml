<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>knowledge-distillation</title>
    <link href="/2021/01/13/knowledge-distillation/"/>
    <url>/2021/01/13/knowledge-distillation/</url>
    
    <content type="html"><![CDATA[<h2 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h2><h4 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1. 基本思想"></a>1. 基本思想</h4><p>​        知识蒸馏通过采用预先训练好的教师模型( teacher model) 的输出作为监督信号去训练另外一个轻量化的网络( student model ) 。从而实现将复杂网络(老师模型)的知识迁移到小网络(学生模型) 中， 提高小网络的精度。</p><p>​        知识蒸馏首先由 Hinton 在 Distilling the Knowledge in a Neural Network 提出，使用 teacher 模型去指导一个参数量和运算量更少的 student 模型。student 模型的训练有两个目标：一个是 student 模型输出的类别概率和 label 的交叉熵，另一个是 student 模型输出的类别概率和 teacher 模型输出的类别概率的交叉熵，记为 soft target，这两个 loss 加权后得到最终的训练 loss，共同指导 student 模型的训练。 实际操作的时候，会将原来的 softmax 除以 T， 变为:</p><script type="math/tex; mode=display">y_i = \frac{exp(x_i / T)}{\sum_j{exp(x_j/T)}}</script><p><img src="/2021/01/13/knowledge-distillation/5.png" alt="img" style="zoom:30%;"></p><h4 id="2-优缺点"><a href="#2-优缺点" class="headerlink" title="2. 优缺点"></a>2. 优缺点</h4><h5 id="2-1-优点"><a href="#2-1-优点" class="headerlink" title="2.1 优点"></a>2.1 优点</h5><ul><li>知识蒸馏不局限于特定的网络， 可以实现任何网络的蒸馏。 </li></ul><h5 id="2-2-缺点"><a href="#2-2-缺点" class="headerlink" title="2.2 缺点"></a>2.2 缺点</h5><ul><li><p>知识蒸馏的过程也是训练的过程， 同样需要足够多的数据并耗费大量的时间</p></li><li><p>需要精心设计学生网络。</p></li></ul><h5 id="2-3-相关改进"><a href="#2-3-相关改进" class="headerlink" title="2.3 相关改进"></a>2.3 相关改进</h5><ul><li><p>使用 GAN 来生成相应的数据</p><p>Data-free Learning of Student Networks</p><p>Data-Free Adversarial Distillation</p></li><li><p>利用反向传播来更新数据</p><p>Data-Free knowledge distillation for Deep Neural Networks</p><p>Dreaming to Distill: Data-free Knowledge Transfer via DeepInversion</p></li><li><p>让教师模型和学生模型的FSP矩阵（特征的内积）尽量一致，降低了蒸馏的难度</p><p>A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning</p></li><li><p>使用深层模型来指导浅层模型的学习，可以实现学生模型和教师模型的联合训练</p><p>Be Your Own Teacher: Improve the Performance of Convolutional Neural Networks via Self Distillation</p><p>FastBERT: a Self-distilling BERT with Adaptive Inference Time</p></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>TensorRT</title>
    <link href="/2021/01/12/TensorRT/"/>
    <url>/2021/01/12/TensorRT/</url>
    
    <content type="html"><![CDATA[<h3 id="1-TensorRT-简介"><a href="#1-TensorRT-简介" class="headerlink" title="1. TensorRT 简介"></a>1. TensorRT 简介</h3><p>TensorRT 是一个前向推理框架。在推理过程中，基于TensorRT 的应用程序的执行速度可以比 CPU 平台速度快 40 倍。</p><ul><li>不同的硬件需要匹配不同的 cuda库，然后还需要进行测试， 比如选核等操作</li><li>TensorRT 以  NVIDIA 的并行编程模型 CUDA 为基础构建而成。</li><li>TensorRT 针对多种深度学习推理应用的生产部署提供 INT8 和 FP 16 优化</li></ul><p>TensorRT 框架支持大多数的 DeepLearning 框架</p><p><img src="/2021/01/12/TensorRT/1.png" style="zoom:35%;"></p><p>TensorRT 核心优化方法</p><p><img src="/2021/01/12/TensorRT/2.png" style="zoom:50%;"></p><h3 id="2-TensorRT-OSS"><a href="#2-TensorRT-OSS" class="headerlink" title="2. TensorRT OSS"></a>2. TensorRT OSS</h3><h5 id="1-TensorRT-OSS"><a href="#1-TensorRT-OSS" class="headerlink" title="(1) TensorRT OSS"></a>(1) TensorRT OSS</h5><p>TensorRT 分为开源和闭源两部分</p><p>开源部分：<a href="https://github.com/NVIDIA/TensorRT">https://github.com/NVIDIA/TensorRT</a></p><p>​        NVIDIA TensorRT 的开源软件(OSS) 组件：其中包括 TensorRT 插件和解析器(caffe 和 ONNX) 的资源， 以及演示 TensorRT 平台用法和功能的示例应用程序。 这些开源软件组件是 TensorRT General Availibility(GA) 发行版的子集， 具有一些扩展和错误修复。</p><p>闭源版本： 量化、推理计算、kernel 查找等</p><h5 id="2-安装流程"><a href="#2-安装流程" class="headerlink" title="(2) 安装流程"></a>(2) 安装流程</h5><p>git 获取完成的 OSS 项目包</p><pre><code class="hljs shell">git clone -b https://github/nvidia/TensorRT TensorRTcd TensorRTgit submodule update --init --recursive # 安装一些子模块: 比如 cub、protobuf、onnx、pybind11 等export TRT_SOURCE=&#x27;pwd&#x27;</code></pre><p>安装 GA 包</p><pre><code class="hljs shell">cd ~/Downloadstar -xvzf TensorRT-7.2.1.6.CentOS-7.6.x86_64-gnu.cuda-11.0.cudnn8.0.tar.gzexport TRT_RELEASE=`pwd`/TensorRT-7.2.1.6</code></pre><p>OSS 项目编译</p><pre><code class="hljs shell">cd $TRT_SOURCEmkdir -p build &amp;&amp; cd buildcmake .. -DTRT_LIB_DIR=$TRT_RELEASE/lib -DTRT_OUT_DIR=`pwd`/out # 会将 OSS 版本覆盖原有版本<span class="hljs-meta">#</span><span class="bash"> 输出二进制库 lib 和 可执行文件(示例代码)</span>make -j$(nproc)</code></pre><h5 id="3-TensorRT-OSS-目录"><a href="#3-TensorRT-OSS-目录" class="headerlink" title="(3) TensorRT OSS 目录"></a>(3) TensorRT OSS 目录</h5><ul><li>parser</li><li>plugin</li><li>examples</li></ul><h3 id="3-TensorRT-开发"><a href="#3-TensorRT-开发" class="headerlink" title="3. TensorRT 开发"></a>3. TensorRT 开发</h3><h5 id="（1）pytorch-gt-onnx"><a href="#（1）pytorch-gt-onnx" class="headerlink" title="（1）pytorch -&gt; onnx"></a>（1）pytorch -&gt; onnx</h5><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<span class="hljs-keyword">import</span> torch.onnx <span class="hljs-keyword">as</span> torch_onnx<span class="hljs-keyword">import</span> onnx<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span>    input_shape = (<span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>)    model_onnx_path = <span class="hljs-string">&#x27;unet.onnx&#x27;</span>    dummy_input = Variable(torch.randn(<span class="hljs-number">1</span>, *input_shape))    model = torch.hub.load(<span class="hljs-string">&#x27;mateuszbuda/brain-segmentation-pytorch&#x27;</span>, <span class="hljs-string">&#x27;unet&#x27;</span>, in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">1</span>, init_features=<span class="hljs-number">32</span>, pretrained=<span class="hljs-literal">True</span>)        model.train(<span class="hljs-literal">False</span>)    inputs = [<span class="hljs-string">&quot;input.1&quot;</span>]    outputs = [<span class="hljs-string">&quot;186&quot;</span>]    dynamic_axes = &#123;<span class="hljs-string">&#x27;input.1&#x27;</span>:&#123;<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>&#125;, <span class="hljs-string">&#x27;186&#x27;</span>:&#123;<span class="hljs-number">0</span>, <span class="hljs-string">&#x27;batch&#x27;</span>&#125;&#125;    out = torch.onnx.export(model, dummy_input, model_onnx_path,                             input_names=inputs, output_names=outputs, dynamic_axes=dynamic_axes)</code></pre><h5 id="（2）计算图优化：onnx-优化"><a href="#（2）计算图优化：onnx-优化" class="headerlink" title="（2）计算图优化：onnx 优化"></a>（2）计算图优化：onnx 优化</h5><p><strong>常见的处理：</strong></p><ul><li><p>reshape 的时候的很多冗余算子的问题</p></li><li><p>输入的归一化：去掉，放在代码逻辑里面</p></li><li>conv_bn 的合并</li><li>一些无法 boardcast 的问题</li><li>新层的注册</li></ul><p><strong>两个工具：</strong></p><ul><li><p>可视化图:  Netron</p></li><li><p>onnx-simplify</p></li></ul><p><strong>onnx 模型快速验证：</strong></p><ul><li><p>TensorRT OSS 完成编译之后会生成 trtexec</p></li><li><p>通过 trtexec 直接加载 onnx， 验证导出模型是否被 TensorRT 支持</p></li><li><p>根据支持情况，指定算子实现方案</p><ul><li>直接基于算子 op 进行开发， 涉及多个 kernel 启动，性能可能相对较差</li><li>使用 plugin 进行开发</li></ul></li></ul><h5 id="（3）-自定义组件-TensorRT-Plugin"><a href="#（3）-自定义组件-TensorRT-Plugin" class="headerlink" title="（3） 自定义组件 TensorRT Plugin"></a>（3） 自定义组件 TensorRT Plugin</h5><p>官方文档： <a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending">https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#extending</a></p><p>TensorRT 的 Plugin 开发详解<br>① 观察网络结构， 确认算子的版本、名称、输入、输出、参数及相应权重<br>② 开发算子的解析模块 parser<br>③ 继承 PluginV2Ext, 完成 kernel 以及相应 API 的开发<br>④ 实现 Creator 相关的操作</p><ul><li>自定义添加是通过扩展 IPluginV2Ext 和 IPluginCreator 实现的</li><li>IPluginV2Ext: IPluginV2 的升级版本， 实现自定义插件的基类， 包含版本化和其他格式和单精度的处理</li><li>IPluginCreator： 自定义层的创建类， 可以通过它获取插件的名称、版本信息、参数等， 也提供网络创建阶段创建插件的方法， 并在推理阶段反序列化它。</li></ul><h3 id="4-TensorRT-Plugin-开发"><a href="#4-TensorRT-Plugin-开发" class="headerlink" title="4. TensorRT Plugin 开发"></a>4. TensorRT Plugin 开发</h3><p>自定义组件 TensorRT Plugin 的整体流程如下所示:</p><ol><li>实现 Plugin 类和 PluginCreator 类</li><li>在  InferPlugin.cpp 中注册新 creator</li><li>修改 CMakeLists.txt 并编译 nvinfer_plugin 库</li><li>在 onnx-tensorrt 中注册新的 Plugin：在 onnx 中添加 parser</li><li>编译 nvonnxparse 库</li><li>替换 nvinfer_plugin 和 nvonnxparser 库，使用 trtexec 将 onnx 转换为 tensorrt 模型</li></ol><p>下面对每一个步骤进行详细的讲解：</p><h5 id="Step1-实现-Plugin-类-和-PluginCreator-类"><a href="#Step1-实现-Plugin-类-和-PluginCreator-类" class="headerlink" title="Step1 实现 Plugin 类 和 PluginCreator 类"></a>Step1 实现 Plugin 类 和 PluginCreator 类</h5><p>该步骤可以参考一下 TensorRT 官方 plugin 库： <a href="https://github.com/NVIDIA/TensorRT/tree/master/plugin。官方提供了较多的">https://github.com/NVIDIA/TensorRT/tree/master/plugin。官方提供了较多的</a> plugin 插件， 我们可以看到其源码，然后通过模仿源码来学习 plugin 的编写。 这里我们以 nmsPlugin 来看一下自定义的插件如何编写:</p><pre><code class="hljs shell">.├── CMakeLists.txt├── README.md├── nmsPlugin.cpp  └── nmsPlugin.h0 directories, 4 files</code></pre><p>这里的 nmsPlugin 主要实现 <code>DetectionOutput</code> 和 <code>NMSPluginCreator</code> 两个类， 前者用于插件的具体实现，后者用于根据需求创建该插件。</p><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">DetectionOutput</span> : <span class="hljs-symbol">public</span> <span class="hljs-symbol">IPluginV2Ext</span><span class="hljs-symbol">class</span> <span class="hljs-symbol">NMSPluginCreator</span> : <span class="hljs-symbol">public</span> <span class="hljs-symbol">BaseCreator</span></code></pre><p><code>DetectionOutput</code> 类继承自 <code>IPluginV2Ext</code>。在阅读其他的插件注册的时候会发现继承自其他类的情况。其实随着 TensorRT 的不断发展，插件接口也在不断地变化，由 v5 版本的<code>IPluginV2Ext</code>，到 v6 版本的 <code>IPluginV2IOExt</code> 和 <code>IPluginV2DynamicExt</code>。 官方的建议是继承自  <code>IPluginV2IOExt</code> 和  <code>IPluginV2DynamicExt</code>。 其实两者在类的编写上类似， 只是其中后者支持动态大小。我们的类需要继承自特定的类，并实现其中的虚函数。</p><p>Plugin 类的相关实现函数， 为了方便阅读，我将其分为五类， 分别是准备工作或者结束工作、具体实现和功能函数、序列化问题、插件的基本设置和返回值信息。</p><p>（1）准备工作或者结束工作</p><p><strong>构造函数:</strong> 需要提供三种初始化方式， 分别是通过参数的方式构造函数， 通过 clone 的方式构造函数， 通过序列化的方式构造函数   🌟🌟</p><pre><code class="hljs cpp"><span class="hljs-comment">// Parameterized constructor</span>DetectionOutput::DetectionOutput(DetectionOutputParameters params) : param(params)&#123;&#125;<span class="hljs-comment">// clone Constrcutor</span>DetectionOutput::DetectionOutput(DetectionOutputParameters params, <span class="hljs-keyword">int</span> C1, <span class="hljs-keyword">int</span> C2, <span class="hljs-keyword">int</span> numPriors)    : param(params), C1(C1), C2(C2), numPriors(numPriors)&#123;&#125;<span class="hljs-comment">// constructor</span>DetectionOutput::DetectionOutput(<span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* data, <span class="hljs-keyword">size_t</span> length)&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span> *d = <span class="hljs-keyword">reinterpret_cast</span>&lt;<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>*&gt;(data), *a = d;    param = read&lt;DetectionOutputParameters&gt;(d);    <span class="hljs-comment">// Channel size of the locData tensor</span>    <span class="hljs-comment">// numPriors * numLocClasses * 4</span>    C1 = read&lt;<span class="hljs-keyword">int</span>&gt;(d);    <span class="hljs-comment">// Channel size of the confData tensor</span>    <span class="hljs-comment">// numPriors * param.numClasses</span>    C2 = read&lt;<span class="hljs-keyword">int</span>&gt;(d);    <span class="hljs-comment">// Number of bounding boxes per sample</span>    numPriors = read&lt;<span class="hljs-keyword">int</span>&gt;(d);    ASSERT(d == a + length);&#125;</code></pre><ul><li>初始化函数 <code>initialize</code> 和 结束函数  <code>terminate</code>   结束函数。 一般没有什么具体的实现， 返回状态，或者打印 log 而已。</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// 在这个插件准备开始 run 之前执行， 做一些初始化工作</span><span class="hljs-comment">// 初始化一些提前开辟空间的参数，一般是 cuda 操作需要的参数</span><span class="hljs-comment">// (例如conv操作需要执行卷积操作，我们就需要提前开辟 weight 和 bias 的显存)，</span><span class="hljs-comment">// 假如我们的算子需要这些参数，则在这里需要提前开辟显存</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">DetectionOutput::initialize</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> STATUS_SUCCESS;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::terminate</span><span class="hljs-params">()</span> </span>&#123;    gLogVerbose &lt;&lt; <span class="hljs-string">&quot;NMSPluginDynamic terminate\n&quot;</span>;&#125;</code></pre><ul><li><code>clone</code>：将这个 plugin 对象克隆一份 TensorRT 的 builder、network 或者 engine   🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Cloning the plugin</span><span class="hljs-function">IPluginV2Ext* <span class="hljs-title">DetectionOutput::clone</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// Create a new instance</span>    IPluginV2Ext* plugin = <span class="hljs-keyword">new</span> DetectionOutput(param, C1, C2, numPriors);    <span class="hljs-comment">// Set the namespace</span>    plugin-&gt;setPluginNamespace(mPluginNamespace.c_str());    <span class="hljs-keyword">return</span> plugin;&#125;</code></pre><ul><li><code>destroy</code>: 一些善后清理工作 </li></ul><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::destroy</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">delete</span> <span class="hljs-keyword">this</span>;&#125;</code></pre><p>(2) 具体实现和功能函数</p><ul><li><code>enqueue</code>： 插件 op 的执行函数 。 其中 enqueue API 实现将具体化的 kernel 调用过程加入执行队列所在流的功能，和具体的 cuda kernel 实现相关联。 🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Plugin layer implementation</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">DetectionOutput::enqueue</span><span class="hljs-params">(</span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">int</span> batchSize, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* <span class="hljs-keyword">const</span>* inputs, <span class="hljs-keyword">void</span>** outputs, <span class="hljs-keyword">void</span>* workspace, cudaStream_t stream)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// Input order &#123;loc, conf, prior&#125;</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* <span class="hljs-keyword">const</span> locData = inputs[param.inputOrder[<span class="hljs-number">0</span>]];    <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* <span class="hljs-keyword">const</span> confData = inputs[param.inputOrder[<span class="hljs-number">1</span>]];    <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* <span class="hljs-keyword">const</span> priorData = inputs[param.inputOrder[<span class="hljs-number">2</span>]];    <span class="hljs-comment">// Output from plugin index 0: topDetections index 1: keepCount</span>    <span class="hljs-keyword">void</span>* topDetections = outputs[<span class="hljs-number">0</span>];    <span class="hljs-keyword">void</span>* keepCount = outputs[<span class="hljs-number">1</span>];    pluginStatus_t status = detectionInference(stream, batchSize, C1, C2, param.shareLocation,        param.varianceEncodedInTarget, param.backgroundLabelId, numPriors, param.numClasses, param.topK, param.keepTopK,        param.confidenceThreshold, param.nmsThreshold, param.codeType, DataType::kFLOAT, locData, priorData,        DataType::kFLOAT, confData, keepCount, topDetections, workspace, param.isNormalized, param.confSigmoid);    ASSERT(status == STATUS_SUCCESS);    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><ul><li><code>attachToContext/detachFromContext</code>：如果这个 op 使用到了一些其他东西， 例如 cublas handle， 可以直接借助 TensorRT 内部提供的 cublas handle。</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Attach the plugin object to an execution context and grant the plugin the access to some context resource.</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::attachToContext</span><span class="hljs-params">(cudnnContext* cudnnContext, cublasContext* cublasContext, IGpuAllocator* gpuAllocator)</span></span>&#123;&#125;<span class="hljs-comment">// Detach the plugin object from its execution context.</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::detachFromContext</span><span class="hljs-params">()</span> </span>&#123;&#125;</code></pre><p>（3）序列化问题</p><ul><li><code>getSerializationSize</code>：序列化时需要写多少字节到 buffer 中   🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Returns the size of serialized parameters</span><span class="hljs-function"><span class="hljs-keyword">size_t</span> <span class="hljs-title">DetectionOutput::getSerializationSize</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// DetectionOutputParameters, C1, C2, numPriors</span>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">sizeof</span>(DetectionOutputParameters) + <span class="hljs-keyword">sizeof</span>(<span class="hljs-keyword">int</span>) * <span class="hljs-number">3</span>;&#125;</code></pre><ul><li><code>serialize</code>：把需要用的数据按照顺序序列化到 buffer 里面    🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Serialization of plugin parameters</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::serialize</span><span class="hljs-params">(<span class="hljs-keyword">void</span>* buffer)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">char</span> *d = <span class="hljs-keyword">reinterpret_cast</span>&lt;<span class="hljs-keyword">char</span>*&gt;(buffer), *a = d;    write(d, param);    write(d, C1);    write(d, C2);    write(d, numPriors);    ASSERT(d == a + getSerializationSize());&#125;</code></pre><p>（4）插件的基本设置</p><p> <code>getPluginType</code> 和  <code>getPluginVersion</code> 插件的类型或者版本</p><pre><code class="hljs cpp"> <span class="hljs-comment">// 注意不要重复即可</span><span class="hljs-keyword">namespace</span> &#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* NMS_PLUGIN_VERSION&#123;<span class="hljs-string">&quot;1&quot;</span>&#125;;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* NMS_PLUGIN_NAME&#123;<span class="hljs-string">&quot;NMS_TRT&quot;</span>&#125;;&#125;   <span class="hljs-comment">// namespace</span><span class="hljs-comment">// Get the plugin type</span><span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">DetectionOutput::getPluginType</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> NMS_PLUGIN_NAME;&#125;<span class="hljs-comment">// Get the plugin version</span><span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">DetectionOutput::getPluginVersion</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> NMS_PLUGIN_VERSION;&#125;</code></pre><ul><li><code>set/getPluginNamespace</code>：设置/获取插件的命名空间。如果不设置则默认为 “”， 需要注意同一个 namespace 下的 plugin 如果名字相同会冲突。</li></ul><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::setPluginNamespace</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* pluginNamespace)</span></span><span class="hljs-function"></span>&#123;    mPluginNamespace = pluginNamespace;&#125;<span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">DetectionOutput::getPluginNamespace</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> mPluginNamespace.c_str();&#125;</code></pre><ul><li><code>supportsFormat</code>：判断格式/数据类型是否合理</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Check if the DataType and Plugin format is supported</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">DetectionOutput::supportsFormat</span><span class="hljs-params">(DataType type, PluginFormat format)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> (type == DataType::kFLOAT &amp;&amp; format == PluginFormat::kNCHW);&#125;</code></pre><ul><li><code>getWorkspaceSize</code>：返回这个插件 op 需要中间显存变量的实际数据大小(bytesize)，这个通过 TensorRT 的接口去获取，是比较规范的方式。  🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Returns the workspace size</span><span class="hljs-function"><span class="hljs-keyword">size_t</span> <span class="hljs-title">DetectionOutput::getWorkspaceSize</span><span class="hljs-params">(<span class="hljs-keyword">int</span> maxBatchSize)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> detectionInferenceWorkspaceSize(param.shareLocation, maxBatchSize, C1, C2, param.numClasses, numPriors, param.topK, DataType::kFLOAT, DataType::kFLOAT);&#125;</code></pre><ul><li><code>configurePlugin</code>：配置这个插件 op：输入和输出和相关参数的验证和配置。 官方还提到这个配置信息可以告知 TensorRT 去选择合适的算法去调优这个模型  🌟🌟</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Configure the layer with input and output data types.</span><span class="hljs-comment">// inutDims: input Dimensions for the plugin layer</span><span class="hljs-comment">// nInputs : Number of inputs to the plugin layer</span><span class="hljs-comment">// outputDims: output Dimensions from the plugin layer</span><span class="hljs-comment">// nOutputs: number of outputs from the plugin layer</span><span class="hljs-comment">// type: DataType configuration for the plugin layer</span><span class="hljs-comment">// format: format NCHW, NHWC etc</span><span class="hljs-comment">// maxbatchSize: maximum batch size for the plugin layer</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">DetectionOutput::configurePlugin</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Dims* inputDims, <span class="hljs-keyword">int</span> nbInputs, <span class="hljs-keyword">const</span> Dims* outputDims, <span class="hljs-keyword">int</span> nbOutputs, <span class="hljs-keyword">const</span> DataType* inputTypes, <span class="hljs-keyword">const</span> DataType* outputTypes, <span class="hljs-keyword">const</span> <span class="hljs-keyword">bool</span>* inputIsBroadcast, <span class="hljs-keyword">const</span> <span class="hljs-keyword">bool</span>* outputIsBroadcast, PluginFormat floatFormat, <span class="hljs-keyword">int</span> maxBatchSize)</span></span><span class="hljs-function"></span>&#123;    ASSERT(nbInputs == <span class="hljs-number">3</span>);    ASSERT(nbOutputs == <span class="hljs-number">2</span>);    <span class="hljs-comment">// Verify all the input dimensions</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nbInputs; i++)    &#123;        ASSERT(inputDims[i].nbDims == <span class="hljs-number">3</span>);    &#125;    <span class="hljs-comment">// Verify all the output dimensions</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nbOutputs; i++)    &#123;        ASSERT(outputDims[i].nbDims == <span class="hljs-number">3</span>);    &#125;    <span class="hljs-comment">// Configure C1, C2 and numPriors</span>    <span class="hljs-comment">// Input ordering  C1, C2, numPriors</span>    C1 = inputDims[param.inputOrder[<span class="hljs-number">0</span>]].d[<span class="hljs-number">0</span>];    C2 = inputDims[param.inputOrder[<span class="hljs-number">1</span>]].d[<span class="hljs-number">0</span>];    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> nbBoxCoordinates = <span class="hljs-number">4</span>;    numPriors = inputDims[param.inputOrder[<span class="hljs-number">2</span>]].d[<span class="hljs-number">1</span>] / nbBoxCoordinates;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> numLocClasses = param.shareLocation ? <span class="hljs-number">1</span> : param.numClasses;    <span class="hljs-comment">// Verify C1</span>    ASSERT(numPriors * numLocClasses * nbBoxCoordinates == inputDims[param.inputOrder[<span class="hljs-number">0</span>]].d[<span class="hljs-number">0</span>]);    <span class="hljs-comment">// Verify C2</span>    ASSERT(numPriors * param.numClasses == inputDims[param.inputOrder[<span class="hljs-number">1</span>]].d[<span class="hljs-number">0</span>]);&#125;</code></pre><p>（5） 返回值信息</p><ul><li><code>getNbOutputs</code>： 插件 op 返回多少个 Tensor。根据该网络层的实际输出，返回一个整数即可。</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">//  The nmsPlugin generates an output of shape [batchSize, 1, keepTopK, 7] which contains the same information // as the outputs nmsed box locations, nmsed box scores, and nmsed box class IDs from batchedNMSPlugin, and an // another output of shape [batchSize, 1, 1, 1] which contains the same information as the output nmsed box // count from batchedNMSPlugin.</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">DetectionOutput::getNbOutputs</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;&#125;</code></pre><ul><li><code>getOutputDataType</code>: 返回结果的类型， 一般来说我们插件 op 返回类型与输入类型一致。</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Return the DataType of the plugin output at the requested index.</span><span class="hljs-function">DataType <span class="hljs-title">DetectionOutput::getOutputDataType</span><span class="hljs-params">(<span class="hljs-keyword">int</span> index, <span class="hljs-keyword">const</span> nvinfer1::DataType* inputTypes, <span class="hljs-keyword">int</span> nbInputs)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// Two outputs</span>    ASSERT(index == <span class="hljs-number">0</span> || index == <span class="hljs-number">1</span>); <span class="hljs-comment">// 这里有两个 output， 需要首先判断 index 是否合理，然后返回类型</span>    <span class="hljs-keyword">return</span> DataType::kFLOAT;&#125;</code></pre><ul><li><code>getOutputDimensions</code>： TensorRT 支持 Dynamic Shape 的时候， batch 这一维度必须是 explicit 的。 也就是说， TensorRT 处理的维度从以往的三维  [3, -1, -1] 变成了 [1, 3, -1, -1]。最新的 onnx-tensort 也必须设置 explicit 的 bacthsize， 而且这个 bacth 维度在 getOutputDimensions 中是可以获取的。</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Returns output dimensions at given index</span><span class="hljs-function">Dims <span class="hljs-title">DetectionOutput::getOutputDimensions</span><span class="hljs-params">(<span class="hljs-keyword">int</span> index, <span class="hljs-keyword">const</span> Dims* inputs, <span class="hljs-keyword">int</span> nbInputDims)</span></span><span class="hljs-function"></span>&#123;    ASSERT(nbInputDims == <span class="hljs-number">3</span>);    ASSERT(index == <span class="hljs-number">0</span> || index == <span class="hljs-number">1</span>); <span class="hljs-comment">// </span>    <span class="hljs-comment">// index 0 : Dimensions 1x param.keepTopK x 7</span>    <span class="hljs-comment">// index 1: Dimensions 1x1x1</span>    <span class="hljs-keyword">if</span> (index == <span class="hljs-number">0</span>)    &#123;        <span class="hljs-keyword">return</span> DimsCHW(<span class="hljs-number">1</span>, param.keepTopK, <span class="hljs-number">7</span>);    &#125;    <span class="hljs-keyword">return</span> DimsCHW(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>);&#125;</code></pre><ul><li><code>isOutputBroadcastAcrossBatch</code>/<code>canBroadcastInputAcrossBatch</code>: output 是否进行 boardcast 以及能否进行 boardcast</li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// Return true if output tensor is broadcast across a batch.</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">DetectionOutput::isOutputBroadcastAcrossBatch</span><span class="hljs-params">(<span class="hljs-keyword">int</span> outputIndex, <span class="hljs-keyword">const</span> <span class="hljs-keyword">bool</span>* inputIsBroadcasted, <span class="hljs-keyword">int</span> nbInputs)</span> <span class="hljs-keyword">const</span></span>&#123;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;<span class="hljs-comment">// Return true if plugin can use input that is broadcast across batch without replication.</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">DetectionOutput::canBroadcastInputAcrossBatch</span><span class="hljs-params">(<span class="hljs-keyword">int</span> inputIndex)</span> <span class="hljs-keyword">const</span></span>&#123;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;</code></pre><p>PluginCreator 类的相关实现函数，相对来说比较简单。</p><p>（1）构造函数</p><pre><code class="hljs cpp"><span class="hljs-comment">// Plugin creator constructor</span>NMSPluginCreator::NMSPluginCreator()&#123;    <span class="hljs-comment">// NMS Plugin field meta data &#123;name,  data, type, length&#125;</span>    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;shareLocation&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;varianceEncodedInTarget&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;backgroundLabelId&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;numClasses&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;topK&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;keepTopK&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;confidenceThreshold&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kFLOAT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;nmsThreshold&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kFLOAT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;inputOrder&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">3</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;confSigmoid&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;isNormalized&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mPluginAttributes.emplace_back(PluginField(<span class="hljs-string">&quot;codeType&quot;</span>, <span class="hljs-literal">nullptr</span>, PluginFieldType::kINT32, <span class="hljs-number">1</span>));    mFC.nbFields = mPluginAttributes.size();    mFC.fields = mPluginAttributes.data();&#125;</code></pre><p>（2）createPlugin：这个成员函数作用是通过 PluginFieldCollection 去创建 plugin， 将 op 需要的权重和参数逐一取出来， 然后调用上文提到的构造函数。</p><pre><code class="hljs cpp"><span class="hljs-comment">// Creates the NMS plugin</span><span class="hljs-function">IPluginV2Ext* <span class="hljs-title">NMSPluginCreator::createPlugin</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* name, <span class="hljs-keyword">const</span> PluginFieldCollection* fc)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> PluginField* fields = fc-&gt;fields;    <span class="hljs-comment">// Default init values for TF SSD network</span>    params.codeType = CodeTypeSSD::TF_CENTER;    params.inputOrder[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;    params.inputOrder[<span class="hljs-number">1</span>] = <span class="hljs-number">2</span>;    params.inputOrder[<span class="hljs-number">2</span>] = <span class="hljs-number">1</span>;    <span class="hljs-comment">// Read configurations from  each fields</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; fc-&gt;nbFields; ++i)    &#123;        <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* attrName = fields[i].name;        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">strcmp</span>(attrName, <span class="hljs-string">&quot;shareLocation&quot;</span>))        &#123;            ASSERT(fields[i].type == PluginFieldType::kINT32);            params.shareLocation = <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(*(<span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span>*&gt;(fields[i].data)));        &#125;        <span class="hljs-comment">// ....</span>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">strcmp</span>(attrName, <span class="hljs-string">&quot;codeType&quot;</span>))        &#123;            ASSERT(fields[i].type == PluginFieldType::kINT32);            params.codeType = <span class="hljs-keyword">static_cast</span>&lt;CodeTypeSSD&gt;(*(<span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span>*&gt;(fields[i].data)));        &#125;    &#125;    DetectionOutput* obj = <span class="hljs-keyword">new</span> DetectionOutput(params);    obj-&gt;setPluginNamespace(mNamespace.c_str());    <span class="hljs-keyword">return</span> obj;&#125;</code></pre><p>（3）deserializePlugin： 这个函数会被 onnx-tensorrt 的一个叫做 TRT_PluginV2 的转换 op 调用， 这个 op 会读取 onnx 模型的 data 数据将其反序列化到 network 中。</p><pre><code class="hljs cpp"><span class="hljs-function">IPluginV2Ext* <span class="hljs-title">NMSPluginCreator::deserializePlugin</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* name, <span class="hljs-keyword">const</span> <span class="hljs-keyword">void</span>* serialData, <span class="hljs-keyword">size_t</span> serialLength)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// This object will be deleted when the network is destroyed, which will</span>    <span class="hljs-comment">// call NMS::destroy()</span>    DetectionOutput* obj = <span class="hljs-keyword">new</span> DetectionOutput(serialData, serialLength);    obj-&gt;setPluginNamespace(mNamespace.c_str());    <span class="hljs-keyword">return</span> obj;&#125;</code></pre><p>（4） 一些插件相关信息配置的函数</p><pre><code class="hljs cpp"><span class="hljs-comment">// Returns the plugin name</span><span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">NMSPluginCreator::getPluginName</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> NMS_PLUGIN_NAME;&#125;<span class="hljs-comment">// Returns the plugin version</span><span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* <span class="hljs-title">NMSPluginCreator::getPluginVersion</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> NMS_PLUGIN_VERSION;&#125;<span class="hljs-comment">// Returns the plugin field names</span><span class="hljs-function"><span class="hljs-keyword">const</span> PluginFieldCollection* <span class="hljs-title">NMSPluginCreator::getFieldNames</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> &amp;mFC;&#125;</code></pre><p>(5)  获取 PluginFieldCollection。PluginFieldCollection 的主要作用是传递这个插件 op 所需要的权重和参数， 在实际的 engine 推理过程中并不使用， 而在 parse 中会用到（比如 caffe2trt、onnx2trt）。</p><pre><code class="hljs cpp"><span class="hljs-comment">// Returns the plugin field names</span><span class="hljs-function"><span class="hljs-keyword">const</span> PluginFieldCollection* <span class="hljs-title">NMSPluginCreator::getFieldNames</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> &amp;mFC;&#125;</code></pre><h5 id="Step2：-在-InferPlugin-cpp-中注册新-creator"><a href="#Step2：-在-InferPlugin-cpp-中注册新-creator" class="headerlink" title="Step2： 在  InferPlugin.cpp 中注册新 creator"></a>Step2： 在  InferPlugin.cpp 中注册新 creator</h5><p>注册过程， 维护map结构，实现字符串到 creator 的映射。</p><p>文件路径：<code>TensorRT/plugin/inferplugin.cpp</code></p><p>将自定义的 plugin 创建器进行初始化。 系统最终通过 creator 映射关系来实现 plugin 的创建和调用</p><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;nmsPlugin.h&quot;</span></span><span class="hljs-keyword">extern</span> <span class="hljs-string">&quot;C&quot;</span>&#123;    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">initLibNvInferPlugins</span><span class="hljs-params">(<span class="hljs-keyword">void</span>* logger, <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* libNamespace)</span></span><span class="hljs-function">    </span>&#123;        initializePlugin&lt;nvinfer1::plugin::NMSPluginCreator&gt;(logger, libNamespace);        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    &#125;&#125; <span class="hljs-comment">// extern &quot;C&quot;</span></code></pre><h5 id="Step3-修改-CMakeLists-txt-并编译-nvinfer-plugin-库"><a href="#Step3-修改-CMakeLists-txt-并编译-nvinfer-plugin-库" class="headerlink" title="Step3: 修改 CMakeLists.txt 并编译 nvinfer_plugin 库"></a>Step3: 修改 CMakeLists.txt 并编译 nvinfer_plugin 库</h5><p>文件路径：<code>TensorRT/plugin/CMakeLists.txt</code></p><pre><code class="hljs cpp"><span class="hljs-comment">// 将 plugin 添加 plugin list</span><span class="hljs-built_in">set</span>(PLUGIN_LISTS    nmsPlugin    )</code></pre><h5 id="setp-4-在-onnx-tensorrt-中注册新的-Plugin"><a href="#setp-4-在-onnx-tensorrt-中注册新的-Plugin" class="headerlink" title="setp 4: 在 onnx-tensorrt 中注册新的 Plugin"></a>setp 4: 在 onnx-tensorrt 中注册新的 Plugin</h5><p>文件路径： <code>TensorRT/parser/onnx/builtin_op_importers.cpp</code>。 添加方法如下所示：</p><pre><code class="hljs cpp">DEFINE_BUILTIN_OP_IMPORTER(BatchNormalization)  <span class="hljs-comment">// OP 导入, 参数部分为 OP 名称， 需要与 onnx 一致</span>&#123;    <span class="hljs-comment">// Scale, bias, mean, and variance must be initializers</span>    <span class="hljs-comment">// 解析输入信息</span>    <span class="hljs-keyword">auto</span> scale_weights = inputs.at(<span class="hljs-number">1</span>).weights();    <span class="hljs-keyword">auto</span> bias_weights = inputs.at(<span class="hljs-number">2</span>).weights();    <span class="hljs-keyword">auto</span> mean_weights = inputs.at(<span class="hljs-number">3</span>).weights();    <span class="hljs-keyword">auto</span> variance_weights = inputs.at(<span class="hljs-number">4</span>).weights();    <span class="hljs-comment">// ...</span>    <span class="hljs-comment">// 解析属性信息</span>    <span class="hljs-function">OnnxAttrs <span class="hljs-title">attrs</span><span class="hljs-params">(node)</span></span>;    <span class="hljs-keyword">float</span> eps = attrs.get&lt;<span class="hljs-keyword">float</span>&gt;(<span class="hljs-string">&quot;epsilon&quot;</span>, <span class="hljs-number">1e-5</span>f);    nvinfer1::Dims dims = tensor_ptr-&gt;getDimensions();    <span class="hljs-keyword">bool</span> need_to_expand_dims = (dims.nbDims == <span class="hljs-number">3</span>);&#125;</code></pre><h5 id="step-5-Plugin-编译支持"><a href="#step-5-Plugin-编译支持" class="headerlink" title="step 5. Plugin 编译支持"></a>step 5. Plugin 编译支持</h5><p>确保 TensorRT/Plugin/CMakeLists  保证新增加的 Plugin 能够被正常编译通过。</p><h5 id="step-6-编译-nvonnxparse-库"><a href="#step-6-编译-nvonnxparse-库" class="headerlink" title="step 6. 编译 nvonnxparse 库"></a>step 6. 编译 nvonnxparse 库</h5><h5 id="step-7-替换-nvinfer-plugin-和-nvonnxparser-库，使用-trtexec-将-onnx-转换为-tensorrt-模型"><a href="#step-7-替换-nvinfer-plugin-和-nvonnxparser-库，使用-trtexec-将-onnx-转换为-tensorrt-模型" class="headerlink" title="step 7. 替换 nvinfer_plugin 和 nvonnxparser 库，使用 trtexec 将 onnx 转换为 tensorrt 模型"></a>step 7. 替换 nvinfer_plugin 和 nvonnxparser 库，使用 trtexec 将 onnx 转换为 tensorrt 模型</h5><p>补充一个学习工具：TensorRT 工具 kaldi-onnx   <a href="https://github/com/XiaoMi/kaldi-onnx">https://github/com/XiaoMi/kaldi-onnx</a></p><p>用于将 kaldi 语音识别工具包神经网络模型移植到onnx模型进行推理的工具。您可以使用 MACE 加快具有高度优化的 neon 内核的 android、ios， linux 或 windows 设备的推断，该工具支持转换 Nnet2 和 Nnet3 模型。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CPP_review</title>
    <link href="/2021/01/10/CPP-review/"/>
    <url>/2021/01/10/CPP-review/</url>
    
    <content type="html"><![CDATA[<p>C++ 复习</p><a id="more"></a><h2 id="零-导读"><a href="#零-导读" class="headerlink" title="零. 导读"></a>零. 导读</h2><h4 id="1-基本理念"><a href="#1-基本理念" class="headerlink" title="1. 基本理念"></a>1. 基本理念</h4><ul><li>勿在浮沙筑高台</li></ul><h4 id="2-内容"><a href="#2-内容" class="headerlink" title="2. 内容"></a>2. 内容</h4><p>(1)  培养正规，大气的编程习惯</p><ul><li>基于对象(Object Based)： 面对的是单一的 class 的设计、将数据和函数封装成类，只有内部的函数可以处理数据；并通过类创建对象。 <code>Class(Data, Functions) -&gt; Objects</code></li><li>面向对象(Object Oriented)： 学习 classes 之间的关系：继承(inheritance)、复合(composition)、委托(delegation)</li></ul><p>(2)   泛型编程(generic programming) </p><p>(3)  深入探索面向对象之继承所形成的的对象模型(object model)，包含隐藏于底层的 this、虚指针、虚表、虚机制以及虚函数所造成的多态效果。</p><h4 id="3-关于-C"><a href="#3-关于-C" class="headerlink" title="3. 关于 C++"></a>3. 关于 C++</h4><p>(1)  C++ 的历史: B语言(1969)  →  C语言(1972)   →  C++ 语言(1983) [new C → C with Class → C++] → Java 语言  →  C# 语言</p><p>(2)  C++ 演化：<strong>C++ 98(1.0) ☆</strong>  →  C++ 03(TR1, Technical Report 1) →  <strong>C++ 11 (2.0) ☆</strong>  → C++ 14</p><p>(3)  C++ 包括  C++语言 和 C++标准库 两部分</p><h4 id="4-书籍推荐"><a href="#4-书籍推荐" class="headerlink" title="4. 书籍推荐:"></a>4. 书籍推荐:</h4><ul><li><p>语言：C++ Primer (Fifth Edition)、The C++ Programming Language (Fourth Edition)</p></li><li><p>规范：Effective C++ (Third Edition) → Efficitive Modern c++</p></li><li><p>标准库： The C++ Standard Library、STL 源码剖析</p></li></ul><h2 id="一-基础"><a href="#一-基础" class="headerlink" title="一. 基础"></a>一. 基础</h2><h3 id="1-代码的基本形式"><a href="#1-代码的基本形式" class="headerlink" title="1.代码的基本形式"></a>1.代码的基本形式</h3><p><img src="/2021/01/10/CPP-review/1.png" style="zoom:35%;"></p><p>扩展名 (extension file name) 不一定是 <code>.h</code> 或者 <code>.cpp</code>， 也可能是 <code>.hpp</code> 或其他或无扩展名。</p><p>(1) 头文件引用</p><pre><code class="hljs cpp"><span class="hljs-comment">// complex.cpp</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;   # 引用 C++ 头文件， 无须 .h</span></span><span class="hljs-meta">#inlcude <span class="hljs-meta-string">&lt;cstdio&gt;     # 引用C头文件, 去掉头文件，前面加 c</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;utils.h&quot;</span>    # 引用自定义的头文件 </span></code></pre><p>(2) 头文件布局</p><pre><code class="hljs cpp"><span class="hljs-comment">// complex.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">ifndef</span> __COMPLEX__    <span class="hljs-comment">// (1) 头文件的防卫式声明：防止重复定义</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __COMPLEX__</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ostream</span>;</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span>;</span> <span class="hljs-built_in">complex</span>&amp; __doapl (<span class="hljs-built_in">complex</span>* ths, <span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp; r);   <span class="hljs-comment">// 1. 前置声明</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span> <span class="hljs-title">class</span> <span class="hljs-title">declarations</span> &#123;</span> ... &#125;;            <span class="hljs-comment">// 2. 类声明</span><span class="hljs-built_in">complex</span>::function ...                                <span class="hljs-comment">// 3. 类定义</span><span class="hljs-meta"># <span class="hljs-meta-keyword">endif</span> </span></code></pre><h3 id="2-类的声明与定义-class-head-class-body"><a href="#2-类的声明与定义-class-head-class-body" class="headerlink" title="2. 类的声明与定义  class head + class body"></a>2. 类的声明与定义  class head + class body</h3><h5 id="2-1-access-level-访问级别"><a href="#2-1-access-level-访问级别" class="headerlink" title="2.1 access level(访问级别)"></a>2.1 access level(访问级别)</h5><p>​        访问级别分为 <code>private</code> , <code>public</code>, <code>protected</code> 三类，其位置可以交错。 数据放在 <code>private</code> 区，封装在类内，然后通过函数访问数据。</p><h5 id="2-2-修饰关键字"><a href="#2-2-修饰关键字" class="headerlink" title="2.2 修饰关键字"></a>2.2 修饰关键字</h5><p>(1)  inline </p><p>​        有些函数可以直接定义在 body 中，另外一些在 body 之外定义。函数若在 class body 内定义，会被默认成为 inline 函数。具体是否内联，需要有编译器而定。 将函数声明为 inline，<strong>表示要求编译器在每个函数调用点上，将函数的内容展开。</strong>面对一个 inline 函数， 编译器可将该函数的操作改为以一份函数代码副本代替。这将使我们获得性能改善。</p><p>！编译器一般不会内联包含循环、递归、switch 等复杂操作的内联函数。在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。</p><p>优点：</p><ul><li><p>内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。</p></li><li><p>内联函数相比宏函数来说，在代码展开时，<strong>会做安全检查或自动类型转换（同普通函数）</strong>，而宏定义则不会。</p></li><li><p>在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数<strong>可以访问类的成员变量</strong>，宏定义则不能。</p></li><li><p>内联函数在<strong>运行时可调试</strong>，而宏定义不可以。</p></li></ul><p>缺点：</p><ul><li><p>代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。</p></li><li><p>inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。</p></li><li><p>是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译</p></li></ul><p>(2) const : 常  🌟🌟</p><p>​        const 表示不会改变数据的内容, const 可以修饰对象、成员函数和成员变量。const 修饰对象表示该对象的成员变量不可改变， const 修饰成员函数表示成员函数不能改变成员变量的值。</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">real</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123;<span class="hljs-keyword">return</span> re;&#125;<span class="hljs-built_in">complex</span>&amp; <span class="hljs-keyword">operator</span> += (<span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp;);<span class="hljs-function"><span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> <span class="hljs-title">str</span><span class="hljs-params">(<span class="hljs-string">&quot;Hello World!&quot;</span>)</span></span>;</code></pre><p>通过对象调用成员函数， 可能会产生如下的四种情况:</p><div class="table-container"><table><thead><tr><th></th><th>const object</th><th>non-const object</th></tr></thead><tbody><tr><td>const member functions</td><td><strong>√</strong></td><td><strong>√</strong></td></tr><tr><td>non-const member functions</td><td><strong>×</strong></td><td><strong>√</strong></td></tr></tbody></table></div><p>使用的基本原则：</p><ul><li><p>不能通过 const 对象调用 non-const 成员函数</p></li><li><p>当成员函数的 const 和 non-const 版本同时存在， const object 只会(只能) 调用 const 版本。 non-const object 只会(只能) 调用 non-const 版本。如下所示的代码, 通过 const 进行函数签名的区分，实现 const 函数和 non-const 函数的分开调用：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 该段代码存在于 class template std::basic_string&lt;...&gt; </span><span class="hljs-comment">// 实现了操作符 [] 的 const 和 non-const 的函数重载, 其中 const 函数并不会更改对象</span><span class="hljs-comment">// 也不用过多的考虑引用计数和写时复制， 其设计相对简单。</span>charT <span class="hljs-keyword">operator</span>[](size_type pos) <span class="hljs-keyword">const</span>&#123;    ...... <span class="hljs-comment">/* 不需要考虑 Copy On Write */</span>  &#125;reference <span class="hljs-keyword">operator</span>[](size_type pos)&#123;    ...... <span class="hljs-comment">/* 需要考虑 Copy On Write */</span>   &#125;</code></pre></li></ul><p>(3) static: 静态  🌟🌟</p><p>这里的静态是指对象的生存周期：</p><ul><li>静态生存期：其生命在作用域 (scope)  结束之后仍然存在，直到整个程序结束</li><li>动态生存期： 起始于定义的位置，终止于最近的 <code>“&#125;”</code></li></ul><p>​        当成员变量或者成员函数是 non-static 的时候， 每个对象会有一个内存存储。通过对象调用这个 non-static 的成员函数时，会将该对象的地址传递给这个成员函数</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span>&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">real</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> re; &#125;  <span class="hljs-comment">// return re; 会默认翻译为 return this-&gt;re;</span><span class="hljs-keyword">private</span>:    <span class="hljs-keyword">double</span> re, im;&#125;;<span class="hljs-built_in">complex</span> c1, c2, c3;<span class="hljs-built_in">cout</span> &lt;&lt; c1.real();  <span class="hljs-comment">// 翻译为 cout &lt;&lt; complex::real(&amp;c1);</span><span class="hljs-built_in">cout</span> &lt;&lt; c2.real();  <span class="hljs-comment">// 翻译为 cou &lt;&lt; complex::real(&amp;c2);</span></code></pre><p>​        当成员变量或者成员函数是 static 的时候， 整个类共享一份成员变量。 这个成员变量不属于任何对象，而属于整个类。</p><ul><li>static 函数可以通过类或者对象进行调用。 </li><li>需要在类定义的外部对这个成员变量进行定义。</li><li>静态成员函数不能调用非静态成员变量。</li></ul><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Account</span>&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-keyword">static</span> <span class="hljs-keyword">double</span> m_rate;    <span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">set_rate</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span> &amp; x)</span> </span>&#123; m_rate = x; &#125;&#125;;<span class="hljs-keyword">double</span> Account::m_rate = <span class="hljs-number">8.0</span>; <span class="hljs-comment">// 需要在类定义的外部对这个静态成员进行定义</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;    <span class="hljs-comment">// static 函数 可以通过 类 或者 对象 进行调用</span>    Account::set_rate(<span class="hljs-number">5.0</span>);        Account a;    a.set_rate(<span class="hljs-number">7.0</span>);&#125;</code></pre><h5 id="2-3-函数"><a href="#2-3-函数" class="headerlink" title="2.3 函数"></a>2.3 函数</h5><p>(1) 参数传递和返回值传递</p><ul><li>参数传递 pass by value  vs    pass by reference(to const)</li></ul><p>​      尽量不用 pass by value(小于4个字节的可以传值)，而要使用 pass by reference。 如果传递引用并不希望修改，前面需要加上 const。</p><ul><li>返回值传递  return by value vs return by reference(to const)</li></ul><p>​      返回值的传递也尽量使用引用传递。局部变量不能传递引用，因为局部变量会在返回时被销毁。</p><p>(2) 设计构造函数</p><ul><li>构造函数尽量使用初始值列表的语法形式，这是在初始化时设定初值，而不是在初始化之后再进行赋值。</li><li>构造函数的函数名称和类名相同，没有返回值，并且可以重载。</li><li>不能显示调用，而是在初始化的时候进行自动调用。</li><li>与构造函数相对应的是析构函数，不带指针类的设计不需要写析构函数</li></ul><p>(3) 默认参数和函数重载 (overloading)</p><ul><li>默认参数多个时候，有默认参数的参数需要放在后面。</li><li>参数的个数和类型不同，返回值不同不能重载</li><li>默认参数和函数重载可能会发生冲突。编译器会无法确认需要调用的函数</li></ul><p>(4) 友元 friend：友元可以获取类的数据， 但是破坏了封装性。相同 class 的各个 objects 互为友元。</p><p>(5) 操作符重载 与 this 指针</p><p>​    this 指针：所有的成员函数都带有一个隐藏的指针，指向调用者。</p><ul><li>成员函数(有this)</li></ul><pre><code class="hljs cpp"><span class="hljs-built_in">complex</span>::<span class="hljs-keyword">operator</span> += (<span class="hljs-keyword">const</span> cimplex&amp; x)&#123;    <span class="hljs-keyword">return</span> __dopal(<span class="hljs-keyword">this</span>, r);&#125;</code></pre><p>   PS: 传递者无需要知道接受者是以什么形式接受的</p><ul><li>非成员函数(无this)</li></ul><pre><code class="hljs cpp"><span class="hljs-keyword">inline</span> <span class="hljs-built_in">complex</span> <span class="hljs-keyword">operator</span> +(<span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp; x, <span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp; y)&#123;    <span class="hljs-keyword">return</span> <span class="hljs-built_in">complex</span>(real(x) + real(y), imag(x) + imag(y));&#125;<span class="hljs-comment">// PS: typename()  创建临时对象</span></code></pre><p>(6) &lt;&lt; 重载</p><pre><code class="hljs cpp">ostream&amp; <span class="hljs-keyword">operator</span> &lt;&lt; (ostream &amp; os, <span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span> &amp; x)&#123;       <span class="hljs-keyword">return</span> os &lt;&lt; <span class="hljs-string">&#x27;(&#x27;</span> &lt;&lt; real(x) &lt;&lt; <span class="hljs-string">&#x27;,&#x27;</span> &lt;&lt; imag(x) &lt;&lt; <span class="hljs-string">&#x27;)&#x27;</span>;   &#125;</code></pre><h2 id="二-拷贝构造、拷贝复制、析构函数"><a href="#二-拷贝构造、拷贝复制、析构函数" class="headerlink" title="二. 拷贝构造、拷贝复制、析构函数"></a>二. 拷贝构造、拷贝复制、析构函数</h2><p>​        类定义的时候，编译器会默认生成六个成员函数：构造函数、拷贝构造函数、拷贝赋值函数、析构函数、取地址运算符、取地址运算符(const版本)。其中拷贝构造函数、拷贝赋值函数、析构函数被称为三大函数(Big Three)。</p><p>​        如果自定义的类带有指针，则需要自己去定义拷贝构造函数和拷贝复制函数。 why?<br>​        默认的拷贝构造函数仅仅是将值拷贝过去，反映在指针上就是改变指针的指向。如下图所示，默认拷贝构造和默认的拷贝赋值会将 b 的指针也指向 a，这也就所谓的浅拷贝。这会导致两个问题：</p><p>(1) 别名 alias: a 和 b 的指针指向同一块内存, 这种操作很危险</p><p>(2) b 原有的指向的内容没有释放，从而产生内存泄漏</p><p><img src="/2021/01/10/CPP-review/2.png" style="zoom:35%;"></p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">String</span>&#123;</span>    String(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* cstr = <span class="hljs-number">0</span>);    String(<span class="hljs-keyword">const</span> String&amp; str);    String&amp; <span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> String&amp; str);    ~String();        <span class="hljs-function"><span class="hljs-keyword">char</span>* <span class="hljs-title">get_c_str</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> m_data; &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">char</span> * m_data;&#125;;<span class="hljs-comment">// 构造函数</span><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-title">String::String</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* cstr =<span class="hljs-number">0</span>)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span>(cstr)&#123;        m_data = <span class="hljs-keyword">new</span> <span class="hljs-keyword">char</span>[<span class="hljs-built_in">strlen</span>(cstr) + <span class="hljs-number">1</span>];        <span class="hljs-built_in">strcpy</span>(m_data, cstr);    &#125;<span class="hljs-keyword">else</span> &#123;    <span class="hljs-comment">// 为指定初值</span>        m_data = <span class="hljs-keyword">new</span> <span class="hljs-keyword">char</span>[<span class="hljs-number">1</span>];        * m_data = <span class="hljs-string">&#x27;\0&#x27;</span>;    &#125;&#125;<span class="hljs-comment">// 析构函数</span><span class="hljs-keyword">inline</span> String::~String()&#123;    <span class="hljs-keyword">delete</span>[] m_data;&#125;<span class="hljs-comment">// 拷贝构造函数</span><span class="hljs-function"><span class="hljs-keyword">inline</span> <span class="hljs-title">String::String</span><span class="hljs-params">(<span class="hljs-keyword">const</span> String&amp; str)</span></span><span class="hljs-function"></span>&#123;    m_data = <span class="hljs-keyword">new</span> <span class="hljs-keyword">char</span>[<span class="hljs-built_in">strlen</span>(str.m_data) + <span class="hljs-number">1</span>];    <span class="hljs-built_in">strcpy</span>(m_data, str.m_data);&#125;<span class="hljs-comment">// 拷贝赋值函数 copy assignment operator</span><span class="hljs-keyword">inline</span> String&amp; String::<span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> String&amp; str)&#123;    <span class="hljs-comment">// 一定要在 operator= 中检查是否 self assignment</span>    <span class="hljs-keyword">if</span>(<span class="hljs-keyword">this</span> == &amp; str)        <span class="hljs-keyword">return</span> * <span class="hljs-keyword">this</span>;            <span class="hljs-keyword">delete</span> [] m_data;  <span class="hljs-comment">// (1) 清除自身内容</span>    m_data = <span class="hljs-keyword">new</span> <span class="hljs-keyword">char</span>[<span class="hljs-built_in">strlen</span>(str.m_data) + <span class="hljs-number">1</span>]; <span class="hljs-comment">// (2) 重新申请一段内存， 用于存储</span>    <span class="hljs-built_in">strcpy</span>(m_data, str.m_data);  <span class="hljs-comment">// (3) 将原有的数据 copy 过来</span>        <span class="hljs-keyword">return</span> * <span class="hljs-keyword">this</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;    <span class="hljs-function">String <span class="hljs-title">s1</span><span class="hljs-params">()</span></span>;    <span class="hljs-function">String <span class="hljs-title">s2</span><span class="hljs-params">(<span class="hljs-string">&quot;Hello&quot;</span>)</span></span>;        <span class="hljs-function">String <span class="hljs-title">s3</span><span class="hljs-params">(s1)</span></span>;    <span class="hljs-built_in">cout</span> &lt;&lt; s3 &lt;&lt; <span class="hljs-built_in">endl</span>;        s3 = s2;    <span class="hljs-built_in">cout</span> &lt;&lt; s3 &lt;&lt; <span class="hljs-built_in">endl</span>;&#125;</code></pre><p>   如果没有自我赋值检查， 左右两个 pointers 指向同一个 memory block。 前述 operator= 做的第一件事情就是 delete，此时自身对象的 m_data 将会被释放， m_data 指向的内容将不存在。然后，当企图访问 rhs时， 会产生不确定行为(undefined behavior)。</p><h2 id="三-内存管理"><a href="#三-内存管理" class="headerlink" title="三. 内存管理"></a>三. 内存管理</h2><h4 id="1-指针和引用的区别-🌟🌟"><a href="#1-指针和引用的区别-🌟🌟" class="headerlink" title="1. 指针和引用的区别 ?  🌟🌟"></a>1. 指针和引用的区别 ?  🌟🌟</h4><pre><code class="hljs cpp"><span class="hljs-keyword">int</span> x = <span class="hljs-number">0</span>;<span class="hljs-keyword">int</span>* p = &amp;x; <span class="hljs-comment">// p is a point to x: p 本身是一个变量，但是存储的是 x 的地址</span>             <span class="hljs-comment">// 一个小小的技巧: 这里的 * 是靠近 int 的, 表示 p 是 int* 类型</span><span class="hljs-keyword">int</span> &amp;r = x;  <span class="hljs-comment">// r is a reference to x: r 代表 x。r, 此时 x 都是 0</span></code></pre><p>(1) 指针是在内存中的四/八字节存储空间，指针存储的内容就是一个地址，根据这个地址可以找到另外一片内存，指针就是这片内存的索引。简单的讲，指针就是一种保存变量地址的变量。</p><p>​    引用则相当于是为对象起了一个别名, 引用和原来的对象具有相同的大小和地址。</p><p>(2) 在编译器方面，两者是一样的，编译器会将两者编译为相同的汇编指令。有一句很好的话可以来形容：reference 就是漂亮的 point。</p><p>(3) 两者主要的区别是在语法层面：</p><ul><li><p>sizeof(指针) 的大小是4/8，sizeof(引用) 的大小是被引用对象的大小；</p></li><li><p><strong>初始化</strong>(引用必须初始化为一个对象的引用、指针则可以初始化为空)、<strong>可改变</strong>(引用不可以改变、指针则可以更改指向)、<strong>传参</strong>(作为<strong>参数传递</strong>时，指针需要被解引用才可进行操作，引用可直接修改)</p></li><li><p><strong>静态</strong>(没有静态引用、但是有静态指针)、<strong>自加运算符</strong>(含义不一样，引用是对其值进行自加， 指针则是表示指针进行移动)</p></li></ul><p>(4) 使用：</p><ul><li><p><strong>引用相对于指针更加安全。平时编程时，在能使用引用的情况下，就不要轻易使用指针</strong>，当然，在操作数组或者大面积内存时，用指针更好。 </p></li><li><p>reference 通常不用于声明变量，而用于参数类型和返回值类型的描述。 reference 的一个优点是可以保持调用端和被调用端的写法与传值写法相同。</p></li><li><p><strong>引用</strong>并不能作为函数签名的区别，这会引起二义性。 但是 const 可以。</p></li></ul><pre><code class="hljs cpp"><span class="hljs-comment">// 如下两个函数声明, 会产生二义性!</span><span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">imag</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span>&amp; im)</span> </span>&#123; ... &#125;<span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">imag</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">double</span> im)</span> </span>&#123;...&#125;</code></pre><h4 id="2-所谓-stack-栈-，-所谓-heap-堆-🌟🌟"><a href="#2-所谓-stack-栈-，-所谓-heap-堆-🌟🌟" class="headerlink" title="2. 所谓 stack(栈)， 所谓 heap(堆)    🌟🌟"></a>2. 所谓 stack(栈)， 所谓 heap(堆)    🌟🌟</h4><p>在 C++ 中， 内存分为 5 个区， 分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。</p><ul><li>栈：存在于某作用于<strong>某作用域(scope) 的一块内存空间(memory space)</strong>。内存<strong>由编译器在需要时自动分配和释放</strong>。通常用来存储局部变量和函数参数(为运行函数而分配的<strong>局部变量、函数参数、返回地址</strong>等存放在栈区)。栈运算分配内置于处理器的指令集中，效率很高，但是分配的内存容量有限。</li><li>堆：由操作系统提供的一块 global 的内存空间，程序<strong>可动态分配 dynamic allocated</strong> 从中获得若干区块。一般是<strong>使用由 new 进行分配，使用 delete 或 delete[] 释放</strong>。如果未能对内存进行正确的释放，会造成内存泄漏。但在程序结束时，会由操作系统自动回收。</li><li>自由存储区：和堆类似，不过存储那些有 malloc 分配，用 free 释放的内存块。</li><li>全局/静态存储区：用于存储全局变量和静态变量</li><li>常量存储区：存放常量，且不允许更改</li></ul><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Complex</span> &#123;</span> ... &#125;;...&#123;    <span class="hljs-function">Complex <span class="hljs-title">c1</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></span>;  <span class="hljs-comment">// c1 占用的空间来自 stack</span>    Complex* p = <span class="hljs-keyword">new</span> Complex(<span class="hljs-number">3</span>);  <span class="hljs-comment">// complex(3) 是个临时对象，</span>                                  <span class="hljs-comment">// 所占用的空间是 new 在 heap 动态分配而得， 并由 p 指向</span>&#125;</code></pre><h4 id="3-区分四种对象"><a href="#3-区分四种对象" class="headerlink" title="3. 区分四种对象"></a>3. 区分四种对象</h4><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Complex</span> &#123;</span> ... &#125;;...&#123;    <span class="hljs-function"><span class="hljs-built_in">complex</span> <span class="hljs-title">c1</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></span>;   <span class="hljs-comment">// stack object: 其生命在作用域结束之际结束，</span>                        <span class="hljs-comment">// 这种作用域内的 object，又称为 auto object， 因为它会被自动清理。</span>    <span class="hljs-function"><span class="hljs-keyword">static</span> Complex <span class="hljs-title">c2</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></span>;  <span class="hljs-comment">//  static object: 其生命在作用域(scope) 结束之后仍然存在，直到整个程序结束</span>        Complex * p = <span class="hljs-keyword">new</span> Complex; <span class="hljs-comment">// heap object: 其生命周期随着 deleted 之际结束。</span>                               <span class="hljs-comment">// 当你申请了一段内存，你就有责任释放它， 否则就会产生内存泄漏。</span>    ...    <span class="hljs-keyword">delete</span> p;  &#125;<span class="hljs-function">Complex <span class="hljs-title">c3</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)</span></span>;  <span class="hljs-comment">// global object: 其生命在整个程序结束之后才结束。</span>                   <span class="hljs-comment">// 你也可以视为一种 static object， 其作用域是整个函数。</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span>&#123;  ...&#125;</code></pre><h4 id="4-new-和-delete"><a href="#4-new-和-delete" class="headerlink" title="4. new 和 delete"></a>4. new 和 delete</h4><p>(1) new：先分配 memory， 再调用 ctor</p><pre><code class="hljs cpp">Complex * pc = <span class="hljs-keyword">new</span> Complex(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>);<span class="hljs-comment">// 编译器会将其转化为如下语句:</span>Complex * pc;<span class="hljs-keyword">void</span> mem = <span class="hljs-keyword">operator</span> <span class="hljs-keyword">new</span>(<span class="hljs-keyword">sizeof</span>(Complex));  <span class="hljs-comment">// (1) 分配内存 --&gt; 其内部调用 malloc(n)</span>pc = <span class="hljs-keyword">static_cast</span>&lt;Complex*&gt;(mem);   <span class="hljs-comment">// (2) 转型</span>pc -&gt; Complex::Complex(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>);      <span class="hljs-comment">// (3) 构造函数 --&gt; Complex::complex(pc, 1, 2);</span></code></pre><p>(2) delete: 先调用 dtor, 再释放内存</p><pre><code class="hljs cpp">String * ps = <span class="hljs-keyword">new</span> String(<span class="hljs-string">&quot;Hello&quot;</span>);...<span class="hljs-keyword">delete</span> ps;<span class="hljs-comment">// 编译器将其转化为:</span>String::~String(ps);   <span class="hljs-comment">// 析构函数</span><span class="hljs-function"><span class="hljs-keyword">operator</span> <span class="hljs-title">delete</span><span class="hljs-params">(ps)</span></span>;    <span class="hljs-comment">// 释放内存 -&gt; 其内部调用 free(ps)</span></code></pre><h4 id="5-动态分配所得的内存块"><a href="#5-动态分配所得的内存块" class="headerlink" title="5. 动态分配所得的内存块"></a>5. 动态分配所得的内存块</h4><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span>&#123;</span>...<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">double</span> re, im;&#125;;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">String</span>&#123;</span>...<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">char</span>* m_data;&#125;;</code></pre><pre><code class="hljs cpp">Complex * pc = <span class="hljs-keyword">new</span> Complex(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>);String * ps = <span class="hljs-keyword">new</span> String(<span class="hljs-string">&quot;Hello!&quot;</span>);</code></pre><p>(1)  内存的分配情况</p><ul><li>实际所占用的内存    complex: (4*2)  string: (4)                                绿色部分</li><li>debug header     (32+4)                           -&gt; 在 debug 模式下才有       灰色部分</li><li>字节对齐           complex:(3/0)   string: (0/1)   -&gt; 调整为8的倍数             青色部分</li><li>上下cookies       (4*2)                                                      粉红色部分</li></ul><p><img src="/2021/01/10/CPP-review/3.png" style="zoom:35%;"></p><p>(2)  动态分配数组所得的 array</p><pre><code class="hljs cpp">Complex * p = <span class="hljs-keyword">new</span> Complex[<span class="hljs-number">3</span>];String * p = <span class="hljs-keyword">new</span> String[<span class="hljs-number">3</span>];</code></pre><ul><li>实际所占用的内存(含有一个整数来标记数组的长度)    complex: (3*4*2+4)   string: (4*3+4)    灰色部分+中间白色</li><li>debug header     (32+4)                         → 在 debug 模式下才有             黄色部分</li><li>字节对齐           complex:(2/3)   string: (1/1)  → 调整为8的倍数                    青色部分</li><li>上下cookies       (4*2)                                                             上下白色部分</li></ul><p><img src="/2021/01/10/CPP-review/4.png" style="zoom:35%;"></p><p>(2) arrary new 一定要搭配 array delete </p><p>如果 delete 的时候没有使用 []， 则之后调用一次析构函数， 默认只删除了 array[0]。 对于数组的其他元素则没有删除。 会造成内存泄漏。</p><p><img src="/2021/01/10/CPP-review/5.png" style="zoom:35%;"></p><h4 id="6-简述一下-new、delete、malloc、free-的关系"><a href="#6-简述一下-new、delete、malloc、free-的关系" class="headerlink" title="6. 简述一下 new、delete、malloc、free 的关系?"></a>6. 简述一下 new、delete、malloc、free 的关系?</h4><p>​        malloc 与 free 是C++/C 语言标准库函数， new/delete 是C++ 的运算符， 他们分别用于申请动态内存(malloc)和释放内存(free)。<br>​        对于非内部数据类型的对象而言，对象在创建的同时要自动执行构造函数， 对象在消亡之前要自动执行析构函数。 由于malloc/free 是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于 malloc/free， 所以只用 malloc/free 无法满足动态对象的要求。 因此， C++ 语言需要一个能完成动态内存分配和初始化工作的运算符 new, 以及一个能完成清理和释放内存工作的运算符 delete。<br>​        实际上， new 首先调用 operator new 函数申请空间(底层通过 malloc 实现)，然后调用构造函数进行初始化，最后返回自定义类型的指针; delete 首先调用析构函数，然后调用 operator delete 释放空间(底层通过 free 实现)。</p><h2 id="四-OOP-Object-Oriented-Programming"><a href="#四-OOP-Object-Oriented-Programming" class="headerlink" title="四. OOP(Object Oriented Programming)"></a>四. OOP(Object Oriented Programming)</h2><p>​        面向对象谈的是对象和对象之间的关系，对象是由类派生而来，所以其实质是类和类之间的关系。<strong>常见的类之间的关系有三种：Inheritance 继承、Composition 组合 和 Delegation 委托。</strong></p><h4 id="1-composition-复合-：-has-a"><a href="#1-composition-复合-：-has-a" class="headerlink" title="1. composition(复合) ： has-a"></a>1. composition(复合) ： has-a</h4><p>(1) 代码示例</p><pre><code class="hljs cpp"><span class="hljs-comment">// 这里体现了 23 个设计模式中的  -- adapter: 利用一个类来实现另一个类</span><span class="hljs-comment">// queue 里面有一个 deque, 这种关系叫做 composition 复合</span><span class="hljs-comment">// queue 借用 deque 的已有的实现来实现自己</span><span class="hljs-keyword">template</span> &lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">T</span>&gt;</span><span class="hljs-class"><span class="hljs-title">class</span> <span class="hljs-title">queue</span> &#123;</span>    ...<span class="hljs-keyword">protected</span>:    <span class="hljs-built_in">deque</span>&lt;T&gt; c;  <span class="hljs-comment">// 底层容器</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">// 以下完全利用 c 的操作完成</span>    <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">empty</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> c.empty(); &#125;    <span class="hljs-function">size_type <span class="hljs-title">size</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> c.size(); &#125;    <span class="hljs-function">reference <span class="hljs-title">front</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> c.front(); &#125;   <span class="hljs-function">reference <span class="hljs-title">back</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> c.back(); &#125;   <span class="hljs-comment">//</span>   <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-keyword">const</span> value_type&amp; x)</span> </span>&#123; c.push_back(x); &#125;   <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;c.pop_front(); &#125; &#125;;</code></pre><p>(2) 复合的 UML 表示</p><p><img src="/2021/01/10/CPP-review/6.png" style="zoom:35%;"></p><p>(3) 内存表示</p><p><img src="/2021/01/10/CPP-review/7.png" style="zoom:35%;"></p><p>(4)  Composition(复合) 关系下的构造和析构</p><p>  构造由内而外： Container 的构造函数首先调用 Component 的 default 构造函数，然后才执行自己。</p><pre><code class="hljs cpp">Container::Container(...):Component() &#123; ... &#125;;</code></pre><p>析构由外而内: Container 的析构函数首先执行自己，然后才调用 Component 的析构函数。</p><pre><code class="hljs cpp">Container::~Container(...)&#123; ... ~Component() &#125;;</code></pre><h4 id="2-Delegation-委托-：Compostion-by-reference"><a href="#2-Delegation-委托-：Compostion-by-reference" class="headerlink" title="2. Delegation(委托) ：Compostion by reference"></a>2. Delegation(委托) ：Compostion by reference</h4><p>(1) 示例代码:</p><pre><code class="hljs cpp"><span class="hljs-comment">// 这个示例体现了设计模式中的 handle/Body(pImpl)  point to implementation</span><span class="hljs-comment">// String 有一个 StringRep， 但是这个 &quot;有&quot; 是通过指针来实现的</span><span class="hljs-comment">// 一个类的真正的实现通过另一个类来实现，该类只是对外的接口， </span><span class="hljs-comment">// 当该类需要某个行为的时候，都调用另一个类的函数来服务</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StringRep</span>;</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">String</span>&#123;</span>    <span class="hljs-keyword">public</span>:        String();        String(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* s);        String(<span class="hljs-keyword">const</span> String&amp; s);        String &amp;<span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> String&amp; s);        ~String();...<span class="hljs-keyword">private</span>:    StringRep* rep; <span class="hljs-comment">// piml</span>&#125;<span class="hljs-comment">// file String.cpp </span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;String.hpp&quot;</span> </span><span class="hljs-keyword">namespace</span> &#123; <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StringRep</span> &#123;</span><span class="hljs-keyword">friend</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">String</span>;</span>     StringRep(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* s);     ~StringRep();     <span class="hljs-keyword">int</span> count;     <span class="hljs-keyword">char</span>* rep; &#125;; &#125;String::String()&#123; ... &#125; ...</code></pre><p>(2) UML 表示</p><p><img src="/2021/01/10/CPP-review/8.png" style="zoom:35%;"></p><h4 id="3-Inheritance-继承-表示-is-a"><a href="#3-Inheritance-继承-表示-is-a" class="headerlink" title="3. Inheritance(继承) 表示 is-a"></a>3. Inheritance(继承) 表示 is-a</h4><p><strong>函数的继承继承的是调用权！</strong></p><p>(1) 示例代码:</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">struct</span> _<span class="hljs-title">List_node_base</span> _<span class="hljs-title">List_node_base</span> &#123;</span>    _List_node_base* _M_next;    _List_node_base* _M_prev; &#125;;<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> _Tp&gt; <span class="hljs-class"><span class="hljs-keyword">struct</span> _<span class="hljs-title">List_node</span> :</span> <span class="hljs-keyword">public</span> _List_node_base&#123;    _Tp _M_data; &#125;;</code></pre><p>(2) UML 表示和内存表示</p><p><img src="/2021/01/10/CPP-review/9.png" style="zoom:35%;"></p><p>！base class 的 dtor 必须是 virtual ， 否则会出现undefined behavior</p><p>(3)  <strong>Inheritance(继承)关系下的构造和析构</strong></p><p>构造由内而外：Derived 的构造函数必须调用 Base 的 default 构造函数， 然后才执行自己。</p><pre><code class="hljs cpp">Derived::Derived(...): Base() &#123;...&#125;;</code></pre><p>析构由外而内: Derived 的析构函数首先执行自己，然后才调用 Base 的析构函数。</p><pre><code class="hljs cpp">Derived::~Derived(...)&#123;... ~Base() &#125;</code></pre><p><strong>(4) Inheritance(继承) + Composition(复合)</strong></p><p>构造由内而外：Derived 的构造函数首先调用 <strong>Base</strong> 的 default 构造函数， 然后调用 <strong>Component</strong> 的 default 构造函数，然后才执行自己。</p><pre><code class="hljs cpp">Derived::Derived(...): Base()，Component()  &#123;...&#125;;</code></pre><p>析构由外而内: Derived 的析构函数首先执行自己， 然后调用 <strong>Component</strong> 的析构函数， 然后调用 Base 的析构函数。</p><pre><code class="hljs cpp">Derived::~Derived(...)&#123;... ~Component(), ~Base() &#125;</code></pre><h4 id="4-基于-Delegation-委托-和-Inheritance-继承-的设计模式"><a href="#4-基于-Delegation-委托-和-Inheritance-继承-的设计模式" class="headerlink" title="4. 基于 Delegation(委托) 和 Inheritance(继承) 的设计模式"></a>4. 基于 Delegation(委托) 和 Inheritance(继承) 的设计模式</h4><h5 id="4-1-观察者模式"><a href="#4-1-观察者模式" class="headerlink" title="4.1  观察者模式"></a>4.1  观察者模式</h5><p>​        观察者组合到某个对象中，当更新的时候，通知观察者。 如下所示：Observer 和 Subject 是 Delegation 关系， 另外 Observer 可以作为父类，派生出许多子类, 并且子类可以组合到 Subject 类中。</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Observer</span>&#123;</span>    <span class="hljs-keyword">public</span>:        <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">update</span><span class="hljs-params">(Subject* sub, <span class="hljs-keyword">int</span> value)</span> </span>= <span class="hljs-number">0</span>;&#125;;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Subject</span>&#123;</span>    <span class="hljs-keyword">int</span> m_value;    <span class="hljs-built_in">vector</span>&lt;Observer *&gt; m_views;<span class="hljs-keyword">public</span>:    <span class="hljs-comment">// 添加观察者</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">attach</span><span class="hljs-params">(Observer* obs)</span></span>&#123;        m_views.push_back(obs);    &#125;        <span class="hljs-comment">// 更新数据， 将该数据 更新到所有的观察者</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">set_val</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span></span>&#123;        m_value = value;        notify();    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">notify</span><span class="hljs-params">()</span></span>&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m_views.size(); ++i)&#123;            m_views[i]-&gt;update(<span class="hljs-keyword">this</span>, m_value);        &#125;    &#125;    <span class="hljs-comment">// 删除操作 </span>    <span class="hljs-comment">// ...</span>&#125;</code></pre><h5 id="4-2-composite-复合"><a href="#4-2-composite-复合" class="headerlink" title="4.2 composite(复合)"></a>4.2 composite(复合)</h5><p>​    如下图所示， 父类为 Component， 两个子类均继承自 Component。 然后 Primitive 和 Composite 为委托关系。</p><p><img src="/2021/01/10/CPP-review/10.png" style="zoom:35%;"></p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Component</span> &#123;</span>    <span class="hljs-keyword">int</span> value; <span class="hljs-keyword">public</span>:    Component(<span class="hljs-keyword">int</span> val) &#123; value = val; &#125;    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">add</span><span class="hljs-params">( Component* )</span> </span>&#123; &#125; &#125;;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Primitive</span>:</span> <span class="hljs-keyword">public</span> Component &#123; <span class="hljs-keyword">public</span>:    Primitive(<span class="hljs-keyword">int</span> val): Component(val) &#123;&#125; &#125;;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Composite</span>:</span> <span class="hljs-keyword">public</span> Component &#123;    <span class="hljs-built_in">vector</span> &lt;Component*&gt; c; <span class="hljs-keyword">public</span>:    Composite(<span class="hljs-keyword">int</span> val): Component(val) &#123; &#125;   <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">add</span><span class="hljs-params">(Component* elem)</span> </span>&#123;       c.push_back(elem);    &#125;    <span class="hljs-comment">// ...</span>&#125;;</code></pre><h5 id="4-3-prototype"><a href="#4-3-prototype" class="headerlink" title="4.3 prototype"></a>4.3 prototype</h5><p>​     考虑如下一种情况，需要一个继承体系，父类(抽象类)想要去创建未来才会出现的子类。其中父类由框架编写者编写，子类则由其他开发者编写。 解决方法为：让派生类创建自身，让父类有办法看到子类(注册)，并进行复制。</p><p>父类如何做: (1) 实现 findAndClone: 实现子类的创建 (2) addPrototype 函数， 实现注册</p><p>子类如何做?  </p><p>(1) 声明一个静态对象，然后将构造函数声明为私有，并在其中进行注册(调用 addPrototype)。</p><p>如下所示的 _LSAT: LandSatImage 和 -LandSatImage()，在其中调用了 addPrototype 进行注册。</p><p>(2) 实现 clone 函数，然后借助一个 protected 的 构造函数返回新建对象。</p><p>如下所示的 clone 函数，借助于 #LandSatImage(int) 新建对象并返回。</p><p><img src="/2021/01/10/CPP-review/11.png" style="zoom:35%;"></p><h4 id="5-Inheritance-继承-with-virtual-functions-虚函数"><a href="#5-Inheritance-继承-with-virtual-functions-虚函数" class="headerlink" title="5. Inheritance(继承) with virtual functions(虚函数)"></a>5. Inheritance(继承) with virtual functions(虚函数)</h4><h5 id="5-1-虚函数和纯虚函数"><a href="#5-1-虚函数和纯虚函数" class="headerlink" title="5.1 虚函数和纯虚函数"></a>5.1 虚函数和纯虚函数</h5><p>(1)  成员函数可以分为三类：</p><ul><li>非虚函数: 你并不希望 derived class(子类)  重新定义(override, 覆写/重写) 它。</li><li>虚函数: (在函数前添加 virtual)：你希望 derived class 重新定义(override, 覆写/重写) 它， 并且它已有默认定义。</li><li>春旭函数函数: 你希望 derived class 一定要重新定义(override, 覆写/重写)它， 你对它没有默认定义。</li></ul><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Shape</span>&#123;</span>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">draw</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>= <span class="hljs-number">0</span>;   <span class="hljs-comment">// pure virtual</span>  <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">error</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>&amp; msg)</span></span>;   <span class="hljs-comment">// impure virtual</span>  <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">objectID</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;   <span class="hljs-comment">// non-virtual  </span>&#125;;</code></pre><p>重载(overload)、覆盖( 重写override) 的区别是什么?</p><ul><li><p>overload 重载: 在 C++ 程序中，可以将语义、功能相似的几个函数用同一个名字表示，但参数不同(包括类型、顺序、个数不同)。重载的调用时根据参数列表来决定调用哪一个函数。其特征是：</p><p> 相同的范围(在同一个类中), 函数名字相同, 参数不同)</p></li><li><p>override 覆盖: 是指派生类函数覆盖基类函数。覆盖的调用时根绝对象类型的不同决定调用哪一个。特征是：</p><p> 不同的范围(分别位于派生类与基类); 函数名字相同; 参数相同; 基类函数必须有 virtual 关键字</p></li></ul><h5 id="5-2-模板方法-Template-method"><a href="#5-2-模板方法-Template-method" class="headerlink" title="5.2 模板方法 Template method"></a>5.2 模板方法 Template method</h5><p>​        借助于虚函数和多态，可以实现模板方法：父类把其中的一个动作写成虚函数，延缓到子类来进行实现，在调用时通过子类进行调用。 这就是著名的 Template method。</p><pre><code class="hljs cpp"><span class="hljs-comment">// 开发者实现的内容: 对于没有办法写出的 Serialize()， 所以将其定义为虚函数 </span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> <span class="hljs-built_in">std</span>;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CDocument</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">OnFileOpen</span><span class="hljs-params">()</span></span>&#123;         <span class="hljs-comment">// 这是个算法， 每个cout 输出代表一个实际动作</span>         <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;dialog ...&quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;         <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;check file status ... &quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;         <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;open file ... &quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;         Serialize();         <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;close file ... &quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;         <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;update all views ... &quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;    &#125;        <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Serialize</span><span class="hljs-params">()</span> </span>&#123;&#125;;  &#125;;<span class="hljs-comment">// 使用者继承父类，并自己去实现 Serialize() 函数</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CMyDoc</span>:</span> <span class="hljs-keyword">public</span> CDocument&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Serilize</span><span class="hljs-params">()</span></span>&#123;        <span class="hljs-comment">// 只有应用程序本身才知道如何读取文件</span>        <span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;CMyDoc::Serialize() &quot;</span> &lt;&lt; <span class="hljs-built_in">endl</span>;    &#125;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    CMyDoc myDoc;    <span class="hljs-comment">// 假设对应(File/Open)</span>    myDoc.OnFileOpen();&#125;</code></pre><h4 id="6-虚指针-和-虚表"><a href="#6-虚指针-和-虚表" class="headerlink" title="6. 虚指针 和 虚表"></a>6. 虚指针 和 虚表</h4><p>(1) 只要类有虚函数，其含有成员就有一个虚指针， 指向虚表， 然后在运行时，通过这个虚指针，找到这个虚表，进而调用这个函数</p><p><img src="/2021/01/10/CPP-review/12.png" style="zoom:35%;"></p><p>(2) 动态绑定要满足三个条件: 子类成员函数声明为虚函数、指针向上转型、调用虚函数</p><p>(3) 动态绑定 与静态绑定的区别：</p><ul><li><p>静态绑定和动态绑定的主要区别在于：在什么时候将函数实现和函数调用关联起来，是在编译期间还是运行期间。</p></li><li><p>静态绑定是指在编译期间就可以确定函数的调用地址，并产生代码。也就是说函数调用地址是早早绑定的。 其代码直接编译为：<br> <code>call xxxx</code></p></li><li><p>动态绑定的函数调用的地址不能在编译期间确定，需要等到运行时才确定，这被叫做延迟绑定。动态绑定往往通过虚函数来实现，虚函数允许派生类重新定义成员函数，而派生类重新定义基类成员函数并实现动态绑定。动态绑定的代码一般编译为 <code>call dword ptr [edx]</code>。这里不再是一个固定的地址，而是通过虚指针找到虚表，然后找到第 n 个函数， 然后将其当做函数指针进行调用。</p></li></ul><h2 id="五-泛型编程"><a href="#五-泛型编程" class="headerlink" title="五. 泛型编程"></a>五. 泛型编程</h2><p>模板 template</p><h4 id="1-函数模板"><a href="#1-函数模板" class="headerlink" title="1. 函数模板"></a>1. 函数模板</h4><pre><code class="hljs cpp"><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span>&#123;</span>   ....   T re,im;&#125;<span class="hljs-function"><span class="hljs-built_in">complex</span>&lt;<span class="hljs-keyword">double</span>&gt; <span class="hljs-title">c1</span><span class="hljs-params">(<span class="hljs-number">2.5</span>,<span class="hljs-number">1.5</span>)</span></span>;</code></pre><h4 id="2-类模板"><a href="#2-类模板" class="headerlink" title="2. 类模板"></a>2. 类模板</h4><pre><code class="hljs cpp"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T&gt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">complex</span> &#123;</span> <span class="hljs-keyword">public</span>:    <span class="hljs-built_in">complex</span> (T r = <span class="hljs-number">0</span>, T i = <span class="hljs-number">0</span>) : re (r), im (i) &#123; &#125;     <span class="hljs-built_in">complex</span>&amp; <span class="hljs-keyword">operator</span> += (<span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp;);     <span class="hljs-function">T <span class="hljs-title">real</span> <span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> re; &#125;     <span class="hljs-function">T <span class="hljs-title">imag</span> <span class="hljs-params">()</span> <span class="hljs-keyword">const</span> </span>&#123; <span class="hljs-keyword">return</span> im; &#125;<span class="hljs-keyword">private</span>:    T re, im;    <span class="hljs-keyword">friend</span> <span class="hljs-built_in">complex</span>&amp; __doapl (<span class="hljs-built_in">complex</span>*, <span class="hljs-keyword">const</span> <span class="hljs-built_in">complex</span>&amp;); &#125;;<span class="hljs-comment">// 调用</span>&#123;    <span class="hljs-function"><span class="hljs-built_in">complex</span>&lt;<span class="hljs-keyword">double</span>&gt; <span class="hljs-title">c1</span><span class="hljs-params">(<span class="hljs-number">2.5</span>,<span class="hljs-number">1.5</span>)</span></span>; c2(<span class="hljs-number">2</span>,<span class="hljs-number">6</span>);    <span class="hljs-built_in">complex</span>&lt;<span class="hljs-keyword">int</span>&gt; ...&#125;</code></pre><h4 id="3-函数模板"><a href="#3-函数模板" class="headerlink" title="3. 函数模板"></a>3. 函数模板</h4><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">stone</span>&#123;</span> <span class="hljs-keyword">public</span>:    stone(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> h, <span class="hljs-keyword">int</span> we)    : _w(w), _h(h), _weight(we) &#123;  &#125;<span class="hljs-keyword">bool</span> <span class="hljs-keyword">operator</span>&lt; (<span class="hljs-keyword">const</span> stone&amp; rhs) <span class="hljs-keyword">const</span>&#123;     <span class="hljs-keyword">return</span> _weight &lt; rhs._weight;&#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">int</span> _w, _h, _weight;&#125;;<span class="hljs-keyword">template</span> &lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">T</span>&gt;</span><span class="hljs-class"><span class="hljs-title">inline</span> <span class="hljs-title">const</span> <span class="hljs-title">T</span>&amp; <span class="hljs-title">min</span>(<span class="hljs-title">const</span> <span class="hljs-title">T</span>&amp; <span class="hljs-title">a</span>, <span class="hljs-title">const</span> <span class="hljs-title">T</span>&amp; <span class="hljs-title">b</span>)&#123;</span>    <span class="hljs-keyword">return</span> b &lt; a ? b : a;  <span class="hljs-comment">// 需要类 T 对 &lt; 进行函数重载 </span>&#125;<span class="hljs-comment">// 调用</span>stone r1(2,3), r2(3,3), r3;r3 = min(r1, r2);  <span class="hljs-comment">// 参数推导的结果，T 为 stone，于是调用 stone::operator &lt;</span></code></pre><h2 id="六、C-11"><a href="#六、C-11" class="headerlink" title="六、C++11"></a>六、C++11</h2><h4 id="1-namespace"><a href="#1-namespace" class="headerlink" title="1. namespace"></a>1. namespace</h4><p>通过 namespace 将代码包起来，防止冲突</p><p>当使用的时候可以有两种:</p><ul><li>using directive:  using namespace std;    cin;  cout</li><li>usding declaration：  std::cout;  std::cin;</li></ul><h4 id="2-auto"><a href="#2-auto" class="headerlink" title="2. auto"></a>2. auto</h4><pre><code class="hljs cpp"><span class="hljs-built_in">list</span>&lt;<span class="hljs-built_in">string</span>&gt; c:<span class="hljs-keyword">auto</span> ite = find(c.begin(), c.end(), target);</code></pre><h4 id="3-ranged-base-for"><a href="#3-ranged-base-for" class="headerlink" title="3. ranged-base for"></a>3. ranged-base for</h4><pre><code class="hljs cpp"><span class="hljs-keyword">for</span>(decl : coll)&#123;    statement&#125;<span class="hljs-comment">// 例如</span><span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i: &#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>&#125;)&#123;    <span class="hljs-built_in">cout</span> &lt;&lt; i &lt;&lt; <span class="hljs-built_in">endl</span>;&#125;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">double</span>&gt; vec;...<span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> elem : vec)&#123;    <span class="hljs-built_in">cout</span> &lt;&lt; elem &lt;&lt; <span class="hljs-built_in">endl</span>;  <span class="hljs-comment">// pass by value</span>&#125;<span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> &amp; elem: vec)&#123;  <span class="hljs-comment">// pass by reference</span>    elem *= <span class="hljs-number">3</span>;&#125;</code></pre><h4 id="4-variadic-templates"><a href="#4-variadic-templates" class="headerlink" title="4. variadic templates"></a>4. variadic templates</h4><h2 id="七-STL-容器"><a href="#七-STL-容器" class="headerlink" title="七. STL 容器"></a>七. STL 容器</h2><h2 id="八、常见问题"><a href="#八、常见问题" class="headerlink" title="八、常见问题 ?"></a>八、常见问题 ?</h2><h4 id="1-class-和-struct-的区别"><a href="#1-class-和-struct-的区别" class="headerlink" title="1. class 和 struct 的区别?"></a>1. class 和 struct 的区别?</h4><p>class 和 struct 的区别在于 class 默认的成员是 private，而 struct 默认的成员是 public 类型的</p><h4 id="2-quot-xx-quot-和-lt-xx-gt-的引用方式的区别"><a href="#2-quot-xx-quot-和-lt-xx-gt-的引用方式的区别" class="headerlink" title="2. &quot;xx&quot; 和 &lt;xx&gt; 的引用方式的区别!"></a>2. <code>&quot;xx&quot;</code> 和 <code>&lt;xx&gt;</code> 的引用方式的区别!</h4><p><code>&lt;&gt;</code> 先去系统目录中找头文件，如果没有在到当前目录下找。所以像标准的头文件 stdio.h、stdlib.h等用这个方法。</p><p>而 <code>&quot; &quot;</code> 首先在当前目录下寻找，如果找不到，再到系统目录中寻找。 这个用于include自定义的头文件，让系统优先使用当前目录中定义的</p><h4 id="3-private、public-和-protected-的继承体系"><a href="#3-private、public-和-protected-的继承体系" class="headerlink" title="3. private、public 和 protected 的继承体系?"></a>3. private、public 和 protected 的继承体系?</h4><h4 id="4-单例模式-Singleton-中需要将-constructor-放在-private-中-试实现一个单例模式"><a href="#4-单例模式-Singleton-中需要将-constructor-放在-private-中-试实现一个单例模式" class="headerlink" title="4. 单例模式 (Singleton) 中需要将 constructor 放在 private 中, 试实现一个单例模式?"></a>4. 单例模式 (Singleton) 中需要将 constructor 放在 private 中, 试实现一个单例模式?</h4><h4 id="5-从空间大小、碎片问题、生成方向、分配方式和分配效率对栈和堆进行比较："><a href="#5-从空间大小、碎片问题、生成方向、分配方式和分配效率对栈和堆进行比较：" class="headerlink" title="5. 从空间大小、碎片问题、生成方向、分配方式和分配效率对栈和堆进行比较："></a>5. 从空间大小、碎片问题、生成方向、分配方式和分配效率对栈和堆进行比较：</h4><p>(1) 空间大小<strong>：</strong>一般来讲在 32 位系统下，堆内存可以达到 4G 的空间<strong>。但是</strong>对于栈来讲，一般都是有一定的空间大小的，例如，在 VC6 下面，默认的栈空间大小是 1M（好像是，记不清楚了）。</p><p>(2) 碎片问题：对于堆来讲，频繁的 new/delete 势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低<strong>。</strong>对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，以至于永远都不可能有一个内存块从栈中间弹出。</p><p>(3) 生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。</p><p>(4) 分配方式<strong>：</strong>堆都是动态分配的，没有静态分配的堆<strong>。</strong>栈有 2 种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由 alloca 函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。</p><p>(5) 分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是 C/C++函数库提供的，它的机制很复杂，堆的效率比栈要低得多</p><h2 id="TBD"><a href="#TBD" class="headerlink" title="TBD"></a>TBD</h2><p>四种类型转换：static_cast, dynamic_cast, const_cast, reinterpret_cast</p><p>模板特化、偏特化，萃取 traits 技巧</p><p>继承、虚继承、菱形继承等</p><p>volatile、extern</p><p>智能指针原理：引用计数、RAII（资源获取即初始化）思想</p><p>智能指针使用：shared_ptr、weak_ptr、unique_ptr等</p><p>C++11 部分新特性，比如右值引用、完美转发等</p><p><strong>转换函数</strong></p><p>​    类型转换运算符(conversion operator) 是类的一种特殊成员函数， 它负责将一个类类型的值转换未其他类型。 其一般形式如下所示:</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">operator</span> <span class="hljs-title">type</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;</code></pre><p>​    其中 type 表示某种类型。 类型转换运算符可以面向任意类型进行定义， 只要该类型能够作为函数的返回类型。 因此我们不允许转换成数组或者函数类型， 但允许转换成指针或者引用类型。</p><p>​    类型转换运算符既没有显式的返回类型， 也没有形参， 而且必须定义成类的成员函数。 类型转换运算符通常不应该改变待转换对象的内容， 因此， 类型转换运算符一般被定义成 const 成员。</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Fraction</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    Fraction(<span class="hljs-keyword">int</span> num, <span class="hljs-keyword">int</span> den = <span class="hljs-number">1</span>)    : m_numerator(num), m_denominator(den) &#123;&#125;    <span class="hljs-function"><span class="hljs-keyword">operator</span> <span class="hljs-title">double</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>&#123;        <span class="hljs-keyword">return</span> (<span class="hljs-keyword">double</span>) (m_numerator / m_denominator);    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">int</span> m_numerator; <span class="hljs-comment">// 分子</span>    <span class="hljs-keyword">int</span> m_denominator;  <span class="hljs-comment">// 分母</span>&#125;<span class="hljs-comment">// 调用</span><span class="hljs-function">Fraction <span class="hljs-title">f</span><span class="hljs-params">(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)</span></span>;<span class="hljs-keyword">double</span> d = <span class="hljs-number">4</span> + f; <span class="hljs-comment">// 调用 operator double() 将 f 转换为 0.6</span></code></pre><p><strong>explicit</strong></p><p>​    当我们使用 explicit 关键字声明构造函数时， 它只能以直接初始化的形式使用。 而且， 编译器将不会再自动转换过程中使用该构造函数。 考虑如下应用场景：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Fraction</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    Fraction(<span class="hljs-keyword">int</span> num, <span class="hljs-keyword">int</span> den = <span class="hljs-number">1</span>)    : m_numerator(num), m_denominator(den) &#123;&#125;    <span class="hljs-function"><span class="hljs-keyword">operator</span> <span class="hljs-title">double</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>&#123;        <span class="hljs-keyword">return</span> (<span class="hljs-keyword">double</span>) (m_numerator / m_denominator);    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">int</span> m_numerator; <span class="hljs-comment">// 分子</span>    <span class="hljs-keyword">int</span> m_denominator;  <span class="hljs-comment">// 分母</span>&#125;<span class="hljs-comment">// 调用</span><span class="hljs-function">Fraction <span class="hljs-title">f</span><span class="hljs-params">(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)</span></span>;<span class="hljs-keyword">double</span> d = f + <span class="hljs-number">4</span>; <span class="hljs-comment">// Error: ambiguous</span><span class="hljs-comment">// 产生二义性的原因:</span><span class="hljs-comment">// 可以使用构造函数，将 4 转换为 Fraction， 然后两者进行相加</span><span class="hljs-comment">// 也可以将 f 转换为 double, 然后两个 double 相加</span><span class="hljs-comment">// 可以使用 explicit 进行声明， 在构造函数之前添加 explicit 关键字， 然后进行隐式转换。</span></code></pre><p><strong>5. 智能指针</strong></p><p>  智能指针的本质是类模板，主要是为了我们更加方便(也更加安全的)使用动态内存，它的行为类似于常规指针，重要的区别是它负责自动释放所指向的对象。</p><pre><code class="hljs cpp"><span class="hljs-keyword">template</span>&lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">T</span>&gt;</span><span class="hljs-class"><span class="hljs-title">class</span> <span class="hljs-title">shared_ptr</span>&#123;</span><span class="hljs-keyword">public</span>:    T&amp; <span class="hljs-keyword">operator</span>*() <span class="hljs-keyword">const</span> &#123; <span class="hljs-keyword">return</span> * px; &#125;    T* <span class="hljs-keyword">operator</span>-&gt;() <span class="hljs-keyword">const</span> &#123;<span class="hljs-keyword">return</span> px; &#125;        <span class="hljs-built_in">shared_ptr</span>(T*p): px(p) &#123;&#125;<span class="hljs-keyword">private</span>:    T* px;    <span class="hljs-keyword">long</span> * pn;    ...&#125;</code></pre>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>transformer-for-vision-task</title>
    <link href="/2020/12/15/transformer-for-vision-task/"/>
    <url>/2020/12/15/transformer-for-vision-task/</url>
    
    <content type="html"><![CDATA[<p>transformer 是一种新提出的神经网络组件， 主要利用注意力机制来提取内在特征。本文主要介绍了视觉方向上 transformer 的应用。</p><a id="more"></a><p>本文先从 transformer 的基本组件 self-attention 入手， 介绍 self-attention 机制并逐渐展开至 transformer 模型。 然后在 计算机视觉领域挑选了四个重要的模型：ViT(classification)、DETR(detection)、D-DETR(detection) 和 TTSR(super resolution) 进行分享。最后阐述一些高效的 transformer 机制。</p><h3 id="1-transformer-的提出-attention-is-all-your-need"><a href="#1-transformer-的提出-attention-is-all-your-need" class="headerlink" title="1. transformer 的提出 : attention is all your need"></a>1. transformer 的提出 : attention is all your need</h3><p>transformer 在 NLP 领域应用有三个重要的节点：</p><ul><li>2017年06月：首次完全基于注意力机制的 transformer， 并将其用于机器翻译和英语分析任务，发表于论文《 Attention is all your need 》。这是 transformer 的起点， 也是本文介绍的重点。</li><li>2018年10月：引入了一种新的语言表示模型，称为 BERT， 通过联合调节左右上下文，从未标记的文本中预训练一个 transformer。</li><li>2020年05月： GPT-3诞生：在 45TB 的纯文本数据上预训练了一个具有 1750 亿超参数的巨型 transformer 模型 GPT-3。这个模型在不进行微调的情况下，在不同的自然语言任务上实现了强大的性能。</li></ul><h4 id="1-1-vanilla-transformer"><a href="#1-1-vanilla-transformer" class="headerlink" title="1.1 vanilla transformer"></a>1.1 vanilla transformer</h4><p>​        原始的 transformer 用于进行机器翻译任务， 其模型如下图所示， 它由一系列的 encoder 和 decoder 组成。 每个 encoder 由 self-attention 层和 feed forward nn 组成， 每个 decoder 则是由 self-attention、encoder-decoder attention 和 feed forward nn 组成。 在输入之前先将句子中的每个单词 embedding 为固定维度的向量， 然后经过 encoder-decoder 进行编解码，最后将输出的向量重新编码为一个 个单词组成句子， 从而完成翻译任务。图中的 encoder 中的 Self-Attention 和 decoder 中的 Encoder-Decode Attention 和几乎相同， 只是输入有所差别。</p><p><img src="/2020/12/15/transformer-for-vision-task/1.png" style="zoom:45%;"></p><h4 id="1-2-self-attention-layer"><a href="#1-2-self-attention-layer" class="headerlink" title="1.2 self attention layer"></a>1.2 self attention layer</h4><p>参考实现： <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">http://nlp.seas.harvard.edu/2018/04/03/attention.html</a></p><p>​        self attention 机制可以描述为将一个查询 query 和一组键值对 key-val 映射到一个输出 output，其中 query、key、val 和 output 都是向量。输出 output 是以值的加权和来计算的，其中分配给每个值的权重 weight 是由 query 与对应 key 的相似度计算出来的。其具体的操作如下所示：</p><p><img src="/2020/12/15/transformer-for-vision-task/self-attention.png" style="zoom:30%;"></p><p>​        在 self-attention 层， 首先将输入 vector 转化为三个不同的 vector， 这三个向量被称为 query vector(to match others) , key vector(to be matched) 和 value vector(information to be  extracted)。将这三个向量打包为 Q、V、K 三个矩阵。在此之后，执行如下步骤:</p><p>Setp 1：计算不同输入之间的分数， 这里记为: $S = Q \cdot K^T$</p><p>Step 2：梯度标准化：$S_n = S / \sqrt{d_K}$</p><p>Step 3:  借助 softmax 将分数转化概率  $P = softmax(S_n)$</p><p>Step 4:  将 P 作为权重，乘以 V 矩阵  $Z = V \cdot P$</p><p>上述的处理过程可以被统一到如下的公式中：</p><script type="math/tex; mode=display">Attention(Q, K, V) = softmax(\frac{Q \cdot K^T}{\sqrt{d_K}}) \cdot V</script><p>​         该公式的解释很简单。 第1步计算两个不同向量之间的分数，该分数的含义是当前位置的单词和其他单词的关联程度。第 2 步对分数进行规范化处理，主要是使其有更稳定的梯度(点积结果较大，输入 softmax 的值较大，从而导致 梯度较小)，以达到更好的训练效果。第 3 步将分数转变成概率。第四步是将每个值向量乘以概率，概率较大的向量会被下面几层更加注意(attention)。 一个简单的 self-attention 实现如下:</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">attention</span>(<span class="hljs-params">query, key, value, mask=None, dropout=<span class="hljs-number">0.0</span></span>):</span>    d_k = query.size(<span class="hljs-number">-1</span>)    scores = torch.matmul(query, key.transpose(<span class="hljs-number">-2</span>, <span class="hljs-number">-1</span>)) / math.sqrt(d_k)    <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:        scores = scores.masked_fill(mask == <span class="hljs-number">0</span>, <span class="hljs-number">-1e9</span>)    p_attn = F.softmax(scores, dim = <span class="hljs-number">-1</span>)    <span class="hljs-comment"># (Dropout described below)</span>    p_attn = F.dropout(p_attn, p=dropout)    <span class="hljs-keyword">return</span> torch.matmul(p_attn, value), p_attn</code></pre><p>​        解码器中的 Encoder-Decode attention 和编码器中的 Self-Attention 几乎相同。不同的是矩阵 K 和 矩阵 V 来自于 编码器， 而 Q 来自上一层输出。</p><h4 id="1-2-Multi-Head-Attention"><a href="#1-2-Multi-Head-Attention" class="headerlink" title="1.2 Multi-Head Attention"></a>1.2 Multi-Head Attention</h4><p>​        为了提升 self-attention 层的性能，加入了一种叫做 multi-head attention 的机制，进一步完善了 self-attention 层。考虑我们在浏览句子的时候，对于一个给定的参考词，往往需要同时关注其他几个词， 而单头的注意力机制限定了对某一个特定位置的关注能力。多头注意力机制通过赋予注意力层不同的表示子空间来实现的。具体来说，对不同的头使用不同的查询、键和值矩阵，由于随机初始化，它们可以在训练后将输入向量投射到不同的表示子空间。</p><p><img src="/2020/12/15/transformer-for-vision-task/2.png" style="zoom:45%;"></p><p>​        在具体实现上， 通过线性函数将单个的 key， query 和 value 分裂为多个， 然后对应的 key， value 和 query 分别进行处理即可。最后将分裂的多个节点 concat， 并通过线性函数进行结合节课。</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiHeadedAttention</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, h, d_model, dropout=<span class="hljs-number">0.1</span></span>):</span>        <span class="hljs-string">&quot;Take in model size and number of heads.&quot;</span>        super(MultiHeadedAttention, self).__init__()        <span class="hljs-keyword">assert</span> d_model % h == <span class="hljs-number">0</span>        <span class="hljs-comment"># We assume d_v always equals d_k</span>        self.d_k = d_model // h        self.h = h        self.linears = clones(nn.Linear(d_model, d_model), <span class="hljs-number">4</span>)        self.attn = <span class="hljs-literal">None</span>        self.dropout = nn.Dropout(p=dropout)            <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, query, key, value, mask=None</span>):</span>        <span class="hljs-string">&quot;Implements Figure 2&quot;</span>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            <span class="hljs-comment"># Same mask applied to all h heads.</span>            mask = mask.unsqueeze(<span class="hljs-number">1</span>)        nbatches = query.size(<span class="hljs-number">0</span>)                <span class="hljs-comment"># 1) Do all the linear projections in batch from d_model =&gt; h x d_k </span>        query, key, value = \            [l(x).view(nbatches, <span class="hljs-number">-1</span>, self.h, self.d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)             <span class="hljs-keyword">for</span> l, x <span class="hljs-keyword">in</span> zip(self.linears, (query, key, value))]                <span class="hljs-comment"># 2) Apply attention on all the projected vectors in batch. </span>        x, self.attn = attention(query, key, value, mask=mask,                                  dropout=self.dropout)                <span class="hljs-comment"># 3) &quot;Concat&quot; using a view and apply a final linear. </span>        x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous() \             .view(nbatches, <span class="hljs-number">-1</span>, self.h * self.d_k)        <span class="hljs-keyword">return</span> self.linears[<span class="hljs-number">-1</span>](x)</code></pre><h4 id="1-3-position-encoding"><a href="#1-3-position-encoding" class="headerlink" title="1.3 position encoding"></a>1.3 position encoding</h4><p>​        需要注意的是，上述过程与每个词的位置无关，因此自注意力层缺乏捕捉句子中词的位置信息的能力。为了解决这个问题，在原始输入嵌入的基础上，增加一个维度为 $d_{model}$ 的位置编码，以得到单词的最终输入向量。具体来说，位置编码的公式如下：</p><script type="math/tex; mode=display">\begin{align}PE(pos, 2i) &= sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}}); \\PE(pos, 2i+1) &= cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\end{align}</script><p>这里的 $pos$ 表示单词在句子中的位置， $i$  则表示当前编码的维度。</p><h4 id="1-4-Other-Parts-in-Transformer"><a href="#1-4-Other-Parts-in-Transformer" class="headerlink" title="1.4 Other Parts in Transformer"></a>1.4 Other Parts in Transformer</h4><p>论文 《attentionis all your need》 的 encoder-decoder 模型如下所示， 接下来介绍一下其他的组成部分：</p><p><img src="/2020/12/15/transformer-for-vision-task/3.png" style="zoom:70%;"></p><ul><li><p>Residual in the encoder and decoder： 如上图所示， 在编码器和解码器的每个子层中都增加了一个残差连接，以加强信息的流动，获得更好的性能。之后再进行 layer normalization。上述运算可以描述为：</p><script type="math/tex; mode=display">layernorm(X + attention(X))</script><p>需要注意的是，这里用 $X$ 作为自关注层的输入，因为 query、key 和 value 矩阵 Q、K 和 V 都是由同一个输入矩阵 $X$ 导出的。</p></li><li><p>Feed-forward neural network：feed-forward NN 是由两个线性变换层和它们内部的 ReLU 激活函数组成的，该运算可以描述为：</p><script type="math/tex; mode=display">FFNN(X) = W_2 \sigma(W_1X)</script><p>其中 $W1$和 $W2$ 是两个线性变换层的两个参数矩阵，$\sigma$ 代表 ReLU激活函数。</p></li><li><p>Final layer in decoder：decoder 的最后一层旨在将输出的向量重新编码为一个字。它是由一个线性层和一个softmax 层实现的。线性层将向量投射成一个 $d<em>{word}$ 维度的 logits 向量，其中 $d</em>{word}$ 是词汇中的单词数。然后，用 softmax 层将 logits 向量转化为概率。</p></li></ul><h3 id="2-Computer-Vision-中的-transformer"><a href="#2-Computer-Vision-中的-transformer" class="headerlink" title="2. Computer Vision 中的 transformer"></a>2. Computer Vision 中的 transformer</h3><p>​        计算机视觉任务中使用的大多数 transformer 都利用了 transformer 的 encoder 模块。简而言之，它可以被视为一种新的特征选择器，它与卷积神经网络(CNNs)和递归神经网络(RNNs)是不同的。</p><ul><li>与 CNN只关注局部特征相比，transformer 能够捕捉长距离特征，这意味着全局信息可以很容易地通过 transformer 得到。</li><li>与 RNN 的隐藏状态必须依次计算相比，transformer 的效率更高，因为自注意层和全连接层的输出可以并行计算，容易加速。</li></ul><p>​        相比于 NLP 输入的一维序列来说， CV 领域的数据则是二维的图像矩阵。 这是两者的区别所在， 所以在最初的研究中， 主要的手段就是考虑怎么将图像转换为训练输入 transformer， 得到输出。接下来，我们从分类、检测、超分三个领域分别选取一到两个模型，对计算机视觉领域的 transformer 进行讲解。</p><h4 id="1-ViT-for-classification"><a href="#1-ViT-for-classification" class="headerlink" title="(1)  ViT for classification"></a>(1)  ViT for classification</h4><p>​    着眼于分类任务， 将图片切分为贴片序列， 将纯 transformer 直接应用于 贴片 序列</p><p>​    这篇论文是比较早的将 transformer 机制应用到 classification 领域的文章。首先，对原始图片进行分块，展平成为序列，然后将其输入进原始的 Transformer 模型的编码器 Encoder 部分，最后连接一个全连接层对图片进行分类。</p><p>github: <a href="https://github.com/lucidrains/vit-pytorch">https://github.com/lucidrains/vit-pytorch</a></p><p>Paper: <a href="https://openreview.net/pdf?id=YicbFdNTTy">An Image is worth 16X16 words: transformers for image recognition at scale</a></p><p><img src="/2020/12/15/transformer-for-vision-task/vit.gif" alt="img" style="zoom:50%;"></p><ol><li><p><strong>数据处理部分</strong>：原始输入的图片数据时 H<em>W</em>C, 我们先对图片进行分块，再进行展平。 假设每个块的长宽为(P, P), 那么分块的数目为 N = H <em> W / (P </em> P)。 图中的 N = 9， 论文中的 P = 16。对每个图片块展平成一维向量， 每个向量大小为 P <em> P </em> C， 总的输入变换为 N <em> (P^2 </em> C)。</p><pre><code class="hljs apache"><span class="hljs-attribute">x</span> = rearrange(img, &#x27;b c (h p<span class="hljs-number">1</span>) (w p<span class="hljs-number">2</span>) -&gt; b (h w) (p<span class="hljs-number">1</span> p<span class="hljs-number">2</span> c)&#x27;, p<span class="hljs-number">1</span> = p, p<span class="hljs-number">2</span> = p) # use einops的拓展包</code></pre></li><li><p><strong>Patch Embedding</strong>：使用全连接层对每一个向量都做一个线性变换， 将向量的维度压缩为D。</p><pre><code class="hljs reasonml">self.patch_to_embedding = nn.<span class="hljs-constructor">Linear(<span class="hljs-params">patch_dim</span>, <span class="hljs-params">dim</span>)</span></code></pre></li><li><p><strong>cls token + Positional Encoding</strong>：</p><ul><li><p><strong>原始的 Transformer 引入了一个 Positional encoding 来加入序列的位置信息</strong>，同样在这里也引入了pos_embedding，是<strong>用一个可训练的变量</strong>替代。</p><pre><code class="hljs angelscript">self.pos_embedding = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, num_patches + <span class="hljs-number">1</span>, dim))        x += self.pos_embedding[:, :(n + <span class="hljs-number">1</span>)]</code></pre></li><li><p>ViT 在 Transformer 输入序列前增加了一个额外可学习的 [class] 标记位，并且该位置的 Transformer Encoder 输出作为图像特征。</p><pre><code class="hljs ini"><span class="hljs-attr">self.cls_token</span> = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dim))<span class="hljs-attr">cls_tokens</span> = repeat(self.cls_token, <span class="hljs-string">&#x27;() n d -&gt; b n d&#x27;</span>, b = b)<span class="hljs-attr">x</span> = torch.cat((cls_tokens, x), dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 添加一个 </span></code></pre></li></ul></li><li><p><strong>transformer：</strong></p><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-type">Transformer</span>(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><span class="hljs-class">    # 堆叠多层的 <span class="hljs-type">Attention</span> 模块 和 <span class="hljs-type">Feed</span> <span class="hljs-type">Fordward</span></span><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>, <span class="hljs-title">dim</span>, <span class="hljs-title">depth</span>, <span class="hljs-title">heads</span>, <span class="hljs-title">mlp_dim</span>, <span class="hljs-title">dropout</span>):</span><span class="hljs-class">        super().__init__()</span><span class="hljs-class">        self.layers = nn.<span class="hljs-type">ModuleList</span>([])</span><span class="hljs-class">        for _ in range(<span class="hljs-title">depth</span>):</span><span class="hljs-class">            self.layers.append(<span class="hljs-title">nn</span>.<span class="hljs-type">ModuleList</span>([</span><span class="hljs-class">                <span class="hljs-type">Residual</span>(<span class="hljs-type">PreNorm</span>(<span class="hljs-title">dim</span>, <span class="hljs-type">Attention</span>(<span class="hljs-title">dim</span>, <span class="hljs-title">heads</span> = <span class="hljs-title">heads</span>, <span class="hljs-title">dropout</span> = <span class="hljs-title">dropout</span>))), </span><span class="hljs-class">                <span class="hljs-type">Residual</span>(<span class="hljs-type">PreNorm</span>(<span class="hljs-title">dim</span>, <span class="hljs-type">FeedForward</span>(<span class="hljs-title">dim</span>, <span class="hljs-title">mlp_dim</span>, <span class="hljs-title">dropout</span> = <span class="hljs-title">dropout</span>)))</span><span class="hljs-class">            ]))</span><span class="hljs-class">            </span><span class="hljs-class">    def forward(<span class="hljs-title">self</span>, <span class="hljs-title">x</span>, <span class="hljs-title">mask</span> = <span class="hljs-type">None</span>):</span><span class="hljs-class">        for attn, ff in self.layers:</span><span class="hljs-class">            x = attn(<span class="hljs-title">x</span>, <span class="hljs-title">mask</span> = <span class="hljs-title">mask</span>)</span><span class="hljs-class">            x = ff(<span class="hljs-title">x</span>)</span><span class="hljs-class">        return x</span></code></pre></li><li><p><strong>mlp_head:</strong>  使用 layernorm 和 全连接 实现</p><pre><code class="hljs fortran">self<span class="hljs-number">.</span>mlp_head = nn<span class="hljs-number">.</span><span class="hljs-keyword">Sequential</span>(    nn<span class="hljs-number">.</span>LayerNorm(<span class="hljs-built_in">dim</span>),    nn<span class="hljs-number">.</span>Linear(<span class="hljs-built_in">dim</span>, num_classes))</code></pre></li></ol><h4 id="2-DETR-for-detection"><a href="#2-DETR-for-detection" class="headerlink" title="(2) DETR for detection"></a>(2) DETR for detection</h4><p>​        DETR 的网络结构如下所示：</p><p><img src="/2020/12/15/transformer-for-vision-task/detr.png" style="zoom:38%;"></p><p>​        首先用 CNN 将输入图像 embedding 成一个二维表征。 并将二维表征转换为一维表征并结合 positional encoding 一起<strong>送入 transformer 进行 encoder-decoder</strong>。然后将 decoder 得到的每个 output embedding 传递到一个共享的前馈网络(FFN)。最后使用 <strong>set loss function</strong> 作为监督信号来进行<strong>端到端训练</strong>，然后同时预测所有目标。三个创新点：（1）使用 transformer （2） 使用 set loss 并抛弃了 anchor 的概念和 nms  (3) end2end。 虽说论文对标的是 faster rcnn。 但是采用新的方法去探索目标检测， 还是值得肯定的。</p><h5 id="1-backbone"><a href="#1-backbone" class="headerlink" title="1. backbone"></a>1. backbone</h5><p>​        CNN backbone 只用于提取特征。CNN backbone 处理 $X_{img} \in R^{N <em>3</em>H_0<em>W_0}$  维的图像，把它转换为 $ F \in R^{N </em> C <em> H </em> W}$ 维的feature map（一般来说 N = 2048 或 N = 256， H =  H_0 / 32，W = W_0 / 32）。 </p><p>​        通道数压缩： 用 1x1 卷积， 将 channels 数量从 C 压缩， 得到一个 $z_0 \in R^{N <em> d </em> H <em> W}$。并将其 reshape 为 $N， H</em>W, d$  维度的 feature map。</p><p>​        位置编码： 在得到 $z_0 \in R^{N <em> d </em> H * W}$  之后， 需要进行位置编码。 需要注意一点的是， 原版的 transformer 只考虑了 $x$ 方向的位置编码， 但是 DETR 考虑 $xy$ 两个方向的编码。另一点不同的是， 原版的 transformer 只在 encoder 输入处进行了 位置编码， 但是 DETR 在 encoder 的每一个 Multi-head self-attention 之前都使用了 positional encoding， 且只对 query 和 key 使用了 positional encoding。</p><h5 id="2-encoder-decoder"><a href="#2-encoder-decoder" class="headerlink" title="2. encoder-decoder"></a>2. encoder-decoder</h5><p>这里直接套用了 NLP 上的 transformer，有些许不同：</p><ul><li><p>位置向量编码要加入到 每个 encoder layer 中。</p></li><li><p>decoder 的输入添加了 object queries。Object queries是一个维度为 (100, b, 256) 维的张量，数值类型是nn.Embedding，说明这个张量是可以学习的，即：我们的Object queries是可学习的。 Object queries矩阵内部通过学习建模了 100 个物体之间的全局关系，例如房间里面的桌子旁边( A 类)一般是放椅子( B 类)，而不会是放一头大象( C 类)，那么在推理时候就可以利用该全局注意力更好的进行解码预测输出。</p></li></ul><h5 id="3-prediction-heads"><a href="#3-prediction-heads" class="headerlink" title="3.  prediction heads"></a>3.  prediction heads</h5><p>​        prediction 由 3 层 perceptron 和一层 linear projection 组成。FFN 预测出 box 的归一化 xywh 和 classes。DETR 预测的是固定数量的 N 个 box 的集合，并且 N 通常比实际目标数要大的多，所以使用一个额外的空类来表示预测得到的 box 不存在目标。 最终 DETR 输出的张量的维度为 (b, 100, class + 1) 和 (b, 100, 4)。这个 100 是个预先设定的， 远大于图中目标总数的数字。 通过这两个张量，就可以解码出对应的检测框和分类。</p><h5 id="4-bipartite-loss"><a href="#4-bipartite-loss" class="headerlink" title="4. bipartite loss"></a>4. bipartite loss</h5><p>​       使用匈牙利算法来寻找 prediction box 和 image object 匹配的总 cost 最小的二分图匹配方案。首先定义每对 prediction box 和 image object 的 cost 损失：</p><p><img src="/2020/12/15/transformer-for-vision-task/6.png" style="zoom:38%;"></p><p>简单解释一下， 如果当 image object 为空 时， 这对 cost 为 零， 当 image object 不为零时， 当(预测相同的)类别概率越大，bbox 的差距越小时， 配对的 cost 越小。 这里的 $L_{box}$ 定义为:</p><p><img src="/2020/12/15/transformer-for-vision-task/8.png" style="zoom:38%;"></p><p>​        我们就完全定义好了每对 prediction box 和 image object 配对时的cost。再利用匈牙利算法即可得到二分图最优匹配。 基于这个最优匹配，来计算 set prediction loss，即评价 transformer 生成这些 prediction boxes 的效果好坏。Set prediction loss 计算公式如下：</p><p><img src="/2020/12/15/transformer-for-vision-task/7.png" style="zoom:38%;"></p><h4 id="3-IPT"><a href="#3-IPT" class="headerlink" title="(3) IPT"></a>(3) IPT</h4><p>​        不同于高层视觉语义任务的目标是进行特征抽取，底层视觉任务的输入和输出均为图像。除超分辨率任务之外，大多数底层视觉任务的输入和输出维度相同。相比于高层视觉任务，输入和输出维度匹配这一特性使底层视觉任务更适合由 Transformer 处理。 具体而言，研究者在特征图处理阶段引入 Transformer 模块，而图像维度匹配则交给了头结构与尾结构，如下图所示：</p><p><img src="/2020/12/15/transformer-for-vision-task/9.png" style="zoom:55%;"></p><p>(1) 首先将图片经过一个头结构变换为特征图：</p><script type="math/tex; mode=display">f_H = H^i(x), f_H \in \R^{C × H × W}</script><p>(2) 对特征图进行切块与拉平操作。首先按照 P×P 的大小将特征图切割成 N 块，每一个特征块再被拉平为维度为 $P^2×C$ 的向量，这里的处理类似于 ViT 中的操作。</p><script type="math/tex; mode=display">f_{p_i} \in \R ^{P^2 × C}, i = {1, ..., N}</script><p>这样一来，每个特征向量可以等同于一个「单词」，即可送入 Transformer 进行处理，得到维度相同的输出特征：</p><script type="math/tex; mode=display">f_{D_i} \in \R^{P^2 × C}</script><p>(3) 这些输出特征再经过整形和拼接操作，还原为与输入相同维度的特征图。如此处理得到的特征图会被送入一个尾结构，被解码为目标图像。</p><p>​        头结构和尾结构负责维度变换，transformer 模块可以专心地做特征处理。这使得多任务的扩展变得简单：对于不同的任务，只需要增加新的头结构与尾结构即可，多种任务之间的 transformer 模块是共享的。为了适应多任务，研究者在 Transformer 的解码模块中加入了一个可学习的任务编码。<br>​        transformer 的成功离不开大量数据预训练带来的性能提升。在这篇论文中，针对底层视觉任务，研究者使用 ImageNet 数据集生成多种退化图像，构成多种底层视觉任务训练集。利用这些人工合成的数据，配以对应任务的多头多尾结构，多个任务的训练数据同时进行训练。训练时的损失函数则使用 L1 损失作为监督损失函数， 使用特征块之间的相关性自监督损失函数</p><h3 id="3-efficient-transformer"><a href="#3-efficient-transformer" class="headerlink" title="3. efficient transformer"></a>3. efficient transformer</h3><p>高效的 transformer</p><p>一些思考和待解决的问题</p><h3 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4. 参考资料"></a>4. 参考资料</h3><ul><li>综述 A Survey on Visual Transformer <a href="https://arxiv.org/abs/2012.12556">https://arxiv.org/abs/2012.12556</a></li><li>综述  Transformers in Vision: A Survey  <a href="https://arxiv.org/pdf/2101.01169.pdf">https://arxiv.org/pdf/2101.01169.pdf</a></li><li>The Annotated Transformer：<a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">http://nlp.seas.harvard.edu/2018/04/03/attention.html</a></li><li><a href="https://mp.weixin.qq.com/s/cY0IkHTpxS6x6cqsueXZIg">https://mp.weixin.qq.com/s/cY0IkHTpxS6x6cqsueXZIg</a></li><li>hongyi Lee transformer lecture <a href="https://www.bilibili.com/video/BV1CK4y1r7AA">https://www.bilibili.com/video/BV1CK4y1r7AA</a></li><li>Efficient Transformers: A Survey <a href="https://arxiv.org/pdf/2009.06732.pdf">https://arxiv.org/pdf/2009.06732.pdf</a></li><li><a href="https://zhuanlan.zhihu.com/p/266069794">https://zhuanlan.zhihu.com/p/266069794</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈DeepLearning落地与工程部署</title>
    <link href="/2020/12/14/%E6%B5%85%E8%B0%88DeepLearning%E8%90%BD%E5%9C%B0%E4%B8%8E%E5%B7%A5%E7%A8%8B%E9%83%A8%E7%BD%B2/"/>
    <url>/2020/12/14/%E6%B5%85%E8%B0%88DeepLearning%E8%90%BD%E5%9C%B0%E4%B8%8E%E5%B7%A5%E7%A8%8B%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>浅谈 Deep Learning 落地与工程部署问题</p><a id="more"></a><h4 id="一-概述"><a href="#一-概述" class="headerlink" title="一. 概述"></a>一. 概述</h4><ol><li>模型的的压缩加速：轻量级架构设计、剪枝、蒸馏、量化、低秩分解</li><li>框架层面<ul><li>基础优化：算子优化(conv 实现)、 图优化(DAG、op 融合)、不同精度的训练/推理</li><li>代码层：循环展开、汇编、并行优化(SIMD)</li><li>系统调度：内存优化、Cache 优化、流水线重排</li><li>计算引擎： neon、cuda、vulkan、Metal、OpenVINO、HiAI、OpenCL</li></ul></li><li>编译器：TVM 和 MLIR</li><li>硬件： arm、gpu、cpu、x86、npu</li></ol><p>几个值得关注的点：</p><ul><li>MLIR(MachineLearning Intermediate Represent) : 可以参照：MLIR(<a href="https://github.com/tensorflow/mlir)、TVM、XLA">https://github.com/tensorflow/mlir)、TVM、XLA</a></li><li>软硬件协同设计</li><li>NLP 领域的模型压缩进展</li></ul><h4 id="二-常用模型压缩与加速方法"><a href="#二-常用模型压缩与加速方法" class="headerlink" title="二. 常用模型压缩与加速方法"></a>二. 常用模型压缩与加速方法</h4><ol><li>轻量级网络设计与搜索:<ul><li>设计轻量化的网络架构，如 mobilenet 、shufflenet、ghostnet 等</li><li>使用 NAS 搜索较为高效的网络结构</li><li>模型蒸馏：使用复杂模型( teacher model) 去训练另一个轻量化的网络(student model)</li></ul></li><li>网络的压缩技术（剪枝、稀疏化、量化）<ul><li>在训练时使用稀疏约束（加入权重的稀疏正则项，引导模型的大部分权重趋向于0，然后在完成训练后，剪去滤波器上的这些权重较低的节点</li><li>量化：模型量化是指权重或激活输出可以被聚类到一些离散、低精度(reduced precision) 的数值点上。常见的有二值网络、三值网络、int8 量化</li><li>低秩分解</li></ul></li></ol><p>上述的 1 会改变网络的计算图， 而 2 则不会改变网络的计算图，而是在原有计算图的基础上进行网络模型的压缩和加速</p><h4 id="三-常见的推理框架"><a href="#三-常见的推理框架" class="headerlink" title="三. 常见的推理框架"></a>三. 常见的推理框架</h4><p>​        一般会提供模型优化和推断引擎两个模块。模型优化模块用于将给定的模型转化为标准的 Intermediate Representation (IR) ，并对模型优化。推断引擎 (Inference Engine) 则会根据特定的硬件进行算子的优化，以实现高效的前向推导。 </p><ul><li><p>国外：</p><ul><li>google：tf-lite    <a href="https://www.tensorflow.org/lite/performance/post_training_quantization">https://www.tensorflow.org/lite/performance/post_training_quantization</a></li><li>facebook：caffe2  + qnnpack: <a href="https://github.com/pytorch/QNNPACK">https://github.com/pytorch/QNNPACK</a></li><li>intel： <strong>open-vino(for intel CPU)</strong>  <a href="https://software.intel.com/en-us/openvino-toolkit">https://software.intel.com/en-us/openvino-toolkit</a></li><li>apple： core ml</li><li>nvidia： <strong>TensorRT(for nvidia GPU)</strong></li></ul></li><li><p>国内：</p><ul><li>腾讯：<strong>ncnn -&gt; TNN(for arm chip)</strong>  <a href="https://github.com/Tencent/ncnn">https://github.com/Tencent/ncnn</a></li><li>阿里： mnn  <a href="https://github.com/alibaba/MNN">https://github.com/alibaba/MNN</a></li><li>百度： paddlelite  <a href="https://github.com/PaddlePaddle/Paddle-Lite">https://github.com/PaddlePaddle/Paddle-Lite</a></li><li>小米：mace  <a href="https://github.com/XiaoMi/mace">https://github.com/XiaoMi/mace</a></li></ul></li><li><p>其他</p><ul><li>TVM: <a href="https://github.com/dmlc/tvm">https://github.com/dmlc/tvm</a></li><li>TC: TensorComprehensions</li><li>onnx: <a href="https://github.com/onnx/onnx">https://github.com/onnx/onnx</a></li></ul></li></ul><h4 id="四、硬件发展"><a href="#四、硬件发展" class="headerlink" title="四、硬件发展"></a>四、硬件发展</h4><p>各类硬件的发展都离不开芯片制程、核心数量、指令架构优化三个主要方向</p><ol><li><p>服务器端硬件分类</p><p>x86_64 CPU、<strong>NVIDIA GPU</strong>、服务器 NPU</p></li><li><p>移动端硬件分类</p></li></ol><p>​        <strong>ARM CPU</strong>、ARM GPU（Adreno、mali系列）、移动端NPU、NVIDIA Jeston系列、<strong>Apple 家的芯片（自家GPU、NPU）</strong> </p><ol><li>其他</li></ol><p>​         DSP、<strong>FPGA</strong>、外接式加速设备，各种云平台形式的部署</p><h4 id="五-一些基本的问题"><a href="#五-一些基本的问题" class="headerlink" title="五. 一些基本的问题"></a>五. 一些基本的问题</h4><h5 id="1-工程上对卷积操作如何进行优化的？"><a href="#1-工程上对卷积操作如何进行优化的？" class="headerlink" title="1. 工程上对卷积操作如何进行优化的？"></a>1. 工程上对卷积操作如何进行优化的？</h5><p>目前，卷积的计算大多采用间接计算的方式，主要有以下几种实现方式， 其中前三种是主流方案</p><ul><li>滑窗机制。这种方法是最直观最简单的方法。 但是，该方法不容易实现大规模加速，因此，通常情况下不采用这种方法（但是也不是绝对不会用，在一些特定的条件下该方法反而是最高效的）</li><li>im2col + GEMM。 caffe/MXNet等很多框架中都使用了这种计算方式，原因是将问题转化为矩阵乘法后可以方便的使用很多矩阵运算库(如MKL、openblas、Eigen等)</li><li>Winograd：快速卷积算法，针对不同大小的卷积核进行优化，减少计算中的乘法运算次数，提升运行速度。-&gt; 大部分的前向推导框架都实现了 winograd算法</li><li>FFT变换。 时域卷积等于频域相乘，因此可将问题转化为简单的乘法问题。傅里叶变换和快速傅里叶变化是在经典图像处理里面经常使用的计算方法，但是，在 ConvNet 中通常不采用，主要是因为在 ConvNet 中的卷积模板通常都比较小，例如 3×3 等，这种情况下，FFT 的时间开销反而更大，所以很少在CNN中利用FFT实现卷积</li></ul><h5 id="2-为什么-mobilenet-理论上速度很快，工程上并没有特别大的提升？"><a href="#2-为什么-mobilenet-理论上速度很快，工程上并没有特别大的提升？" class="headerlink" title="2. 为什么 mobilenet 理论上速度很快，工程上并没有特别大的提升？"></a>2. 为什么 mobilenet 理论上速度很快，工程上并没有特别大的提升？</h5><p>(1) 硬件相关：GPU 偏重于并行、CPU 侧重于侧重于串行。很多细粒度的操作没法很好的并行。</p><p>(2) 和对应的 DL 框架实现细节有关：没有对 dw 和 pw 算子进行优化，比如访存次数、cache miss 较多等。</p><p>(3) 参数量和计算量：设计衡量的指标是 FLOPS、而不是时间。很多 element-wise 操作以及细粒度操作会增加推导时间</p><h5 id="3-模型压缩方向-NAS-研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）"><a href="#3-模型压缩方向-NAS-研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）" class="headerlink" title="3. 模型压缩方向 NAS 研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）"></a>3. 模型压缩方向 NAS 研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）</h5><ul><li>DARTS：Differentiable Architecture   Search  可微分神经网络架构搜索</li><li>Designing Network Design Spaces</li><li><p>NAS-Bench-101: Towards Reproducible Neural Architecture Search</p></li><li><p>AMC：AMC: AutoML for Model Compression and Acceleration on Mobile Devices</p></li><li>AutoSlim: Towards One-shot Architecture Search for Channel Numbers</li></ul><h5 id="4-软硬件联合设计研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）"><a href="#4-软硬件联合设计研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）" class="headerlink" title="4. 软硬件联合设计研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）"></a>4. 软硬件联合设计研究进展追踪（该方向自己暂时没有形成系统理论，不独立成文）</h5><ul><li>Algorithm-Hardware Co-Design of Adaptive Floating-Point</li><li>SmartExchange: Trading Higher-cost Memory Storage/Access for Lower-cost Computation</li><li>Drynamic region-based quantization for deep neural network acceleration</li><li><p>MCUNet: Tiny Deep Learning on IoT Devices</p></li><li><p>Once-for-all: train one network and specialize it for efficient deployment</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>efficient-conv</title>
    <link href="/2020/12/13/efficient-conv/"/>
    <url>/2020/12/13/efficient-conv/</url>
    
    <content type="html"><![CDATA[<p>阐述一些底层的卷积实现方式：包含：滑动窗口、im2col + gemm、winograd 等</p><a id="more"></a><p>卷积的具体实现有如下几种方法：</p><ul><li>直接卷积 direct：按照定义直接计算， 一般来说，访存很差。在特定情况下可能是最优方案。</li><li>im2col+gemm：先将特征图换成矩阵，然后用kernel矩阵乘以特征图转换的矩阵，得到输出，访存性能能好一些</li><li>winograd：用加法换乘法，通过减少乘法次数来提高卷积执行速度。</li></ul><p>此外还有 Strassen(减少卷积操作数) 和 FFT(通过 FFT 来减少 conv 的计算量、在大卷积核下收益明显) 、MEC 等方法。但是这几种方案并非主流。下面我们主要详细来阐述主流的三种方案。</p><p>本文主要从工程的角度来阐述这三种主流方案，对于具体的理论推导和细节原理，则不涉及。</p><h3 id="一-direct"><a href="#一-direct" class="headerlink" title="一. direct"></a>一. direct</h3><p>直接按照定义进行计算。需要进行多重 for 循环的展开。</p><h3 id="二-im2col-gemm"><a href="#二-im2col-gemm" class="headerlink" title="二. im2col  + gemm"></a>二. im2col  + gemm</h3><p>Im2col(Image to Column)把输入 feature map 按照卷积核的形式一一展开并拼接成列，接着通过高性能 MatMul（Matrix Multiplication） Kernel 进行矩阵乘，得到输出 feature map。它的本质是把卷积运算转换成矩阵运算。</p><p><img src="/2020/12/13/efficient-conv/8.jpeg" alt></p><p>Pack 优化: </p><p>​        理论上来说， 获得了输入特征图和卷积核的 im2col 变换矩阵之后其实就可以利用 Sgemm 计算出卷积的结果了。</p><p>​        但是如果直接使用矩阵乘法计算，在卷积核尺寸比较大并且输出特征图通道数也比较大的时候，我们会发现这个时候 im2col 获得矩阵是一个行非常多列非常少的矩阵，在做矩阵乘法的时候访存会变得比较差，从而降低计算效率。这里有一个优化技巧，就是数据打包(Pack)。具体来说，对于卷积核我们进行的Pack（所谓 4 的Pack就是在 im2Col获得的二维矩阵的高维度进行压缩，在宽维度进行膨胀，每四行进行交叉拼接）。 如下图所示， 这是一个的卷积核并且输出通道数为，它经过Im2Col之后首先变成上图的上半部分，然后经过Pack 之后变成了上图的下半部分，即变成了每个卷积核的元素按列方向交织排列。</p><p><img src="/2020/12/13/efficient-conv/7.jpeg" style="zoom:35%;"></p><p>还有一个技巧是，每次在执行卷积计算时，对于 Image 的 Im2col 和 Pack 每次都会执行，但对于卷积核，Im2col 和 Pack 在任意次只用做一次，所以我们可以在模型初始化的时候提前把卷积核给 Pack 好，这样就可以节省卷积核 im2col 和 pack 耗费的时间。</p><p>代码实现可以参考： <a href="https://github.com/msnh2012/Msnhnet/blob/master/src/layers/arm/MsnhConvolutionSgemm.cpp">https://github.com/msnh2012/Msnhnet/blob/master/src/layers/arm/MsnhConvolutionSgemm.cpp</a></p><h3 id="三-Winograd"><a href="#三-Winograd" class="headerlink" title="三. Winograd"></a>三. Winograd</h3><p>论文参见： <a href="https://arxiv.org/abs/1509.09308v2">https://arxiv.org/abs/1509.09308v2</a></p><p>​        可以看到 img2col 提高了访存速度，但是它并没有降低运算的时间复杂度。于是在卷积的实践中诞生了 Winograd 算法。Winograd 的 本质是通过降低乘法的次数来提高卷积运算速度。 Winograd 算法主要应用于卷积核为 3x3，步幅为 1 的 2D 卷积神经网络，其参数表示为 F(mxm, rxr)，其中 mxm 是运算之后输出块的大小，rxr 是卷积核的大小，以 F(2x2, 3x3) 和 F(6x6, 3x3) 使用最多，前者加速比可达 2.25x，后者加速比则高达 5.06x。</p><p><img src="/2020/12/13/efficient-conv/5.jpeg" style="zoom:75%;"></p><p>​        首先以一维卷积 $F(2,3)$ 为例。设输入信号为  </p><script type="math/tex; mode=display">d=[d0, d1, d2, d3]^T</script><p>卷积核为：</p><script type="math/tex; mode=display">g=[g0, g1, g2]^T</script><p>滑动步长为 1，不做 padding 操作，则输出结果可以写成</p><script type="math/tex; mode=display">F(2,3)=\left[\begin{array}{ccc}d_0 &d_1  &d_2 \\d_1 &d_2  &d_3\end{array}\right]\left[\begin{array}{ccc}g_0  \\g_1\\g_2\end{array}\right]=\left[\begin{array}{c}r_0\\r_1\end{array}\right]</script><p>其中</p><script type="math/tex; mode=display">r_0=d_0*g_0+d_1*g_1+d_2*g_2 \\r_1=d_1*g_0+d_2*g_1+d_3*g_2</script><p>可以看到如果用一般的矩阵乘法，则需要 6 次乘法和 4 次加法。</p><p>winograd 做法如下</p><script type="math/tex; mode=display">F(2,3)=\left[\begin{array}{ccc}d_0 &d_1  &d_2 \\d_1 &d_2  &d_3\end{array}\right]\left[\begin{array}{ccc}g_0  \\g_1\\g_2\end{array}\right]=\left[\begin{array}{c}m_1+m_2+m_3\\m_2-m_3-m_4\end{array}\right]</script><p>其中</p><script type="math/tex; mode=display">m_1=(d_0-d_2)g_0, \quad m_2=(d_1+d_2)\frac{g_0+g_1+g_2}{2}\\m_4=(d_1-d_3)g_2, \quad m_3=(d_2-d_1)\frac{g_0-g_1+g_2}{2}\\</script><p>可以看到利用 winograd 算法需要 4 次乘法，8次加法，相比一般矩阵乘法，通过增加加法运算减少乘法的运算，可以实现加速。</p><p>由于 winograd 算法证明比较复杂暂时不写了，直接丢计算公式，一维卷积计算公式如下：</p><script type="math/tex; mode=display">Y=A^T\left[[Gg]\bigodot[B^Td]\right]</script><p>其中 ⨀ 表示 element-wise，A,G,B 都是根据输出大小和卷积核提前确定好的(有人已经写好了,可参考 <a href="https://github.com/andravin/wincnn">wincnn</a>)， g 表示卷积核，d 表示输入数据(也就是需要进行卷积计算的数据)。 可以看到，它可以将 $m * r$ 次乘法 降低为 $m + r - 1$ 次乘法。</p><p>对应二维卷积计算公式如下:</p><script type="math/tex; mode=display">Y=A^T\left[[GgG^T]\bigodot[B^TdB]\right]A</script><p>基于上面介绍的二维的 Winograd的原理，我们现在只需要分 4 步即可实现 winograd 算法：</p><ol><li>根据卷积核的大小，确定变换矩阵 G， 对输入卷积核的变换   $U = GgG^T$</li><li>根据输入数据的大小， 确定变换矩阵 B，并对输入数据的变换  $V = B^T d B$ </li><li>计算 M 矩阵：  $M = \sum U \bigodot V$</li><li>计算最终结果: $Y = A^T M A$</li></ol><p>需要注意以下几点：</p><ol><li>当输入较大的时候， 需要把输入拆成多个 4x4 的 block，stride 2 即可。</li><li>当对卷积核和输入数据进行转换后， 需要对其进行内存重拍， 方便去利用 gemm 。</li></ol><p>具体的代码实现可以参照： <a href="https://github.com/Tencent/ncnn/blob/master/src/layer/arm/convolution_3x3.h">https://github.com/Tencent/ncnn/blob/master/src/layer/arm/convolution_3x3.h</a>  line 1702 - line 1864 </p><h3 id="四-其他"><a href="#四-其他" class="headerlink" title="四. 其他"></a>四. 其他</h3><ul><li><p>不同的卷积的快慢并非一成不变， 特定的情况下可能通常较快的方法反而运行较快。旷视的 megengine 提出了 Fast-Run 来寻找最优算子，其工程实现分为选择和执行两个阶段：</p><ul><li>选择阶段，测速模型每个算子，选出最优实现，保存算子名称和最优实现的映射表；</li><li>执行阶段，根据映射表直接调用相应实现完成计算。</li></ul></li><li><p>数据排布和 cache 命中是极其重要的。</p></li><li>数据排布(Tensor Layout) ：数据排布是推理侧卷积计算优化方面首先面临的问题。选择合适的数据排布不仅会使卷积优化事半功倍，还可作为其他优化方法的基础， 目前，深度学习框架中常见的数据排布格式有3种：<ul><li>NHWC：[Batch, Height, Width, Channels]</li><li>NCHW：[Batch, Channels, Height, Width]</li><li>NCHWX：[Batch, Channels/X, Height, Width, X=4/8]</li></ul></li></ul><p>​    数据的排布对卷积计算有着整体性的直接影响。NHWC 和 NCHW 的空间复杂度相同，区别在于访存行为，NCHWX 介于两者之间，但是有其他优点。</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>quantizing</title>
    <link href="/2020/12/12/quantizing/"/>
    <url>/2020/12/12/quantizing/</url>
    
    <content type="html"><![CDATA[<p>​        量化， 也被称为定点化、离散化，是指用低精度整数来近似表示浮点数(权重和偏置)的方法。 在量化之后，可以在特定的硬件平台上使用特定的指令集对其加速， 另外，由于存储位宽的减小，模型的体积也会显著减小。常见的量化方案可以分为二值量化、三值量化、低比特量化(介于2-8bit之间) 和 int8 量化。</p><h4 id="1-二值量化"><a href="#1-二值量化" class="headerlink" title="1. 二值量化"></a>1. 二值量化</h4><p><strong>Binary Weight</strong> (只对权重进行二值化)</p><p>🌟 [BinaryConnect] BinaryConnect: Training Deep Neural Networks with binary weights during propagations</p><p>🌟 [BWN]  Binary-Weights-Networks</p><p><strong>Binary Weight &amp; activation</strong> (对权重和激活都进行二值化)</p><p>🌟 [BNN] <a href="https://arxiv.org/pdf/1602.02830.pdf">Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1</a></p><p>🌟 [XNOR Net] <a href="https://arxiv.org/pdf/1603.05279.pdf">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a></p><p> [ABCNet] Towards Accurate Binary Convolutional Neural Network by Xiaofan Lin, Cong Zhao, and Wei Pan.</p><p> [Bi-Real Net] Enhancing the Performance of 1bit CNNs with Improved Representational Capacity and Advanced Training Algorithm</p><p> [HORQ]Performance Guaranteed Network Acceleration via High-Order Residual Quantization</p><h4 id="2-三值量化"><a href="#2-三值量化" class="headerlink" title="2. 三值量化"></a>2. 三值量化</h4><p>🌟 [TWN] <a href="https://arxiv.org/pdf/1605.04711.pdf">Ternary weight networks</a></p><p>[TNN] Ternary Neural Networks for Resource-Efficient AI Applications </p><p>[TTQ] Trained Ternary Quantization </p><h4 id="3-2bit-8bit"><a href="#3-2bit-8bit" class="headerlink" title="3. 2bit - 8bit"></a>3. 2bit - 8bit</h4><p>🌟 [DOREFA-NET] DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradient</p><p>​       实现了权重， 激活 值、梯度的量化， 其中权重、激活和梯度分别使用 1bit、2bit 和 4bit 进行表示， 可以实现在特殊硬件上并行训练。</p><p>🌟  [ACIQ]:4bit</p><p>🌟  [AdaRound]: 4bit </p><p>上述方案的对比</p><p><img src="/2020/12/12/quantizing/2.png" style="zoom:50%;"></p><h4 id="4-int8-量化"><a href="#4-int8-量化" class="headerlink" title="4. int8 量化"></a>4. int8 量化</h4><p>int8 方案按照量化的时机可以分为感知量化 (Quantization Aware Training, QAT) 和训练后量化 (Post Training Quantization，PTQ)。 在此的重点关注于训练后量化， 因为其不需要重新 fine-tune， 方便在工业界进行落地使用。</p><ul><li>感知量化， 是在训练过程中对量化进行建模以确定量化参数， 它能够保持较高精度。 该解决方案由 google 提出并将其应用于 tensorflow， 见于论文 Quantizing deep convolutional networks for efficient inference: A whitepaper。</li><li>对于训练后量化， 则是使用对训练生成的模型直接进行映射。该方法精度损失稍大但是不需要重新训练可以快速得到量化模型。常见的解决方案有四种：max-max(max-min)、KL、admm、easyquant。 其中 KL 方案由 nvidia 提出，是现在主流的 int8 量化方案。</li></ul><h5 id="4-1-max-abs"><a href="#4-1-max-abs" class="headerlink" title="4.1 max-abs"></a>4.1 max-abs</h5><p>​        首先求出一个 layer 的激活值范围， 将绝对值的最大值作为阈值， 把这个范围按照比例映射到 -127 到 128 的范围内, 如下左图所示。 其 fp32 和 int8 的转换公式为:</p><pre><code class="hljs lisp">FP32 Tensor (<span class="hljs-name">T</span>) = scale_factor(<span class="hljs-name">sf</span>) * <span class="hljs-number">8</span>-bit Tensor(<span class="hljs-name">t</span>) + FP32_bias (<span class="hljs-name">b</span>)</code></pre><p>  通过实验得知，bias值去掉对精度的影响不是很大，因此我们直接去掉, 所以该公式可以简化为:</p><pre><code class="hljs excel"><span class="hljs-built_in">T</span> = sf * <span class="hljs-built_in">t</span></code></pre><p>该方案存在一个问题：不饱和， 即通常在正负上会有一些量化值未被利用， 且会产生较大的精度损失。</p><p><img src="/2020/12/12/quantizing/tensorrt_qua.png" style="zoom:35%;"></p><p>！ 注意区分一下 min-max 和 max-max。 前者是将最大值和最小值映射到对应区间， 而后者是找到取最大值和最小值的绝对值。 tensorflow lite 的训练后量化过程是采用的 min-max 方式。</p><h5 id="4-2-KL"><a href="#4-2-KL" class="headerlink" title="4.2 KL`"></a>4.2 KL`</h5><p>​        针对非饱和映射精度损失的问题，TensorRT 提出了非饱和映射， 即选取一个阈值 $T$ ，然后将 $-|T|$ ~  $|T|$ 之间的值映射到 -127 到 128 这个范围内。这样确定了阈值 T 之后，其实也能确定 scale，一个简单的线性公式是: <code>scale = T/127</code>。 量化的核心就是找到这个阈值 T。 那么问题来了，T 应该取何值?  其基本流程如下:</p><p>​    (a) 选取不同的 T 阈值进行量化, 将 P(fp32) 映射到 Q(int8)。</p><p>​    (b) 将 Q(int8) 反量化到 P(fp32) 一样长度，得到分布 Q_expand；</p><p>​    (c) 计算 P 和 Q_expand 的相对熵( KL 散度)，然后选择相对熵最少的一个，也就是跟原分布最像的一个,  从而确定Scale。</p><p>​        其中的 KL 散度可以用来描述 P、Q 两个分布的差异<strong>。</strong>散度越小，两个分布的差异越小，概率密度函数形状和数值越接近。这里的所有分布、计算，都是离散形式的。分布是以统计直方图的方式存在，KL散度公式如下：</p><p><img src="/2020/12/12/quantizing/kl.png" style="zoom:50%;"></p><p>​        从上式中我们还发现一个问题：KL 散度计算公式要求 P、Q 两个统计直方图长度一样（也就是 bins 的数量一样）。Q 一直都是 -127～127；可是 P 的数量会随着 T 的变化而变化。那这怎么做 KL 散度呢？</p><p>ncnn 的做法是将 Q 扩展到和 P 一样的长度，下面举个例子( NVIDIA PPT 中的例子)：</p><pre><code class="hljs python">P = [<span class="hljs-number">1</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">5</span> <span class="hljs-number">3</span> <span class="hljs-number">1</span> <span class="hljs-number">7</span>]     // fp32 的统计直方图，T = <span class="hljs-number">8</span> // 假设只量化到两个 bins，即量化后的值只有 <span class="hljs-number">-1</span>/<span class="hljs-number">0</span>/+<span class="hljs-number">1</span> 三种 Q = [<span class="hljs-number">6</span>, <span class="hljs-number">16</span>]  // P 和 Q 现在没法做 KL 散度，所以要将 Q 扩展到和 P 一样的长度 Q_expand=[<span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>]=[<span class="hljs-number">2</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span>] // P 中有 <span class="hljs-number">0</span> 时不算在内 D = KL(P||Q_expand)  // 这样就可以做 KL 散度计算了</code></pre><p>​    这个扩展的操作，就像图像的上采样一样，将低精度的统计直方图(Q)，上采样的高精度的统计直方图上去(Q_expand)。由于 Q 中一个 bin 对应P中的 4 个bin，因此在 Q 上采样的 Q_expand 的过程中，所有的数据要除以4。另外，在计算 fp32 的分布 P 时，被 T 截断的数据，是要算在最后一个 bin 里面的。</p><p>TNN int8 量化方案代码位置  <a href="https://github.com/Tencent/TNN/tree/master/tools/quantization">https://github.com/Tencent/TNN/tree/master/tools/quantization</a></p><h5 id="4-3-admm"><a href="#4-3-admm" class="headerlink" title="4.3 admm"></a>4.3 admm</h5><p>admm 算法由 阿里巴巴提出， 应用在 MNN之中。 ADMM 算法是从优化的角度出发，来保证编码前后数据尽可能相似的方法。</p><p>首先我们定义一个分段函数 $E(x)$ 如下所示,  则 int8 的求解过程可以表示为 $E(\frac{X}{s})$</p><script type="math/tex; mode=display">E(x) = \left \{\begin{aligned}x &= round(x), abs(x) < 2^8 \\x &= 2^8 - 1, abs(x) > 2^8 \end{aligned}\right.</script><p>可以定义一个目标函数来衡量反量化之后的数据和原数据的“距离”。 这里选择度量 D 为 L2 度量， 则目标函数可以记为：</p><script type="math/tex; mode=display">L = ||s \cdot E(\frac{X}{s}) - X||^2</script><p>对其进行求导， 可得:</p><script type="math/tex; mode=display">\frac{\partial{L}}{\partial s} = E(\frac{X}{S})[s \cdot E(\frac{X}{s}) - X]</script><p>得到目标函数关于 $s$ 的导数公式以后， 该问题转化为求解 $L$ 关于 $s$ 的导数为 0 的数学问题。 论文采用了 admm 的思想：首先固定 E 中的变量 s，进行 s 值的求解；再通过求解后的 s 去估计 E 的值，如此反复直到 s 值收敛到最优。于是上述的式子要弱化为如下公式： </p><script type="math/tex; mode=display">\frac{\partial{L}}{\partial s} = E(\frac{X}{s_k})[s_{k+1} \cdot E(\frac{X}{s_k}) - X] = 0</script><p>所以， 迭代的过程也就变成了交替求解如下两个公式的过程:</p><script type="math/tex; mode=display">\left \{\begin{aligned}& s_{k+1} = \frac{E(\frac{X}{s_k}) \cdot X}{ E(\frac{X}{s_k} ) \cdot E(\frac{X}{s_k})}, \\& E(\frac{X}{s_k})\end{aligned}\right.</script><p>MNN 中 admm 算法的实现： <a href="https://github.com/alibaba/MNN/blob/master/tools/quantization/quantizeWeight.cpp">https://github.com/alibaba/MNN/blob/master/tools/quantization/quantizeWeight.cpp</a></p><h5 id="4-4-easyquant"><a href="#4-4-easyquant" class="headerlink" title="4.4 easyquant"></a>4.4 easyquant</h5><p>github 主页: <a href="https://github.com/deepglint/EasyQuant">https://github.com/deepglint/EasyQuant</a></p><p>原始的卷积输出结果可以表示为:</p><script type="math/tex; mode=display">Q_l = A_l * W_l</script><p>其中，A 表示网络层的输入， W 表示网络层的参数。</p><p>如果用 $Q$ 表示量化操作，量化层输出再反量化的结果可以表示如下， 其中 $S$ 表示 scale 值。</p><script type="math/tex; mode=display">\hat{O}_l = \frac{Q(A_l, S^a_l) * Q(W_l. S^w_l)}{S_l^a \cdot S_l^w}</script><p>easyquant 将其看做一个优化问题， 优化目标为量化前的输出和反量化之后的输出的余弦距离。数学表达式为:</p><script type="math/tex; mode=display">max_{s_l} \frac{1}{N} \sum_{i=1}^{N} cos(Q_l^i, \hat{Q_l^i}) \\s.t. S_l \in R^+</script><h5 id="4-5-GDFQ-和-ZeroQ"><a href="#4-5-GDFQ-和-ZeroQ" class="headerlink" title="4.5 GDFQ 和 ZeroQ"></a>4.5 GDFQ 和 ZeroQ</h5><p>​        结合 GAN 网络实现生成数据，实现 data-free。 然后结合知识蒸馏（teacher model 为高精度网络， student model 为量化网络）来实现网络的量化。</p><p>​    ·</p><h4 id="5-int8-实际应用"><a href="#5-int8-实际应用" class="headerlink" title="5. int8 实际应用"></a>5. int8 实际应用</h4><p>关于量化之后，如何使用的问题，有两种解决方案：</p><ul><li><p>混合 fp32/int8 推理: 该解决方案引入 Quantize 和 Dequantize 两个操作。在进行卷积操作前，将权重和输入进行 Quantize 为 int8，然后使用 int8 进行卷积，最后将结果  Dequantize 为 float32。这种方案并不需要所有的算子(operator) 都支持量化，但是由于需要数据的 Quantize 和 Dequantize，降低了网络的推理速度。一般而言， 对于权重量化采用 kl量化 或者 easyquant 量化，而对于激活(输入和输出) 的量化可以采用 max-max 量化 。</p><p><img src="/2020/12/12/quantizing/q1.png" title="混合fp32/int8推理" style="zoom:50%;"></p></li><li><p>纯 int8 推理：将网络整体转换为 int8 格式，因此在推理期间没有高低精度数据的转换，因此推理速度更快。但是该解决方案要求算子(Operator) 都支持量化，因为运算符之间的数据流是 int8。对于尚未支持的那些，降级到混合 fp32/int8 推理。 </p><p><img src="/2020/12/12/quantizing/q2.png" title="纯int8推理" style="zoom:50%;"></p></li></ul><h4 id="6-ncnn-量化工具的使用"><a href="#6-ncnn-量化工具的使用" class="headerlink" title="6. ncnn 量化工具的使用"></a>6. ncnn 量化工具的使用</h4><p>(1)  Optimization graphic</p><pre><code class="hljs smali"><span class="hljs-keyword">.</span>/ncnnoptimize mobilenet-fp32.param mobilenet-fp32.bin mobilenet-nobn-fp32.param mobilenet-nobn-fp32.bin</code></pre><p>(2) Create the calibration table file</p><pre><code class="hljs angelscript">./ncnn2table --param mobilenet-nobn-fp32.param --bin mobilenet-nobn-fp32.bin --images images/ --output mobilenet-nobn.table --mean <span class="hljs-number">104</span>,<span class="hljs-number">117</span>,<span class="hljs-number">123</span> --norm <span class="hljs-number">0.017</span>,<span class="hljs-number">0.017</span>,<span class="hljs-number">0.017</span> --size <span class="hljs-number">224</span>,<span class="hljs-number">224</span> --thread <span class="hljs-number">2</span></code></pre><p>(3) Quantization</p><pre><code class="hljs stylus">./ncnn2int8 mobilenet-nobn-fp32<span class="hljs-selector-class">.param</span> mobilenet-nobn-fp32<span class="hljs-selector-class">.bin</span> mobilenet-int8<span class="hljs-selector-class">.param</span> mobilenet-int8<span class="hljs-selector-class">.bin</span> mobilenet-nobn.table</code></pre><h4 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a>7. 参考资料</h4><p>[1] <a href="https://me.csdn.net/sinat_31425585">https://me.csdn.net/sinat_31425585</a></p><p>[2] <a href="https://zhuanlan.zhihu.com/c_1064124187198705664">https://zhuanlan.zhihu.com/c_1064124187198705664</a></p><p>[3] <a href="https://github.com/BUG1989/caffe-int8-convert-tools">https://github.com/BUG1989/caffe-int8-convert-tools</a></p><p>[4] <a href="https://github.com/Tencent/ncnn/wiki/quantized-int8-inference">Tencent/ncnn</a></p><p>[5] Nvidia solution： Szymon Migacz. 8-bit Inference with TensorRT</p><p>[6] Google solution：Quantizing deep convolutional networks for efficient inference: A whitepaper</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>模型层融合conv与bn</title>
    <link href="/2020/12/11/%E6%A8%A1%E5%9E%8B%E5%B1%82%E8%9E%8D%E5%90%88conv%E4%B8%8Ebn/"/>
    <url>/2020/12/11/%E6%A8%A1%E5%9E%8B%E5%B1%82%E8%9E%8D%E5%90%88conv%E4%B8%8Ebn/</url>
    
    <content type="html"><![CDATA[<p>本文主要介绍了卷积层 conv 和 批归一化层 batch normalization 融合的原理。</p><a id="more"></a><h3 id="1-批归一化-Batch-Normalization"><a href="#1-批归一化-Batch-Normalization" class="headerlink" title="1.  批归一化 Batch Normalization"></a>1.  批归一化 Batch Normalization</h3><p>​     批归一化（Batch Normalization）因其可以加速神经网络训练、使网络训练更稳定，而且还有一定的正则化效果，所以得到了非常广泛的应用。但是，在推理阶段，BN层一般是可以完全融合到前面的卷积层的，而且丝毫不影响性能。</p><p>​      Batch Normalization 的思想非常简单，一句话概括就是，对一个神经元（或者一个卷积核）的<strong>输出减去统计得到的均值除以标准差，然后乘以一个可学习的系数，再加上一个偏置</strong>，这个过程就完成了。</p><p>​     在训练过程中， 主要执行如下四个步骤:</p><script type="math/tex; mode=display">\begin{aligned}& \mu = \frac{1}{m}\sum_{i=1}^{m} x_i, \\& \sigma = \frac{1}{m} \sum_{i=1}^{m}(x_i - \mu)^2,  \\& \hat{x_i} = \frac{x_i - \mu}{\sqrt{\sigma^2 + \epsilon}}, \\& y_i = \gamma * \hat{x_i} + \beta \\\end{aligned}</script><p>其中 $\epsilon$ 为一个非常小的常数， 例如 0.0001， 主要是为了避免除零错误。 而 $\gamma$  和 $\beta$  则是可学习参数， 在训练过程中，和其他卷积核的参数一样， 通过梯度下降来学习。 在训练过程中，为保持稳定，一般使用滑动平均法更新均值和方差，滑动平均就是在更新当前值的时候，以一定比例保存之前的数值，以均值 $\mu$ 为例，以一定比例 $\theta$ (例如这里0.99）保存之前的均值，当前只更新 $(1-\theta)$ 倍（也就是0.001倍）的本Batch 的均值，计算方法如下：</p><script type="math/tex; mode=display">\mu_i = \theta \mu_{i-1} + (1 - \theta) \mu_i</script><p>标准差的滑动平均计算方法也一样。</p><p>​        在推理(测试)阶段，我们不太会对一个batch图像进行预测，一般是对单张图像测试。因此，通过前面公式计算 $\mu$ 和 $\sigma$ 就不可能。其实对于预测阶段时所使用的均值和方差，其实也是来源于训练集。比如我们在模型训练时我们就记录下每个 batch 下的均值和方差，待训练完毕后，我们求整个训练样本的均值和方差期望值(滑动均值和方差)，作为我们进行预测时进行BN的的均值和方差。</p><p>具体的 batchnorm 的一维 python 实现可以参考如下代码：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">batchnorm_forward</span>(<span class="hljs-params">x, gamma, beta, bn_param</span>):</span>    mode = bn_param[<span class="hljs-string">&#x27;mode&#x27;</span>]    eps = bn_param.get(<span class="hljs-string">&#x27;eps&#x27;</span>, <span class="hljs-number">1e-5</span>)     momentum = bn_param.get(<span class="hljs-string">&#x27;momentum&#x27;</span>, <span class="hljs-number">0.9</span>)        N, D = s.shape  <span class="hljs-comment"># N is batch_size * H * W, D is channels</span>    running_mean = bn_param.get(<span class="hljs-string">&#x27;running_mean&#x27;</span>, np.zeros(D, dtype=x.dtype))    running_var = bn_param.get(<span class="hljs-string">&#x27;running_var&#x27;</span>, np.zeros(D, dtype=x.dtype))        out, cahce = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:            batch_mean = np.mean(x, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)        batch_var = np.var(x, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)         x_norm = (inp - batch_mean) / np.sqrt(batch_var + eps)        out = x_norm * gamma + beta        <span class="hljs-comment"># store variables in cache</span>        cache = (x, x_norm, gamma, beta, eps, batch_mean, batch_var)        <span class="hljs-comment"># update running_mean &amp; running var</span>        running_mean = momentum * running_mean + (<span class="hljs-number">1</span> - momentum) * batch_mean        running_var = momentum * running_var + (<span class="hljs-number">1</span> - momentum) * batch_var    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;test&#x27;</span>:        x_norm = (x - running_mean) / np.sqrt(running_var + eps)        out = x_norm * gamma + beta            bn_param[<span class="hljs-string">&#x27;running_mean&#x27;</span>] = running_mean    bn_param[<span class="hljs-string">&#x27;running_var&#x27;</span>] = running_var    <span class="hljs-keyword">return</span> out, cache</code></pre><h3 id="2-conv-与-Batchnorm-的融合"><a href="#2-conv-与-Batchnorm-的融合" class="headerlink" title="2. conv 与 Batchnorm 的融合"></a>2. conv 与 Batchnorm 的融合</h3><p>​     网络完成训练后，在 inference 阶段，为了加速运算，通常将卷积层和BN层进行融合:</p><p>（1）卷积层可以抽象为如下公式:</p><script type="math/tex; mode=display">x_{i} = w * x_{i-1} + b</script><p>（2）bn 层可以抽象为如下公式:</p><script type="math/tex; mode=display">y = \frac{x_i - \mu}{\sqrt{\sigma + \epsilon}} \cdot \gamma + \beta</script><p>其中 $\mu$ 和 $\sigma$ 是整个训练集的均值和方差(滑动)， 这是两个常量。$\gamma$ 和 $\beta$ 是学习完成的参数， 也是两个常量。</p><p>（3）融合两层：将 conv 层的公式带入到 BN 层的公式</p><script type="math/tex; mode=display">\begin{align}&y = \frac{x_i - \mu}{\sqrt{\sigma + \epsilon}} \cdot \gamma + \beta \\   &= \frac{w * x_i + b - \mu}{\sqrt{\sigma + \epsilon}} \cdot \gamma + \beta \\   &= \frac{w * \gamma}{\sqrt{\sigma + \epsilon}} \cdot x + (\frac{b-\mu}{\sqrt{\sigma + \epsilon}} \cdot \gamma + \beta)\end{align}</script><p>融合后相当于：</p><script type="math/tex; mode=display">\begin{align}& w_{new} = \frac{w * \gamma}{\sqrt{\sigma + \epsilon}}, \\& b_{new} = (\frac{b-\mu}{\sqrt{\sigma + \epsilon}} \cdot \gamma + \beta)\end{align}</script><p>​    通过公式可以看出， 我们可以将 Batch Normalization 层融合到卷积层中，相当于对卷积核进行一定的修改，没有增加卷积的计算量，同时整个 Batch Normalization 层的计算量都省去了。</p><p>Pytorch 提供了相关的 conv 和 bn 融合的代码： <a href="https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/fusion.py">https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/fusion.py</a></p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fuse_conv_bn_weights</span>(<span class="hljs-params">conv_w, conv_b, bn_rm, bn_rv, bn_eps, bn_w, bn_b</span>):</span>    <span class="hljs-keyword">if</span> conv_b <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:        conv_b = torch.zeros_like(bn_rm)    <span class="hljs-keyword">if</span> bn_w <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:        bn_w = torch.ones_like(bn_rm)    <span class="hljs-keyword">if</span> bn_b <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:        bn_b = torch.zeros_like(bn_rm)    bn_var_rsqrt = torch.rsqrt(bn_rv + bn_eps)  <span class="hljs-comment"># 注意一下，这里直接取了倒数 rsqrt</span>    conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape([<span class="hljs-number">-1</span>] + [<span class="hljs-number">1</span>] * (len(conv_w.shape) - <span class="hljs-number">1</span>))    conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b    <span class="hljs-keyword">return</span> torch.nn.Parameter(conv_w), torch.nn.Parameter(conv_b)</code></pre><h3 id="3-实际测试"><a href="#3-实际测试" class="headerlink" title="3. 实际测试"></a>3. 实际测试</h3><pre><code class="hljs python">In [<span class="hljs-number">1</span>]: <span class="hljs-keyword">import</span> torchIn [<span class="hljs-number">2</span>]: <span class="hljs-keyword">import</span> torchvisionIn [<span class="hljs-number">3</span>]: <span class="hljs-keyword">from</span> torch.nn.utils.fusion <span class="hljs-keyword">import</span> fuse_conv_bn_weightsIn [<span class="hljs-number">4</span>]: resnet18 = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)In [<span class="hljs-number">5</span>]: resnet18.eval()In [<span class="hljs-number">6</span>]: conv_bn = torch.nn.Sequential(   ...:     resnet18.conv1,    ...:     resnet18.bn1    ...: )                                                                                                                         In [<span class="hljs-number">7</span>]: bn_var, bn_mean = resnet18.bn1.running_var, resnet18.bn1.running_meanIn [<span class="hljs-number">8</span>]: bn_eps = resnet18.bn1.epsIn [<span class="hljs-number">9</span>]: bn_weight, bn_bias = resnet18.bn1.weight, resnet18.bn1.biasIn [<span class="hljs-number">10</span>]: conv_weight, conv_bias = resnet18.conv1.weight, resnet18.conv1.biasIn [<span class="hljs-number">11</span>]: fused_w, fused_b = fuse_conv_bn_weights(conv_weight, conv_bias, mean, var, eps, weight, bias)In [<span class="hljs-number">12</span>]: fused_conv = torch.nn.Conv2d(    ...:             resnet18.conv1.in_channels,    ...:             resnet18.conv1.out_channels,    ...:             kernel_size=resnet18.conv1.kernel_size,    ...:             stride=resnet18.conv1.stride,    ...:             padding=resnet18.conv1.padding,    ...:             bias=<span class="hljs-literal">True</span>    ...:         )In [<span class="hljs-number">13</span>]: fused.weight.copy_(fused_w)In [<span class="hljs-number">14</span>]: fused.bias.copy_(fused_b)In [<span class="hljs-number">15</span>]: torch.set_grad_enabled(<span class="hljs-literal">False</span>) In [<span class="hljs-number">16</span>]: x = torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>)In [<span class="hljs-number">17</span>]: res1 = conv_bn.forward(x)In [<span class="hljs-number">18</span>]: res1Out[<span class="hljs-number">18</span>]: tensor([[[[ <span class="hljs-number">3.7646e-01</span>,  <span class="hljs-number">7.3849e-01</span>, <span class="hljs-number">-1.1688e-03</span>,  ...,  <span class="hljs-number">4.6396e-01</span>,            <span class="hljs-number">5.1061e-01</span>,  <span class="hljs-number">7.1462e-02</span>],          [ <span class="hljs-number">1.0769e+00</span>,  <span class="hljs-number">1.2775e+00</span>,  <span class="hljs-number">5.5155e-01</span>,  ...,  <span class="hljs-number">1.2121e+00</span>,           <span class="hljs-number">-7.6443e-02</span>,  <span class="hljs-number">4.3850e-01</span>],          [ <span class="hljs-number">5.2745e-02</span>, <span class="hljs-number">-3.7510e-01</span>, <span class="hljs-number">-3.4277e-01</span>,  ..., <span class="hljs-number">-2.5618e-01</span>,           <span class="hljs-number">-7.3687e-01</span>, <span class="hljs-number">-2.6337e-01</span>],          ...,          [ <span class="hljs-number">3.1750e-01</span>,  <span class="hljs-number">2.7688e-01</span>, <span class="hljs-number">-7.8872e-01</span>,  ...,  <span class="hljs-number">4.0573e-01</span>,            <span class="hljs-number">2.3306e-01</span>, <span class="hljs-number">-6.2662e-01</span>],          [ <span class="hljs-number">7.0026e-01</span>, <span class="hljs-number">-1.9506e-01</span>,  <span class="hljs-number">5.6528e-01</span>,  ..., <span class="hljs-number">-1.3667e-01</span>,           <span class="hljs-number">-5.3668e-03</span>,  <span class="hljs-number">5.2011e-01</span>],          [ <span class="hljs-number">4.6626e-02</span>,  <span class="hljs-number">5.6441e-01</span>,  <span class="hljs-number">5.7992e-01</span>,  ..., <span class="hljs-number">-1.9146e-01</span>,            <span class="hljs-number">3.9299e-01</span>,  <span class="hljs-number">2.9972e-01</span>]]]])In [<span class="hljs-number">19</span>]: res2 = fused(x)In [<span class="hljs-number">20</span>]: res2Out[<span class="hljs-number">20</span>]: tensor([[[[ <span class="hljs-number">3.7646e-01</span>,  <span class="hljs-number">7.3850e-01</span>, <span class="hljs-number">-1.1688e-03</span>,  ...,  <span class="hljs-number">4.6396e-01</span>,            <span class="hljs-number">5.1061e-01</span>,  <span class="hljs-number">7.1462e-02</span>],          [ <span class="hljs-number">1.0769e+00</span>,  <span class="hljs-number">1.2775e+00</span>,  <span class="hljs-number">5.5155e-01</span>,  ...,  <span class="hljs-number">1.2121e+00</span>,           <span class="hljs-number">-7.6443e-02</span>,  <span class="hljs-number">4.3850e-01</span>],          [ <span class="hljs-number">5.2745e-02</span>, <span class="hljs-number">-3.7510e-01</span>, <span class="hljs-number">-3.4277e-01</span>,  ..., <span class="hljs-number">-2.5618e-01</span>,           <span class="hljs-number">-7.3687e-01</span>, <span class="hljs-number">-2.6337e-01</span>],          ...,          [ <span class="hljs-number">3.1750e-01</span>,  <span class="hljs-number">2.7688e-01</span>, <span class="hljs-number">-7.8872e-01</span>,  ...,  <span class="hljs-number">4.0573e-01</span>,            <span class="hljs-number">2.3306e-01</span>, <span class="hljs-number">-6.2662e-01</span>],          [ <span class="hljs-number">7.0026e-01</span>, <span class="hljs-number">-1.9506e-01</span>,  <span class="hljs-number">5.6528e-01</span>,  ..., <span class="hljs-number">-1.3667e-01</span>,           <span class="hljs-number">-5.3669e-03</span>,  <span class="hljs-number">5.2011e-01</span>],          [ <span class="hljs-number">4.6626e-02</span>,  <span class="hljs-number">5.6441e-01</span>,  <span class="hljs-number">5.7992e-01</span>,  ..., <span class="hljs-number">-1.9146e-01</span>,            <span class="hljs-number">3.9299e-01</span>,  <span class="hljs-number">2.9972e-01</span>]]]])</code></pre><p>​    运行代码，会发现融合 conv 和 bn 层之后推理结果是一样，所以是等效替换。另外也可以对比前后推理时间的差异，会发现融合后推理时间会减少。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>network-pruning</title>
    <link href="/2020/11/24/network-pruning/"/>
    <url>/2020/11/24/network-pruning/</url>
    
    <content type="html"><![CDATA[<p>模型剪枝的相关工作记录</p><a id="more"></a><p>​        神经网络剪枝是指裁减掉网络中冗余的节点或参数，减少参数量，从而降低模型复杂度， 加快推理速度。 LeCun 于上世纪 90年代首次提出将剪枝应用于神经网络的压缩， 并论证其有效性。一个典型的网络剪枝过程如下所示， 其中最重要的是对节点或者参数重要性的评估。</p><p><img src="/2020/11/24/network-pruning/2.png" style="zoom:50%;"></p><p>​       剪枝可以分为结构化剪枝和非结构化剪枝。在非结构化剪枝中， 直接将参数置零，并没有进行剪枝， 通常需要搭配特定的硬件。结构化剪枝则是指在 filter 层面，通道层面，或者 shape 层面的剪枝， 直接删除相关参数，可以运行在通用的硬件设备上。 本文主要关注于结构化剪枝的相关工作，较为典型的工作梳理如下：</p><h3 id="一-解决方案"><a href="#一-解决方案" class="headerlink" title="一. 解决方案"></a>一. 解决方案</h3><h5 id="1-基于度量"><a href="#1-基于度量" class="headerlink" title="1. 基于度量"></a>1. 基于度量</h5><p>(1) 基于权重</p><ul><li><p>Pruning Filters for Efficient ConvNets   🌟</p><p>以 Filter 的 L1 norm 作为衡量标准</p></li><li><p>Filter pruning via geometric median for deep convolutional neural networks acceleration    🌟</p><p>以距离卷积核的几何中心的远近作为衡量标准。  对于神经网络中的某一层，计算所有 filter 的几何中心 (geometric median, GM)， 该几何中心附近的 filter 可以认为是冗余的， 可以将其移除。 </p></li><li><p>SFP Soft filter pruning</p><p>利用卷积核的 l2 norm 作为衡量标准， 进行软剪枝</p></li><li><p>Learning both Weights and Connections for Efficient Neural Networks  —— no structured prune: weight</p></li></ul><p>(2) feature map</p><ul><li><p>APoZ: Network trimming: A data-driven neuron pruning approach towards efficient deep architectures</p><p>作者定义了 APoZ(Average Percentage of Zeros) 来衡量每一个 filter 中激活为 0 的值的数量，并以此作为 filter 是否重要的标准</p></li><li><p>HRank 🌟</p><p>以 feature map 的秩作为衡量标准。 对 feature map 求秩并进行排序， 秩越小所含信息量越小，其重要性越低。根据秩的大小移除 feature map 对应的卷积核。 最后进行微调。</p></li></ul><p>（3）loss func</p><ul><li><p>Pruning Convolutional Neural Networks for Resource Efficient Inference ZAS</p><p>评测修剪网络参数引起的损失函数的变化</p></li></ul><h5 id="2-基于重建误差"><a href="#2-基于重建误差" class="headerlink" title="2. 基于重建误差"></a>2. 基于重建误差</h5><ul><li>Channel pruning for accelerating very deep neural networks</li></ul><p>​      衡量标准: 通过最小化裁剪后特征图和裁剪前特征图之间的误差</p><ul><li><p>ThiNet (Luo et al., 2017) 🌟</p><p>衡量标准: 用输入子集代替原来的输入得到输出的相似度</p></li></ul><h5 id="3-稀疏化"><a href="#3-稀疏化" class="headerlink" title="3. 稀疏化"></a>3. 稀疏化</h5><ul><li>(SSL) Learning Structured Sparsity in Deep Neural Networks  <strong>🌟</strong></li></ul><p>​       使用 group Lasso 给损失函数加入相应的惩罚，进行结构化稀疏</p><ul><li><p>(Network Slimming)  l1 norm: bn gamma  <strong>🌟</strong></p><p>利用 BN 层中的 γ 作为缩放因子，在训练过程当中来衡量 channel 的重要性，将不重要的 channel 进行删减，达到压缩模型大小，提升运算速度的效果。如下图所示，左边为训练当中的模型，中间一列是 scaling factors，也就是 BN 层当中的缩放因子 γ，当 γ 较小时(如图中0.001, 0.003)，所对应的 channel 就会被删减，得到右边所示的模型。 </p></li></ul><h5 id="4-prune-nas"><a href="#4-prune-nas" class="headerlink" title="4. prune + nas"></a>4. prune + nas</h5><ul><li><p>AMC：AutoML for Model Compression and Acceleration on Mobile Devices  🌟</p><p>将强化学习引入剪枝，使用 nas 进行网络压缩和加速</p></li><li><p>AutoSlim：Towards One-Shot Architecture Search for Channel Numbers </p><p>先训练出一个slimmable 模型，然后通过贪心的方式逐步对网络进行裁剪。</p></li><li><p>Network Pruning via Transformable Architecture Search</p><p>融合可微分网络进行剪枝</p></li><li><p>Approximated Oracle Filter Pruning for Destructive CNN Width Optimization </p><p>平行操作网络的所有层，用二分搜索的方式确定每层的剪枝数。</p></li><li><p>Fine-Grained Neural Architecture Search</p><p>把NAS的粒度降到了通道</p></li></ul><h5 id="5-理论思考和总结"><a href="#5-理论思考和总结" class="headerlink" title="5. 理论思考和总结"></a>5. 理论思考和总结</h5><ul><li><p>Rethinking the value of network pruning   🌟</p><p>参数修剪的实际作用在于得到网络结构而非权值。对于修剪后的模型，微调得到的效果和重新从头训练几乎相同。</p></li><li><p>The lottery ticket hypothesis: Finding sparse, trainable neural networks  🌟</p><p>(未剪枝的)大型网络包含一个(剪枝获得的)小的子网络。 如果从一开始就训练这个子网络，且初始化数值一一对应地取自原网络的初始化数值集合， 则会得到和原始网络相似的准确率。 </p></li><li><p>Pruning from Scratch  🌟</p><p>在相同的计算开支下，从随机初始化的权重(scratch)直接进行剪枝，也能获得较高性能的模型。该文抛弃了之前预训练、剪枝、fine-tune 的剪枝流程。降低了对预训练模型的依赖，也促使人们重新思考网络剪枝现有方法的有效性。</p></li><li><p>What is the state of neural network pruning ?  🌟</p><p>对神经网络的相关论文进行对比分析， 并提出了剪枝工作的基准 ShrinkBench 。</p></li></ul><h5 id="6-简单应用"><a href="#6-简单应用" class="headerlink" title="6.简单应用"></a>6.简单应用</h5><p>(1) YOLO 剪枝: 主要参考如下两篇论文</p><ul><li><p>Learning Efficient Convolutional Networks through Network Slimming</p></li><li><p>Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers</p></li></ul><p>(2) GAN</p><ul><li><p>GAN Slimming: All-in-One GAN Compression by A Unified Optimization Framework</p></li><li><p>GAN Compression: Efficient Architectures for Interactive Conditional GANs</p></li></ul><h3 id="二-注意事项："><a href="#二-注意事项：" class="headerlink" title="二. 注意事项："></a>二. 注意事项：</h3><ol><li>剪裁一个卷积层的 filter，需要修改后续卷积层的 filter. 即剪掉 $X<em>i$ 的一个 filter，会导致 $X</em>{i+1}$ 少一个 channel,  $X<em>{i+1}$ 对应的 filter 在 input_channel 维度上也要减 1。剪裁完 $X_i$之后，在计算 $X</em>{i+1}$ 的 filters 的 l1_norm  (下图中绿色一列)的时候，有两种选择<ul><li>算上被删除的一行：independent pruning </li><li>减去被删除的一行：greedy pruning</li></ul></li></ol><p><img src="/2020/11/24/network-pruning/5.png" style="zoom:45%;"></p><ol><li><p>在对 ResNet 等复杂网络剪裁的时候，还要考虑到后当前卷积层的修改对上一层卷积层的影响。在对 residual block 剪裁时，$X<em>{i+1}$ 层如何剪裁取决于 project shortcut 的剪裁结果，因为我们要保证 project shortcut 的 output 和 $X</em>{i+1}$ 的 output 能被正确的 concat.</p><p><img src="/2020/11/24/network-pruning/6.png" style="zoom:45%;"></p></li></ol><h5 id="2-敏感度的理解和迭代剪枝"><a href="#2-敏感度的理解和迭代剪枝" class="headerlink" title="2. 敏感度的理解和迭代剪枝"></a>2. 敏感度的理解和迭代剪枝</h5><p><img src="/2020/11/24/network-pruning/4.png" style="zoom:50%;"></p><p>​        如上图所示，横坐标是将 filter 剪裁掉的比例，竖坐标是精度，每条彩色虚线表示的是网络中的一个卷积层。 以不同的剪裁比例<strong>单独</strong>剪裁一个卷积层，并观察其在验证数据集上的精度损失，并绘出图中的虚线。虚线下降较慢的，对应的卷积层相对不敏感，我们优先修剪不敏感的卷积层的 filter。</p><p>​        考虑到多个卷积层间的相关性，一个卷积层的修改可能会影响其它卷积层的敏感度，我们采取了多次剪裁的策略，步骤如下：</p><ul><li>step1：统计各卷积层的敏感度信息</li><li>step2: 根据当前统计的敏感度信息，对每个卷积层剪掉少量 filter,  并统计 FLOPS，如果 FLOPS 已满足要求，进入 step4，否则进行step3。</li><li>step3: 对网络进行简单的 fine-tune，进入 step1</li><li>step4: fine-tune训练至收敛</li></ul><h4 id="三-参考资料"><a href="#三-参考资料" class="headerlink" title="三. 参考资料"></a>三. 参考资料</h4><ul><li><a href="https://zhuanlan.zhihu.com/p/153496637">https://zhuanlan.zhihu.com/p/153496637</a>    </li><li><a href="https://github.com/coldlarry/YOLOv3-complete-pruning">https://github.com/coldlarry/YOLOv3-complete-pruning</a></li><li><a href="https://zhuanlan.zhihu.com/p/97198052">https://zhuanlan.zhihu.com/p/97198052</a></li><li><a href="https://blog.csdn.net/jinzhuojun/article/details/100621397">https://blog.csdn.net/jinzhuojun/article/details/100621397</a></li><li><a href="https://blog.csdn.net/wujianing_110117/article/details/105526241?utm_medium=distribute.pc_relevant.none-task-blog-title-6&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/wujianing_110117/article/details/105526241?utm_medium=distribute.pc_relevant.none-task-blog-title-6&amp;spm=1001.2101.3001.4242</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>lightweight-cnn-architecture-design</title>
    <link href="/2020/11/15/lightweight-cnn-architecture-design/"/>
    <url>/2020/11/15/lightweight-cnn-architecture-design/</url>
    
    <content type="html"><![CDATA[<p>常见的移动端模型：mobilenet 系列和 shufflenet 系列和 GhostNet。对于 MnasNet、PorxylessNas、FBNet 等轻量级搜索架构则不涉及。</p><a id="more"></a><h4 id="1-Mobilenet-v1"><a href="#1-Mobilenet-v1" class="headerlink" title="1. Mobilenet v1"></a>1. Mobilenet v1</h4><p>MobileNet模型的核心就是<strong>将原本标准的卷积操作因式分解成一个depthwise convolution和一个1*1的卷积（文中叫pointwise convolution）操作。简单讲就是将原来一个卷积层分成两个卷积层，其中前面一个卷积层的每个filter 都只跟 input 的每个 channel 进行卷积，然后后面一个卷积层则负责 combining，即将上一层卷积的结果进行合并。 </strong></p><h5 id="具体实现："><a href="#具体实现：" class="headerlink" title="具体实现："></a>具体实现：</h5><p>(1) 传统的卷积计算：假设 M 表示 input 的 channel 个数，N 表示 output 的 channel 个数（也是本层的卷积核个数）。因此如果假设卷积核大小是 <code>DK*DK*M*N</code>，输出是 <code>DF*DF*N</code>，那么标准卷积的计算量是 <code>DK*DK*M*N*DF*DF</code>。如下图(a)所示。</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/1.png" alt="x" style="zoom:50%;"></p><ul><li><p>首先使用 <code>M</code> 个 <code>Dk*Dk</code>的卷积核对输入( <code>M*DF*DF</code> )进行卷积,这里要注意的是每个 filter 只跟输入的一个通道进行卷积(也就是说，卷积核的通道数为 1)，将不同卷积核的结果进行组合，可以得到大小为：<code>M*DF*DF</code>的输出。其计算量为  <code>M*DK*DK*DF*DF</code>。(这里使用的 3*3 的卷积核，padding 为 1 )。如上图 (b) 所示。</p></li><li><p>第二步是对之前的 <code>M*DF*DF</code> 的输出进行卷积，卷积核为N个 <code>1*1*M</code>  的卷积，这样可以得到大小 <code>N*DF*DF</code>  的输出。其计算量为 <code>1*1*N*M*DF*DF</code>。如上图 (c) 所示。</p></li></ul><p>所以其总的计算量相比传统的卷积计算减少了：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/2.png" alt="x" style="zoom:50%;"></p><p>（2）标准卷积（左边）和因式分解后的卷积（右边）的差别如下所示。注意到卷积操作后都会跟一个Batchnorm和ReLU操作。</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/3.png" alt="x" style="zoom:50%;"></p><p>​      总的来说，由于采用 depth-wise convolution 会有一个问题，就是导致「信息流通不畅」，即 <strong>输出的 feature map 仅包含输入的 feature map 的一部分</strong>，MobileNet 用 point-wise convolution 解决这个问题。在后来，ShuffleNet 采用同样的思想对网络进行改进，只不过把 point-wise convolution 换成了 channel shuffle。</p><h4 id="2-Shufflenet-v1"><a href="#2-Shufflenet-v1" class="headerlink" title="2. Shufflenet v1"></a>2. Shufflenet v1</h4><p>​    Shufflenet v1 主要采用 <strong>channel shuffle、pointwise group convolutions 和 depthwise convolution来修改原来的ResNet单元</strong>。从而大幅度降低深度网络计算量。</p><ul><li>channel shuffle：不同group的通道进行组合。</li><li>pointwise group convolutions：带有 group 的 1 * 1 卷积。</li><li>depthwise convolutions：group 等于通道数的组卷积。</li></ul><h5 id="具体实现：-1"><a href="#具体实现：-1" class="headerlink" title="具体实现："></a>具体实现：</h5><p>（1）a 图是一个带有 depthwise convolution 的resnet 结果，所谓的 depthwise convolution 可以参见</p><p>（2）a 图 —&gt; b 图，用带group的 1 <em> 1卷积(2个)代替原来的1 </em> 1卷积，同时添加一个channel shuffle 操作。</p><p>（3）b 图 —&gt; c 图，添加了一个步长为2的 Average pooling，将Resnet最后的Add操作c改为concat操作，也就是按channel合并，类似googleNet的Inception操作。</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/5.png" alt="x" style="zoom:38%;"></p><p>​    shuffle 具体来说是 channel shuffle，将各部分的 feature map 的 channel 进行有序的打乱，构成新的 feature map，以解决 group convolution 带来的「信息流通不畅」问题。（MobileNet 用 pointwise convolution 解决）因此可知道 shuffle 不是什么网络都需要用的，有一个前提，就是采用了 group convolution。采用 shuffle 替换掉 1<em>1 卷积，可以减少权值参数，而且是大量减少。<em>*文中提到两次，对于小型网络，多多使用通道会比较好。所以，以后若涉及小型网络，可考虑如何提升通道使用效率。</em></em></p><p>ShuffleNet V1 与 Mobilenet V1的区别：</p><ol><li>与 MobileNet 一样采用了 depth-wise convolution，但是针对 depth-wise convolution 带来的副作用——「信息流通不畅」，ShuffleNet 用 channel shuffle 来解决，MobileNet 用 point-wise convolution 解决。</li><li>在网络拓扑方面，ShuffleNet 采用的是 resnet 的思想，而 mobielnet 采用的是 VGG 的堆叠思想（SqueezeNet 也是采用 VGG 思想）。</li></ol><h4 id="3-Mobilenet-V2"><a href="#3-Mobilenet-V2" class="headerlink" title="3. Mobilenet V2"></a>3. Mobilenet V2</h4><h5 id="MobileNet-v2的主要贡献：Inverted-Residual-和-Linear-Bottleneck。具体实现："><a href="#MobileNet-v2的主要贡献：Inverted-Residual-和-Linear-Bottleneck。具体实现：" class="headerlink" title="MobileNet v2的主要贡献：Inverted Residual 和 Linear Bottleneck。具体实现："></a>MobileNet v2的主要贡献：Inverted Residual 和 Linear Bottleneck。具体实现：</h5><p>(1) <strong>添加 residual connection</strong>。</p><p>(2) <strong>通过 1x1 卷积先提升通道数，再通过 depthwise 的 3x3 空间卷积，再用 1x1 卷积降低维度。作者称之为Inverted residual block，两边窄中间宽，像柳叶，仅用较小的计算量就能得到较好的性能</strong>。</p><p>(3) <strong>使用ReLU6替换传统的ReLU,  并将最后输出的 ReLU6 去掉，直接线性输出</strong>。</p><p>如下图是 mobilenet v1与 mobilenet v2 的对比图。两者的区别在于：</p><ul><li>v2在原有的 dw 之前加了一个 pw 专门用来升维。这么做是因为不能改变通道数量，先加 pw 升维后，dw就能在高维提特征了。</li><li>v2 把原本 dw 之后用来降维的 pw 后的激活函数给去掉了。这么做是因为他认为非线性在高维有益处，但在低维（例如pw降维后的空间）不如线性好。<strong>ReLU 会对 channel 数低的张量造成较大的信息损耗。ReLU 会使负值置零，channel 数较低时会有相对高的概率使某一维度的张量值全为 0，即张量的维度减小了，而且这一过程无法恢复。</strong></li></ul><p><img src="/2020/11/15/lightweight-cnn-architecture-design/8.png" alt="x" style="zoom:50%;"></p><p>如下图是 Resnet 与 mobilenet v2 的对比图。可以看到两者的结果很相似。不过ResNet是先降维（0.25倍）、提特征、再升维。而v2则是先升维（6倍）、提特征、再降维。另外 v2 也用 DW 代替了标准卷积来做特征提取。why ? <strong>原始的 ResNet block 之所以 1x1 卷积降通道，是为了减少计算量，不然中间的 3x3 卷积计算量太大。所以是两边宽中间窄的沙漏形。但现在中间的 3x3 卷积为 Depthwise 的，计算量很少了，所以通道多一点效果更好，所以通过 1x1 卷积先提升通道数。</strong>两端的通道数都很小，所以 1x1 卷积升通道或降通道计算量都不大，而中间通道数虽然多，但 Depthwise 的卷积计算量也不大。是两边窄中间宽的柳叶形。</p><p>注：示意表达式省略了Shortcut。</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/7.png" alt="x" style="zoom:50%;"></p><h4 id="4-shufflenet-V2"><a href="#4-shufflenet-V2" class="headerlink" title="4. shufflenet V2"></a>4. shufflenet V2</h4><h5 id="shufflenetV2-提出了一种channel-split操作-1-将输入channels分为两部分，-2-一部分保持不变，另一部分由三个卷积组成-3-卷积之后，将两部分拼接起来-4-最后在通过channel-shuffle操作来保持两个分支间的信息交流。"><a href="#shufflenetV2-提出了一种channel-split操作-1-将输入channels分为两部分，-2-一部分保持不变，另一部分由三个卷积组成-3-卷积之后，将两部分拼接起来-4-最后在通过channel-shuffle操作来保持两个分支间的信息交流。" class="headerlink" title="shufflenetV2 提出了一种channel split操作, (1) 将输入channels分为两部分， (2) 一部分保持不变，另一部分由三个卷积组成  (3) 卷积之后，将两部分拼接起来 (4) 最后在通过channel shuffle操作来保持两个分支间的信息交流。"></a><strong>shufflenetV2 提出了一种channel split操作, (1) 将输入channels分为两部分， (2) 一部分保持不变，另一部分由三个卷积组成  (3) 卷积之后，将两部分拼接起来 (4) 最后在通过channel shuffle操作来保持两个分支间的信息交流。</strong></h5><h5 id="具体实现：-2"><a href="#具体实现：-2" class="headerlink" title="具体实现："></a>具体实现：</h5><p><strong>(1) 基本单元</strong></p><p>如下左图所示</p><p>(1) 在每个单元的开始，<code>c</code> 特征通道的输入被分为两支，分别带有 <code>c−c&#39;</code> 和 <code>c&#39;</code>个通道。</p><p>(2)  一个分支仍然保持不变。另一个分支由三个卷积组成，令输入和输出通道相同。与 ShuffleNet V1 不同的是，两个 1×1 卷积不再是组卷积。是因为分割操作已经产生了两个组。</p><p>(3) 卷积之后，把两个分支拼接起来，从而通道数量保持不变。</p><p>(4) 然后进行与 ShuffleNet V1 相同的「Channel Shuﬄe」操作来保证两个分支间能进行信息交流。「Shuffle」之后，下一个单元开始运算。</p><p>注意，! ShuﬄeNet V1 [15] 中的「加法」操作不再存在。! 像 ReLU 和深度卷积这样的操作只存在一个分支中。另外，! 三个连续的操作「拼接」、「Channel Shuﬄe」和「通道分割」合并成一个操作。</p><p><strong>空间下采样单元：</strong></p><p>对于空间下采样，该单元经过稍微修改，详见下图右， 通道分割运算被移除。因此，输出通道数量翻了一倍。</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/9.png" alt="x" style="zoom:50%;"></p><p>ShuffleNet V2 对高效的网络架构设计得出了 4 个实用的指导原则：</p><ol><li>卷积的输入通道 c1 和输出通道 c2 相同时，有最小的内存访问成本 (MAC)</li><li>过多的分组卷积增加 MAC，MAC 随着组数 g 的增长而增加</li><li>降低网络结构的破碎程度（减少分支以及所包含的基本单元）。”multi-path“结构使用许多碎片操作符，虽然有利于提高精度，但它降低了并行度</li><li>减少 element-wise 操作。包括 ReLU、AddTensor、AddBias等。它们的 FLOPs 较小，但 MAC 相对较大</li></ol><p>ShuffleNet V2 的设计原则基于以上四点：pointwise group 卷积和瓶颈结构都增加了 MAC (1和2)。这一成本是不可忽视的，特别是对轻量的模型。此外，使用太多组违反了 3。 快捷连接中的 element-wise Add”操作也是不可取的 (4)。因此，为了达到高的模型容量和效率，关键问题是保持同样宽的通道，既不密集卷积，也不过多组。</p><h4 id="5-MobileNet-V3"><a href="#5-MobileNet-V3" class="headerlink" title="5. MobileNet V3"></a>5. MobileNet V3</h4><p>​    用神经结构搜索（NAS）来完成 V3。参考了三种模型：MobileNe tV1 的深度可分离卷积、MobileNet V2 的具有线性瓶颈的反向残差结构、MnasNe+SE 的自动搜索模型。</p><p>相关技术：</p><ol><li>网络的架构为基于 <strong>NAS</strong> 实现的 MnasNet（效果比 MobileNet V2 好）。借鉴与 Mnasnet， 相对于 mobilenet V2, V3 启用 5×5 的 deepwise 卷积。</li><li>网络结构搜索中，结合两种技术：资源受限的 NAS（platform-aware NAS）与 NetAdapt。</li><li>引入 MobileNet V1 的深度可分离卷积、MobileNet V2 的具有线性瓶颈的倒残差结构、SENet 的 squeeze and excitation 结构、新的激活函数 h-swish。</li><li>修改 MobileNet V2 网络端部最后阶段为 1x1 卷积，减小计算。作者认为， V2 模型中的倒残差结构使用 1×1 卷积来构建最后层，以扩展到高维特征空间，可以提取更多更丰富的特征，但同时也引入了额外的计算成本与延时。所以，需要在保留高维特征的前提下减小延时。方法是将 1×1 层放到最终的平均池化之后。这样的话最后一组特征由 <strong>avgpool 7x7</strong> 变为 <strong>pool 7x7+conv2d 1x1</strong>。</li></ol><p>综合以上，V3 的 block 结构如下所示：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/11.png" alt="x" style="zoom:60%;"></p><h4 id="6-ShuffleNetV2"><a href="#6-ShuffleNetV2" class="headerlink" title="6. ShuffleNetV2+"></a>6. ShuffleNetV2+</h4><p>没有相关论文，只是旷视提出的一个简单的 shufflenetv2 的加强版本， 发布在 github 上。主要的操作是替换其中的激活函数为 h-swish， 并且添加了 SE 模块。</p><p>参考网址：<a href="https://github.com/megvii-model/ShuffleNet-Series/tree/master/ShuffleNetV2%2B">https://github.com/megvii-model/ShuffleNet-Series/tree/master/ShuffleNetV2%2B</a></p><h4 id="7-MobileNeXt"><a href="#7-MobileNeXt" class="headerlink" title="7. MobileNeXt"></a>7. MobileNeXt</h4><p>​        本文主要针对MobileNetV2中倒置残差块（inverted residual block）的设计和不足进行了分析，并基于分析结果提出了新颖的sandglass模块，这种轻量级模块有原生残差块和倒置残差块的影子，是一种正向残差设计。</p><ul><li><p>原生残差块组成：1x1卷积（降维<strong>降低模型复杂度</strong>）、3x3卷积（空间信息变换）、1x1卷积（升维<strong>用于和 shortcut 分支相加</strong>）</p></li><li><p>逆残差块组成：1x1卷积（升维<strong>提升模型效果</strong>）、3x3深度可分卷积（空间信息变换）、1x1卷积（降维）</p></li></ul><p>​        本文作者认为逆残差模块会削弱梯度跨层传播的能力，将特征从高维空间压缩到低维空间，会造成信息丢失，同时这也容易引起梯度混淆问题(特指梯度消失或梯度爆炸)，从而影响训练的收敛和最终模型的性能。本文提出的sandglass模块如下图所示：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/15.png" alt="x" style="zoom:35%;"></p><p>​        sandglass 模块是在轻量级的残差块上依据逆残差块所存在的问题所改进的，同时这个模块还用到了MobileNetV2中的线性瓶颈设计，即只在第一个 3x3 卷积后边和第二个 1x1 卷积后边使用非线性激活函数 relu6，其他层后边使用线性激活函数(y=x), 这有助于避免零化现象的出现，进而减少信息损失</p><h4 id="8-xception"><a href="#8-xception" class="headerlink" title="8. xception"></a>8. xception</h4><p>Xception 的结构基于 ResNet，但是将其中的卷积层换成了 Separable Convolution（极致的 Inception模块）。 Xception（极致的 Inception）: 先进行1x1 卷积操作，再对 1×1 卷积后的每个channel分别进行 3×3 卷积操作，最后将结果 concat：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/18.png" alt="x" style="zoom:35%;"></p><h4 id><a href="#" class="headerlink" title=" "></a> </h4><h4 id="9-efficinet-原理"><a href="#9-efficinet-原理" class="headerlink" title="9. efficinet 原理"></a>9. efficinet 原理</h4><p><strong>原论文: EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks ICML 2019</strong> </p><p><strong>利用复合系数统一缩放模型的所有维度，达到精度最高效率最高，符合系数包括 w, d, r，其中，w表示卷积核大小，决定了感受野大小；d表示神经网络的深度；r表示分辨率大小。</strong></p><p>文中总结了我们常用的三种网络调节方式：<strong>增大感受野w，增大网络深度d，增大分辨率大小r</strong>，三种方式示意图如下：其中，(a)为基线网络，也可以理解为小网络；(b)为增大感受野的方式扩展网络；(c)为增大网络深度d的方式扩展网络；(d)为增大分辨率r的方式扩展网络；(e)为本文所提出的混合参数扩展方式；</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/19.png" alt="x" style="zoom:75%;"></p><p><strong>复合系数的数学模型</strong></p><p>文中给出了一般卷积的数学模型如下：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/20.png" alt="x" style="zoom:100%;"></p><p>其中 H, W为卷积核大小，C为通道数，X为输入tensor。 则复合系数的确定转为如下的优化问题：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/21.png" alt="x" style="zoom:100%;"></p><p>调节 d, w, r 使得满足内存Memory和浮点数量都小于阈值要求； 为了达到这个目标，文中提出了如下的方法：</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/22.png" alt="x" style="zoom:100%;"></p><p>对于这个方法，我们可以通过一下两步来确定d, w, r参数： 第一步是固定Φ=1，然后通过网格搜索找到满足公式3的最优α、β、γ，比如对于EfficientNet-B0网络而言，最佳的参数分别是α=1.2、β=1.1、γ=1.15（此时得到的也就是EfficientNet-B1）。第二步是固定第一步求得的α、β、γ参数，然后用不同的Φ参数得到EfficientNet-B1到EfficientNet-B7网络。</p><h4 id="10-GhostNet"><a href="#10-GhostNet" class="headerlink" title="10. GhostNet"></a>10. GhostNet</h4><h5 id="1-出发点："><a href="#1-出发点：" class="headerlink" title="(1) 出发点："></a>(1) 出发点：</h5><p>​      通过对比分析 ResNet-50 网络第一个残差组( Residual group )输出的特征图可视化结果，发现一些特征图高度相似。如果按照传统的思考方式，可能认为这些相似的特征图存在冗余，是多余信息，想办法避免产生这些高度相似的特征图。本文的思路是<strong>不去刻意的避免产生这种Ghost对，而是尝试利用简单的线性操作来获得更多的Ghost对。</strong></p><p>其基本操作如下：</p><ul><li>使用常规卷积(这里使用的 conv1x1)来获得本征特征层。</li><li>通过一个线性操作(这里使用的是 depthwise 操作)对本征特征层进行线性变化，获得 ghost 特征层。</li><li>将 ghost 特征层和 ghost 特征层进行拼接。</li></ul><p><img src="/2020/11/15/lightweight-cnn-architecture-design/13.png" alt="x" style="zoom:50%;"></p><p>通过将 ResNet 中的 Residual Block 中的卷积操作用 Ghost Module 替换就可以得到 Ghost BottleNeck。图下图所示:</p><p><img src="/2020/11/15/lightweight-cnn-architecture-design/14.png" style="zoom:50%;"></p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li><p>关于网络结构的变迁， 如下图所示(所有 conv 层之后，都使用了 BN 层， 且 BN 层在激活函数之前)</p><ul><li>mobilenet v1 将普通卷积分解为  DepthWise 和 PointWise 两个操作</li><li>shufflenet v1 引入 channel shuffle 操作，初步形成 GConv + shuffle + DW + GConv 的卷积组合</li><li>mobilenet v2 引入了 逆残差模块， 此时的形成了 PW+DW+PW 的组合。 注意这里最后一个 PW 使用线性函数</li><li>shufflent v2 引入了 channels split 操作， 并将 concat + shuffle + split 进行合并</li></ul></li></ul><p><img src="/2020/11/15/lightweight-cnn-architecture-design/17.png" alt></p><ul><li><p>一些小经验</p><ul><li>使用 DW 和 PW 进行加速是常规操作， 但是对 DW和 PW 的顺序还需要进一步探索。（比如 mobilenext 则使用了 DW + PW + PW+ DW 的组合形式）</li><li><strong>MobileNetV2的倒置残差模块 + SE block + H-swish 是一个屡试不爽的组合</strong>，虽然速度会有所损失。</li><li><strong>激活函数的放置位置还没有定论</strong>（虽然 mobilenet v2 进行了探索，提出了线性瓶颈）</li><li>有一些网络(ghostnet 和 bsconv ) 提出了<strong>对卷积核/特征层的冗余进行探索分析</strong>，从而降低运算量， 这也算一个方向。</li></ul></li><li><p>一些对于轻量级检测和分割网络的探索： 轻量级检测的核心问题还是低层特征和高层特征的融合问题，在 backbone 通常选择上面的 轻量级分类网络：</p><ul><li>Pelee: A Real-Time Object Detection System on Mobile Devices</li><li>Tiny-dsod: Lightweight object detection for resource-restricted usages.</li><li>Light-head R-cnn: In defense of two-stage object detector</li><li>ThunderNet: Towards Real-time Generic Object Detection</li><li><p>NanoDet</p></li><li><p>BiSeNet（分割）</p></li><li>DFANet（分割）</li></ul></li><li><p>MIT Han Lab 在模型压缩和加速方向做了很多探索性的工作， 可以重点关注。</p></li><li><p>nas 在相关领域一度很火，诞生了 MnasNet、PorxylessNas、FBNet  等工作。但是由于需要资源较多等原因，一直未加尝试。</p></li></ul><h4 id="参考论文："><a href="#参考论文：" class="headerlink" title="参考论文："></a>参考论文：</h4><ul><li><p>SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and &lt;0.5MB model size.</p></li><li><p>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</p></li><li><p>MobileNetV2: Inverted Residuals and Linear Bottlenecks</p></li><li><p>Searching for MobileNetV3(nas for efficient conv neural network) </p></li><li><p>ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</p></li><li><p>ShuffleNet V2: Practical Guidelines for Ecient CNN Architecture Design </p></li><li><p>Xception: Deep Learning with Depthwise Separable Convolutions</p></li></ul><p>mobilent 逆残差结构的实现：</p><pre><code class="hljs python"><span class="hljs-comment"># Mobilenet V2</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InvertedResidual</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, inp, oup, stride, expand_ratio</span>):</span>        super(InvertedResidual, self).__init__()        self.stride = stride        self.use_res_connect = self.stride == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> inp == oup        self.conv = nn.Sequential(            <span class="hljs-comment"># pw</span>            nn.Conv2d(inp, inp * expand_ratio, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),            nn.BatchNorm2d(inp * expand_ratio),            nn.ReLU6(inplace=<span class="hljs-literal">True</span>),            <span class="hljs-comment"># dw</span>            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, <span class="hljs-number">3</span>, stride, <span class="hljs-number">1</span>, groups=inp * expand_ratio, bias=<span class="hljs-literal">False</span>),            nn.BatchNorm2d(inp * expand_ratio),            nn.ReLU6(inplace=<span class="hljs-literal">True</span>),            <span class="hljs-comment"># pw-linear</span>            nn.Conv2d(inp * expand_ratio, oup, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),            nn.BatchNorm2d(oup),        )    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        <span class="hljs-keyword">if</span> self.use_res_connect:            <span class="hljs-keyword">return</span> x + self.conv(x)        <span class="hljs-keyword">else</span>:            <span class="hljs-keyword">return</span> self.conv(x)</code></pre>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>img2col</title>
    <link href="/2020/11/13/img2col/"/>
    <url>/2020/11/13/img2col/</url>
    
    <content type="html"><![CDATA[<h4 id="1-im2col-基本原理"><a href="#1-im2col-基本原理" class="headerlink" title="1. im2col 基本原理"></a>1. im2col 基本原理</h4><p><strong>(1) 对于图像的变换：</strong></p><p>首先将每个卷积所卷积的区域作为一行，所有的卷积区域纵向排列，作为右乘矩阵。需要注意的是多个通道应该堆叠在下面。如下图所示：</p><p>单通道：</p><p><img src="/2020/11/13/img2col/1.jpeg" alt="img"></p><p>多通道：</p><p><img src="/2020/11/13/img2col/2.jpeg" alt="img"></p><p><strong>输入特征图转化得到的矩阵尺度 = (卷积组输入通道数*卷积核高*卷积核宽) * (卷积层输出单通道特征图高 * 卷积层输出单通道特征图宽)</strong></p><p><strong>(2) 对于卷积核的变换</strong></p><p>将一个卷积核拉伸为一个横行，作为左乘矩阵：(为什么要拉伸为横行，在于对应的卷积区域拉伸为竖行，这样才能与之相对应，进行矩阵乘法)</p><p><img src="/2020/11/13/img2col/3.jpeg" alt="img"></p><p><strong>权值矩阵尺度 = (输出层通道数) * (卷积输入通道数*卷积核高*卷积核宽)</strong></p><p><strong>(3) 将卷积核矩阵核图像矩阵相乘即可</strong></p><p><img src="/2020/11/13/img2col/4.jpeg" alt="img"></p><p><strong>卷积层输出尺度 = (卷积层输出通道数) * (卷积层输出单通道特征图高 * 卷积层输出单通道特征图宽)</strong></p><p>最后需要将结果调整成为需要的大小： </p><p><img src="/2020/11/13/img2col/5.jpeg" alt="img"></p><p><strong>(4) 对于多个输出通道图像的卷积</strong></p><p>应该纵向堆叠每个卷积层</p><p><img src="/2020/11/13/img2col/6.jpeg" alt="img"></p><p>最后再调整输出矩阵：</p><p><img src="/2020/11/13/img2col/7.jpeg" alt="img"></p><h4 id="2-总体简图："><a href="#2-总体简图：" class="headerlink" title="2. 总体简图："></a>2. 总体简图：</h4><p>下面是一个整体矩阵乘法的简图：</p><p><img src="/2020/11/13/img2col/8.jpeg" alt="img"></p><h4 id="3-im2col-cpu-源码剖析"><a href="#3-im2col-cpu-源码剖析" class="headerlink" title="3. im2col_cpu 源码剖析"></a>3. im2col_cpu 源码剖析</h4><p>im2col_cpu函数将卷积层输入转化为矩阵相乘的右元，核心是5个for循环，首先第一个for循环表示按照输入的通道数逐个处理卷积层输入的特征图，下面笔者将用图示表示剩余的四个for循环操作，向读者朋友们展示卷积层输入的单通道特征图是通过怎样的方式转化为一个矩阵。在这里我们假设，卷积层输入单通道特征图原大小为5*5，高和宽方向的pad为1，高和宽方向步长为2，卷积核不进行扩展。</p><p>  我们先计算一下，卷积层输入单通道特征图转化得到的矩阵的尺度，矩阵的行数应该为卷积核高<em>卷积核宽，即为9，列数应该为卷积层输出特征图高(output_h)</em>卷积层输出特征图宽(output_w)，也为9，那么，im2col算法起始由下图开始：</p><p><img src="/2020/11/13/img2col/11.png" alt></p><p>首先kernel_row为0，kernel_col也为0。按照input_row = -pad_h + kernel_row * dilation_h计算input_row的值，在这里，pad_h为1，kernel_row为0，dilation_h为1，计算出input_row为-1，此时output_row为3，满足函数中的第一个if条件，那么在输出图像上先置output_w个零，因为output_w为3，因此得到下图：</p><p><img src="/2020/11/13/img2col/12.png" alt></p><p> 然后input_row加上步长2，由-1变成1，此时output_rows为2，计算input_col等于-1，此时执行input_col定义下面的for循环，得到3个值：依次往目标矩阵中填入0，data_im[1*5+1]和data_im[1*5+3]，即填入0,7和9。得到下图：</p><p><img src="/2020/11/13/img2col/13.png" alt></p><p>再接着执行，此时input_row再加上2变为3，此时output_rows变为1，计算input_col等于-1，执行input_col定义下面的for循环，得到3个值，分别为0，data_im[3*5+1]和data_im[3*5+3]，即填入0,17和19。得到下图：(以上操作是将第一个通道的卷积对应第一个对应位置进放好)</p><p><img src="/2020/11/13/img2col/14.png" alt></p><p> 接着，kernel_col变成1，此时kernel_row为0，kernel_col为1。计算input_row又变成-1，第一个if条件成立，那么，再在输出矩阵上输出3个0。然后，input_row变成1，input_col分别为0(-1+1)，2(-1+1+2)和4(-1+1+2+2)时，输出矩阵上分别输出data_im[1*5+0]，data[1*5+2]，data[1*5+4]，即分别填入6,8,10。然后，input_row变成3，input_col分别为0，2，4时，输出矩阵上分别输出data_im[3*5+0]，data[3*5+2]，data[3*5+4]，即分别输出16,18,20。（将第一个通道的卷积对应第二个对应位置进放好）</p><p><img src="/2020/11/13/img2col/15.png" alt></p><p>然后，kernel_col变成2，此时kernel_row为0，kernel_col为2。计算input_row又变成-1，第一个if条件成立，那么，再在输出矩阵上输出3个0。然后，input_row变成1，input_col分别为1(-1+2)，3(-1+2+2)和5(-1+2+2+2)时，输出矩阵上分别输出data_im[1*5+1]，data[1*5+3]，0，即分别填入7,9,0。然后，input_row变成3，input_col分别为1，3，5时，输出矩阵上分别输出data_im[3*5+0]，data[3*5+2]，0，即分别输出17,19,0。见下图：（将第一个通道的卷积对应第三个对应位置进放好）</p><p><img src="/2020/11/13/img2col/16.png" alt></p><p>接着，kernel_row变成1，kernel_col变成0。计算input_row又变成0，input_col分别为-1(-1+0)，1(-1+0+2)和3(-1+0+2+2)，输出矩阵上分别输出0，data[0*5+1]，data[0*5+3]，即分别填入0,2,4。然后，input_row变成2，input_col分别为-1，1和3时，输出矩阵上分别输出0，data[2*5+1]，data[2*5+3]，即分别填入0,12,14。然后，input_row变成4，input_col分别为-1，1，3时，输出矩阵上分别输出0，data[4*5+1]，data[4*5+3]，即分别输出0,22,24。见下图：（将第一个通道的卷积对应第四个对应位置进放好）</p><p><img src="/2020/11/13/img2col/17.png" alt></p><p>然后，kernel_row为1，kernel_col变成1。计算input_row为0，input_col分别为0(-1+1)，2(-1+1+2)和4(-1+1+2+2)，输出矩阵上分别输出data[0*5+0]，data[0*5+2]，data[0*5+4]，即分别填入1,3,5。然后，input_row变成2，input_col分别为0，2和4时，输出矩阵上分别输出data[2*5+0]，data[2*5+2]，data[2*5+4]，即分别填入11,13,15。然后，input_row变成4，input_col分别为0，2，4时，输出矩阵上分别输出data[4*5+0]，data[4*5+2]，data[4*5+4]，即分别输出21,23,25。见下图：（将第一个通道的卷积对应第五个对应位置进放好）</p><p><img src="/2020/11/13/img2col/18.png" alt></p><p>然后，kernel_row为1，kernel_col变成2。计算input_row为0，input_col分别为1(-1+2)，3(-1+2+2)和5(-1+2+2+2)，输出矩阵上分别输出data[0*5+1]，data[0*5+3]，0，即分别填入2,4,0。然后，input_row变成2，input_col分别为1，3和5时，输出矩阵上分别输出data[2*5+1]，data[2*5+3]，0，即分别填入12,14,0。然后，input_row变成4，input_col分别为1，3，5时，输出矩阵上分别输出data[4*5+1]，data[4*5+3]，0，即分别输出22,24,0。见下图：（将第一个通道的卷积对应第六个对应位置进放好）</p><p><img src="/2020/11/13/img2col/19.png" alt></p><p>   接着，kernel_row变成2，kernel_col变成0。计算input_row为1，input_col分别为-1(-1+0)，1(-1+0+2)和3(-1+0+2+2)，输出矩阵上分别输出0，data[1*5+1]，data[1*5+3]，即分别填入0,7,9。然后，input_row变成3，input_col分别为-1，1和3时，输出矩阵上分别输出0，data[3*5+1]，data[3*5+3]，即分别填入0,17,19。然后，input_row变成5，满足第一个if条件，直接输出三个0。见下图：（**将第一个通道的卷积对应第七个对应位置进放好）</p><p><img src="/2020/11/13/img2col/20.png" alt="Center"></p><p>   然后，kernel_row为2，kernel_col变成1。计算input_row为1，input_col分别为0(-1+1)，2(-1+1+2)和4(-1+1+2+2)，输出矩阵上分别输出data[1*5+0]，data[1*5+2]，data[1*5+4]，即分别填入6,8,10。然后，input_row变成3，input_col分别为0，2和4时，输出矩阵上分别输出data[3*5+0]，data[3*5+2]，data[3*5+4]，即分别填入16,18,20。然后，input_row变成5，满足第一个if条件，直接输出三个0。见下图：（将第一个通道的卷积对应第八个对应位置进放好）</p><p><img src="/2020/11/13/img2col/21.png" alt></p><p>   最后，kernel_row为2，kernel_col变成2。计算input_row为1，input_col分别为1(-1+2)，3(-1+2+2)和5(-1+2+2+2)，输出矩阵上分别输出data[1*5+1]，data[1*5+3]，0，即分别填入7,9,0。然后，input_row变成3，input_col分别为1，3和5时，输出矩阵上分别输出data[3*5+1]，data[3*5+3]，0，即分别填入17,19,0。然后，input_row变成5，满足第一个if条件，直接输出三个0。见下图：（将第一个通道的卷积对应第五个对应位置进放好）</p><p><img src="/2020/11/13/img2col/22.png" alt></p><p>   到此卷积层单通道输入特征图就转化成了一个矩阵，请读者朋友们仔细看看，矩阵的各列就是卷积核操作的各小窗口。</p><p><img src="/2020/11/13/img2col/23.png" alt></p><p><strong>!!! 注意点：</strong></p><p><strong>（1）如果是多个通道的话，就要将其他通道放置在这个通道的下面，最终的结果是生成矩阵的每一列对应一个卷积核(多个通道)。</strong></p><p><strong>（2）卷积中的zero-padding操作的实现，并不是真正在原始输入特征图周围添加0，而是在特征图转化得到的矩阵上的对应位置添加0。</strong></p><p><strong>（3）这种算法的核心点在于，先去找卷积核(单通道)对应所有卷积结果对应的某个位置的像素值，将其放置在一行，从而完整单通道的复制。当然也可以找到某个卷积核(单通道)对应的位置，将其拉伸为列。</strong></p><p><strong>而im2col_cpu函数功能的相反方向的实现则有由col2im_cpu函数完成，笔者依旧把该函数的代码注释放在下面：</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">/*col2im_cpu为im2col_cpu的逆操作接收13个参数，分别为输入矩阵数据指针(data_col)，卷积操作处理的一个卷积组的通道 数(channels)，输入图像的高(height)与宽(width)，原始卷积核的高(kernel_h)与宽(kernel_w)， 输入图像高(pad_h)与宽(pad_w)方向的pad，卷积操作高(stride_h)与宽(stride_w)方向的步长， 卷积核高(stride_h)与宽(stride_h)方向的扩展，输出图像数据指针(data_im)*/</span>  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Dtype&gt;  <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">col2im_cpu</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Dtype* data_col, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> channels,  </span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> height, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> width, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> kernel_h, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> kernel_w,  </span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> pad_h, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> pad_w,  </span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> stride_h, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> stride_w,  </span></span><span class="hljs-function"><span class="hljs-params">    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> dilation_h, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> dilation_w,  </span></span><span class="hljs-function"><span class="hljs-params">    Dtype* data_im)</span> </span>&#123;      caffe_set(height * width * channels, Dtype(<span class="hljs-number">0</span>), data_im);   <span class="hljs-comment">//首先对输出的区域进行初始化，全部填充0  </span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> output_h = (height + <span class="hljs-number">2</span> * pad_h - (dilation_h * (kernel_h - <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>)) / stride_h + <span class="hljs-number">1</span>;  <span class="hljs-comment">//计算卷积层输出图像的宽  </span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> output_w = (width + <span class="hljs-number">2</span> * pad_w - (dilation_w * (kernel_w - <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>)) / stride_w + <span class="hljs-number">1</span>;  <span class="hljs-comment">//计算卷积层输出图像的高  </span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> channel_size = height * width;   <span class="hljs-comment">//col2im输出的单通道图像容量</span>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> channel = channels; channel--; data_im += channel_size) &#123;<span class="hljs-comment">//按照输出通道数一个一个处理  </span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> kernel_row = <span class="hljs-number">0</span>; kernel_row &lt; kernel_h; kernel_row++) &#123;              <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> kernel_col = <span class="hljs-number">0</span>; kernel_col &lt; kernel_w; kernel_col++) &#123;              <span class="hljs-keyword">int</span> input_row = -pad_h + kernel_row * dilation_h;<span class="hljs-comment">//在这里找到卷积核中的某一行在输入图像中的第一个操作区域的行索引  </span>         <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> output_rows = output_h; output_rows; output_rows--) &#123;               <span class="hljs-keyword">if</span> (!is_a_ge_zero_and_a_lt_b(input_row, height)) &#123;<span class="hljs-comment">//如果计算得到的输入图像的行值索引小于零或者大于输入图像的高(该行为pad)  </span>                data_col += output_w;  <span class="hljs-comment">//那么，直接跳过这output_w个数，这些数是输入图像第一行上面或者最后一行下面pad的0  </span>             &#125; <span class="hljs-keyword">else</span> &#123;                   <span class="hljs-keyword">int</span> input_col = -pad_w + kernel_col * dilation_w;<span class="hljs-comment">//在这里找到卷积核中的某一列在输入图像中的第一个操作区域的列索引  </span>                 <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> output_col = output_w; output_col; output_col--) &#123;                        <span class="hljs-keyword">if</span> (is_a_ge_zero_and_a_lt_b(input_col, width)) &#123;<span class="hljs-comment">//如果计算得到的输入图像的列值索引大于等于于零或者小于输入图像的宽(该列不是pad)  </span>                      data_im[input_row * width + input_col] += *data_col;<span class="hljs-comment">//将矩阵上对应的元放到将要输出的图像上  </span>                 &#125; <span class="hljs-comment">//这里没有else，因为如果紧挨的if条件不成立的话，input_row*width + input_col这个下标在data_im中不存在，同时遍历到data_col的对应元为0  </span>                 data_col++;<span class="hljs-comment">//遍历下一个data_col中的数  </span>                 input_col += stride_w;<span class="hljs-comment">//按照宽方向步长遍历卷积核上固定列在输入图像上滑动操作的区域  </span>             &#125;            &#125;            input_row += stride_h;<span class="hljs-comment">//按照高方向步长遍历卷积核上固定行在输入图像上滑动操作的区域  </span>             &#125;              &#125;          &#125;      &#125;  &#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>principles-of-detection-network-design</title>
    <link href="/2020/10/21/principles-of-detection-network-design/"/>
    <url>/2020/10/21/principles-of-detection-network-design/</url>
    
    <content type="html"><![CDATA[<p>​    对于一个深度学习问题， 我们应该尽量从模型、数据、算法三个方向进行处理。对于目标检测也不例外。 这里，我们将从模型、数据和算法三个角度对目标检测这个问题进行展开探讨。 由于很多问题都是行业内有待讨论，值得商榷的， 所以一些观点也会附上链接， 并挑选出笔者认为合适的方案。</p><a id="more"></a><h3 id="一-模型部分："><a href="#一-模型部分：" class="headerlink" title="一. 模型部分："></a>一. 模型部分：</h3><p>一个典型的目标检测的前向推理流程为：</p><p>输入图像  →  提取特征 → 特征融合 →  解析为 bbox →  nms → result</p><p>目标检测训练的典型流程为：</p><p>输入图像 → 提取特征→  特征融合 →  解析为 bbox → bbox 匹配 → 计算 loss 并反向传播</p><p>在此以 YOLOv3 为例， 来探讨一下检测模型的几个核心部分：</p><ul><li>网络主体框架：包括特征提取 backbone、特征融合 neck、特征输出 head</li><li>nms</li><li>loss 损失</li></ul><h4 id="1-网络主体框架"><a href="#1-网络主体框架" class="headerlink" title="1. 网络主体框架"></a>1. 网络主体框架</h4><p>一般分为三个部分： backbone、neck、head</p><h6 id="（1）backbone：常见的-backbone-设计方案有"><a href="#（1）backbone：常见的-backbone-设计方案有" class="headerlink" title="（1）backbone：常见的 backbone 设计方案有"></a>（1）backbone：常见的 backbone 设计方案有</h6><ul><li><p>基础网络：VGG16、Resnet50、CSPReNeXt50</p></li><li><p>Efficientnet、HRNet、SpineNet</p></li><li>轻量级网络：shufflenet、mobilenet、ghostnet </li></ul><h6 id="2-neck"><a href="#2-neck" class="headerlink" title="(2) neck"></a>(2) neck</h6><p>addition-aggregation：SPP 模块、ASPP 模块、RFB 模块和 SAM 模块</p><p>Path-aggregation：FPN、PANet、NAS-FPN、 FC-FPN、BiFPN、ASFF、 SFAM</p><h6 id="3-head"><a href="#3-head" class="headerlink" title="(3) head"></a>(3) head</h6><p>主要是用于输出结果，一般为常见的卷积层</p><ul><li>Dense Prediction(one-stage):<ul><li>RPN、SSD/YOLO、RetinaNet(anchor based)</li><li>CornerNet、CenterNet、MatrixNet、FCOS(anchor free)</li></ul></li><li>Sparse Prediction(two stage)<ul><li>Faster RCNN、F-FCN、Mask R-CNN(anchor based)</li><li>RepPoints(anchor free)</li></ul></li></ul><h4 id="2-nms-设计"><a href="#2-nms-设计" class="headerlink" title="2. nms 设计"></a>2. nms 设计</h4><p>nms 设计要点在于判定两个 bbox 的 IoU。常见的 IoU 如下所示：</p><h5 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h5><p>IoU就是我们所说的交并比，是目标检测中最常用的指标。 他的作用不仅用来确定正样本和负样本，还可以用来评价输出框 (predict box) 和 ground-truth 的距离。</p><script type="math/tex; mode=display">IoU = \frac{A \cup B}{ A \cap B}</script><p>其拥有几个特性：</p><ul><li>尺度不变形， 也就是说对尺度不敏感(scale invariant)。</li><li>度量的三要素：非负性、对称性、三角不等式。</li></ul><p>IoU 存在的问题：</p><ul><li>如果两个框没有相交，根据定义，IoU=0，不能反映两者的距离大小( 重合度 )。同时因为 loss=0，没有梯度回传，无法进行学习训练。</li><li>IoU 无法精确的反映两者的重合度大小。如下图所示，三种情况IoU都相等，但看得出来他们的重合度是不一样的，左边的图回归的效果最好，右边的最差。</li></ul><p><img src="/2020/10/21/principles-of-detection-network-design/3.png" style="zoom:40%;"></p><p>代码实现如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">IoU</span>(<span class="hljs-params">box1, box2</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; box1, box2: top, left, bottom, right &quot;&quot;&quot;</span>    area1 = (box1[<span class="hljs-number">2</span>] - box1[<span class="hljs-number">0</span>]) * (box1[<span class="hljs-number">3</span>] - box1[<span class="hljs-number">1</span>])    area2 = (box2[<span class="hljs-number">2</span>] - box2[<span class="hljs-number">0</span>]) * (box2[<span class="hljs-number">3</span>] - box2[<span class="hljs-number">1</span>])        in_h = min(box1[<span class="hljs-number">2</span>], box2[<span class="hljs-number">2</span>]) - max(box1[<span class="hljs-number">0</span>], box2[<span class="hljs-number">0</span>])    in_w = min(box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">3</span>]) - max(box1[<span class="hljs-number">1</span>], box2[<span class="hljs-number">1</span>])        inter = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> (in_h &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> in_w &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">else</span> in_h * in_w    <span class="hljs-keyword">return</span> inter / (area1 + area2 - inter)</code></pre><h5 id="GIoU"><a href="#GIoU" class="headerlink" title="GIoU"></a>GIoU</h5><p>论文地址: <a href="https://arxiv.org/pdf/1902.09630.pdf">https://arxiv.org/pdf/1902.09630.pdf</a></p><p>​        GIoU（Generalized Intersection over Union）相较于 IoU 多了一个 ‘Generalized’，这也意味着它能在更广义的层面上计算IoU，并解决刚才我们说的 ‘两个图像没有相交时，无法比较两个图像的距离远近’ 的问题。</p><p>GIoU 的计算公式为：</p><script type="math/tex; mode=display">GIoU = IoU - \frac{A^c - (A \cup B)}{ A^c}</script><p>其中 $A^c$ 代表两个图像的最小包络面积，也可以理解为这两个图像的最小外接矩形的面积。由此我们可以看出：</p><ul><li>原有 IoU 取值区间为 [0,1]，而 GIoU 的取值区间为 [-1,1]；在两个图像完全重叠时，IoU = GIoU = 1，在两个图像距离无限远时，IoU = 0 而 GIoU = -1。</li><li>与IoU只关注重叠区域不同，<strong>GIoU不仅关注重叠区域，还关注非重叠区域，这样能更好的的反映两个图像的重合度</strong>。其完善了图像的重叠度的计算功能。</li></ul><p>代码实现如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">GIoU</span>(<span class="hljs-params">box1, box2</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; box1, box2: top, left, bottom, right &quot;&quot;&quot;</span>    area1 = (box1[<span class="hljs-number">2</span>] - box1[<span class="hljs-number">0</span>]) * (box1[<span class="hljs-number">3</span>] - box1[<span class="hljs-number">1</span>])    area2 = (box2[<span class="hljs-number">2</span>] - box2[<span class="hljs-number">0</span>]) * (box2[<span class="hljs-number">3</span>] - box2[<span class="hljs-number">1</span>])        in_h = min(box1[<span class="hljs-number">2</span>], box2[<span class="hljs-number">2</span>]) - max(box1[<span class="hljs-number">0</span>], box2[<span class="hljs-number">0</span>])    in_w = min(box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">3</span>]) - max(box1[<span class="hljs-number">1</span>], box2[<span class="hljs-number">1</span>])    inter = <span class="hljs-number">0</span> <span class="hljs-keyword">if</span> (in_h &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> in_w &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">else</span> in_h * in_w    union = area1 + area2 - inter         iou = inter / union         area_C = ((max(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>]) - min(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>])) *               (max(box1[<span class="hljs-number">0</span>], box1[<span class="hljs-number">2</span>], box2[<span class="hljs-number">0</span>], box2[<span class="hljs-number">2</span>]) - min(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>])))          <span class="hljs-keyword">return</span> iou - (area_C - union) / area_C</code></pre><h5 id="DIoU"><a href="#DIoU" class="headerlink" title="DIoU"></a>DIoU</h5><p>参考论文：Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression</p><p>​        GIoU 虽然解决了 IoU 的一些问题(这里主要是重叠度的问题)，但是它并不能直接反映预测框与目标框之间的距离，比如当目标框完全包裹预测框的时候，IoU 和 GIoU 的值都一样，此时 GIoU 退化为IoU,  无法区分其相对位置关系。</p><p>DIoU(Distance-IoU)即可解决这个问题，它将两个框之间的重叠度、距离、尺度都考虑了进来，DIoU的计算公式如下：</p><script type="math/tex; mode=display">DIoU = IoU - \frac{\rho^2(b, b^{gt})}{c^2}</script><p>其中 $b$，$b^{gt}$ 分别代表两个框的中心点， $rho$ 代表两个中心点之间的欧氏距离，$c$ 代表最小包络矩形的对角线，即如下图所示：</p><p><img src="/2020/10/21/principles-of-detection-network-design/4.png" style="zoom6%;"></p><p>DIoU 相较于其他两种计算方法的优点是：</p><ul><li>DIoU 可直接最小化两个框之间的距离，所以作为损失函数的时候 loss 收敛的更快；</li><li>在两个框完全上下排列或左右排列时，没有空白区域，此时 GIoU 几乎退化为了 IoU，但是 DIoU 仍然有效。</li></ul><p>我们可以认为，<strong>DIoU 在完善图像重叠度的计算功能的基础上，实现了对图形距离的考量，但仍无法对图形长宽比的相似性进行很好的表示</strong>。</p><p>代码实现如下：</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">DIoU</span>(<span class="hljs-params">box1, box2</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; box1, box2: top, left, bottom, right &quot;&quot;&quot;</span>    C_2 = ((max(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>]) - min(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>])) ** <span class="hljs-number">2</span> +            (max(box1[<span class="hljs-number">0</span>], box1[<span class="hljs-number">2</span>], box2[<span class="hljs-number">0</span>], box2[<span class="hljs-number">2</span>]) - min(box1[<span class="hljs-number">1</span>], box1[<span class="hljs-number">3</span>], box2[<span class="hljs-number">1</span>], box2[<span class="hljs-number">3</span>])) ** <span class="hljs-number">2</span>)        D_2 = (((box2[<span class="hljs-number">1</span>]+box2[<span class="hljs-number">3</span>])/<span class="hljs-number">2</span> - (box1[<span class="hljs-number">1</span>]+box1[<span class="hljs-number">3</span>])/<span class="hljs-number">2</span>)**<span class="hljs-number">2</span> +          ((box2[<span class="hljs-number">0</span>]+box2[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span> - (box1[<span class="hljs-number">0</span>]+box1[<span class="hljs-number">2</span>])/<span class="hljs-number">2</span>)**<span class="hljs-number">2</span>)     iou = IoU(box1, box2)    <span class="hljs-keyword">return</span> iou - D_2 / C_2</code></pre><h5 id="CIoU"><a href="#CIoU" class="headerlink" title="CIoU"></a>CIoU</h5><p>CIoU 的全称为 Complete IoU，它在 DIoU 的基础上，还能同时考虑两个矩形的长宽比，也就是形状的相似性，CIoU 的计算公式为：</p><script type="math/tex; mode=display">CIoU = IoU - \frac{\rho^2(b, b^{gt})}{c^2} - \alpha v</script><p>其中 $\alpha$ 是权重参数，而 $v$ 用来度量长宽比的相似性：</p><script type="math/tex; mode=display">v = \frac{4}{\pi^2} (arctan \frac{w^{gt}}{h^{gt}} - arctan \frac{w}{h})^2, \\\alpha = \frac{v}{(1-IoU) + v }</script><p>可以看出，<strong>CIoU 就是在 DIoU 的基础上，增加了图像相似性(长宽比)的影响因子，因此可以更好的反映两个框之间的差异性</strong>。</p><p>代码实现如下：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">CIoU</span>(<span class="hljs-params">box1, box2</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; box1, box2: top, left, bottom, right &quot;&quot;&quot;</span>    iou = IoU(box1, box2)    diou = DIoU(box1, box2)    v = <span class="hljs-number">4</span> / math.pi**<span class="hljs-number">2</span> * (math.atan((box2[<span class="hljs-number">3</span>] - box2[<span class="hljs-number">1</span>])/(box2[<span class="hljs-number">2</span>] - box2[<span class="hljs-number">0</span>]))                          - math.atan((box1[<span class="hljs-number">3</span>] - box1[<span class="hljs-number">1</span>])/(box1[<span class="hljs-number">2</span>] - box1[<span class="hljs-number">0</span>])))**<span class="hljs-number">2</span> + <span class="hljs-number">1e-5</span>    alpha = v / ((<span class="hljs-number">1</span>-iou) + v)    <span class="hljs-keyword">return</span> diou - alpha * v</code></pre><p>如下图所示， 是以不同的 IoU 作为损失函数， 在 Pascal VOC 验证集上的增益：</p><p><img src="/2020/10/21/principles-of-detection-network-design/5.png" style="zoom:40%;"></p><h4 id="3-loss-设计"><a href="#3-loss-设计" class="headerlink" title="3. loss 设计"></a>3. loss 设计</h4><p>目标检测中的损失函数 loss 可以分为两类： 第一类是分类损失， 第二类是检测回归损失。</p><p>常见的分类损失有： cross entropy、 focal loss、GHM loss、AP loss 和 DR loss 等等</p><p>常见的回归损失有：</p><ul><li>l1、l2、smooth l1 </li><li>IOU loss</li><li>其他本文未展开 loss： softer nms 的 KL loss、 GHM-R loss、IoU-bounded loss、 huber loss 的概率解释新 loss， libra RCNN 的 balanced l1 loss</li></ul><h5 id="3-1-分类损失"><a href="#3-1-分类损失" class="headerlink" title="3.1  分类损失"></a>3.1  分类损失</h5><h5 id="3-1-1-cross-entropy-交叉熵损失"><a href="#3-1-1-cross-entropy-交叉熵损失" class="headerlink" title="3. 1.1 cross entropy 交叉熵损失"></a>3. 1.1 cross entropy 交叉熵损失</h5><p>交叉熵损失是我们再计算分类损失的时候最常用的损失函数， 其公式如下：</p><script type="math/tex; mode=display">CE = \left\{\begin{aligned}-log(p) , && if \ \ y = 1 \\-log(1-p),&& if \ \ y = 0\end{aligned}\right.</script><p>单阶段的目标检测器通常会产生高达 100k 的候选目标， 只有极少数是正样本， 正负样本数量非常不平衡。  为了解决正负样本不平衡的问题， 我们通常会在交叉熵损失的前面加上一个参数 $\alpha$, 即:</p><script type="math/tex; mode=display">CE = \left\{\begin{aligned}-\alpha log(p) , && if \ \ y = 1 \\-(1-\alpha)log(1-p),&& if \ \ y = 0\end{aligned}\right.</script><h5 id="3-1-2-focal-Loss"><a href="#3-1-2-focal-Loss" class="headerlink" title="3.1. 2 focal Loss"></a>3.1. 2 focal Loss</h5><p>​        focal loss 的引入主要是为了解决难以样本数量不平衡（注意， 有区别于正负样本数量不平衡）的问题。在目标检测算法中，添加权重 $\alpha$ 平衡了正负样本的数量， 但是对于难易样本的不平衡并无助益。 实际上，易分样本对模型的提升效果非常小， 模型应该主要关注那些难分对象。 (这个观点有问题， 是 GHM 的主要改进对象)。 focal loss 的提出主要是为了解决难易样本数量的不平衡问题。其思路很简单： 把高置信度 $p$ 样本的损失降低一些即可:</p><script type="math/tex; mode=display">CE = \left\{\begin{aligned}-(1-p)^\gamma log(p) , && if \ \ y = 1 \\-p^\gamma log(1-p),&& if \ \ y = 0\end{aligned}\right.</script><p>举个例子， $\gamma $ 取 2， p 取 0.968 的时候， $(1-0.968)^2$ 约定于 0.001， 损失衰减了 1000 倍。 focal loss 的最终形式结合了正负样本的权重 $\alpha$ 和 难易样本的权重 $(1-p)^\gamma$。 同时解决了正负样本的不均衡和难易样本的不均衡问题。 最终的 focal loss 形式如下：</p><script type="math/tex; mode=display">CE = \left\{\begin{aligned}-\alpha (1-p)^\gamma log(p) , && if \ \ y = 1 \\-(1-\alpha) p^\gamma log(1-p),&& if \ \ y = 0\end{aligned}\right.</script><p>实验证明， 当 $\gamma$ 取 2， $\alpha$ 取 0.25 的时候效果最佳。</p><h5 id="3-1-3-GHM"><a href="#3-1-3-GHM" class="headerlink" title="3.1.3 GHM"></a>3.1.3 GHM</h5><p>focal loss 存在两个问题： (1) 让模型过多的关注那些难分样本是存在问题的。 比如样本中有离群点， 那么模型已经收敛的模型还要去关注这些样本。 (2) 公式中的 $\alpha$ 和 $\gamma$ 的取值需要凭借试验得出， 且 $\alpha$ 和 $\beta$ 要联合起来一起试验才行。 GHM(gradient harmonizing mechaism) 解决了上述两个问题。</p><p>文章首先定义了一个梯度模长 g:</p><script type="math/tex; mode=display">g = |p - p^*| = \left\{\begin{aligned}(1-p) , && if \ \ p^* = 1 \\p,&& if \ \ p^* = 0\end{aligned}\right.</script><p>其中 $p$ 是模型预测的概率， $p^<em>$ 是 ground-truth 的标签， $p^</em>$ 的取值为 0 或 1。</p><p><strong>g 正比于检测的难易程度， g 越大则检测难度越大。</strong> 注意到梯度模长和样本数量的关系如下图所示：</p><p><img src="/2020/10/21/principles-of-detection-network-design/6.png" style="zoom:40%;"></p><p>可以看到， 梯度模长接近于 0 的样本数量最多， 随着梯度模长的增长， 样本数量迅速减少， 但是在梯度模长接近于1 时， 样本数量也挺多。  GHM 的想法是， 我们确实应该如 focal loss 所说的不应该过分关系易分样本，但是特别难分的样本(outliers, 离群点) 也不该关注。所以作者认为应该同时衰减易分样本和难分样本， 区分的方法是定义了梯度密度 $GD(g)$ 这个变量， 来衡量出一定梯度范围内的样本数量。</p><script type="math/tex; mode=display">GD(g) = \frac{1}{l_\varepsilon (g)} \sum_{k=1}^{N} \delta_\epsilon(g_k, g)</script><p>其中 $\delta<em>\epsilon(g_k, g)$ 表明了样本 1- N 中， 梯度模长分布在 $(g-\frac{\epsilon}{2}, g+\frac{\epsilon}{2})$ 范围内的样本个数， $l</em>\epsilon(g)$ 代表了 $(g-\frac{\epsilon}{2}, g+\frac{\epsilon}{2})$ 区间的长度。梯度密度的含义是：单位梯度模长 g 部分的样本个数。所谓的 GHM 损失  $l_{GHM-C}$ 就是 交叉熵CE 除以该样本的梯度密度即可。</p><script type="math/tex; mode=display">L_{GHM-C} = \sum_{i=1}^{N} \frac{L_{CE}(p_i, p_i^*)}{GD(g_i)}</script><p>其实不同的损失函数都是对不同的样本赋予不同的权重， CE 中添加 $\alpha$ 是为了抑制负样本； focal loss 添加 $(1-p)^\gamma$ 则是用来抑制简单样本，而 GHM 则用来同时抑制简单样本和较困难样本。</p><h4 id="3-2-回归损失"><a href="#3-2-回归损失" class="headerlink" title="3. 2. 回归损失"></a>3. 2. 回归损失</h4><h5 id="3-2-1-L2-L1-smooth-L1"><a href="#3-2-1-L2-L1-smooth-L1" class="headerlink" title="3. 2. 1  L2, L1, smooth L1"></a>3. 2. 1  L2, L1, smooth L1</h5><script type="math/tex; mode=display">\begin{align}L_2(x) &= x^2 \\L_1(x) &= |x| \\smooth_{L1}(x) &= \left\{\begin{aligned}0.5x^2 &&if |x| < 1\\|x| - 0.5& &  otherwise\\\end{aligned}\right.\end{align}</script><p>​        smooth L1 loss 相对于 l2 loss 的优点： 当预测框与 ground truth 差别过大时，梯度值不至于过大；当预测框与 ground truth 差别很小时，梯度值足够小。</p><h5 id="3-2-2-IoU-loss"><a href="#3-2-2-IoU-loss" class="headerlink" title="3.2.2  IoU loss"></a>3.2.2  IoU loss</h5><p>​        首次将 IoU 的概念引入 loss 损失函数由旷视提出， 发表于 UnitBox: An Advanced Object Detection Network。 论文指出，通过 4 个点回归坐标框的方式是假设4个坐标点是相互独立的，没有考虑其相关性，实际 4 个坐标点具有一定的相关性。其中 $IoU_{loss} = 1 - IoU + 修正项$。其中， IoU 可以是 IoU， GIoU， DIoU 和 CIoU。</p><h3 id="二-数据增强技术-含标签增强"><a href="#二-数据增强技术-含标签增强" class="headerlink" title="二. 数据增强技术(含标签增强)"></a>二. 数据增强技术(含标签增强)</h3><p>常见的数据增强方式可以分为四种： 几何变换、光学变换、增强噪声、数据源扩充。</p><ul><li><p>几何变换：可以丰富物体在图像中出现的位置和尺度等， 从而满足模型的平移不变性与尺度不变性。例如平移， 翻转、翻转、缩放和裁剪等操作。尤其是水平翻转 180度， 在多个物体检测算法中都有使用， 效果很好。</p></li><li><p>光学变化：可以增加不同光照和场景下的图像， 典型的操作有亮度、对比度、色相与饱和度的随机扰动、通道色域之间的交换等。</p></li><li><p>增加噪声： 通过在原始图像上增加一定的扰动， 如高斯噪声。稍微复杂一点的就是在面积大小可选定、位置随机的矩形区域上丢弃像素产生黑色矩形块。 增加噪声可以使模型对可能遇到的噪声等自然扰动产生鲁棒性， 从而提升模型的泛化能力。 需要注意噪声不能过大， 以免影响模型的输出。上面的几何变换类操作，没有改变图像本身的内容，它可能是选择了图像的一部分或者对像素进行了重分布。如果要改变图像本身的内容，就属于颜色变换类的数据增强了，常见的包括<strong>噪声、模糊、颜色变换、擦除、填充</strong>等等。</p></li><li>数据源头： 有时为了扩充数据集， 可以将检测物体与其他背景图像融合，通过替换物体背景的方式来增加数据集的丰富性。  比如比较时髦的 CutOut、Mixup、CutMix、Mosaic、label-smoothing 等方案。</li></ul><p>一些比较有用的数据增强方案的代码解析</p><h3 id="三-算法优化"><a href="#三-算法优化" class="headerlink" title="三. 算法优化"></a>三. 算法优化</h3><h4 id="1-学习率"><a href="#1-学习率" class="headerlink" title="1. 学习率"></a>1. 学习率</h4><p>常见的几种学习率的调整方法：  ReduceLROnPlateau、余弦退火、StepLR</p><ul><li>ReduceLROnPlateau：当指定指标不下降（上升）的时候， 将学习率降低为原来的十分之一。是这三种方案里面最优的， 他可以根据训练的情况进行动态调整， 需要注意的是， 用的时候最好设置一下最小学习率，不然后期会因为学习率衰减得过小导致模型不再训练。</li><li>余弦退火使用的时候，最大学习率和最小学习率相差的数量级不要太大(比如1e-1和1e-4)，不然会导致在该快的时候太慢，在该慢的时候太快，特别的接近最优解的时候，太大就直接跑偏。</li><li>StepLR就很传统，也挺好用的，但是灵活度不如 ReduceLROnPlateau。</li></ul><p>warmup：warmup 是在 resnet 论文中提到的一种学习率预热的方法，它在训练开始的时候先选择使用一个较小的学习率，训练了一些 epoches 或者 steps (比如 4 个epoches, 10000steps)， 再修改为预先设置的学习来进行训练。由于刚开始训练时，模型的权重(weights)是随机初始化的，此时若选择一个较大的学习率,可能带来模型的不稳定(振荡)，选择 Warmup 预热学习率的方式，可以使得开始训练的几个 epoches 或者一些 steps 内学习率较小，在预热的小学习率下，模型可以慢慢趋于稳定,等模型相对稳定后再选择预先设置的学习率进行训练,使得模型收敛速度变得更快，模型效果更佳。</p><h4 id="2-优化器"><a href="#2-优化器" class="headerlink" title="2. 优化器"></a>2. 优化器</h4><h4 id="3-归一化"><a href="#3-归一化" class="headerlink" title="3. 归一化"></a>3. 归一化</h4><p>常见的归一化方式如下图所示，其中 N 是 batch size， C 表示的是 channel， H 和 W 表示单张图片的宽度和高度, 蓝色区域的部分就是需要归一化的部分。</p><p><img src="/2020/10/21/principles-of-detection-network-design/7.png" style="zoom:60%;"></p><p>归一化步骤</p><ul><li><p>计算归一化部分的均值 $\mu$，方差 $\sigma^2$ , 进行归一化  $x’ = \frac{x-\mu}{\sqrt{\sigma^2 + t}}$ </p></li><li><p>加入缩放和平移变量 $\gamma$ 和 $\beta$， 归一化后的值 $y = \gamma x’ + \beta$</p></li></ul><p>Batch Normalization：<strong>BN适用于判别模型，比如图片分类模型</strong>。BN 注重对每个 batch 进行归一化，从而保证数据分布的一致性，而判别模型的结果正是取决于数据整体分布。但是 BN 对 batchsize 的大小比较敏感，由于每次计算的均值和方差是在一个 batch 上，所以如果 batchsize 太小，则计算的均值方差不足以代表整个数据分布。</p><p>Instance Normalization<strong>: </strong>IN 适用于生成模型，比如图片分割、迁移。因为图片生成的结果主要依赖于某个图像实例，所以对整个 batch 归一化不适合图像风格化中，在风格迁移中使用Instance Norm 不仅可以加速模型收敛，并且可以保持图像实例之间的独立。</p><p>Group Normalization:为了解决 Batch Normalization 对较小的 mini-batch 效果差的问题(没办法通过几个样本的数据量，来近似总体的均值和标准差)。其主要思想是在 channel 方向 group，然后每个 group 内做归一化<em>*，计算 (C/G)</em>H*W 的均值和方差，这样就与 batch size 无关，不受其约束。Group Normalization 把每一个样本特征图的通道分成 G 组，对每组求均值和标准差，并独立地进行归一化。</p><p>Layer Normlization：Layer Normalization 的一个优势是不需要批训练，在单条数据内部就能归一化，因此可以用于 batch size 为 1 和 RNN 中。<strong>Layer Normalization 用于 RNN 效果比较明显，但是在CNN上，效果不如BN</strong> </p><h4 id="4-初始化"><a href="#4-初始化" class="headerlink" title="4. 初始化"></a>4. 初始化</h4><p>网络参数初始化的优劣在极大程度上决定了网络的最终性能。网络参数初始化方式主要有以下几种：</p><ul><li>全零初始化：全零初始化会导致神经元的输出相同，相同的输出导致梯度更新完全一样，这样便会令更新后的参数仍然保持一样的状态，从而无法对模型进行训练。</li><li>随机初始化：将参数值随机设定为接近0的一个很小的随机数（有正有负）。比如使用高斯分布或者均匀分布。比较推荐的模型包括： Xavier 初始化方式和 Kaiming 初始化方式。</li><li><p>预训练模型初始化</p></li><li><p>数据敏感的参数初始化方式  <a href="https://github.com/philkr/magic_init">https://github.com/philkr/magic_init</a></p></li></ul><h3 id="四-其他"><a href="#四-其他" class="headerlink" title="四. 其他"></a>四. 其他</h3><h4 id="1-编写代码的基本流程"><a href="#1-编写代码的基本流程" class="headerlink" title="1. 编写代码的基本流程"></a>1. 编写代码的基本流程</h4><ul><li>构建网络， 输入随机 Tensor， 检查输入和输出是否正确。</li><li>构建数据集读取接口， 查看是否能够准确的读取数据、可视化，并检测数据</li><li>编写损失函数、评价指标，优化方法</li><li>组合优化、数据和网络</li></ul><h4 id="2-网络设计的考虑点"><a href="#2-网络设计的考虑点" class="headerlink" title="2. 网络设计的考虑点"></a>2. 网络设计的考虑点</h4><ul><li>现有精度能否得到需求的指标</li><li>运算资源是否足够</li></ul><h3 id="五-常见问题"><a href="#五-常见问题" class="headerlink" title="五. 常见问题"></a>五. 常见问题</h3><h5 id="1-多尺度问题"><a href="#1-多尺度问题" class="headerlink" title="1. 多尺度问题"></a>1. 多尺度问题</h5><p>我们总结了 6 种 有效解决多尺度问题的方案， 其中前四种是比较通用的提升多尺度检测的经典方法</p><p>（1） 降低下采样率和使用空洞卷积可以显著提高小物体的检测性能： 对于小物体检测而言， 降低网络的下采样率是最为简单的提升方式， 通常的做法是直接去掉 pooling 层。 如果仅仅去掉 pooling 层， 则后序层的感受野会较小， 由于后序层的感受野和预训练模型对应层的感受野不同， 从而会导致不能很好的收敛， 一个比较常见的做法是<strong>去掉 pooling 层后，将后序的一个 3x3 卷积变为 空洞数为 2 的卷积， 可以达到有效的降低下采样的目的</strong>。</p><p>（2） 设计更好的 anchor 可以有效提升 proposal 的质量：由于不同的数据集合任务中， 由于物体的尺度、大小会有所差异， 与通用的标签会有所区别， 这时需要调整 anchor 的大小和宽高。 <strong>一个比较经典的做法是 yolo 采用的 anchor 聚类算法</strong>。</p><p>（3）多尺度训练(MST, Multi Scale Training， MST)可以近似构建出图像金字塔， 增加样本的多样性：通常是指<strong>设置几种不同的图片输入尺度， 训练时从多个尺度中随机选取一种尺度， 将输入图片缩放到该尺度并送入网络中</strong>。 在测试中， <strong>为了得到精准的检测效果，可以将测试图片的尺度放大， 例如放大 4 倍。 这样可以避免小物体的漏检</strong>。</p><p>（4） 特征融合可以构建出特征金字塔， 将浅层与深层特征优势互补：随着网络层数的增加， 感受野会增大，语义信息也更为丰富， 但是对于小物体， 其特征会随着层数的加深而逐渐丢失， 从而导致检测性能的降低。 <strong>将深浅层特征进行融合，可以实现底层特征和高层语义信息的融合</strong>。 常见的做法有： FPN的特征金字塔、 DetNet 的空洞卷积与残差、HyperNet 的反卷积与通道拼接、DSSD 的反卷积与特征相乘、RefineDet 的反卷积与逐元素相加， YOLOv3 的上采样与通道拼接。</p><p>（5） SNIP: SNIP 使用了累死 MST 的多尺度训练方法， 构建了 3 个 尺度的图像金字塔， 3 个尺度分别拥有各自的 RPN 模块， 各自预测指定范围内的物体。但是在训练时， 只对指定范围的 proposal 进行反向传播。</p><p><img src="/2020/10/21/principles-of-detection-network-design/9.png" style="zoom:40%;"></p><p>（6） TridentNet：提出了一个拥有三个分支的网络结构， 3个不同的分支使用了空洞数不同的空洞卷积， 感受野由大到小， 更好的覆盖了多尺度的物体分布。 三个分支检测的内容是相同的， 要学习的特征也相同， 不过是形成不同的感受野来检测不同尺度的物体， 借鉴了 SNIP 的思想， 每一个分支只训练一定范围内的样本。</p><p><img src="/2020/10/21/principles-of-detection-network-design/8.png" style="zoom:49%;"></p><h5 id="2-拥挤和遮挡物体检测"><a href="#2-拥挤和遮挡物体检测" class="headerlink" title="2. 拥挤和遮挡物体检测"></a>2. 拥挤和遮挡物体检测</h5><p>(1) 改进 nms： 由于 nms 对遮挡检测影响较大， 因此改进 nms 是一个思路。 比如使用 soft nms 和 IoU-Net 等方法都能在一定程度上提升检测的性能。</p><p>(2) 增加语义信息： 遮挡会造成部分信息的缺失， 因此可以尝试引入额外的特征， 如分割信息、梯度和边缘信息等。如 CVPR 2017 的论文 HyperLearner。</p><p>(3) 划分多个 part 处理：比如行人之间的形状较为类似， 因此可以利用这个先验信息， 将行人按照不同部位， 如头部、上身、手臂等划分为多个 part 进行单独处理， 然后再综合考虑。</p><p>(4) repulsion los: CVPR 2018 的 Repulsion Loss 方法从损失函数的角度出发， 引入了新颖的排斥损失。</p><p>(5) OR-CNN: ECCV 2018 的 ORCNN 设计引入了一种新的损失 Aggregation Loss， 使得多个匹配到同一物体标签的 anchor 尽量地靠近； 在 RoI pooling 处根据行人部位分为了 5 个不同的模块， 提出了 PORoI Pooling 方法。</p><h5 id="3-高效-detection"><a href="#3-高效-detection" class="headerlink" title="3. 高效 detection"></a>3. 高效 detection</h5><ul><li><p>可以从模型压缩和加速的角度进行考虑：使用轻量级网络、剪枝、量化、蒸馏等方法对主干网络进行简化。</p></li><li><p>可以从检测框架的角度进行考虑：通过合理的设计 backbone、FPN、head 甚至是重新设计网络结构。</p></li></ul><h5 id="4-样本不均衡的问题"><a href="#4-样本不均衡的问题" class="headerlink" title="4. 样本不均衡的问题"></a>4. 样本不均衡的问题</h5><p>很多问题， 应该从三个方向进行考虑： 模型(model + loss + nms)、数据、算法</p><ul><li>一个很直观的方向：修改损失函数， 比如 focal loss 和 OHGM</li><li>从数据集的角度进行分析：进行数据的重采样、数据的增强、cutmix 操作等</li><li></li></ul><h5 id="5-其他的几个问题"><a href="#5-其他的几个问题" class="headerlink" title="5. 其他的几个问题"></a>5. 其他的几个问题</h5><ul><li>物体不均衡的问题 &amp; 长尾问题</li><li>重新思考 nms 和 anchor</li><li>物体的关系： relation network</li><li>nas</li><li>实际场景结合：<ul><li>传感器融合</li><li>实际场景的检测：雾霾、雨天、夜晚</li></ul></li><li>其他</li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>super_resolution</title>
    <link href="/2020/10/10/super-resolution/"/>
    <url>/2020/10/10/super-resolution/</url>
    
    <content type="html"><![CDATA[<p>超分辨率增强方向的一些记录</p><a id="more"></a><h4 id="1-解决方案"><a href="#1-解决方案" class="headerlink" title="1. 解决方案"></a>1. 解决方案</h4><h5 id="1-基本解决方案"><a href="#1-基本解决方案" class="headerlink" title="(1) 基本解决方案"></a>(1) 基本解决方案</h5><ul><li><p>SRCNN: 首次提出了 特征提取、非线性映射和重建三个模块的理论。</p></li><li><p>VDSR: 首次将整体残差引入到 SR 中， 引导了之后的大部分的 SR 残差设计。</p></li><li><p>SRResNet：</p><ul><li>首次设计了 特征提取、非线性映射、上采样、重建四个模块</li><li>首次使用 GAN 进行网络训练</li><li>首次提出了 感知损失的概念</li></ul></li><li><p>EDSR：去掉了其中的 BN 层      <strong>NTIRE 2017 冠军模型</strong></p></li><li><p>RCAN：加入了 channnel 机制</p></li></ul><h5 id="2-移动端网络"><a href="#2-移动端网络" class="headerlink" title="(2) 移动端网络:"></a>(2) 移动端网络:</h5><p>CRAN：涉及了一种独特的连接机制，有利于信息的流动。轻量级别超分</p><p>WDSR：主要有三点改进:         <strong>NTIRE 2018 冠军模型</strong></p><ul><li>整体结构涉及改进: 两次上采样</li><li>weight Normalization</li><li>在残差模块中 ReLU 激活函数前增大特征图</li></ul><h5 id="3-一些其他论文"><a href="#3-一些其他论文" class="headerlink" title="(3) 一些其他论文:"></a>(3) 一些其他论文:</h5><ul><li>TTSR:  融入 transformer 模型</li><li>FANet: 特征融合</li><li>IGNN(NUS): 基于图网络的超分辨率模型</li><li>FLASR(xiaomi): 基于nas 的超分辨率模型</li><li>Microsoft: Invertible Image Rescaling</li><li>RawSR: 从 Raw 数据直接进行超分重建</li><li>Real SR： 解决真实场景和合成数据之间的域自适应问题     UDSR    <strong>NTIRE 2019 冠军模型</strong></li><li>videoSR</li><li>一些新式卷积的应用</li></ul><h5 id="4-一些新的解决方案"><a href="#4-一些新的解决方案" class="headerlink" title="(4) 一些新的解决方案"></a>(4) 一些新的解决方案</h5><ul><li><p>IMDN:              <strong>NTIRE 2019 冠军模型</strong>  <strong>2019年声网 4xSR 冠军模型</strong></p></li><li><p>AWSRN</p></li><li><p>DRLN</p></li></ul><h4 id="2-评价指标"><a href="#2-评价指标" class="headerlink" title="2. 评价指标"></a>2. 评价指标</h4><h5 id="1-客观评价指标"><a href="#1-客观评价指标" class="headerlink" title="(1) 客观评价指标"></a>(1) 客观评价指标</h5><p>​    对于超分辨率重建，常用的两个客观评价指标是<strong>峰值信噪比 (peak single to noise ratio， PSNR)</strong>和<strong>结构相似性指标 (structure Similarity Index, SSIM)</strong>， 这两个指标的值越高， 重建结果与原图越接近。 主要注意的是， 基于感知损失的网络在 psnr 指标 和 ssim 上并不一定好， 但是看起来效果相对会比较好。</p><p><strong>PSNR</strong> 的定义为:</p><script type="math/tex; mode=display">PSNR = 10 log_{10}(\frac{Peak^2}{MSE})</script><p>针对于 uint8 数据， 最大的像素值为 255, 针对于浮点型数据， 最大像素值为 1。</p><p><strong>SSIM</strong> 公式基于样本  x 和 y  之间的三个比较衡量: 亮度(luminance)、对比度(contrast) 和结构(structure)。 </p><script type="math/tex; mode=display">l(x, y) = \frac{2\mu_x \mu_y + c_1}{\mu_x^2 + \mu_y^2 + c_1} \\c(x, y) = \frac{2\sigma_x \sigma_y + c_2}{\sigma_x^2 + \sigma_y^2 + c_2} \\s(x, y) = \frac{\sigma_{xy} + c_3}{\sigma_x\sigma_y + c_3}</script><p>$\mu<em>x$ 为 $x$ 的均值，$\mu_y$为 $y$ 的均值。$\sigma_x$ 为 $x$ 的方差, $\sigma_y$ 为 $y$ 的方差,  $σ</em>{xy}$ 为 $x$ 和 $y$ 的协方差。</p><p>一般取 $c1=(k_1L)^2$， $c2=(k_2L)^2 $，  $c3=c2/2$，避免除零。其中 $L$位像素值的范围 $2^B-1$， $k_1 = 0.01, k_2 = 0.03 为默认值$。</p><h5 id="2-主观评价指标"><a href="#2-主观评价指标" class="headerlink" title="(2) 主观评价指标"></a>(2) 主观评价指标</h5><p>​    目前还没有较好的(伪)主观评价指标， 一般还是以展示或者<strong>平均主观得分(MOS) </strong>的方式来对比不同算法的主观效果。MOS 要求人类测评员对测试图像进行评价。通常情况下，分数从1（坏）到5（好），而最后的 MOS 是以所有评分的算术平均值计算的。</p><h5 id="3-其他"><a href="#3-其他" class="headerlink" title="(3) 其他"></a>(3) 其他</h5><p>​    除上述 IQA 方法外，还有其他一些不太常用的方法， 比如: 多尺度结构相似性(MS-SSIM)、特征相似性(FSIM)、自然图像质量评估器(NIQE)等。</p><ul><li>MS-SSIM 使用多尺度的 SSIM</li><li>特征相似性(FSIM)  提取特征点， 基于相位一致性和图像的人类兴趣的梯度幅度来评估图像质量。</li><li>NIQE</li></ul><p>​     最近，Blau等人[77]用数学方法证明了失真（如PSNR，SSIM）和感知质量（如MOS）是相互矛盾的，并表明随着失真度降低，感知质量一定更差。 因此，如何准确地测量SR质量，仍然是一个亟待解决的问题。</p><h5 id="4-复杂度，运行时间、参数量"><a href="#4-复杂度，运行时间、参数量" class="headerlink" title="(4) 复杂度，运行时间、参数量"></a>(4) 复杂度，运行时间、参数量</h5><p>另外，网络的好坏不应该仅仅依次来进行评判， 还需要考虑网络的<strong>网络的复杂度</strong>，<strong>运行时间 runtime</strong>,  <strong>参数量</strong> 等因素。</p><ul><li><p>运行时间: 这里选择 <code>torch.cuda.Event</code> 进行计时:</p><pre><code class="hljs python">start = torch.cuda.Event(enable_timing=<span class="hljs-literal">True</span>)end = torch.cuda.Event(enable_timing=<span class="hljs-literal">True</span>)start.record() ... some CPU bound operations, i.e. loading data ...end.record()<span class="hljs-comment"># Waits for everything to finish running</span>torch.cuda.synchronize()print(start.elapsed_time(end))</code></pre></li><li><p>模型复杂度<br>使用  <a href="https://github.com/mit-han-lab/torchprofile">https://github.com/mit-han-lab/torchprofile</a>  来统计模型的复杂度， 其对每一层进行分析。</p></li></ul><h4 id="3-数据增强"><a href="#3-数据增强" class="headerlink" title="3. 数据增强"></a>3. 数据增强</h4><ul><li>翻转</li><li>旋转</li><li>Rethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy</li></ul><h4 id="4-损失函数"><a href="#4-损失函数" class="headerlink" title="4. 损失函数:"></a>4. 损失函数:</h4><h5 id="L1-or-L2"><a href="#L1-or-L2" class="headerlink" title="L1 or L2"></a>L1 or L2</h5><ul><li><p>l2 损失是刷高 pnsr 的理想损失函数，但是，l2 损失对大的 error 有较强的惩罚，对小的 error 则惩罚较低， 这样容易导致图像平滑，对与人类的视觉感知系统并不友好。(人类的视觉系统对图像中的无纹理区域的亮度和颜色变化更加敏感)。</p></li><li><p>l1 的损失函数的收敛性能是优于 l2 损失函数的</p></li></ul><h5 id="内容-特征-损失-content-loss"><a href="#内容-特征-损失-content-loss" class="headerlink" title="内容(特征)损失 content loss"></a>内容(特征)损失 content loss</h5><p>​    使用预训练模型来计算图像的高层特征的欧式距离。并非着眼于单个像素的匹配，而是让两张图像的感知更加接近。个人认为在得到感知域内容的过程中，对图像的内容进行了一次提炼，因此在感知域空间中计算损失相当于结合图像内容的损失，会使得复原后的图像视觉效果上更好。</p><h5 id="texture-loss"><a href="#texture-loss" class="headerlink" title="texture loss"></a>texture loss</h5><h5 id="adversarial-loss"><a href="#adversarial-loss" class="headerlink" title="adversarial loss"></a>adversarial loss</h5><h5 id="全变分损失-total-variation-loss"><a href="#全变分损失-total-variation-loss" class="headerlink" title="全变分损失 total variation loss"></a>全变分损失 total variation loss</h5><p>​     TV loss 是常用的一种正则项（注意是正则项，配合其他 loss 一起使用，用来约束噪声）。TV 损失用在图像超分辨率中的作用就是<strong>保持图像的光滑性，消除图像超分可能带来的伪影和噪声</strong>。缺陷在于会使得复原的图像过于光滑，在一些细节比较多的图像中会使得超分后的图像丢失细节。它定义为<strong>相邻像素的差值的绝对值之和，可以用来衡量图片的噪声</strong>。</p><h4 id="6-综述"><a href="#6-综述" class="headerlink" title="6. 综述"></a>6. 综述</h4><p>Deep Learning for Image Super-resolution: A Survey</p><h4 id="7-几个经典问题"><a href="#7-几个经典问题" class="headerlink" title="7. 几个经典问题"></a>7. 几个经典问题</h4><ul><li><p>框架设计</p><p>基本可以分为四个阶段: 特征提取、非线性映射、上采样、重建。 主要的设计几种在非线性映射上。</p></li><li><p>几种上采样方式的区别? 优劣?</p></li></ul><p>常见的上采样方式有：插值、反卷积、subpixel等</p><p>比较好的方式是：最近邻采样 + 卷积。在时间上最快， 然后也能够避免反卷积带来的棋盘格效应。</p><ul><li>为啥不需要 bn 层? 为啥 wn 可以用?</li><li>三通道重建 or YCrcb 空间 Y 通道重建</li></ul><p>现在基本是在 RGB 空间进行超分辨率重建，YCrcb 在之前的工作中使用过。</p><ul><li>噪声问题 ?</li></ul><p>现在想到的一个解决方案是添加 TV Loss， 但是会带来一定的平滑。</p><ul><li>前采样 和 后采样的区别？</li></ul><p>后采样使得整个特征提取在高维空间中进行，虽然能够 hold 住能多得细节信息。但是计算量较大。现在一般都是前采样来降低分辨率，从而能够显著降低计算量。</p><h4 id="8-相关比赛"><a href="#8-相关比赛" class="headerlink" title="8. 相关比赛"></a>8. 相关比赛</h4><ul><li>AIM 2019 &amp; AIM 2020</li><li>NTIRE</li></ul><p>参考文献</p><p>[1] Loss Functions for Image Restoration with Neural Networks IEEE TCI 2017 [[<a href="https://link.zhihu.com/?target=http%3A//ieeexplore.ieee.org/document/7797130/">paper</a>]] [[<a href="https://link.zhihu.com/?target=https%3A//github.com/NVlabs/PL4NN">code</a>]]</p><p>[2] 2018 PIRM Challenge on Perceptual Image Super-resolution [[<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1809.07517">paper</a>]]</p>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn前向计算流程浅析</title>
    <link href="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/"/>
    <url>/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<p><strong>1. 前向计算</strong></p><p>​    使用ncnn进行前向计算的步骤很简单，就如下十几行代码即可完成。</p><pre><code class="hljs groovy"><span class="hljs-comment">/* Step 1.1 : 加载.parma 文件 */</span>NSString *paramPath = [[NSBundle mainBundle] <span class="hljs-attr">pathForResource:</span>@<span class="hljs-string">&quot;squeezenet_v1.1&quot;</span> <span class="hljs-attr">ofType:</span>@<span class="hljs-string">&quot;param&quot;</span>];ncnn_net.load_param(paramPath.UTF8String);<span class="hljs-comment">/* Step 1.2 : 加载.bin 文件 */</span>NSString *binPath = [[NSBundle mainBundle] <span class="hljs-attr">pathForResource:</span>@<span class="hljs-string">&quot;squeezenet_v1.1&quot;</span> <span class="hljs-attr">ofType:</span>@<span class="hljs-string">&quot;bin&quot;</span>];ncnn_net.load_model(binPath.UTF8String);<span class="hljs-comment">/* Step 2.1 : 构建并配置 提取器 */</span><span class="hljs-attr">ncnn:</span>:Extractor extractor = ncnn_net.create_extractor();extractor.set_light_mode(<span class="hljs-literal">true</span>);<span class="hljs-comment">/* Step 2.2 : 设置输入（将图片转换成ncnn::Mat结构作为输入） */</span>UIImage *srcImage = [UIImage <span class="hljs-attr">imageNamed:</span>@<span class="hljs-string">&quot;mouth&quot;</span>];<span class="hljs-attr">ncnn:</span>:Mat mat_src;ts_image2mat(mat_src, srcImage);extractor.input(<span class="hljs-string">&quot;data&quot;</span>, mat_src);<span class="hljs-comment">/* Step 2.3 : 提取输出 */</span><span class="hljs-attr">ncnn:</span>:Mat mat_dst;extractor.extract(<span class="hljs-string">&quot;prob&quot;</span>, mat_dst);</code></pre><p>​    如果你仅仅想使用ncnn，上面的参考足够了；但若你想要了解，甚至去更改一些其中的源代码，可以跟我一起看看上面这十多行代码的底层运作原理。</p><p><strong>2 代码分析</strong></p><p>我姑且将其分为：<strong>加载模型</strong>、前向检测、输出处理(半划水)、模型封装(全划水) 四个部分来加以分析。</p><p><strong>2.1 加载模型</strong></p><p>ncnn 在 iOS 端使用 <strong>.param</strong> 和 <strong>.bin</strong> 两个文件来描述一个神经网络模型，</p><p>其中：</p><p><strong>.param</strong>：描述神经网络的结构，包括层名称，层输入输出信息，层参数信息（如卷积层的kernal大小等）等。</p><p><strong>.bin</strong> 文件则记录神经网络运算所需要的数据信息（比如卷积层的权重、偏置信息等）</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/1.png" alt="x" style="zoom:50%;"></p><p><strong>2.1.1 load_param 加载神经网络配置信息</strong></p><pre><code class="hljs objective-c">&#x2F;* Step1.1 : 加载.parma 文件 *&#x2F;NSString *paramPath &#x3D; [[NSBundle mainBundle] pathForResource:@&quot;squeezenet_v1.1&quot; ofType:@&quot;param&quot;];ncnn_net.load_param(paramPath.UTF8String);</code></pre><p>load_param 的根本目的是将.param文件的信息加载到目标神经网络（一个ncnn::Net结构）中</p><p><strong>2.1.1.1 .param文件的结构</strong></p><p>首先我们看一下 .param 文件的内容格式</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/2.png" style="zoom:50%;"></p><p><strong>一个.param文件由以下几部分组成：</strong></p><p><strong>1）MagicNum</strong></p><p>固定位7767517，为什么这个数字，不知道问倪神去吧</p><p>2）layer、blob个数</p><p>上图示例的文件两个数字分别为：75、83</p><p><strong>layer：我们知道神经网络是一层一层向前推进计算的，每一层我们用一个layer表示；</strong></p><p><strong>blob：每一个layer都可能会有输入、输出，在ncnn中，它们统一用一个多维（3维）向量表示，我们称每一个输入、输出的原子为一个blob，并为它起名</strong></p><p>2.1.1.2 layer的描述</p><p>layer 在 .param 中是一个相对复杂的元素（从第3行起的每一行描述一个layer），所以我们把它单独抽出来一小节进行说明。</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/3.png" alt></p><p>如图，<strong>每一行层描述的内容包括以下几部分</strong>：</p><p><strong>1）层类型</strong>     比如<strong>Input、Convolution、ReLU</strong></p><p><strong>2）层名</strong>       模型训练者为该层起得名字（毕竟相同类型的层可能多次使用，我们要区分它们）</p><p><strong>3）层输入输出  包含：层输入blob数量，层输出blob数量，层输入、输出blob的名称</strong></p><p><strong>4）层配置参数</strong></p><p>比如 <strong>卷积层（Convolution Layer）的 卷积核大小、步长信息</strong> 等</p><p>在 具体层里面都有一个函数: load_param, 从里面可以查询到相关信息。</p><p><strong>data层： 0=长 1=宽 3=通道</strong></p><p><strong>Convolution层 0=输出单元 1=卷积核大小  2=核膨胀[见膨胀卷积]    3=stride</strong>    </p><p>​                                 <strong>4=padding    5=是否存在偏置    6=权重数量</strong></p><p><strong>pooling 层    0=池化类型   1=卷积核大小   2=步长stride   3=padding   4=全局池化  5=padding类型</strong></p><p><strong>ReLU 层 0=0.000000 无参数</strong></p><p><strong>softmax 层 0=0 无参数</strong></p><p><strong>Concat Split Dropout 无参数</strong></p><p><strong>ConvolutionDepthWise    7=group 数目</strong></p><p><strong>2.1.1.3 ncnn的加载的效果</strong></p><p>​    其实了解了param文件的数据结构后，我们就大致知道ncnn做了哪些事情了。无非是 <strong>读取文件</strong>—&gt;<strong>解析神经网络信息</strong> —&gt; <strong>缓存神经网络信息</strong>，那么，信息缓存在哪里呢？</p><pre><code class="hljs cpp"><span class="hljs-comment">/* in net.h */</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span></span><span class="hljs-class">&#123;</span>...<span class="hljs-keyword">protected</span>:    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Blob&gt; blobs;    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Layer*&gt; layers;...&#125;;</code></pre><p>​    原来，ncnn::Net 结构中有 <strong>blobs</strong> 和 <strong>layers</strong> 两个 vector，它们保存了 .param文件 中加载的信息。关于 Blob、Layer 的数据结构，在此暂不赘述。</p><p><strong>2.1.2 load_model 加载模型训练数据</strong></p><pre><code class="hljs objective-c">&#x2F;* Step1.2 : 加载.bin 文件 *&#x2F;NSString *binPath &#x3D; [[NSBundle mainBundle] pathForResource:@&quot;squeezenet_v1.1&quot; ofType:@&quot;bin&quot;];ncnn_net.load_model(binPath.UTF8String);</code></pre><p>​    load_model的根本目的是将 .bin文件 的信息加载到 目标神经网络（一个ncnn::Net结构）中。</p><p><strong>2.1.2.1 .bin文件的内容</strong></p><p><strong>.bin 文件存储了对应模型中部分层的计算需求参数。</strong>比如2.1.1.1节中的第四行的Convolution层</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/4.png" alt></p><p>​    <strong>.bin 文件中就存储了其 1728(3 * 3 * 3 * 64) 个float类型的 权重数据(weight_data) 和 64个float类型的 偏置数据(bias_data)。</strong></p><p>2.1.2.2 .bin文件的结构</p><p>​    <strong>.bin 文件中就存储了其 1728(3 * 3 * 3 * 64) 个float类型的 权重数据(weight_data) 和 64个float类型的 偏置数据(bias_data)。</strong></p><p>2.1.2.2 .bin文件的结构</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/5.png" alt></p><p>bin = binary，.bin 文件的基本结构就是 [二进制]。但这 并不代表我们失去了 [手动修改它] 的权利！</p><p>惊不惊喜，意不意外？下节即揭晓！</p><p><strong>2.1.2.3 手撕二进制</strong></p><p>1）bin文件信息存储说明</p><p>假设 bin 文件存储 0.3342, 0.4853, 0.2843, 0.1231 四个数字，这四个数字使用float32的数据结构来描述，分别为：3eab1c43、3ef8793e、3e918fc5、3dfc1bda，那么bin文件中的内容就是 3eab1c433ef8793e3e918fc53dfc1bda，我们进行读取的时候使用一个float的数组去承载这些二进制数据即可。</p><p>2）手撕</p><p>你当然也可以自己写一段bin文件数据的读取方法，比如这么一段</p><pre><code class="hljs lsl">const void * __log_binInfo_conv1(const void *dataOffset) &#123;    printf(<span class="hljs-string">&quot;<span class="hljs-subst">\n</span> conv1 层类型为 Convolution(卷积层)<span class="hljs-subst">\n</span>&quot;</span>)     printf(<span class="hljs-string">&quot;<span class="hljs-subst">\n</span> 加载weight_data数据类型标志（固定为自动类型）<span class="hljs-subst">\n</span>&quot;</span>);    unsigned char *p_load1_1 = (unsigned char *)dataOffset;    for (int i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">4</span>; i++) &#123;        printf(<span class="hljs-string">&quot;Flag %d : %d<span class="hljs-subst">\n</span>&quot;</span>, i, p_load1_1[i]);    &#125;    p_load1_1 += <span class="hljs-number">4</span>;        printf(<span class="hljs-string">&quot;<span class="hljs-subst">\n</span> Load1_2: 加载weight_data数据（1728项，自动为float32类型）<span class="hljs-subst">\n</span>&quot;</span>);    <span class="hljs-type">float</span> *p_load1_2 = (<span class="hljs-type">float</span> *)p_load1_1;    for (int i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1728</span>; i++) &#123;        if (i &lt; <span class="hljs-number">10</span> || i &gt; <span class="hljs-number">1720</span>) &#123;            printf(<span class="hljs-string">&quot;Weight %d : %.9f<span class="hljs-subst">\n</span>&quot;</span>, i, p_load1_2[i]);        &#125;    &#125;    p_load1_2 += <span class="hljs-number">1728</span>;        printf(<span class="hljs-string">&quot;<span class="hljs-subst">\n</span> Load3: 加载bias偏置数据（64项，固定为float32类型）<span class="hljs-subst">\n</span>&quot;</span>);    <span class="hljs-type">float</span> *p_load2 = (<span class="hljs-type">float</span> *)p_load1_2;    for (int i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">64</span>; i++) &#123;        if (i &lt; <span class="hljs-number">5</span> || i &gt; <span class="hljs-number">60</span>) &#123;            printf(<span class="hljs-string">&quot;Bias %d : %.9f<span class="hljs-subst">\n</span>&quot;</span>, i, p_load2[i]);        &#125;    &#125;    p_load2 += <span class="hljs-number">64</span>;        return p_load2;&#125;</code></pre><p><strong>Demo：</strong></p><p><a href="https://github.com/chrisYooh/ncnnSrcDemo">https://github.com/chrisYooh/ncnnSrcDemo</a></p><p>1）打开其下的 NcnnSrcDemo 工程</p><p>2）进入 ViewController，解除 自定义bin文件加载测试的 注释</p><p>/<em> 自定义 bin 文件加载测试 </em>/</p><p>[self loadModel_myAnalysis];</p><p>3）运行看看结果吧，也可以用 ncnn的loadModel 去跑，然后打断点看看解读的 .bin 文件数据一致不。</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/6.png" alt></p><p>​    了解了bin文件的信息存储形式，我们当然就可以进行信息修改咯！不同的框架模型进行转化时，就要做这样的事情。哇，那我们可以 自己写转模型的工具啦！从技术上说，完全没错！</p><p><strong>2.2 Detect 检测</strong></p><p>   完成了 网络初始化 <strong>load_param()</strong>、 <strong>load_bin()</strong>之后，我们可以填写一个输入并使用 网络提取器Extractor 计算输出了。</p><p><strong>2.2.1 创建提取器 Extractor</strong></p><pre><code class="hljs reasonml"><span class="hljs-comment">/* Step2.1 : 构建并配置 提取器 */</span>ncnn::Extractor extractor = ncnn_net.create<span class="hljs-constructor">_extractor()</span>;extractor.set<span class="hljs-constructor">_light_mode(<span class="hljs-params">true</span>)</span>;</code></pre><p>   提取器 extractor 使用 目标网络 通过 友元函数 创建实例，因为它需要获取对应神经网络的信息；同时，extractor 还可以自定义部分配置信息。</p><p>Extractor含3个关键类变量</p><p>1）<strong>net： 指向对应网络的指针</strong></p><p>2）<strong>blob_mats： 计算的过程中存储输入、输出的临时数据</strong></p><p>3）<strong>opt： 配置参数</strong></p><p><strong>2.2.2 extractor.input 配置输入</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">/* Step2.2 : 设置输入（将图片转换成ncnn::Mat结构作为输入） */</span>UIImage *srcImage = [UIImage imageNamed:@<span class="hljs-string">&quot;mouth&quot;</span>];ncnn::Mat mat_src;ts_image2mat(mat_src, srcImage);extractor.input(<span class="hljs-string">&quot;data&quot;</span>, mat_src);</code></pre><p>1）我们要 构造一个ncnn::Mat的结构，将我们的输入填入其中</p><p>2）利用 Extractor的input()函数 将输入mat填入对应的位置。</p><p>注意：input() 函数中的第一个字符串参数输入的是blob的名称 而不是layer的名称 哦！</p><p><strong>2.2.3 extractor.extract 提取输出</strong></p><pre><code class="hljs less"><span class="hljs-comment">/* Step2.3 : 提取输出 */</span><span class="hljs-attribute">ncnn</span>::Mat mat_dst;<span class="hljs-selector-tag">extractor</span><span class="hljs-selector-class">.extract</span>(<span class="hljs-string">&quot;prob&quot;</span>, mat_dst);</code></pre><p>1）我们要 构造一个ncnn::Mat的结构，用以承载输出；</p><p>2）利用 Extractor的extract()函数 将计算结果填写到我们构造的输出mat中。</p><p>注意：extract()函数中的第一个字符串参数输入的是 blob的名称 而不是 layer的名称 哦！</p><p><strong>2.2.3.1 extract() 的递归流程图</strong></p><p>ncnn 在进行 extract() 的时候，使用了递归的方式，这边将其 宏观逻辑进行抽象。（描绘所有的代码细节会使图过于复杂，不易阅读）</p><p>递归实现.png</p><p><strong>2.2.3.2 extract() 最简递归展开流程</strong></p><p>之所以说最简，因为我们假设：</p><p>1 目标网络的每层都只有 一个输入(blob) 和 一个输出(blob)，</p><p>2 使用的extract是新创建的（即 无缓存数据）</p><p><img src="/2020/09/21/ncnn%E5%89%8D%E5%90%91%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B%E6%B5%85%E6%9E%90/7.png" alt></p><p>如图：</p><p>1）每一层进行forward()的时候，需要一些输入参数，这些输入参数是 由上面的层的forward()运算输出的。</p><p>2）只有 输入层的输入参数是我们填写的（2.2.2 节），也正是因为它的存在，递归得以有了终结。</p><p>2.3 输出处理</p>  <pre><code class="hljs reasonml"><span class="hljs-comment">/* Step3.1 : 结果处理(获取检测概率最高的5种物品，认为存在) */</span>   NSArray *rstArray = ts<span class="hljs-constructor">_mat2array(<span class="hljs-params">mat_dst</span>)</span>;   NSArray *top5Array = ts<span class="hljs-constructor">_topN(<span class="hljs-params">rstArray</span>, 5)</span>;      <span class="hljs-comment">/* Step3.2 : 打印输出 */</span>   <span class="hljs-constructor">NSLog(@<span class="hljs-string">&quot;%@&quot;</span>, <span class="hljs-params">top5Array</span>)</span>;      <span class="hljs-comment">/* 说明：该Demo中发现输出的第一项是 index 为 673 的项目，</span><span class="hljs-comment">    * 在result_info.json中查找下 &quot;index&quot; : &quot;673&quot; 发现对应的描述是 鼠标</span><span class="hljs-comment">    * 也可以换其他图片进行检测，但要将图片规格化成 227 * 227 的大小才可以保证结果的准确性</span><span class="hljs-comment">    */</span></code></pre><p>​    输出处理是根据需求具体模型需求，很灵活的。比如我给予输出结果的每个数字以 概念（识别到某种物品的概率） ，并对输出结果进行排序后取其 概率最高的 五个值。</p><p><strong>2.4 封装</strong></p><p>​    玩一玩的话，12行代码足够了；但若真的要工程化的话，我们还是要将 面向过程 的思路 向 面向对象靠拢的。</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_6</title>
    <link href="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-6/"/>
    <url>/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-6/</url>
    
    <content type="html"><![CDATA[<p>分析了几个比较常见的算子 forward 过程， 比如 abs， bias，argmax， conv，pool， bn </p><a id="more"></a><h4 id="1-abs"><a href="#1-abs" class="headerlink" title="1. abs"></a>1. abs</h4><pre><code class="hljs c"><span class="hljs-comment">// 绝对值层特性: 单输入，单输出，可直接对输入进行修改</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">AbsVal::forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> w = bottom_top_blob.w;    <span class="hljs-keyword">int</span> h = bottom_top_blob.h;    <span class="hljs-keyword">int</span> channels = bottom_top_blob.c;    <span class="hljs-keyword">int</span> size = w * h;    <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)  <span class="hljs-comment">// openmp </span></span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)    &#123;        <span class="hljs-keyword">float</span>* ptr = bottom_top_blob.channel(q);<span class="hljs-comment">// 当前通道数据的起始指针</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)        &#123;            <span class="hljs-keyword">if</span> (ptr[i] &lt; <span class="hljs-number">0</span>)                ptr[i] = - ptr[i]; <span class="hljs-comment">// 小于零取相反数，大于零保持原样</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="2-bias"><a href="#2-bias" class="headerlink" title="2. bias"></a>2. bias</h4><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Bias::forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> w = bottom_top_blob.w;    <span class="hljs-keyword">int</span> h = bottom_top_blob.h;    <span class="hljs-keyword">int</span> channels = bottom_top_blob.c;    <span class="hljs-keyword">int</span> size = w * h;    <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)    &#123;        <span class="hljs-keyword">float</span>* ptr = bottom_top_blob.channel(q);  <span class="hljs-comment">// 每个通道数据起始指针</span>        <span class="hljs-keyword">float</span> bias = bias_data[q];   <span class="hljs-comment">// 需要添加的偏置数据 前面从模型中载入的参数 每通道偏置参数一样</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)        &#123;            ptr[i] += bias;<span class="hljs-comment">// 加上偏置</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="2-argmax"><a href="#2-argmax" class="headerlink" title="2.  argmax"></a>2.  argmax</h4><pre><code class="hljs c"><span class="hljs-comment">// 层参数包含两个参数，第一个是是否需要包含值对应在源blob中的位置，第二个是需要前多少个最大的数</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">ArgMax::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; pd)</span></span><span class="hljs-function"></span>&#123;    out_max_val = pd.get(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);<span class="hljs-comment">// 是否 需要存储位置</span>    topk = pd.get(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>);       <span class="hljs-comment">// 在前topk个最大的数</span>       <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">ArgMax::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> size = bottom_blob.total(); <span class="hljs-comment">// 输入blob参数总数量</span>        <span class="hljs-comment">// 创建一个新的输出 blob </span>    <span class="hljs-keyword">if</span> (out_max_val)        top_blob.create(topk, <span class="hljs-number">2</span>, <span class="hljs-number">4u</span>, opt.blob_allocator); <span class="hljs-comment">// topk个值 + topk个值对应的位置</span>    <span class="hljs-keyword">else</span>        top_blob.create(topk, <span class="hljs-number">1</span>, <span class="hljs-number">4u</span>, opt.blob_allocator); <span class="hljs-comment">// 只存  topk个值，不存位置</span>    <span class="hljs-keyword">if</span> (top_blob.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* ptr = bottom_blob;        <span class="hljs-comment">// partial sort topk with index, optional value</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt; <span class="hljs-built_in">std</span>::<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">float</span>, <span class="hljs-keyword">int</span>&gt; &gt; vec;    vec.resize(size);    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)    &#123;        vec[i] = <span class="hljs-built_in">std</span>::<span class="hljs-built_in">make_pair</span>(ptr[i], i);<span class="hljs-comment">// 源 输入blob 的参数的 值：位置id 键值对</span>    &#125;    <span class="hljs-built_in">std</span>::partial_sort(vec.begin(), vec.begin() + topk, vec.end(),                      <span class="hljs-built_in">std</span>::greater&lt; <span class="hljs-built_in">std</span>::<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">float</span>, <span class="hljs-keyword">int</span>&gt; &gt;());<span class="hljs-comment">// 按第一列排序，获取前 topk个</span>    <span class="hljs-comment">// 保存前面最大的 topk 个参数</span>    <span class="hljs-keyword">float</span>* outptr = top_blob;    <span class="hljs-keyword">if</span> (out_max_val)    &#123;        <span class="hljs-keyword">float</span>* valptr = outptr + topk; <span class="hljs-comment">// 前面topk的位置存值，后面存对应值在源输入 blob 中的位置ID</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;topk; i++)        &#123;            outptr[i] = vec[i].first; <span class="hljs-comment">// 存值</span>            valptr[i] = vec[i].second;<span class="hljs-comment">// 存位置</span>        &#125;    &#125;    <span class="hljs-keyword">else</span>    &#123;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;topk; i++)        &#123;            outptr[i] = vec[i].second;<span class="hljs-comment">// 只存值</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="3-concat"><a href="#3-concat" class="headerlink" title="3.concat"></a>3.concat</h4><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Concat::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; bottom_blobs, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; top_blobs, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> dims = bottom_blobs[<span class="hljs-number">0</span>].dims;    <span class="hljs-keyword">size_t</span> elemsize = bottom_blobs[<span class="hljs-number">0</span>].elemsize;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">1</span>) <span class="hljs-comment">// axis == 0</span>    &#123;        <span class="hljs-keyword">int</span> top_w = <span class="hljs-number">0</span>; <span class="hljs-comment">// 输出长度</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> b = <span class="hljs-number">0</span>; b &lt; bottom_blobs.size(); b++)        &#123;            <span class="hljs-keyword">const</span> Mat&amp; bottom_blob = bottom_blobs[b];            top_w += bottom_blob.w;        &#125;        <span class="hljs-comment">// 创建输出 blob</span>        Mat&amp; top_blob = top_blobs[<span class="hljs-number">0</span>];        top_blob.create(top_w, elemsize, opt.blob_allocator);        <span class="hljs-keyword">if</span> (top_blob.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;        <span class="hljs-comment">// 将不同的输入复制到输出</span>        <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>* outptr = top_blob;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> b = <span class="hljs-number">0</span>; b &lt; bottom_blobs.size(); b++)        &#123;            <span class="hljs-keyword">const</span> Mat&amp; bottom_blob = bottom_blobs[b];            <span class="hljs-keyword">int</span> w = bottom_blob.w;            <span class="hljs-keyword">const</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>* ptr = bottom_blob;            <span class="hljs-built_in">memcpy</span>(outptr, ptr, w * elemsize);            outptr += w * elemsize;        &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">2</span> &amp;&amp; axis == <span class="hljs-number">0</span>)&#123;        <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">2</span> &amp;&amp; axis == <span class="hljs-number">1</span>)&#123;        <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">3</span> &amp;&amp; axis == <span class="hljs-number">0</span>)&#123;        <span class="hljs-comment">//  ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">3</span> &amp;&amp; axis == <span class="hljs-number">1</span>)&#123;      <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">3</span> &amp;&amp; axis == <span class="hljs-number">2</span>)&#123;       <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="4-卷积层"><a href="#4-卷积层" class="headerlink" title="4. 卷积层"></a>4. 卷积层</h4><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Convolution::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// convolv with NxN kernel</span>    <span class="hljs-comment">// value = value + bias</span>    <span class="hljs-keyword">if</span> (opt.use_int8_inference &amp;&amp; weight_data.elemsize == (<span class="hljs-keyword">size_t</span>)<span class="hljs-number">1u</span>)    &#123;        <span class="hljs-keyword">return</span> forward_int8(bottom_blob, top_blob, opt);    &#125;    <span class="hljs-comment">// flattened blob, implement as InnerProduct</span>    <span class="hljs-comment">//...</span>    <span class="hljs-keyword">int</span> w = bottom_blob.w;    <span class="hljs-keyword">int</span> h = bottom_blob.h;    <span class="hljs-keyword">int</span> channels = bottom_blob.c;    <span class="hljs-keyword">size_t</span> elemsize = bottom_blob.elemsize;    <span class="hljs-comment">// NCNN_LOGE(&quot;Convolution input %d x %d  pad = %d %d  ksize=%d %d  stride=%d %d&quot;, w, h, pad_w, pad_h, kernel_w, kernel_h, stride_w, stride_h);</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> kernel_extent_w = dilation_w * (kernel_w - <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> kernel_extent_h = dilation_h * (kernel_h - <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>;    Mat bottom_blob_bordered;    make_padding(bottom_blob, bottom_blob_bordered, opt);    <span class="hljs-keyword">if</span> (bottom_blob_bordered.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    w = bottom_blob_bordered.w;    h = bottom_blob_bordered.h;    <span class="hljs-keyword">int</span> outw = (w - kernel_extent_w) / stride_w + <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> outh = (h - kernel_extent_h) / stride_h + <span class="hljs-number">1</span>;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> maxk = kernel_w * kernel_h;    <span class="hljs-comment">// kernel offsets</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; _space_ofs(maxk);    <span class="hljs-keyword">int</span>* space_ofs = &amp;_space_ofs[<span class="hljs-number">0</span>];    &#123;        <span class="hljs-keyword">int</span> p1 = <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> p2 = <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> gap = w * dilation_h - kernel_w * dilation_w;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; kernel_h; i++)        &#123;            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; kernel_w; j++)            &#123;                space_ofs[p1] = p2;                p1++;                p2 += dilation_w;            &#125;            p2 += gap;        &#125;    &#125;    <span class="hljs-comment">// 申请输出</span>    top_blob.create(outw, outh, num_output, elemsize, opt.blob_allocator);    <span class="hljs-keyword">if</span> (top_blob.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    <span class="hljs-comment">// num_output</span>    <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> p = <span class="hljs-number">0</span>; p &lt; num_output; p++) <span class="hljs-comment">// 逐输出通道</span>    &#123;        <span class="hljs-keyword">float</span>* outptr = top_blob.channel(p);        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; outh; i++) <span class="hljs-comment">// 输出高度</span>        &#123;            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; outw; j++) <span class="hljs-comment">// 输出宽度</span>            &#123;                <span class="hljs-keyword">float</span> sum = <span class="hljs-number">0.f</span>;                <span class="hljs-keyword">if</span> (bias_term)                    sum = bias_data[p];                <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* kptr = (<span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>*)weight_data + maxk * channels * p; <span class="hljs-comment">// 卷积单元对应的起始位置</span>                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q = <span class="hljs-number">0</span>; q &lt; channels; q++) <span class="hljs-comment">// 输入</span>                &#123;                    <span class="hljs-keyword">const</span> Mat m = bottom_blob_bordered.channel(q);                    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* sptr = m.row(i * stride_h) + j * stride_w;                    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = <span class="hljs-number">0</span>; k &lt; maxk; k++) <span class="hljs-comment">// 29.23</span>                    &#123;                        <span class="hljs-keyword">float</span> val = sptr[space_ofs[k]]; <span class="hljs-comment">// 20.72</span>                        <span class="hljs-keyword">float</span> w = kptr[k];                        sum += val * w; <span class="hljs-comment">// 41.45</span>                    &#125;                    kptr += maxk;                &#125;                                <span class="hljs-comment">// 激活函数</span>                <span class="hljs-comment">// ......</span>                outptr[j] = sum;            &#125;            outptr += outw;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="5-pooling"><a href="#5-pooling" class="headerlink" title="5. pooling"></a>5. pooling</h4><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Pooling::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// max value in NxN window</span>    <span class="hljs-keyword">int</span> w = bottom_blob.w;    <span class="hljs-keyword">int</span> h = bottom_blob.h;    <span class="hljs-keyword">int</span> channels = bottom_blob.c;    <span class="hljs-keyword">size_t</span> elemsize = bottom_blob.elemsize;    <span class="hljs-keyword">if</span> (global_pooling)    &#123;        <span class="hljs-comment">// ...</span>    &#125;    Mat bottom_blob_bordered;    make_padding(bottom_blob, bottom_blob_bordered, opt);    <span class="hljs-keyword">if</span> (bottom_blob_bordered.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    w = bottom_blob_bordered.w;    h = bottom_blob_bordered.h;    <span class="hljs-keyword">int</span> outw = (w - kernel_w) / stride_w + <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> outh = (h - kernel_h) / stride_h + <span class="hljs-number">1</span>;、        <span class="hljs-comment">// 申请输出 blob</span>    top_blob.create(outw, outh, channels, elemsize, opt.blob_allocator);    <span class="hljs-keyword">if</span> (top_blob.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> maxk = kernel_w * kernel_h;    <span class="hljs-comment">// kernel offsets</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; _space_ofs(maxk); <span class="hljs-comment">// </span>    <span class="hljs-keyword">int</span>* space_ofs = &amp;_space_ofs[<span class="hljs-number">0</span>];    &#123;        <span class="hljs-keyword">int</span> p1 = <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> p2 = <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> gap = w - kernel_w;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; kernel_h; i++)        &#123;            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; kernel_w; j++)            &#123;                space_ofs[p1] = p2;                p1++;                p2++;            &#125;            p2 += gap;        &#125;    &#125;    <span class="hljs-keyword">if</span> (pooling_type == PoolMethod_MAX)    &#123;        <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q = <span class="hljs-number">0</span>; q &lt; channels; q++) <span class="hljs-comment">// 通道</span>        &#123;            <span class="hljs-keyword">const</span> Mat m = bottom_blob_bordered.channel(q);            <span class="hljs-keyword">float</span>* outptr = top_blob.channel(q);            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; outh; i++) <span class="hljs-comment">// 输出层高度</span>            &#123;                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; outw; j++) <span class="hljs-comment">// 输出层宽度</span>                &#123;                    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* sptr = m.row(i * stride_h) + j * stride_w; <span class="hljs-comment">// 池化单元对应的起始位置</span>                    <span class="hljs-keyword">float</span> max = sptr[<span class="hljs-number">0</span>];                    <span class="hljs-comment">// 求每个池化单元对应的最大值</span>                    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = <span class="hljs-number">0</span>; k &lt; maxk; k++)                    &#123;                        <span class="hljs-keyword">float</span> val = sptr[space_ofs[k]];                        max = <span class="hljs-built_in">std</span>::max(max, val);                    &#125;                    outptr[j] = max;                &#125;                outptr += outw;            &#125;        &#125;    &#125;    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (pooling_type == PoolMethod_AVE)    &#123;        <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h4 id="6-Batchnorm"><a href="#6-Batchnorm" class="headerlink" title="6. Batchnorm"></a>6. Batchnorm</h4><pre><code class="hljs c"><span class="hljs-comment">// 可以看出来， 这里的其实就是 value = b * value + a, 完全可以和 conv 进行合并</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">BatchNorm::forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// a = bias - slope * mean / sqrt(var)</span>    <span class="hljs-comment">// b = slope / sqrt(var)</span>    <span class="hljs-comment">// value = b * value + a</span>    <span class="hljs-keyword">int</span> dims = bottom_top_blob.dims;        <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">1</span>) <span class="hljs-comment">// 1维度====================</span>    &#123;        <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">2</span>) <span class="hljs-comment">// 2维度======================</span>    &#123;        <span class="hljs-comment">// ...</span>    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">3</span>) <span class="hljs-comment">// 3维度================================</span>    &#123;        <span class="hljs-keyword">int</span> w = bottom_top_blob.w;        <span class="hljs-keyword">int</span> h = bottom_top_blob.h;        <span class="hljs-keyword">int</span> size = w * h;        <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)        &#123;            <span class="hljs-keyword">float</span>* ptr = bottom_top_blob.channel(q);            <span class="hljs-keyword">float</span> a = a_data[q];            <span class="hljs-keyword">float</span> b = b_data[q];            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)            &#123;                ptr[i] = b * ptr[i] + a;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_5</title>
    <link href="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-5/"/>
    <url>/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-5/</url>
    
    <content type="html"><![CDATA[<a id="more"></a><p>ncnn 提供了两种解析网络 layer 的方法：</p><h4 id="方法一-在推理中进行解析"><a href="#方法一-在推理中进行解析" class="headerlink" title="方法一: 在推理中进行解析"></a>方法一: 在推理中进行解析</h4><p>模型转换之后，某些 layer 没有转换成功：(在转换的过程中)。 如 shufflenetv2 中，param 文件只转换到了 fc 这一个 layer。这时需要添加一层softmax，可以先对param文件中转换成功的layer做推理，然后手动添加一个softmax层：</p><pre><code class="hljs cpp">ncnn::Extractor ex = shufflenetv2.create_extractor();ex.input(<span class="hljs-string">&quot;data&quot;</span>, in);ncnn::Mat out;ex.extract(<span class="hljs-string">&quot;fc&quot;</span>, out);<span class="hljs-comment">// manually call softmax on the fc output</span><span class="hljs-comment">// convert result into probability</span><span class="hljs-comment">// skip if your model already has softmax operation</span>&#123;    ncnn::Layer* softmax = ncnn::create_layer(<span class="hljs-string">&quot;Softmax&quot;</span>);    ncnn::ParamDict pd;    softmax-&gt;load_param(pd);    softmax-&gt;forward_inplace(out, shufflenetv2.opt);    <span class="hljs-keyword">delete</span> softmax;&#125;out = out.reshape(out.w * out.h * out.c);</code></pre><h4 id="方法二-自定义层"><a href="#方法二-自定义层" class="headerlink" title="方法二: 自定义层"></a>方法二: 自定义层</h4><h5 id="1-新建空的类"><a href="#1-新建空的类" class="headerlink" title="1. 新建空的类"></a>1. 新建空的类</h5><pre><code class="hljs c"><span class="hljs-comment">// 在 ncnn/src/layer/ 下新建两个文件 mylayer.h mylayer.cpp</span><span class="hljs-comment">// 1.mylayer.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer.h&quot;</span></span><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> ncnn;      <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyLayer</span> :</span> <span class="hljs-keyword">public</span> Layer&#123;&#125;;<span class="hljs-comment">// 2. mylayer.cpp</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;mylayer.h&quot;</span></span>DEFINE_LAYER_CREATOR(MyLayer)   <span class="hljs-comment">// 注册新定义的层</span></code></pre><h5 id="2-定义层参数-parameters-和-权重-weights-并实现载入函数"><a href="#2-定义层参数-parameters-和-权重-weights-并实现载入函数" class="headerlink" title="2. 定义层参数 parameters 和 权重 weights, 并实现载入函数"></a>2. 定义层参数 parameters 和 权重 weights, 并实现载入函数</h5><pre><code class="hljs c"><span class="hljs-comment">// mylayer.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer.h&quot;</span></span><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> ncnn;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyLayer</span> :</span> <span class="hljs-keyword">public</span> Layer&#123;<span class="hljs-keyword">public</span>:  <span class="hljs-comment">// 公有方法</span>      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDic&amp; pd)</span></span>;<span class="hljs-comment">// 虚函数，可以被子类覆盖</span>      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span>;   <span class="hljs-comment">// </span><span class="hljs-keyword">private</span>: <span class="hljs-comment">// 私有参数</span>      <span class="hljs-keyword">int</span> channels;   <span class="hljs-comment">// 参数1 通道数量</span>      <span class="hljs-keyword">float</span> eps;      <span class="hljs-comment">// 参数2 精度</span>      Mat gamma_data; <span class="hljs-comment">// 权重</span>&#125;；<span class="hljs-comment">// 2. mylayer.cpp</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;mylayer.h&quot;</span></span>DEFINE_LAYER_CREATOR(MyLayer) <span class="hljs-comment">// 实现 load_param() 载入网络层参数</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; pd)</span></span><span class="hljs-function"></span>&#123;      <span class="hljs-comment">// 使用pd.get(key,default_val); 从param文件中（key=val）获取参数</span>      channels = pd.get(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);      <span class="hljs-comment">// 解析 0=&lt;int value&gt;, 默认为0</span>      eps      = pd.get(<span class="hljs-number">1</span>, <span class="hljs-number">0.001f</span>); <span class="hljs-comment">// 解析 1=&lt;float value&gt;, 默认为0.001f</span>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <span class="hljs-comment">// 载入成功返回0</span>&#125;<span class="hljs-comment">// 实现 load_model() 载入模型权重</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span><span class="hljs-function"></span>&#123;      <span class="hljs-comment">// 读取二进制数据的长度为 channels * sizeof(float)</span>      <span class="hljs-comment">// 0 自动判断数据类型， float32 float16 int8</span>      <span class="hljs-comment">// 1 按 float32读取  2 按float16读取 3 按int8读取</span>      gamma_data = mb.load(channels, <span class="hljs-number">1</span>);<span class="hljs-comment">// 按 float32读取 </span>      <span class="hljs-keyword">if</span>(gamma_data.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>; <span class="hljs-comment">// 错误返回非0数，-100表示 out-of-memory </span>      <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <span class="hljs-comment">//  载入成功返回0</span>&#125;</code></pre><h5 id="3-定义类构造函数，确定前向传播行为"><a href="#3-定义类构造函数，确定前向传播行为" class="headerlink" title="3.  定义类构造函数，确定前向传播行为"></a>3.  定义类构造函数，确定前向传播行为</h5><pre><code class="hljs c"><span class="hljs-comment">// mylayer.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer.h&quot;</span></span><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> ncnn;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyLayer</span> :</span> <span class="hljs-keyword">public</span> Layer&#123;<span class="hljs-keyword">public</span>:        MyLayer();  <span class="hljs-comment">// 构造函数</span>      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDic&amp; pd)</span></span>;      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span>;  <span class="hljs-keyword">private</span>:      <span class="hljs-keyword">int</span> channels;         <span class="hljs-keyword">float</span> eps;       Mat gamma_data; &#125;；<span class="hljs-comment">// mylayer.cpp</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;mylayer.h&quot;</span></span>DEFINE_LAYER_CREATOR(MyLayer) <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; pd)</span></span><span class="hljs-function"></span>&#123;      channels = pd.get(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);           eps      = pd.get(<span class="hljs-number">1</span>, <span class="hljs-number">0.001f</span>);            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span><span class="hljs-function"></span>&#123;      gamma_data = mb.load(channels, <span class="hljs-number">1</span>);      <span class="hljs-keyword">if</span>(gamma_data.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;      <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-comment">// 构造函数</span>MyLayer::MyLayer()&#123;      <span class="hljs-comment">// 是否为 1输入1输出层</span>      <span class="hljs-comment">// 1输入1输出层： Convolution, Pooling, ReLU, Softmax ...</span>      <span class="hljs-comment">// 反例       ： Eltwise, Split, Concat, Slice ...</span>      one_blob_only = <span class="hljs-literal">true</span>;      <span class="hljs-comment">// 是否可以在 输入blob 上直接修改 后输出</span>      <span class="hljs-comment">// 支持在原位置上修改： Relu、BN、scale、Sigmod...</span>      <span class="hljs-comment">// 不支持： Convolution、Pooling ...</span>      support_inplace = <span class="hljs-literal">true</span>;&#125;</code></pre><h5 id="4-选择合适的-forward-函数接口，-并实现对应的-forward-函数"><a href="#4-选择合适的-forward-函数接口，-并实现对应的-forward-函数" class="headerlink" title="4.  选择合适的 forward()函数接口， 并实现对应的 forward 函数"></a>4.  选择合适的 forward()函数接口， 并实现对应的 forward 函数</h5><p>Layer类定义了四种 forward()函数：</p><ul><li><p>多输入多输出，const 不可直接对输入进行修改</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; bottom_blobs, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; top_blobs, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;</code></pre></li><li><p>单输入单输出，const 不可直接对输入进行修改</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;</code></pre></li><li><p>多输入多输出，可直接对输入进行修改</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward_inplace</span><span class="hljs-params">(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; bottom_top_blobs, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;</code></pre></li><li><p>单输入单输出，可直接对输入进行修改</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;</code></pre></li></ul><p>具体实现:</p><pre><code class="hljs c"><span class="hljs-comment">// mylayer.h</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer.h&quot;</span></span><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> ncnn;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyLayer</span> :</span> <span class="hljs-keyword">public</span> Layer&#123;<span class="hljs-keyword">public</span>:      MyLayer();      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDic&amp; pd)</span></span>;      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span>;            <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>; <span class="hljs-comment">// 单输入单输出</span>      <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;          <span class="hljs-comment">// 单入单出本地修改 </span><span class="hljs-keyword">private</span>:       <span class="hljs-keyword">int</span> channels;        <span class="hljs-keyword">float</span> eps;       Mat gamma_data;&#125;；<span class="hljs-comment">// mylayer.cpp </span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;mylayer.h&quot;</span></span>DEFINE_LAYER_CREATOR(MyLayer)MyLayer::MyLayer()&#123;      one_blob_only = <span class="hljs-literal">true</span>;      support_inplace = <span class="hljs-literal">true</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; pd)</span></span><span class="hljs-function"></span>&#123;      channels = pd.get(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>);      eps      = pd.get(<span class="hljs-number">1</span>, <span class="hljs-number">0.001f</span>);             <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span><span class="hljs-function"></span>&#123;      gamma_data = mb.load(channels, <span class="hljs-number">1</span>);      <span class="hljs-keyword">if</span>(gamma_data.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;      <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;<span class="hljs-comment">// 单入单出 前向传播网络 不可修改 非const</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">MyLayer::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;      <span class="hljs-keyword">if</span>(bottom_blob.c != channels)            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;            <span class="hljs-comment">// 实现运算 x = (x + eps) * gamma_per_channel</span>      <span class="hljs-keyword">int</span> w = bottom_blob.w;      <span class="hljs-keyword">int</span> h = bottom_blob.h;      <span class="hljs-keyword">size_t</span> elemsize = bottom_blob.elemsize;      <span class="hljs-keyword">int</span> size = w * h;            <span class="hljs-comment">// 输出需要新建，不可直接在输入blob上修改</span>      top_blob.create(w, h, channels, elemsize, opt.blob_allocator);      <span class="hljs-keyword">if</span>(top_blob.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;            <span class="hljs-meta">#pragam omp parallel for num_threads(opt.num_threads);</span>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)      &#123;            <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* in_ptr = bottom_blob.channel(q);            <span class="hljs-keyword">float</span>* out_ptr = top_blob.channel(q);            <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> gamma = gamma_data[q];                        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)            &#123;                  out_ptr[i] = (in_ptr[i] + eps)*gamma;            &#125;            &#125;            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>；&#125;<span class="hljs-comment">// 单入单出 前向传播网络  可在输入blob上修改</span><span class="hljs-keyword">int</span> MyLayer::forward_inplace(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt) <span class="hljs-keyword">const</span>&#123;      <span class="hljs-keyword">if</span>(bottom_blob.c != channels)            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;             <span class="hljs-comment">// 实现运算 x = (x + eps) * gamma_per_channel</span>      <span class="hljs-keyword">int</span> w = bottom_blob.w;      <span class="hljs-keyword">int</span> h = bottom_blob.h;      <span class="hljs-keyword">int</span> size = w * h;            <span class="hljs-comment">// 输出不需要新建，可直接在输入blob上修改</span>      <span class="hljs-meta">#pragam omp parallel for num_threads(opt.num_threads);</span>      <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)      &#123;            <span class="hljs-keyword">float</span>* in_out_ptr = bottom_top_blob.channel(q);            <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> gamma = gamma_data[q];            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)            &#123;                  in_out_ptr[i] = (in_out_ptr[i] + eps)*gamma;            &#125;            &#125;            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>；&#125;</code></pre><h5 id="5-集成进-ncnn-库"><a href="#5-集成进-ncnn-库" class="headerlink" title="5. 集成进 ncnn 库"></a>5. 集成进 ncnn 库</h5><pre><code class="hljs c"><span class="hljs-comment">// 层类型       层名称   输入数量  输出数量   输入层   输出层</span><span class="hljs-comment">// MyLayer     mylayer    1       1     conv2d   mylayer0  0=32 1=0.2 // 对应 param</span><span class="hljs-comment">// 层类型: 和对应的注册的名名称一致</span><span class="hljs-comment">// 注册新层</span>ncnn::Net net;net.register_custom_layer(<span class="hljs-string">&quot;MyLayer&quot;</span>, MyLayer_layer_creator); <span class="hljs-comment">// 注册新层</span>net.load_param(<span class="hljs-string">&quot;model.param&quot;</span>);net.load_model(<span class="hljs-string">&quot;model.bin&quot;</span>);</code></pre><p>​      </p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_4</title>
    <link href="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/"/>
    <url>/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/</url>
    
    <content type="html"><![CDATA[<p>ncnn源码分析-4 模型量化源码</p><a id="more"></a><p>ncnn量化分析代码对应的文件主要有两个:ncnn/tools/quantize/<strong>ncnn2table.cpp</strong> 和 ncnn/tools/quantize/<strong>ncnn2int8.cpp</strong>。</p><ul><li><strong>ncnn2table.cpp</strong> <strong>主要是分析生成相应的量化表， 其中存储了每个层的 scale 值。</strong></li><li><strong>ncnn2int8.cpp</strong> <strong>则是对网络进行 int8量化</strong></li></ul><h4 id="1-ncnn2int8"><a href="#1-ncnn2int8" class="headerlink" title="1. ncnn2int8"></a>1. ncnn2int8</h4><p>​    我们首先对 ncnn2int8.cpp 这个文件进行分析。 该文件完成的主要功能是将 float32 类型转化为 int8 类型。主要分为四个步骤:</p><p>(1) 读取生成的 table 文件，里面存储了对应的 scale。这本质上就是一个文本文件的读取和解析。</p><p>​    read<em>int8_scale_table 负责读取 table 文件, 将 scale 分别存储在 weight_int8scale_table (带 _param\</em>) 和 blob<em>int8scale_table(不带_param\</em>)。 这里只是一个读取文件并解析的过程。</p><p><strong>weight</strong>( 带_param_)格式示例： scale 个数和通道数相同，是主通道进行量化</p><p><img src="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/1.jpg" alt></p><p><strong>blob</strong> (不带_param_) 格式示例：</p><p><img src="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/2.jpg" alt></p><p>(2) <strong>载入原始的参数和模型文件。</strong>net 中的 .param 和 .bin 载入方式<strong>。</strong></p><p>(3) <strong>对卷积层、深度可分离卷积层和全连接层进行量化。quantize_convolution、quantize_convolutiondepthwise、quantize_innerproduct</strong> 分别对卷积层、可分离卷积层和全连接层进行量化<strong>。 这里其实是构建了一个量化层，然后将原始的fp32类型的权重和scale作为输入, 进行一次forward运算，将结果替换原来的fp32权重</strong></p><p>(4) <strong>保存量化后的权重文件</strong></p><p><img src="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/3.jpg" alt></p><p><strong>从主函数入手</strong>: 分别读取了5个参数, <strong>分别是输入模型文件、参数文件、输出模型文件、输出参数文件和量化表的路径</strong>。 然后执行如上所示的四个步骤。</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>** argv)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// 读取相应的参数 </span>    <span class="hljs-keyword">if</span> (argc != <span class="hljs-number">6</span>)    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;usage: %s [inparam] [inbin] [outparam] [outbin] [calibration table]\n&quot;</span>, argv[<span class="hljs-number">0</span>]);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* inparam = argv[<span class="hljs-number">1</span>];  <span class="hljs-comment">// 输入模型文件</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* inbin = argv[<span class="hljs-number">2</span>];  <span class="hljs-comment">// 输入参数文件</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* outparam = argv[<span class="hljs-number">3</span>];  <span class="hljs-comment">// 输出模型文件</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* outbin = argv[<span class="hljs-number">4</span>];  <span class="hljs-comment">// 输出参数文件</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* int8scale_table_path = argv[<span class="hljs-number">5</span>]; <span class="hljs-comment">// 量化表的路径</span>    NetQuantize quantizer; <span class="hljs-comment">// 主要的量化类</span>    <span class="hljs-comment">// (1)  读取并解析 scale table 文件</span>    <span class="hljs-keyword">if</span> (int8scale_table_path)    &#123;        <span class="hljs-keyword">bool</span> s2 = read_int8scale_table(int8scale_table_path, quantizer.blob_int8scale_table, quantizer.weight_int8scale_table);        <span class="hljs-keyword">if</span> (!s2)         &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;read_int8scale_table failed\n&quot;</span>);            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;    &#125;    <span class="hljs-comment">// (2) 载入模型文件和参数</span>    quantizer.load_param(inparam);     quantizer.load_model(inbin);    <span class="hljs-comment">// (3) 量化: 主要量化三层: conv、convdw 和 fc</span>    quantizer.quantize_convolution();    quantizer.quantize_convolutiondepthwise();    quantizer.quantize_innerproduct();    <span class="hljs-comment">// (4) 存储模型和参数文件</span>    quantizer.save(outparam, outbin);    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>​    <strong>代码的最核心的三个函数:</strong> <strong>quantize_convolution、quantize_convolutiondepthwise、quantize_innerproduct</strong> 分别对卷积层、可分离卷积层和全连接层进行量化, </p><p>我们在此以 <strong>quantize_convolution</strong> 为例:</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">NetQuantize::quantize_convolution</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> layer_count = <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(layers.size());    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; layer_count; i++)    &#123;        <span class="hljs-comment">// 查找所有的卷积层</span>        <span class="hljs-keyword">if</span> (layers[i]-&gt;type != <span class="hljs-string">&quot;Convolution&quot;</span>)            <span class="hljs-keyword">continue</span>;                         <span class="hljs-comment">// 获取卷积层的名称           </span>        <span class="hljs-keyword">char</span> key[<span class="hljs-number">256</span>];        <span class="hljs-built_in">sprintf</span>(key, <span class="hljs-string">&quot;%s_param_0&quot;</span>, layers[i]-&gt;name.c_str());                            <span class="hljs-comment">// 在 blob_int8scale_table 找到该层  /* 其实这里的 blob_int8scale_table 下文并没有用到 */</span>        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; &gt;::iterator iter_data = blob_int8scale_table.find(layers[i]-&gt;name);        <span class="hljs-keyword">if</span> (iter_data == blob_int8scale_table.end())            <span class="hljs-keyword">continue</span>;        <span class="hljs-comment">// 在 weight_int8scale_table 找到该层</span>        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">map</span>&lt;<span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; &gt;::iterator iter = weight_int8scale_table.find(key);        <span class="hljs-keyword">if</span> (iter == weight_int8scale_table.end())        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;this layer need to be quantized, but no scale param!\n&quot;</span>);            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;                <span class="hljs-comment">// 卷积层量化 -&gt;  fp32 到 int8</span>        ncnn::Convolution* convolution = (ncnn::Convolution*)layers[i]; <span class="hljs-comment">// (1) 获取该卷积层</span>        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;quantize_convolution %s\n&quot;</span>, convolution-&gt;name.c_str());        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; weight_data_int8_scales = iter-&gt;second; <span class="hljs-comment">//  (2) 获取weight_data_int8_scales</span>        &#123;            <span class="hljs-function">ncnn::Mat <span class="hljs-title">int8_weight_data</span><span class="hljs-params">(convolution-&gt;weight_data_size, (<span class="hljs-keyword">size_t</span>)<span class="hljs-number">1u</span>)</span></span>; <span class="hljs-comment">// (3) 结果，和weight的大小一致</span>            <span class="hljs-keyword">if</span> (int8_weight_data.empty())                <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;            <span class="hljs-comment">// 这里所谓的量化，即进行了一次简单的前向传播，将原来的float32类型的权重替换为int类型结果</span>            <span class="hljs-comment">// 在此之前我们准备的东西有</span>            <span class="hljs-comment">// (1) 卷积层的 fp32 的数据 (2) scale 数据 (3) 声明了一个 int8_weight_data的数据</span>            <span class="hljs-comment">// 我们的目标就是 (1) + (2) -&gt; (3)</span>            <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> weight_data_size_output = convolution-&gt;weight_data_size / convolution-&gt;num_output;            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> n = <span class="hljs-number">0</span>; n &lt; convolution-&gt;num_output; n++)   <span class="hljs-comment">// 逐卷积核进行量化</span>            &#123;                <span class="hljs-comment">// (4) 创建一个quantize op</span>                ncnn::Layer* op = ncnn::create_layer(ncnn::LayerType::Quantize);                 <span class="hljs-comment">// (5) 把量化表中的scale设置进op里去</span>                ncnn::ParamDict pd;                pd.<span class="hljs-built_in">set</span>(<span class="hljs-number">0</span>, weight_data_int8_scales[n]);                op-&gt;load_param(pd);                <span class="hljs-comment">// (6) blob_allocator</span>                ncnn::Option opt;                opt.blob_allocator = int8_weight_data.allocator;                <span class="hljs-comment">// (7) weight_data &lt;-&gt; weight_data_n , int8_weight_data &lt;-&gt;  int8_weight_data_n </span>                <span class="hljs-keyword">const</span> ncnn::Mat weight_data_n = convolution-&gt;weight_data.range(weight_data_size_output * n, weight_data_size_output);                ncnn::Mat int8_weight_data_n = int8_weight_data.range(weight_data_size_output * n, weight_data_size_output);                <span class="hljs-comment">// (8) quantitze op前传，计算量化权值 weight_data_n -&gt;  int8_weight_data_n</span>                op-&gt;forward(weight_data_n, int8_weight_data_n, opt);                                 <span class="hljs-keyword">delete</span> op;            &#125;            convolution-&gt;weight_data = int8_weight_data; <span class="hljs-comment">// (9) 用量化后的权值替换原来的权值</span>        &#125;        convolution-&gt;int8_scale_term = <span class="hljs-number">2</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>可以来简单的看一下 <strong>quantize</strong> 层:</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">signed</span> <span class="hljs-keyword">char</span> <span class="hljs-title">float2int8</span><span class="hljs-params">(<span class="hljs-keyword">float</span> v)</span></span>&#123;    <span class="hljs-keyword">int</span> int32 = <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(round(v)); <span class="hljs-comment">// 取整数, 然后转化为 int32类型</span>    <span class="hljs-keyword">if</span> (int32 &gt; <span class="hljs-number">127</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">127</span>;  <span class="hljs-comment">// 如果大于127, 返回127</span>    <span class="hljs-keyword">if</span> (int32 &lt; <span class="hljs-number">-127</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">-127</span>; <span class="hljs-comment">// 如果小于 -127, 返回 -127</span>    <span class="hljs-keyword">return</span> (<span class="hljs-keyword">signed</span> <span class="hljs-keyword">char</span>)int32; <span class="hljs-comment">// 返回 int32 -&gt; int8</span>&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Quantize::forward</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Mat&amp; bottom_blob, Mat&amp; top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>&#123;    <span class="hljs-keyword">int</span> dims = bottom_blob.dims;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">1</span>)&#123;        <span class="hljs-keyword">int</span> w = bottom_blob.w;        top_blob.create(w, (<span class="hljs-keyword">size_t</span>)<span class="hljs-number">1u</span>, opt.blob_allocator);        <span class="hljs-keyword">if</span> (top_blob.empty())            <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;        <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span>* ptr = bottom_blob;        <span class="hljs-keyword">signed</span> <span class="hljs-keyword">char</span>* outptr = top_blob;        <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;w; i++)        &#123;            <span class="hljs-comment">// ! 这一句是最核心的，也是整个量化部分代码的核心</span>            <span class="hljs-comment">// 将 float32 乘以 scale， 然后将其转化为 int8 类型</span>            outptr[i] = float2int8(ptr[i] * scale);         &#125;    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">2</span>)&#123;        ...    &#125;    <span class="hljs-keyword">if</span> (dims == <span class="hljs-number">3</span>)&#123;        ...    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>2. ncnn2table.cpp</strong> </p><p>ncnn2table.cpp 主要用于<strong>量化表的计算</strong>，说白了就是使用我们之前说的算法来计算各个参数的 scale，在ncnn2table.cpp下，顶层代码核心就一句话：</p><pre><code class="hljs cpp"><span class="hljs-comment">/* ncnn2table.cpp */</span><span class="hljs-comment">// filenames: 用来calibration的图片list </span><span class="hljs-comment">// parampath: 参数文件路径</span><span class="hljs-comment">// binpath: bin 二进制文件路径</span><span class="hljs-comment">// tablepath: 生成的量化表的路径</span><span class="hljs-comment">// pre_param: 参数</span>post_training_quantize(filenames, parampath, binpath, tablepath, pre_param);</code></pre><p>我们接下来重点看post_training_quantize这个函数，该函数做了如下几件事：</p><p><strong>&gt;&gt;&gt;&gt;  (1) 初始化quantitize_datas    (2) 计算最大值    (3) 初始化直方图的间隔      (4) 计算直方图           (5) 计算Scale</strong></p><p><strong>(1) 初始化quantitize_datas</strong></p><p>​    没什么好说的，每一个层有一个<strong>QuantizeData</strong>对象，初始化 num_bins=2048，也就是原始的fp32分布Po，其统计直方图一共有<strong>2048个bins</strong></p><pre><code class="hljs cpp"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;QuantizeData&gt; quantize_datas;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; net.conv_names.size(); i++)&#123;    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> layer_name = net.conv_names[i];    <span class="hljs-function">QuantizeData <span class="hljs-title">quantize_data</span><span class="hljs-params">(layer_name, <span class="hljs-number">2048</span>)</span></span>;    quantize_datas.push_back(quantize_data);&#125;</code></pre><p><strong>(2) 计算最大值</strong></p><p>​    遍历所有图片，计算每个blob的最大激活值，这里找的是绝对值最大的那个</p><pre><code class="hljs cpp">    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; image_list.size(); i++) <span class="hljs-comment">// 遍历calibration数据</span>    &#123;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> img_name = image_list[i];        <span class="hljs-keyword">if</span> ((i + <span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>)        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;    %d/%d\n&quot;</span>, <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(i + <span class="hljs-number">1</span>), <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(size));        &#125;        cv::Mat bgr = cv::imread(img_name, cv::IMREAD_COLOR);        <span class="hljs-keyword">if</span> (bgr.empty())        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;cv::imread %s failed\n&quot;</span>, img_name.c_str());            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;        ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, swapRB ? ncnn::Mat::PIXEL_BGR2RGB : ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, width, height);        in.substract_mean_normalize(mean_vals, norm_vals);        ncnn::Extractor ex = net.create_extractor();        ex.input(net.input_names[<span class="hljs-number">0</span>].c_str(), in);        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> j = <span class="hljs-number">0</span>; j &lt; net.conv_names.size(); j++)        &#123;            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> layer_name = net.conv_names[j];            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> blob_name = net.conv_bottom_blob_names[layer_name];            ncnn::Mat out;            ex.extract(blob_name.c_str(), out); <span class="hljs-comment">// 前传网络，相当于caffe的forwardTo，拿到blob数据</span>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> k = <span class="hljs-number">0</span>; k &lt; quantize_datas.size(); k++)            &#123;                <span class="hljs-keyword">if</span> (quantize_datas[k].name == layer_name)                &#123;                    quantize_datas[k].initial_blob_max(out); <span class="hljs-comment">// 统计最大值</span>                    <span class="hljs-keyword">break</span>;                &#125;            &#125;        &#125;    &#125;    <span class="hljs-comment">// 被调函数:</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">QuantizeData::initial_blob_max</span><span class="hljs-params">(ncnn::Mat data)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> channel_num = data.c;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> size = data.w * data.h;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q = <span class="hljs-number">0</span>; q &lt; channel_num; q++)    &#123;        <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> *data_n = data.channel(q);        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; size; i++)        &#123;            max_value = <span class="hljs-built_in">std</span>::max(max_value, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">fabs</span>(data_n[i]));        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>(3) 初始化直方图间隔</strong></p><p>也很简单，遍历每个层，初始化直方图间隔=最大激活值/2048</p><pre><code class="hljs cpp">    <span class="hljs-comment">// step 2 histogram_interval</span>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;    ====&gt; step 2 : generate the histogram_interval.\n&quot;</span>);    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; net.conv_names.size(); i++)    &#123;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> layer_name = net.conv_names[i];        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> k = <span class="hljs-number">0</span>; k &lt; quantize_datas.size(); k++)        &#123;            <span class="hljs-keyword">if</span> (quantize_datas[k].name == layer_name)            &#123;                quantize_datas[k].initial_histogram_interval();                <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;%-20s : max = %-15f interval = %-10f\n&quot;</span>, quantize_datas[k].name.c_str(), quantize_datas[k].max_value, quantize_datas[k].histogram_interval);                <span class="hljs-keyword">break</span>;            &#125;        &#125;    &#125;    <span class="hljs-comment">// 被调函数    </span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">QuantizeData::initial_histogram_interval</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    histogram_interval = max_value / <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">float</span>&gt;(num_bins);    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>(4) 计算直方图</strong></p><p>​    再前传一次，遍历每个blob，向每个bin中投票，计算出直方图，得到原始fp32分布</p><pre><code class="hljs cpp">    <span class="hljs-comment">// step 3 histogram</span>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;    ====&gt; step 3 : generate the histogram.\n&quot;</span>);    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; image_list.size(); i++)    &#123;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> img_name = image_list[i];        <span class="hljs-keyword">if</span> ((i + <span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>)            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;          %d/%d\n&quot;</span>, (<span class="hljs-keyword">int</span>)(i + <span class="hljs-number">1</span>), (<span class="hljs-keyword">int</span>)size);                    cv::Mat bgr = cv::imread(img_name, cv::IMREAD_COLOR);        <span class="hljs-keyword">if</span> (bgr.empty())        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;cv::imread %s failed\n&quot;</span>, img_name.c_str());            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;        ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, swapRB ? ncnn::Mat::PIXEL_BGR2RGB : ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, width, height);        in.substract_mean_normalize(mean_vals, norm_vals);        ncnn::Extractor ex = net.create_extractor();        ex.input(net.input_names[<span class="hljs-number">0</span>].c_str(), in);        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> j = <span class="hljs-number">0</span>; j &lt; net.conv_names.size(); j++)        &#123;            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> layer_name = net.conv_names[j];            <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> blob_name = net.conv_bottom_blob_names[layer_name];            ncnn::Mat out;            ex.extract(blob_name.c_str(), out);            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> k = <span class="hljs-number">0</span>; k &lt; quantize_datas.size(); k++)            &#123;                <span class="hljs-keyword">if</span> (quantize_datas[k].name == layer_name)                &#123;                    quantize_datas[k].update_histogram(out);                    <span class="hljs-keyword">break</span>;                &#125;            &#125;        &#125;    &#125;    <span class="hljs-comment">// 被调函数      </span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">QuantizeData::update_histogram</span><span class="hljs-params">(ncnn::Mat data)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> channel_num = data.c;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> size = data.w * data.h;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q = <span class="hljs-number">0</span>; q &lt; channel_num; q++)    &#123;        <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> *data_n = data.channel(q);        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; size; i++)        &#123;            <span class="hljs-keyword">if</span> (data_n[i] == <span class="hljs-number">0</span>)                <span class="hljs-keyword">continue</span>;            <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> index = <span class="hljs-built_in">std</span>::min(<span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">int</span>&gt;(<span class="hljs-built_in">std</span>::<span class="hljs-built_in">abs</span>(data_n[i]) / histogram_interval), <span class="hljs-number">2047</span>);            histogram[index]++;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>(5) 计算Scale</strong></p><pre><code class="hljs cpp">    <span class="hljs-comment">// step4 kld</span>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;    ====&gt; step 4 : using kld to find the best threshold value.\n&quot;</span>);    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; net.conv_names.size(); i++)    &#123;        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> layer_name = net.conv_names[i];        <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> blob_name = net.conv_bottom_blob_names[layer_name];        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;%-20s &quot;</span>, layer_name.c_str());        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> k = <span class="hljs-number">0</span>; k &lt; quantize_datas.size(); k++)        &#123;            <span class="hljs-keyword">if</span> (quantize_datas[k].name == layer_name)            &#123;                quantize_datas[k].get_data_blob_scale();                <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;bin : %-8d threshold : %-15f interval : %-10f scale : %-10f\n&quot;</span>,                        quantize_datas[k].threshold_bin,                        quantize_datas[k].threshold,                        quantize_datas[k].histogram_interval,                        quantize_datas[k].scale);                <span class="hljs-built_in">fprintf</span>(fp, <span class="hljs-string">&quot;%s %f\n&quot;</span>, layer_name.c_str(), quantize_datas[k].scale);                <span class="hljs-keyword">break</span>;            &#125;        &#125;    &#125;<span class="hljs-comment">// 被调函数 </span><span class="hljs-function"><span class="hljs-keyword">float</span> <span class="hljs-title">QuantizeData::get_data_blob_scale</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;       normalize_histogram();   <span class="hljs-comment">// 直方图归一化</span>    threshold_bin = threshold_distribution(histogram);   <span class="hljs-comment">// 计算最后有多少个bins</span>    threshold = (threshold_bin + <span class="hljs-number">0.5</span>) * histogram_interval;   <span class="hljs-comment">// 之后很容易就能找到Threshold</span>    scale = <span class="hljs-number">127</span> / threshold;   <span class="hljs-comment">// Scale也很简单就能z好到</span>    <span class="hljs-keyword">return</span> scale;&#125;</code></pre><p>其实说了半天，<strong>最核心的就在get_data_blob_scale这个函数里，函数分为3步</strong>：</p><p><strong>a. 直方图归一化</strong></p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">QuantizeData::normalize_histogram</span><span class="hljs-params">()</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">size_t</span> length = histogram.size();    <span class="hljs-keyword">float</span> sum = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; length; i++)        sum += histogram[i];    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i = <span class="hljs-number">0</span>; i &lt; length; i++)        histogram[i] /= sum;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>b. 使用KL散度计算最后用多少个bins比较合适</strong></p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">QuantizeData::threshold_distribution</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; &amp;distribution, <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> target_bin = <span class="hljs-number">128</span>)</span></span><span class="hljs-function"></span>&#123;    ...    <span class="hljs-comment">// 这里length就是原始分布Po的长度，NCNN默认2048。这里的threshold实际上是num_bins，可以换算成T</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> threshold = target_bin; threshold &lt; length; threshold++)   <span class="hljs-comment">// target_bin=128，length = 2048</span>    &#123;         <span class="hljs-comment">// ①. 计算截断的fp32分布P</span>         <span class="hljs-comment">// ②. 计算int8分布Q</span>         <span class="hljs-comment">// ③. 计算扩展分布Q_expand</span>        <span class="hljs-comment">// ④. 计算KL散度</span>        <span class="hljs-comment">// ⑤. 比大小</span>    &#125;&#125;</code></pre><p>①. 计算截断的fp32分布P也很简单：</p><pre><code class="hljs cpp"><span class="hljs-keyword">float</span> threshold_sum = <span class="hljs-number">0</span>;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> threshold=target_bin; threshold&lt;length; threshold++) &#123;    threshold_sum += distribution[threshold];   <span class="hljs-comment">// 128以上的所有数据和</span>&#125;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> threshold=target_bin; threshold&lt;length; threshold++) &#123;    <span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; <span class="hljs-title">t_distribution</span><span class="hljs-params">(distribution.begin(), distribution.begin()+threshold)</span></span>;        t_distribution[threshold<span class="hljs-number">-1</span>] += threshold_sum;   <span class="hljs-comment">// P的最后一个bin加上被截断的所有概率，得到截断的fp32分布P</span>    threshold_sum -= distribution[threshold];       <span class="hljs-comment">// 是通过减法来保证数值正确性的，很巧秒</span>    ...</code></pre><p>②. 计算int8分布Q，注意Q是从Po得来的，而不是从P得来的，大于T的部分并不会加进最后一个bin内（存疑，不理解）；另外，当发生了4舍5入时，会有特殊处理</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; <span class="hljs-title">quantize_distribution</span><span class="hljs-params">(target_bin)</span></span>;  <span class="hljs-comment">// 量化后分布Q，长度是128</span> fill(quantize_distribution.begin(), quantize_distribution.end(), <span class="hljs-number">0</span>);<span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> num_per_bin = <span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">float</span>&gt;(threshold) / target_bin;  <span class="hljs-comment">// 其实就是当前T下的Scale </span><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;target_bin; i++) &#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> start = i * num_per_bin;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> end = start + num_per_bin;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> left_upper = <span class="hljs-built_in">ceil</span>(start);    <span class="hljs-keyword">if</span> (left_upper &gt; start)     &#123;   <span class="hljs-comment">// 这里的意思是，如果发生了5入，则需要将舍掉的那个bin按比例加进来</span>        <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> left_scale = left_upper - start;        quantize_distribution[i] += left_scale * distribution[left_upper - <span class="hljs-number">1</span>];    &#125;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> right_lower = <span class="hljs-built_in">floor</span>(end);    <span class="hljs-keyword">if</span> (right_lower &lt; end)     &#123;        <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> right_scale = end - right_lower;        quantize_distribution[i] += right_scale * distribution[right_lower];    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j=left_upper; j&lt;right_lower; j++)     &#123;        quantize_distribution[i] += distribution[j];    &#125;&#125;</code></pre><p>③. 计算Q_expand，统计count时0不算在内，注意不管是统计数量还是上采样的过程中，都有4舍5入相关的问题</p><pre><code class="hljs cpp"><span class="hljs-comment">// get Q</span><span class="hljs-function"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; <span class="hljs-title">expand_distribution</span><span class="hljs-params">(threshold, <span class="hljs-number">0</span>)</span></span>;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;target_bin; i++) &#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> start = i * num_per_bin;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> end = start + num_per_bin;    <span class="hljs-keyword">float</span> count = <span class="hljs-number">0</span>;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> left_upper = <span class="hljs-built_in">ceil</span>(start);    <span class="hljs-keyword">float</span> left_scale = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span> (left_upper &gt; start)     &#123;        left_scale = left_upper - start;        <span class="hljs-keyword">if</span> (distribution[left_upper - <span class="hljs-number">1</span>] != <span class="hljs-number">0</span>)         &#123;            count += left_scale;        &#125;    &#125;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> right_lower = <span class="hljs-built_in">floor</span>(end);    <span class="hljs-keyword">float</span> right_scale = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span> (right_lower &lt; end)     &#123;        right_scale = end - right_lower;        <span class="hljs-keyword">if</span> (distribution[right_lower] != <span class="hljs-number">0</span>)         &#123;            count += right_scale;        &#125;    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j=left_upper; j&lt;right_lower; j++)     &#123;        <span class="hljs-keyword">if</span> (distribution[j] != <span class="hljs-number">0</span>)         &#123;            count++;        &#125;    &#125;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> expand_value = quantize_distribution[i] / count;    <span class="hljs-keyword">if</span> (left_upper &gt; start)     &#123;        <span class="hljs-keyword">if</span> (distribution[left_upper - <span class="hljs-number">1</span>] != <span class="hljs-number">0</span>)         &#123;            expand_distribution[left_upper - <span class="hljs-number">1</span>] += expand_value * left_scale;  <span class="hljs-comment">// 上采样过程中一样有四舍五入的问题</span>        &#125;    &#125;    <span class="hljs-keyword">if</span> (right_lower &lt; end)     &#123;        <span class="hljs-keyword">if</span> (distribution[right_lower] != <span class="hljs-number">0</span>)         &#123;            expand_distribution[right_lower] += expand_value * right_scale;        &#125;    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j=left_upper; j&lt;right_lower; j++)     &#123;        <span class="hljs-keyword">if</span> (distribution[j] != <span class="hljs-number">0</span>)         &#123;            expand_distribution[j] += expand_value;        &#125;    &#125;&#125;</code></pre><p>④. 计算KL散度，注意当Q为0时，KL散度只加一（存疑，不理解）</p><pre><code class="hljs cpp"><span class="hljs-keyword">float</span> kl_divergence = compute_kl_divergence(t_distribution, expand_distribution);<span class="hljs-function"><span class="hljs-keyword">float</span> <span class="hljs-title">QuantizeData::compute_kl_divergence</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; &amp;dist_a, <span class="hljs-keyword">const</span> <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; &amp;dist_b)</span> </span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> length = dist_a.size();    assert(dist_b.size() == length);    <span class="hljs-keyword">float</span> result = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;length; i++)     &#123;        <span class="hljs-keyword">if</span> (dist_a[i] != <span class="hljs-number">0</span>)         &#123;            <span class="hljs-keyword">if</span> (dist_b[i] == <span class="hljs-number">0</span>)             &#123;                result += <span class="hljs-number">1</span>;   <span class="hljs-comment">// Q为0时，KL散度只加一</span>            &#125;             <span class="hljs-keyword">else</span>             &#123;                result += dist_a[i] * <span class="hljs-built_in">log</span>(dist_a[i] / dist_b[i]);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> result;&#125;</code></pre><p>⑤. 轻松愉悦的找最大值</p><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (kl_divergence &lt; min_kl_divergence) &#123;    min_kl_divergence = kl_divergence;       target_threshold = threshold;   <span class="hljs-comment">// 实际上是num_bins</span>&#125;</code></pre><p><strong>c. 计算 Threshold 和 bins</strong></p><p>至此，我们得到了KL散度最小的桶数num_bins，可以通过下述公式得到T和Scale，就三行：</p><pre><code class="hljs cpp">threshold = (<span class="hljs-keyword">static_cast</span>&lt;<span class="hljs-keyword">float</span>&gt;(threshold_bin) + <span class="hljs-number">0.5f</span>) * histogram_interval;scale = <span class="hljs-number">127</span> / threshold;<span class="hljs-keyword">return</span> scale;</code></pre><p>最后就是将Scale数据存下来，得到量化表了。</p><p><strong>总结一下以上的代码逻辑:</strong></p><p><img src="/2020/09/21/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-4/4.png" alt></p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_3</title>
    <link href="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/"/>
    <url>/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/</url>
    
    <content type="html"><![CDATA[<p>ncnn 源码分析 模型量化原理</p><a id="more"></a><h4 id="1-FP32-vs-int8"><a href="#1-FP32-vs-int8" class="headerlink" title="1. FP32 vs int8"></a>1. FP32 vs int8</h4><p>​     来看一下 <strong>FP32、FP16和int8</strong>之间的动态范围和精度的对比， 可以看到float32 的取值范围几乎是无穷的， 而int8只有<strong>-128~127</strong>. 因此需要建立映射关系将float32类型的浮点数映射到指定范围的int8类型。 </p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/ncnn1.png" alt></p><h4 id="2-TensorRT-int8-量化方案"><a href="#2-TensorRT-int8-量化方案" class="headerlink" title="2. TensorRT int8 量化方案"></a>2. TensorRT int8 量化方案</h4><p>Nvidia 的 TensorRT提供了一种量化方案，但是它仅仅提供相应的SDK和解决方案， 没有公布对应的源代码， 诸多第三方厂家则根据该解决方案自己造轮子，产生了对应的解决方案。该量化方案的最重要的两份参考资料如下所示:</p><p>- TensorRT Develop guide: <a href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#work-with-qat-networks">https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#work-with-qat-networks</a></p><p>- PDF 链接： <a href="http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">http://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf</a></p><p><strong>(1)</strong> <strong>max-max 映射</strong>： 最简单粗暴的方式如下左图所示</p><p>​    首先求出一个laye 的激活值范围， 然后按照绝对值的最大值作为阈值， 然后把这个范围按照比例映射到-127到128的范围内, 其fp32和int8的转换公式为:</p><p><strong>FP32 Tensor (T) = scale_factor(sf) * 8-bit Tensor(t) + FP32_bias (b)</strong> </p><p>通过实验得知，bias值去掉对精度的影响不是很大，因此我们直接去掉, 所以该公式可以简化为:</p><p><strong>T = sf * t</strong></p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/ncnn2.png" alt></p><p><strong>(2) 饱和映射</strong></p><p>​    如上方法会有一个问题：<strong>不饱和，即通常在正负上会有一些量化值未被利用，且会产生的精度损失较大。</strong>针对 max-max 映射存在的问题， TensorRT提出了如上右图的饱和映射。 <strong>选取一个阈值T，然后将 -|T|~|T| 之间的值映射到 -127 到 128 这个范围内。这样确定了阈值T之后，其实也能确定Scale，一个简单的线性公式是: Scale = T/127。 所以要计算Scale，只要找到合适的阈值T就可以了。那么问题来了，T应该取何值? 其基本流程如下:</strong></p><p>​    <strong>(a) 选取不同的 T 阈值进行量化, 将 P(fp32) 映射到 Q(int8)。</strong></p><p>​    <strong>(b) 将 Q(int8) 反量化到 P(fp32) 一样长度，得到分布 Q_expand；</strong></p><p>​    <strong>(c) 计算P和Q_expand 的相对熵(KL散度)，然后选择相对熵最少的一个，也就是跟原分布最像的一个,</strong> <strong>从而确定Scale**</strong>。**</p><p><strong>(3) KL 散度</strong></p><p>​    KL散度可以用来<strong>描述P、Q两个分布的差异</strong>。<strong>散度越小，两个分布的差异越小，概率密度函数形状和数值越接近</strong>。这里的所有分布、计算，都是离散形式的。分布是以统计直方图的方式存在，KL散度公式也是离散公式：</p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/ncnn5.png" alt></p><p>从上式中我们还发现一个问题：KL散度计算公式要求P、Q两个统计直方图长度一样（也就是bins的数量一样）。Q一直都是-127～127；可是P的数量会随着T的变化而变化。那这怎么做KL散度呢？</p><p>ncnn 的做法是将 Q扩展到和P一样的长度，下面举个例子(NVIDIA PPT中的例子)：</p><pre><code class="hljs cpp">P = [<span class="hljs-number">1</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">5</span> <span class="hljs-number">3</span> <span class="hljs-number">1</span> <span class="hljs-number">7</span>]     <span class="hljs-comment">// fp32的统计直方图，T=8</span><span class="hljs-comment">// 假设只量化到两个bins，即量化后的值只有-1/0/+1三种</span>Q=[<span class="hljs-number">1</span>+<span class="hljs-number">0</span>+<span class="hljs-number">2</span>+<span class="hljs-number">3</span>, <span class="hljs-number">5</span>+<span class="hljs-number">3</span>+<span class="hljs-number">1</span>+<span class="hljs-number">7</span>] = [<span class="hljs-number">6</span>, <span class="hljs-number">16</span>]<span class="hljs-comment">// P和Q现在没法做KL散度，所以要将Q扩展到和P一样的长度</span>Q_expand = [<span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>] = [<span class="hljs-number">2</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span>]  <span class="hljs-comment">// P中有0时，不算在内</span>D = KL(P||Q_expand)  <span class="hljs-comment">// 这样就可以做KL散度计算了</span></code></pre><p>​    这个扩展的操作，就像图像的上采样一样，将低精度的统计直方图(Q)，上采样的高精度的统计直方图上去(Q_expand)。由于Q中一个bin对应P中的4个bin，因此在Q上采样的Q_expand的过程中，所有的数据要除以4。另外，在计算fp32的分布P时，被T截断的数据，是要算在最后一个bin里面的。</p><h4 id="3-ncnn的conv量化计算流程"><a href="#3-ncnn的conv量化计算流程" class="headerlink" title="3. ncnn的conv量化计算流程"></a>3. ncnn的conv量化计算流程</h4><p>正常的 fp32 计算中， 一个conv 的计算流程如下所示， 所有的数据均是 fp32， 没什么特殊的</p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/ncnn3.png" alt="fp32 conv计算流程"></p><p>在 ncnn conv 进行Int8计算时， 计算流程如下所示，ncnn首先<strong>将输入(bottom_blob)和权重量化成Int8，在Int8下计算卷积，然后反量化到 fp32，再和未量化的bias相加，得到输出 top_blob</strong>(ncnn并没有对bias做量化)</p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-3/ncnn4.png" alt="int8 conv 计算流程， 在conv前， 对input和weight做量化， 计算完后反量化到 fp32, 再加 bias"></p><p>输入和权重的<strong>量化公式</strong>为:</p><pre><code class="hljs cpp">bottom_blob(int8) = bottom_blob_in8t_scale * bottom(fp32)weight_blob(int8) = weight_data_int8_scale * weight(fp32)</code></pre><p><strong>反量化</strong>的目的是将int8映射回到原来的fp32,范围保持要一致, 由于 weight_blob(int8) 和 bottom_blob(int8) 相乘， 所以此处的量化反量化的 scale 应该为:</p><pre><code class="hljs cpp">dequantize_scale = <span class="hljs-number">1</span>/(bottom_blob_int8_scale * weight_data_int8_scale)innner_blob(fp32) = dequantize_scale * inner_blob</code></pre><p><strong>! 值得注意的是， 权重是在网络初始化时候就进行量化了， 而输入则是在前向推导时进行量化。</strong></p><h4 id="4-ncnn-量化工具的使用"><a href="#4-ncnn-量化工具的使用" class="headerlink" title="4. ncnn 量化工具的使用"></a>4. <strong>ncnn 量化工具的使用</strong></h4><p>(1) <strong>Optimization graphic 图优化: 最明显的变化是将conv层和bn层进行合并</strong></p><pre><code class="hljs shell">./ncnnoptimize mobilenet-fp32.param mobilenet-fp32.bin mobilenet-nobn-fp32.param mobilenet-nobn-fp32.bin</code></pre><p><strong>(2) Create the calibration table file(建议使用超过5000张图片的验证集进行对齐): 计算产生对应的 scale</strong></p><pre><code class="hljs shell">./ncnn2table --param mobilenet-nobn-fp32.param --bin mobilenet-nobn-fp32.bin --images images/ --output mobilenet-nobn.table --mean 104,117,123 --norm 0.017,0.017,0.017 --size 224,224 --thread 2</code></pre><p><strong>(3) Quantization：量化</strong></p><pre><code class="hljs shell">./ncnn2int8 mobilenet-nobn-fp32.param mobilenet-nobn-fp32.bin mobilenet-int8.param mobilenet-int8.bin mobilenet-nobn.table</code></pre><h4 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a>5. 参考资料</h4><p>[1] <a href="https://me.csdn.net/sinat_31425585">https://me.csdn.net/sinat_31425585</a></p><p>[2] <a href="https://zhuanlan.zhihu.com/c_1064124187198705664">https://zhuanlan.zhihu.com/c_1064124187198705664</a></p><p>[3] <a href="https://github.com/BUG1989/caffe-int8-convert-tools">https://github.com/BUG1989/caffe-int8-convert-tools</a></p><p>[4] <a href="https://github.com/Tencent/ncnn/wiki/quantized-int8-inference">Tencent/ncnn</a></p><p>[5] QNNPACK</p><p>[6] Nvidia solution： Szymon Migacz. 8-bit Inference with TensorRT</p><p>[7] Google solution：Quantizing deep convolutional networks for efficient inference: A whitepaper</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_2</title>
    <link href="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-2/"/>
    <url>/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-2/</url>
    
    <content type="html"><![CDATA[<p>ncnn 源码分析（二） Extractor</p><a id="more"></a><p>前面大致总结了一下ncnn模型载入的流程，模型载入之后，就是新建一个<strong>Extractor</strong>，然后设置输入，获取输出：</p><pre><code class="hljs cpp">ncnn::Extractor ex = net.create_extractor();ex.set_num_threads(<span class="hljs-number">4</span>); ex.input(<span class="hljs-string">&quot;data&quot;</span>, in); ncnn::Mat out;ex.extract(<span class="hljs-string">&quot;detection_out&quot;</span>, out);</code></pre><p>现在可以看一下Extractor的定义了：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Extractor</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">// enable light mode, intermediate blob will be recycled when enabled</span>    <span class="hljs-comment">// enabled by default</span>    <span class="hljs-comment">// 设置light模式，启用时中间 blob 将会循环利用</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">set_light_mode</span><span class="hljs-params">(<span class="hljs-keyword">bool</span> enable)</span></span>;     <span class="hljs-comment">// set thread count for this extractor, 设置线程数</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">set_num_threads</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num_threads)</span></span>;     <span class="hljs-comment">// set blob memory allocator, 设置blob的内存分配器</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">set_blob_allocator</span><span class="hljs-params">(Allocator* allocator)</span></span>;     <span class="hljs-comment">// set workspace memory allocator, 设置工作空间的内存分配器</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">set_workspace_allocator</span><span class="hljs-params">(Allocator* allocator)</span></span>;  <span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>    <span class="hljs-comment">// set input by blob name</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 设置网络输入：字符串layer名</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">input</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* blob_name, <span class="hljs-keyword">const</span> Mat&amp; in)</span></span>;     <span class="hljs-comment">// get result by blob name</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 设置提取器的输入：得到对应输出</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">extract</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* blob_name, Mat&amp; feat)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>     <span class="hljs-comment">// set input by blob index</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 设置int类型blob索引及输入</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">input</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blob_index, <span class="hljs-keyword">const</span> Mat&amp; in)</span></span>;     <span class="hljs-comment">// get result by blob index</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 设置int类型blob索引及输出</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">extract</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blob_index, Mat&amp; feat)</span></span>; <span class="hljs-keyword">protected</span>:    <span class="hljs-comment">// 对外提供create_extractor接口</span>    <span class="hljs-function"><span class="hljs-keyword">friend</span> Extractor <span class="hljs-title">Net::create_extractor</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;    Extractor(<span class="hljs-keyword">const</span> Net* net, <span class="hljs-keyword">int</span> blob_count); <span class="hljs-keyword">private</span>:    <span class="hljs-comment">// 网络 </span>    <span class="hljs-keyword">const</span> Net* net;    <span class="hljs-comment">// blob的 mat</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt; blob_mats;    <span class="hljs-comment">// 选项</span>    Option opt; &#125;;</code></pre><p>除了设置option的接口之外，就只剩下我们需要使用的几个接口函数了：</p><p><strong>(1) Extractor</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">// 创建Extractor</span><span class="hljs-function">Extractor <span class="hljs-title">Net::create_extractor</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> Extractor(<span class="hljs-keyword">this</span>, blobs.size());&#125;</code></pre><p>内部调用了接口为，就是将blob_mat数组resize到网络的blob数目大小，然后设置了一下选项：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 执行器</span>Extractor::Extractor(<span class="hljs-keyword">const</span> Net* _net, <span class="hljs-keyword">int</span> blob_count) : net(_net)&#123;    blob_mats.resize(blob_count);    opt = net-&gt;opt;&#125;</code></pre><p><strong>(2) input接口：</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">// 设置输入</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Extractor::input</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* blob_name, <span class="hljs-keyword">const</span> Mat&amp; in)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// 获取输入模块对应index</span>    <span class="hljs-keyword">int</span> blob_index = net-&gt;find_blob_index_by_name(blob_name);    <span class="hljs-keyword">if</span> (blob_index == <span class="hljs-number">-1</span>)        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;     <span class="hljs-comment">// 调用直接用index的设置input方法</span>    <span class="hljs-keyword">return</span> input(blob_index, in);&#125;</code></pre><p>内部调用的接口为：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 输入为index的输入接口</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Extractor::input</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blob_index, <span class="hljs-keyword">const</span> Mat&amp; in)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span> (blob_index &lt; <span class="hljs-number">0</span> || blob_index &gt;= (<span class="hljs-keyword">int</span>)blob_mats.size())        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;     <span class="hljs-comment">// 设置blob_index对应 Mat</span>    blob_mats[blob_index] = in;     <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p><strong>(3) extract接口：</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">// 将输入string类型name转换成对应的索引</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Extractor::extract</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* blob_name, VkMat&amp; feat, VkCompute&amp; cmd)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> blob_index = net-&gt;find_blob_index_by_name(blob_name);    <span class="hljs-keyword">if</span> (blob_index == <span class="hljs-number">-1</span>)        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;     <span class="hljs-keyword">return</span> extract(blob_index, feat, cmd);&#125;</code></pre><p>这里调用的接口为：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 提取特征</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Extractor::extract</span><span class="hljs-params">(<span class="hljs-keyword">int</span> blob_index, Mat&amp; feat)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span> (blob_index &lt; <span class="hljs-number">0</span> || blob_index &gt;= (<span class="hljs-keyword">int</span>)blob_mats.size())        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;     <span class="hljs-keyword">int</span> ret = <span class="hljs-number">0</span>;        <span class="hljs-keyword">if</span> (blob_mats[blob_index].dims == <span class="hljs-number">0</span>)     <span class="hljs-comment">// 如果输出blob为空</span>    &#123;        <span class="hljs-keyword">int</span> layer_index = net-&gt;blobs[blob_index].producer;  <span class="hljs-comment">// 查找输出blob对应的生产者</span>        ret = net-&gt;forward_layer(layer_index, blob_mats, opt);   <span class="hljs-comment">// 前向推理</span>    &#125;    feat = blob_mats[blob_index];   <span class="hljs-comment">// 输出特征</span>     <span class="hljs-keyword">if</span> (opt.use_packing_layout)   <span class="hljs-comment">// 对特征进行unpack</span>    &#123;        Mat bottom_blob_unpacked;        convert_packing(feat, bottom_blob_unpacked, <span class="hljs-number">1</span>, opt);        feat = bottom_blob_unpacked;    &#125;     <span class="hljs-keyword">return</span> ret;&#125;</code></pre><p>​    这里就是调用各层前向推理forward_layer方法来进行推理的，这个对应于特定层的推理过程，后面总结各个层的时候再说。</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_1</title>
    <link href="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/"/>
    <url>/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/</url>
    
    <content type="html"><![CDATA[<p>ncnn 源码分析 — 参数与模型载入</p><a id="more"></a><h4 id="1-实例代码"><a href="#1-实例代码" class="headerlink" title="1. 实例代码"></a>1. 实例代码</h4><p>使用ncnn进行前向计算的步骤很简单，就如下几行代码即可完成。</p><pre><code class="hljs cpp"> <span class="hljs-comment">// 代码来自 ncnn/examples/shufflenetv2.cpp</span> <span class="hljs-comment">/* Step 1.1 : 加载.parma 文件 和 .bin 文件 */</span> ncnn::Net shufflenetv2; shufflenetv2.load_param(<span class="hljs-string">&quot;shufflenet_v2_x0.5.param&quot;</span>); shufflenetv2.load_model(<span class="hljs-string">&quot;shufflenet_v2_x0.5.bin&quot;</span>); <span class="hljs-comment">/* Step 1.2 : 构建并配置 提取器 */</span> ncnn::Extractor ex = shufflenetv2.create_extractor(); <span class="hljs-comment">/* Step 1.3 : 设置输入（将图片转换成ncnn::Mat结构作为输入） */</span>    ncnn::Mat in = ncnn::Mat::from_pixels_resize(bgr.data, ncnn::Mat::PIXEL_BGR, bgr.cols, bgr.rows, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>);<span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> norm_vals[<span class="hljs-number">3</span>] = &#123;<span class="hljs-number">1</span>/<span class="hljs-number">255.f</span>, <span class="hljs-number">1</span>/<span class="hljs-number">255.f</span>, <span class="hljs-number">1</span>/<span class="hljs-number">255.f</span>&#125;;in.substract_mean_normalize(<span class="hljs-number">0</span>, norm_vals);ex.input(<span class="hljs-string">&quot;data&quot;</span>, in);        <span class="hljs-comment">/* Step 1.4 : 提取输出 */</span> ncnn::Mat out;ex.extract(<span class="hljs-string">&quot;fc&quot;</span>, out);</code></pre><h4 id="2-代码分析"><a href="#2-代码分析" class="headerlink" title="2. 代码分析"></a>2. 代码分析</h4><p><strong>我姑且将其分为：加载模型</strong>、<strong>构建并配置提取器</strong>、<strong>设置输入</strong>、<strong>输出处理</strong>、<strong>模型封装</strong>五个部分来加以分析</p><p><strong>模型载入</strong>:</p><p><strong>相关代码:</strong></p><p><strong>net.h/cpp</strong>   <strong>blob.h/cpp</strong>   <strong>layer.h/.cpp</strong>  </p><p>​    <strong>paramdict.cpp/h</strong>  </p><p>​    <strong>modelbin.h/.cpp</strong></p><p><strong>相关文件:</strong></p><p>xx.bin  xx.param</p><h4 id="3-加载模型"><a href="#3-加载模型" class="headerlink" title="3. 加载模型"></a>3. 加载模型</h4><p>ncnn 在使用 <strong>.param</strong> 和 <strong>.bin</strong> 两个文件来描述一个神经网络模型。 模型加载的根本目的是将 .param 和 .bin 文件的信息加载到目标神经网络（一个ncnn::Net结构）中</p><p>其中：</p><p><strong>.param</strong>：描述神经网络的结构，包括层名称，层输入输出信息，层参数信息（如卷积层的kernal大小等）等。</p><p><strong>.bin</strong> 文件则记录神经网络运算所需要的数据信息（比如卷积层的权重、偏置信息等）</p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/ncnn1.png" alt="ncnn官方demo中的模型文件"></p><h6 id="3-1-param-文件"><a href="#3-1-param-文件" class="headerlink" title="3.1 param 文件"></a>3.1 param 文件</h6><p><strong>一个.param文件由以下几部分组成：</strong></p><p><img src="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-1/ncnn2.png" alt></p><p><strong>1）MagicNum</strong></p><p>固定位7767517，可以通过这个数来判定版本 -&gt; 为什么这个数字，不知道问倪神去吧 </p><p>2）<strong>layer、blob个数</strong></p><p>上图示例的文件两个数字分别为：75、83</p><p>​    <strong>layer：我们知道神经网络是一层一层向前推进计算的，每一层我们用一个layer表示；</strong></p><p>​    <strong>blob：每一个layer都可能会有输入、输出，在ncnn中，它们统一用一个多维（3维）向量表示，我们称每一个输入、输出的原子为一个blob，并为它起名</strong></p><p>2.1.1.2 layer的描述</p><p>layer 在 .param 中是一个相对复杂的元素（从第3行起的每一行描述一个layer），所以我们把它单独抽出来进行说明。</p><p><strong>1）层类型</strong>     比如<strong>Input、Convolution、ReLU</strong></p><p><strong>2）层名</strong>       模型训练者为该层起得名字（毕竟相同类型的层可能多次使用，我们要区分它们）</p><p><strong>3）层输入输出  包含：层输入blob数量，层输出blob数量，层输入、输出blob的名称</strong></p><p><strong>4）层配置参数</strong></p><p>比如 <strong>卷积层（Convolution Layer）的 卷积核大小、步长信息</strong> 等</p><p>在 具体层里面都有一个函数: load_param, 从里面可以查询到相关信息。</p><p><strong>data层： 0=长 1=宽 3=通道</strong></p><p><strong>Convolution层 0=输出单元 1=卷积核大小  2=核膨胀[见膨胀卷积]    3=stride</strong>    </p><p>​                                 <strong>4=padding    5=是否存在偏置    6=权重数量</strong></p><p><strong>pooling 层    0=池化类型   1=卷积核大小   2=步长stride   3=padding   4=全局池化  5=padding类型</strong></p><p><strong>ReLU 层 0=0.000000 无参数</strong></p><p><strong>softmax 层 0=0 无参数</strong></p><p><strong>Concat Split Dropout 无参数</strong></p><p><strong>ConvolutionDepthWise    7=group 数目</strong></p><h6 id="3-2-读取"><a href="#3-2-读取" class="headerlink" title="3.2 读取"></a>3.2 读取</h6><p><strong>下面我们具体从代码的角度来看看如何读取这个文件的:(文件为 net.cpp/h 和 paramdict.cpp/h) 为了方便， 我们将 Vulkan 相关代码剔除掉。</strong></p><p><strong>net.h 主要是 Net 类的接口， 其中最重要的功能是实现 load_param(载入模型参数) 和 load_model(载入模型的数据) 功能</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">// net.h</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Net</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">// empty init</span>    Net();    <span class="hljs-comment">// clear and destroy</span>    ~Net();<span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>    <span class="hljs-comment">// register custom layer by layer type name</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 注册自定义类型层， 通过string类型名</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">register_custom_layer</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* type, layer_creator_func creator)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>    <span class="hljs-comment">// register custom layer by layer type</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 注册自定义层， 通过int类型的 layer 索引</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">register_custom_layer</span><span class="hljs-params">(<span class="hljs-keyword">int</span> index, layer_creator_func creator)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STDIO</span><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>    <span class="hljs-comment">// load network structure from plain param file</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 从文件指针中载入参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(FILE* fp)</span></span>;    <span class="hljs-comment">// 从 param 文件中载入参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* protopath)</span></span>;    <span class="hljs-comment">// 从 mem 中载入参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param_mem</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* mem)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>    <span class="hljs-comment">// load network structure from binary param file</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 从二进制文件指针中载入 param 参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param_bin</span><span class="hljs-params">(FILE* fp)</span></span>;    <span class="hljs-comment">// 从二进制文件中载入参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param_bin</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* protopath)</span></span>;    <span class="hljs-comment">// load network weight data from model file</span>    <span class="hljs-comment">// return 0 if success</span>    <span class="hljs-comment">// 从 file 指针中传入模型</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(FILE* fp)</span></span>;    <span class="hljs-comment">// 从二进制文件中载入模型</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* modelpath)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STDIO</span></span>    <span class="hljs-comment">// load network structure from external memory</span>    <span class="hljs-comment">// memory pointer must be 32-bit aligned</span>    <span class="hljs-comment">// return bytes consumed</span>    <span class="hljs-comment">// 从外部内存中载入参数</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>* mem)</span></span>;    <span class="hljs-comment">// reference network weight data from external memory</span>    <span class="hljs-comment">// weight data is not copied but referenced</span>    <span class="hljs-comment">// so external memory should be retained when used</span>    <span class="hljs-comment">// memory pointer must be 32-bit aligned</span>    <span class="hljs-comment">// return bytes consumed</span>    <span class="hljs-comment">// 从外部内存中载入网络权重</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>* mem)</span></span>;    <span class="hljs-comment">// unload network structure and weight data</span>    <span class="hljs-comment">// 清空网络结构</span>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">clear</span><span class="hljs-params">()</span></span>;    <span class="hljs-comment">// construct an Extractor from network</span>    <span class="hljs-comment">// 从网络构建一个执行器</span>    <span class="hljs-function">Extractor <span class="hljs-title">create_extractor</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;<span class="hljs-keyword">protected</span>:    <span class="hljs-keyword">friend</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Extractor</span>;</span> <span class="hljs-comment">// 外部 Extractor 接口</span><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRIN</span>    <span class="hljs-comment">// 通过name查找blob对应的索引</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">find_blob_index_by_name</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* name)</span> <span class="hljs-keyword">const</span></span>;     <span class="hljs-comment">// 通过name查找对应的 layer 索引</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">find_layer_index_by_name</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* name)</span> <span class="hljs-keyword">const</span></span>;    <span class="hljs-comment">// 通过类型查找对应的 layer索引</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">custom_layer_to_index</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* type)</span></span>;    <span class="hljs-comment">// 通过类型创建layer</span>    <span class="hljs-function">Layer* <span class="hljs-title">create_custom_layer</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* type)</span></span>;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>    <span class="hljs-comment">// 通过 index 穿件 layer</span>    <span class="hljs-function">Layer* <span class="hljs-title">create_custom_layer</span><span class="hljs-params">(<span class="hljs-keyword">int</span> index)</span></span>;    <span class="hljs-comment">// 前向推理层</span>    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">forward_layer</span><span class="hljs-params">(<span class="hljs-keyword">int</span> layer_index, <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Mat&gt;&amp; blob_mats, Option&amp; opt)</span> <span class="hljs-keyword">const</span></span>;<span class="hljs-keyword">protected</span>:    <span class="hljs-comment">// blobs &amp; layers</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Blob&gt; blobs;    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;Layer*&gt; layers;    <span class="hljs-comment">// layers</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;layer_registry_entry&gt; custom_layer_registry;&#125;;</code></pre><p>在此我们可以先来看一下 blob类 ! 着重看一下，对应的生产者、消费者模型</p><pre><code class="hljs cpp"><span class="hljs-comment">// Blob 用于记录数据传输过程， producer 记录当前blob从那一层产生的，</span><span class="hljs-comment">// consumer 记录当前blob被哪些层调用:</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Blob</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">// empty</span>    Blob();<span class="hljs-keyword">public</span>:<span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>    <span class="hljs-comment">// blob name</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span> name;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>    <span class="hljs-comment">// layer index which produce this blob as output</span>    <span class="hljs-comment">// 生产者</span>    <span class="hljs-keyword">int</span> producer;    <span class="hljs-comment">// layer index which need this blob as input</span>    <span class="hljs-comment">// 消费者</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; consumers;&#125;;</code></pre><p>然后我们打开 net.cpp 文件，来看一下 load_param 的具体实现:</p><pre><code class="hljs cpp"><span class="hljs-comment">// 从文件中载入 net 参数</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Net::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* protopath)</span></span><span class="hljs-function"></span>&#123;    FILE* fp = fopen(protopath, <span class="hljs-string">&quot;rb&quot;</span>);    <span class="hljs-keyword">if</span> (!fp)    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;fopen %s failed\n&quot;</span>, protopath);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;    <span class="hljs-comment">// 从文件指针中载入 param</span>    <span class="hljs-keyword">int</span> ret = load_param(fp);    fclose(fp);    <span class="hljs-keyword">return</span> ret;&#125;</code></pre><p>参数载入接口中， 调用了另外一个参数载入接口: load_param(FILE * fp)</p><p>(1) 读取 magic number, 通过判断 magic number 是否等于 7767517, 就可以判断当前param文件是否是最新的 param 文件 </p><pre><code class="hljs cpp"><span class="hljs-keyword">int</span> magic = <span class="hljs-number">0</span>;<span class="hljs-comment">// 读取 magic number</span><span class="hljs-keyword">int</span> nbr = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%d&quot;</span>, &amp;magic);<span class="hljs-comment">// 读取失败</span><span class="hljs-keyword">if</span> (nbr != <span class="hljs-number">1</span>)&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;issue with param file\n&quot;</span>);    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;<span class="hljs-comment">// 判断是否是最新的 magic number</span><span class="hljs-keyword">if</span> (magic != <span class="hljs-number">7767517</span>)&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;param is too old, please regenerate\n&quot;</span>);    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;</code></pre><p>(2) 解析出网络的 layer 层数和 blob 数目 </p><pre><code class="hljs cpp"><span class="hljs-comment">// 对 layer 和 blob 进行解析</span><span class="hljs-keyword">int</span> layer_count = <span class="hljs-number">0</span>;<span class="hljs-keyword">int</span> blob_count = <span class="hljs-number">0</span>;<span class="hljs-comment">// 层数 &amp;&amp; blob 数目</span>nbr = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%d %d&quot;</span>, &amp;layer_count, &amp;blob_count);<span class="hljs-comment">// 层数和 blob数读取失败</span><span class="hljs-keyword">if</span> (nbr != <span class="hljs-number">2</span> || layer_count &lt;= <span class="hljs-number">0</span> || blob_count &lt;= <span class="hljs-number">0</span>)&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;issue with param file\n&quot;</span>);    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;<span class="hljs-comment">// resize 网络的层数和blob数目</span>layers.resize((<span class="hljs-keyword">size_t</span>)layer_count);blobs.resize((<span class="hljs-keyword">size_t</span>)blob_count);</code></pre><p>(3) 遍历所有的 layer, 解析每层 layer 层的类型(layer type)、名称(layer name)、输入数目(bottom_count) 和 输出数目(top_count)</p><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;layer_count; i++)&#123;    <span class="hljs-keyword">int</span> nscan = <span class="hljs-number">0</span>;    <span class="hljs-comment">// layer 的类型和名称</span>    <span class="hljs-keyword">char</span> layer_type[<span class="hljs-number">257</span>];    <span class="hljs-keyword">char</span> layer_name[<span class="hljs-number">257</span>];    <span class="hljs-keyword">int</span> bottom_count = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> top_count = <span class="hljs-number">0</span>;    <span class="hljs-comment">// 读取层类型、名称。输入bottom数目和输出top数目</span>    nscan = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%256s %256s %d %d&quot;</span>, layer_type, layer_name, &amp;bottom_count, &amp;top_count);    <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">4</span>) <span class="hljs-comment">// 解析失败</span>    &#123;        <span class="hljs-keyword">continue</span>;    &#125;</code></pre><p>(4) 根据layer的类型， 创建 layer</p><pre><code class="hljs cpp"><span class="hljs-comment">// 创建 layer</span>Layer* layer = create_layer(layer_type);<span class="hljs-comment">// layer_type 不是默认类型</span><span class="hljs-keyword">if</span> (!layer)&#123;    <span class="hljs-comment">// 从自定义 layer 读取</span>    layer = create_custom_layer(layer_type);&#125;<span class="hljs-keyword">if</span> (!layer) <span class="hljs-comment">// 如果自定义 layer 中不存在当前类型的 layer </span>&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;layer %s not exists or registered\n&quot;</span>, layer_type);    clear();    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;<span class="hljs-comment">// 设置 layer 参数: layer的类型、名称、输入和输出      </span>layer-&gt;type = <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>(layer_type);layer-&gt;name = <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>(layer_name);</code></pre><p>(5) 在设置输入时，如果当前blob名不存在，就将当前blob名添加到net的blobs数组里面</p><pre><code class="hljs cpp">layer-&gt;bottoms.resize(bottom_count); <span class="hljs-comment">// layer的输入</span><span class="hljs-comment">// 解析 layer 的输入</span><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j=<span class="hljs-number">0</span>; j&lt;bottom_count; j++)&#123;    <span class="hljs-keyword">char</span> bottom_name[<span class="hljs-number">257</span>];    <span class="hljs-comment">// 解析 bottom的name</span>    nscan = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%256s&quot;</span>, bottom_name);    <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>)    &#123;        <span class="hljs-keyword">continue</span>;    &#125;    <span class="hljs-comment">// 按照 bottom 的name 查找对应 blob 的index</span>    <span class="hljs-keyword">int</span> bottom_blob_index = find_blob_index_by_name(bottom_name);    <span class="hljs-comment">// 如果没有找到 bottom_name 对应的 blob</span>    <span class="hljs-comment">// 将向 blobs 数组中插入一个名为 bottom_name 的 blob</span>    <span class="hljs-keyword">if</span> (bottom_blob_index == <span class="hljs-number">-1</span>)    &#123;        <span class="hljs-comment">// 设置第blob_index个blob 的参数</span>        Blob&amp; blob = blobs[blob_index];        <span class="hljs-comment">// blob的索引</span>        bottom_blob_index = blob_index;        <span class="hljs-comment">// 设置blob的name</span>        blob.name = <span class="hljs-built_in">std</span>::<span class="hljs-built_in">string</span>(bottom_name);        <span class="hljs-comment">// 更新全局的 blob 索引</span>        blob_index++;    &#125;    <span class="hljs-comment">// 设置当前的blob的参数</span>    Blob&amp; blob = blobs[bottom_blob_index];    <span class="hljs-comment">// 使用当前的blob记录传输关系， 第i层以当前blob为输入</span>    blob.consumers.push_back(i);    <span class="hljs-comment">// 第i层layer的第j个输入</span>    layer-&gt;bottoms[j] = bottom_blob_index;&#125;</code></pre><p> (6) 设置输出的过程和这个类似，在此不再赘述，最后就是<strong>参数载入了</strong>:</p><p>例如: <strong>conv1的参数: 0=64 1=3 11=3 5=1 6=1728</strong></p><pre><code class="hljs cpp"><span class="hljs-comment">//解析 blob后面跟随的特定参数字典 pd</span><span class="hljs-keyword">int</span> pdlr = pd.load_param(fp);<span class="hljs-keyword">if</span> (pdlr != <span class="hljs-number">0</span>)&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict load_param failed\n&quot;</span>);    <span class="hljs-keyword">continue</span>;&#125;<span class="hljs-comment">// layer 载入 param</span><span class="hljs-keyword">int</span> lr = layer-&gt;load_param(pd);<span class="hljs-keyword">if</span> (lr != <span class="hljs-number">0</span>)&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;layer load_param failed\n&quot;</span>);    <span class="hljs-keyword">continue</span>;&#125;layers[i] = layer;</code></pre><p>这其中有两个重要的函数:</p><p>pd.load_param(fp) 和  layer_param(pd)。前者负责解析 .param 文件中特定的参数， 后者则是用解析的参数来构建对应的layer</p><p>(7) 用参数字典来解析layer相关参数！ 看一下这个自己构造layer， 以及解析的过程 </p><p>   在使用load_param接口载入参数时，需要用参数字典ParamDict来解析.param文件中的特定参数，那么参数字典具体如何进行解析的？我们首先看一下paramdict.h文件中定义的数据成员变量：</p><pre><code class="hljs cpp"><span class="hljs-comment">// parameters</span><span class="hljs-class"><span class="hljs-keyword">struct</span></span><span class="hljs-class">&#123;</span>    <span class="hljs-comment">// 是否已经被载入：1表示已载入</span>    <span class="hljs-keyword">int</span> loaded;    <span class="hljs-comment">// 单个值可能为整形也有可能为浮点型</span>    <span class="hljs-keyword">union</span> &#123; <span class="hljs-keyword">int</span> i; <span class="hljs-keyword">float</span> f; &#125;;    <span class="hljs-comment">// 还有可能是数组</span>    Mat v;&#125; params[NCNN_MAX_PARAM_COUNT];</code></pre><p>​    这里，NCNN_MAX_PARAM_COUNT大小为20，params是一个大小为32的结构体数组，即一行中特定参数数量不能超过20，当然，一般情况下也不会超过20。</p><pre><code class="hljs cpp"><span class="hljs-comment">// at most 20 parameters</span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> NCNN_MAX_PARAM_COUNT 20</span></code></pre><p>​    然后，我们看一下paramdict.cpp源码，可以看到，这里会解析出当前行的index（id），也即是等号左边部分： </p><pre><code class="hljs cpp"><span class="hljs-comment">// 解析之后的 key=value 对</span><span class="hljs-keyword">int</span> id = <span class="hljs-number">0</span>;<span class="hljs-keyword">while</span> (<span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%d=&quot;</span>, &amp;id) == <span class="hljs-number">1</span>)&#123;    ...&#125;</code></pre><p> 在这里可以结合 <a href="https://github.com/Tencent/ncnn/wiki/param-and-model-file-structure">https://github.com/Tencent/ncnn/wiki/param-and-model-file-structure</a> 阅读源码：</p><p><strong>index-value 的规则为:</strong></p><ul><li>index为0~19: 对应整形或浮点型数据</li><li><p>index小于 -23000： 对应整形或浮点型数组, 等号右边第一个参数就是数组长度，后面顺序就是数组内容，[array size],int,int,…,int或[array size],float,float,…,float，例如：</p><p><strong>0=1 1=2.5 -23303=2,2.0,3.0</strong></p><p>index为 -23303，表明当前参数为数组，等号右边第一个参数为2，表明数组长度为2，后面2.0,3.0就是数组的内容</p></li></ul><pre><code class="hljs cpp"><span class="hljs-keyword">bool</span> is_array = id &lt;= <span class="hljs-number">-23300</span>; <span class="hljs-comment">// index &lt;= -23300：数组</span><span class="hljs-keyword">if</span> (is_array) <span class="hljs-comment">// 如果是数组</span>&#123;  <span class="hljs-comment">// 计算id</span>    id = -id - <span class="hljs-number">23300</span>;&#125;<span class="hljs-keyword">if</span> (is_array)  <span class="hljs-comment">// 如果当前参数是数组类型</span>&#123;    <span class="hljs-keyword">int</span> len = <span class="hljs-number">0</span>;  <span class="hljs-comment">// 数组长度</span>    <span class="hljs-keyword">int</span> nscan = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%d&quot;</span>, &amp;len);    <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>)             <span class="hljs-comment">// 等于1才表示读取成功</span>    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict read array length failed\n&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;        params[id].v.create(len);  <span class="hljs-comment">// 创建数组：就是一个Mat</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; len; j++)    &#123;        <span class="hljs-keyword">char</span> vstr[<span class="hljs-number">16</span>]; <span class="hljs-comment">// 从二值文件中读取string</span>        nscan = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;,%15[^,\n ]&quot;</span>, vstr);        <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>) <span class="hljs-comment">// 如果读取失败</span>        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict read array element failed\n&quot;</span>);            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;         <span class="hljs-comment">// 是否为浮点型：看解析的字符串中是否存在&#x27;.&#x27;或&#x27;e&#x27;</span>        <span class="hljs-comment">// 小数点计数法和科学计数法</span>        <span class="hljs-keyword">bool</span> is_float = vstr_is_float(vstr);        <span class="hljs-comment">// 如果是浮点数</span>        <span class="hljs-keyword">if</span> (is_float)  <span class="hljs-comment">// vstr赋值给params[id].v[j]</span>        &#123;            <span class="hljs-keyword">float</span>* ptr = params[id].v;            nscan = <span class="hljs-built_in">sscanf</span>(vstr, <span class="hljs-string">&quot;%f&quot;</span>, &amp;ptr[j]);        &#125;        <span class="hljs-keyword">else</span>  <span class="hljs-comment">// vstr赋值给params[id].v[j]</span>        &#123;            <span class="hljs-keyword">int</span>* ptr = params[id].v;            nscan = <span class="hljs-built_in">sscanf</span>(vstr, <span class="hljs-string">&quot;%d&quot;</span>, &amp;ptr[j]);        &#125;        <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>)  <span class="hljs-comment">// 赋值失败</span>        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict parse array element failed\n&quot;</span>);            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        &#125;    &#125;&#125;</code></pre><p>​    这里有个vstr_is_float函数，原理很简单，就是判断数字对应字符串中是否存在小数点’.’或字母’e’，对应小数的两种写法，一种正常的小数点表示法，一种是科学计数法。</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">bool</span> <span class="hljs-title">vstr_is_float</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span> vstr[<span class="hljs-number">16</span>])</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// look ahead for determine isfloat</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j=<span class="hljs-number">0</span>; j&lt;<span class="hljs-number">16</span>; j++)    &#123;        <span class="hljs-keyword">if</span> (vstr[j] == <span class="hljs-string">&#x27;\0&#x27;</span>)            <span class="hljs-keyword">break</span>;        <span class="hljs-keyword">if</span> (vstr[j] == <span class="hljs-string">&#x27;.&#x27;</span> || <span class="hljs-built_in">tolower</span>(vstr[j]) == <span class="hljs-string">&#x27;e&#x27;</span>)            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;</code></pre><p>​    如果不是数组，直接读取即可：</p><pre><code class="hljs cpp"><span class="hljs-keyword">else</span>   <span class="hljs-comment">// 不是数组</span>&#123;    <span class="hljs-keyword">char</span> vstr[<span class="hljs-number">16</span>];    <span class="hljs-keyword">int</span> nscan = <span class="hljs-built_in">fscanf</span>(fp, <span class="hljs-string">&quot;%15s&quot;</span>, vstr); <span class="hljs-comment">// 直接将字符串赋值给vstr</span>    <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>)  <span class="hljs-comment">// 赋值失败</span>    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict read value failed\n&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;    <span class="hljs-keyword">bool</span> is_float = vstr_is_float(vstr);  <span class="hljs-comment">// 判断是否为浮点数</span>    <span class="hljs-keyword">if</span> (is_float)  <span class="hljs-comment">// 将字符串中的值赋给参数字典</span>        nscan = <span class="hljs-built_in">sscanf</span>(vstr, <span class="hljs-string">&quot;%f&quot;</span>, &amp;params[id].f);    <span class="hljs-keyword">else</span>        nscan = <span class="hljs-built_in">sscanf</span>(vstr, <span class="hljs-string">&quot;%d&quot;</span>, &amp;params[id].i);    <span class="hljs-keyword">if</span> (nscan != <span class="hljs-number">1</span>)  <span class="hljs-comment">// 赋值失败</span>    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;ParamDict parse value failed\n&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;&#125;params[id].loaded = <span class="hljs-number">1</span>;         <span class="hljs-comment">// 载入成功</span></code></pre><p>(8) 用参数字典来解析layer相关参数</p><p>如前所示, layer会根据参数字典来构造 layer</p><pre><code class="hljs cpp"> <span class="hljs-comment">// layer载入param</span><span class="hljs-keyword">int</span> lr = layer-&gt;load_param(pd);</code></pre><p>转到 layer层的 load_param 接口可以看到：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 载入参数：参数列表</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Layer::load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; <span class="hljs-comment">/*pd*/</span>)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>这里并没有实现，在layer.h头文件中有：</p><pre><code class="hljs cpp"><span class="hljs-comment">// load layer specific parameter from parsed dict</span><span class="hljs-comment">// return 0 if success</span><span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">load_param</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ParamDict&amp; pd)</span></span>;</code></pre><p> ! load_param实际上是一个虚函数，熟悉C++的同学应该知道，调用虚函数时，实际调用的是继承类的版本，那么到底如何调用的？，我们可以往回看，有这样一段代码：</p><pre><code class="hljs cpp">Layer* layer = create_layer(layer_type)  <span class="hljs-comment">// 创建layer</span><span class="hljs-keyword">if</span> (!layer) <span class="hljs-comment">// layer_type不是默认类型</span>&#123;       layer = create_custom_layer(layer_type);   <span class="hljs-comment">// 从自定义layer读取</span>&#125;<span class="hljs-keyword">if</span> (!layer)   <span class="hljs-comment">// 如果自定义layer中也不存在当前类型layer</span>&#123;    <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;layer %s not exists or registered\n&quot;</span>, layer_type);    clear();    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;</code></pre><p>回到layer.cpp文件中，可以看到，代码中先找到当前层layer类型对应层注册器中类型的索引index。</p><p><strong>layer_type -&gt; index -&gt; create_layer</strong></p><pre><code class="hljs cpp"> <span class="hljs-comment">// 将string对应layer类型转换成对应index</span> <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">layer_to_index</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* type)</span></span><span class="hljs-function"> </span>&#123;     <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;layer_registry_entry_count; i++)     &#123;         <span class="hljs-keyword">if</span> (<span class="hljs-built_in">strcmp</span>(type, layer_registry[i].name) == <span class="hljs-number">0</span>)             <span class="hljs-keyword">return</span> i;     &#125;     <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>; &#125;   <span class="hljs-comment">// 根据index创建layer：</span><span class="hljs-function">Layer* <span class="hljs-title">create_layer</span><span class="hljs-params">(<span class="hljs-keyword">int</span> index)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span> (index &lt; <span class="hljs-number">0</span> || index &gt;= layer_registry_entry_count)     <span class="hljs-comment">// index不能超过索引范围</span>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;     layer_creator_func layer_creator = layer_registry[index].creator;     <span class="hljs-comment">// 创建layer构造器</span>    <span class="hljs-keyword">if</span> (!layer_creator)     <span class="hljs-comment">// layer构造器创建失败</span>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;     Layer* layer = layer_creator();     <span class="hljs-comment">// 构造layer</span>    layer-&gt;typeindex = index;    <span class="hljs-comment">// 设置layer的类型index</span>    <span class="hljs-keyword">return</span> layer;&#125;<span class="hljs-comment">// 根据字符串layer类型创建layer -&gt; 调用上面两个函数， 创建layer</span><span class="hljs-function">Layer* <span class="hljs-title">create_layer</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* type)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">int</span> index = layer_to_index(type);    <span class="hljs-keyword">if</span> (index == <span class="hljs-number">-1</span>)        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;     <span class="hljs-keyword">return</span> create_layer(index);&#125;</code></pre><p>line 18 有个layer_registry，其定义为：</p><pre><code class="hljs cpp"><span class="hljs-keyword">static</span> <span class="hljs-keyword">const</span> layer_registry_entry layer_registry[] =&#123;    #include <span class="hljs-string">&quot;layer_registry.h&quot;</span>&#125;;</code></pre><p>而这个”layer_registry.h”文件是在build项目的时候自动产生的，部分内容如下：</p><pre><code class="hljs cpp"> <span class="hljs-comment">// Layer Registry header</span> <span class="hljs-comment">//</span> <span class="hljs-comment">// This file is auto-generated by cmake, don&#x27;t edit it.</span>  <span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span> &#123;<span class="hljs-string">&quot;AbsVal&quot;</span>,AbsVal_final_layer_creator&#125;, <span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span> &#123;AbsVal_final_layer_creator&#125;, <span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span> <span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>&#123;<span class="hljs-string">&quot;ArgMax&quot;</span>,<span class="hljs-number">0</span>&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>&#123;<span class="hljs-number">0</span>&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>&#123;<span class="hljs-string">&quot;BatchNorm&quot;</span>,BatchNorm_final_layer_creator&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>&#123;BatchNorm_final_layer_creator&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>&#123;<span class="hljs-string">&quot;Bias&quot;</span>,Bias_final_layer_creator&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span>&#123;Bias_final_layer_creator&#125;,<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span></code></pre><p>而 layer_registry_entry 的结构为：</p><pre><code class="hljs cpp"><span class="hljs-comment">// layer factory function</span><span class="hljs-keyword">typedef</span> Layer* (*layer_creator_func)(); <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">layer_registry_entry</span></span><span class="hljs-class">&#123;</span><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STRING</span>    <span class="hljs-comment">// layer type name</span>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* name;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STRING</span></span>    <span class="hljs-comment">// layer factory entry</span>    layer_creator_func creator;&#125;;</code></pre><p>我们代入一组参数进去就是：</p><pre><code class="hljs cpp">name = <span class="hljs-string">&quot;AbsVal&quot;</span>;layer_creator_func = AbsVal_final_layer_creator;</code></pre><p>这里layer_creator_func定义为：</p><pre><code class="hljs cpp"><span class="hljs-keyword">typedef</span> Layer* (*layer_creator_func)();</code></pre><p>那么，layer_creator_func AbsVal_final_layer_creator转换过去就是： </p><pre><code class="hljs isbl"><span class="hljs-variable">Layer</span>* <span class="hljs-function"><span class="hljs-title">AbsVal_final_layer_creator</span>()</span></code></pre><p>在layer.h文件最下面还有一个定义：</p><pre><code class="hljs cpp"><span class="hljs-comment">// ## 字符串连接</span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> DEFINE_LAYER_CREATOR(name) \</span>    ::ncnn::Layer* name##_layer_creator() &#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> name; &#125;</code></pre><p>我们在absval.cpp文件中可以看到 DEFINE_LAYER_CREATOR(AbsVal)，相当于就是声明了一个函数：</p><pre><code class="hljs cpp"><span class="hljs-comment">// #define DEFINE_LAYER_CREATOR(name) \</span><span class="hljs-comment">//    ::ncnn::Layer* name##_layer_creator() &#123; return new name; &#125;</span><span class="hljs-comment">// 由上面这段代码可知，DEFINE_LAYER_CREATOR(AbsVal)等价于：</span>::<span class="hljs-function">ncnn::Layer* <span class="hljs-title">AbsVal_layer_creator</span><span class="hljs-params">()</span> </span>&#123; <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> AbsVal; &#125;</code></pre><p>​    上面那句话相当于就是new了一个AbsVal层，但是这里还是对应不起来，上面的是 AbsVal_final_layer_creator()，这里声明的是AbsVal_layer_creator()，这里就涉及到ncnn还有一层继承，使用cmake编译ncnn项目后，除了生成了layer_registry.h文件之外，还生成了一个layer_declaration.h文件，打开这个文件，一切就清楚了：</p><pre><code class="hljs cpp"><span class="hljs-comment">// Layer Declaration header</span><span class="hljs-comment">//</span><span class="hljs-comment">// This file is auto-generated by cmake, don&#x27;t edit it.</span> <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer/absval.h&quot;</span></span><span class="hljs-keyword">namespace</span> ncnn &#123;    <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AbsVal_final</span> :</span> <span class="hljs-keyword">virtual</span> <span class="hljs-keyword">public</span> AbsVal&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">create_pipeline</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Option&amp; opt)</span> </span>&#123;        &#123; <span class="hljs-keyword">int</span> ret = AbsVal::create_pipeline(opt); <span class="hljs-keyword">if</span> (ret) <span class="hljs-keyword">return</span> ret; &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    &#125;    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">destroy_pipeline</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Option&amp; opt)</span> </span>&#123;        &#123; <span class="hljs-keyword">int</span> ret = AbsVal::destroy_pipeline(opt); <span class="hljs-keyword">if</span> (ret) <span class="hljs-keyword">return</span> ret; &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    &#125;&#125;;DEFINE_LAYER_CREATOR(AbsVal_final)&#125; <span class="hljs-comment">// namespace ncnn</span> <span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;layer/batchnorm.h&quot;</span></span><span class="hljs-keyword">namespace</span> ncnn &#123;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BatchNorm_final</span> :</span> <span class="hljs-keyword">virtual</span> <span class="hljs-keyword">public</span> BatchNorm&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">create_pipeline</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Option&amp; opt)</span> </span>&#123;        &#123; <span class="hljs-keyword">int</span> ret = BatchNorm::create_pipeline(opt); <span class="hljs-keyword">if</span> (ret) <span class="hljs-keyword">return</span> ret; &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    &#125;    <span class="hljs-function"><span class="hljs-keyword">virtual</span> <span class="hljs-keyword">int</span> <span class="hljs-title">destroy_pipeline</span><span class="hljs-params">(<span class="hljs-keyword">const</span> Option&amp; opt)</span> </span>&#123;        &#123; <span class="hljs-keyword">int</span> ret = BatchNorm::destroy_pipeline(opt); <span class="hljs-keyword">if</span> (ret) <span class="hljs-keyword">return</span> ret; &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    &#125;&#125;;DEFINE_LAYER_CREATOR(BatchNorm_final)&#125; <span class="hljs-comment">// namespace ncnn</span></code></pre><p>​    AbsVal_final层继承了AbsVal层，如果当前操作系统不是linux系统，就会将create_pipeline()和destroy_pipeline()抽象出来，具体调用时，就调用对应优化了的代码。那么layer载入ParamDict具体实现就对应于各个layer的载入流程了。</p><h6 id="3-3-bin文件"><a href="#3-3-bin文件" class="headerlink" title="3.3 bin文件"></a>3.3 bin文件</h6><p>​    前面已经大致总结了ncnn的param文件载入，根据param文件创建网络结构，然后通过bin文件载入每一层对应的网络参数。这里就总结一下，如何载入每一层的参数：</p><p>​        我们常用的网络参数载入的接口为：</p><pre><code class="hljs reasonml"><span class="hljs-comment">// 从二进制文件中载入模型</span><span class="hljs-built_in">int</span> load<span class="hljs-constructor">_model(<span class="hljs-params">const</span> <span class="hljs-params">char</span><span class="hljs-operator">*</span> <span class="hljs-params">modelpath</span>)</span>;</code></pre><p>​    找到对应net.cpp文件实现部分有：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 从二进制文件中载入模型</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Net::load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* modelpath)</span></span><span class="hljs-function"></span>&#123;    FILE* fp = fopen(modelpath, <span class="hljs-string">&quot;rb&quot;</span>);    <span class="hljs-keyword">if</span> (!fp)    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;fopen %s failed\n&quot;</span>, modelpath);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;     <span class="hljs-keyword">int</span> ret = load_model(fp);     fclose(fp);     <span class="hljs-keyword">return</span> ret;&#125;</code></pre><p>和载入模型参数一样，ncnn模型载入这里调用了另外一个接口，从文件指针载入权重参数：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 从文件指针载入模型</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">Net::load_model</span><span class="hljs-params">(FILE* fp)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span> (layers.empty()) <span class="hljs-comment">// 判断当前layer是否为空</span>    &#123;        <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;network graph not ready\n&quot;</span>);        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;        <span class="hljs-keyword">int</span> ret = <span class="hljs-number">0</span>;     <span class="hljs-comment">// load file</span>    <span class="hljs-function">ModelBinFromStdio <span class="hljs-title">mb</span><span class="hljs-params">(fp)</span></span>;     <span class="hljs-comment">// 从二进制文件读取</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">size_t</span> i=<span class="hljs-number">0</span>; i&lt;layers.size(); i++)     <span class="hljs-comment">// 遍历所有的层</span>    &#123;        Layer* layer = layers[i]; <span class="hljs-comment">// 读取第i层</span>        <span class="hljs-comment">//Here we found inconsistent content in the parameter file.</span>        <span class="hljs-keyword">if</span> (!layer)&#123;    <span class="hljs-comment">// 如果第i层不存在</span>            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;load_model error at layer %d, parameter file has inconsistent content.\n&quot;</span>, (<span class="hljs-keyword">int</span>)i);            ret = <span class="hljs-number">-1</span>;            <span class="hljs-keyword">break</span>;        &#125;         <span class="hljs-comment">// 载入模型参数</span>        <span class="hljs-keyword">int</span> lret = layer-&gt;load_model(mb);        <span class="hljs-keyword">if</span> (lret != <span class="hljs-number">0</span>)        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;layer load_model %d failed\n&quot;</span>, (<span class="hljs-keyword">int</span>)i);            ret = <span class="hljs-number">-1</span>;            <span class="hljs-keyword">break</span>;        &#125;         <span class="hljs-keyword">int</span> cret = layer-&gt;create_pipeline(opt);  <span class="hljs-comment">// 从opt处创建网络的pipline</span>        <span class="hljs-keyword">if</span> (cret != <span class="hljs-number">0</span>) <span class="hljs-comment">// 如果创建第i层的pipline失败</span>        &#123;            <span class="hljs-built_in">fprintf</span>(<span class="hljs-built_in">stderr</span>, <span class="hljs-string">&quot;layer create_pipeline %d failed\n&quot;</span>, (<span class="hljs-keyword">int</span>)i);            ret = <span class="hljs-number">-1</span>;            <span class="hljs-keyword">break</span>;        &#125;    &#125;     <span class="hljs-comment">// 网络复用</span>    fuse_network();    <span class="hljs-keyword">return</span> ret;&#125;</code></pre><p>​    按照代码注释，应该还是比较好懂得，这里需要解析两个部分，第一个部分为<strong>ModelBinFromStdio</strong>，对应于二进制模型文件解析，另外一部分为 <strong>layer-&gt;load_model(mb)</strong>，对应于具体某个层的参数载入：</p><p>​    （1）二进制模型文件解析</p><p>​    这里对应于modelbin.h和modelbin.cpp文件，首先看一下modelbin.h文件：</p><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ModelBin</span></span><span class="hljs-class">&#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-keyword">virtual</span> ~ModelBin();    <span class="hljs-comment">// element type</span>    <span class="hljs-comment">// 0 = auto</span>    <span class="hljs-comment">// 1 = float32</span>    <span class="hljs-comment">// 2 = float16</span>    <span class="hljs-comment">// 3 = int8</span>    <span class="hljs-comment">// load vec</span>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span> </span>= <span class="hljs-number">0</span>;    <span class="hljs-comment">// load image</span>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> h, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span>;    <span class="hljs-comment">// load dim</span>    <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> h, <span class="hljs-keyword">int</span> c, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span>;&#125;; <span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> NCNN_STDIO</span><span class="hljs-comment">// 载入模型参数到一个Mat中</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ModelBinFromStdio</span> :</span> <span class="hljs-keyword">public</span> ModelBin&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-comment">// construct from file</span>    ModelBinFromStdio(FILE* binfp);     <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span>; <span class="hljs-keyword">protected</span>:    FILE* binfp;&#125;;<span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span> <span class="hljs-comment">// NCNN_STDIO</span></span> <span class="hljs-comment">// 载入模型参数到一个Mat中</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ModelBinFromMemory</span> :</span> <span class="hljs-keyword">public</span> ModelBin&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-comment">// construct from external memory</span>    ModelBinFromMemory(<span class="hljs-keyword">const</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>*&amp; mem);     <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span>; <span class="hljs-keyword">protected</span>:    <span class="hljs-keyword">const</span> <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">char</span>*&amp; mem;&#125;; <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ModelBinFromMatArray</span> :</span> <span class="hljs-keyword">public</span> ModelBin&#123;<span class="hljs-keyword">public</span>:    <span class="hljs-comment">// construct from weight blob array</span>    ModelBinFromMatArray(<span class="hljs-keyword">const</span> Mat* weights);     <span class="hljs-function"><span class="hljs-keyword">virtual</span> Mat <span class="hljs-title">load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span>; <span class="hljs-keyword">protected</span>:    <span class="hljs-keyword">mutable</span> <span class="hljs-keyword">const</span> Mat* weights;&#125;;</code></pre><p>   找到对应实现部分，就是modelbin.cpp，可以看到，ModelBinFromStdio mb(fp);就是将文件指针传给binfp对象</p><pre><code class="hljs cpp">ModelBinFromStdio::ModelBinFromStdio(FILE* _binfp) : binfp(_binfp)&#123;&#125;</code></pre><p>​    下面再看一下layer载入参数，layer具体操作对应于具体类型的层操作，例如batchnorm，可以看到：</p><pre><code class="hljs cpp"><span class="hljs-comment">// 载入模型</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">BatchNorm::load_model</span><span class="hljs-params">(<span class="hljs-keyword">const</span> ModelBin&amp; mb)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-comment">// slope数据</span>    slope_data = mb.load(channels, <span class="hljs-number">1</span>);    <span class="hljs-comment">// 载入失败：返还-100</span>    <span class="hljs-keyword">if</span> (slope_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;     <span class="hljs-comment">// mean数据</span>    mean_data = mb.load(channels, <span class="hljs-number">1</span>);    <span class="hljs-comment">// 载入数据失败，返还-100</span>    <span class="hljs-keyword">if</span> (mean_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;     <span class="hljs-comment">// variance数据</span>    var_data = mb.load(channels, <span class="hljs-number">1</span>);    <span class="hljs-comment">// 载入数据失败，返还-100</span>    <span class="hljs-keyword">if</span> (var_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;     <span class="hljs-comment">// bias数据</span>    bias_data = mb.load(channels, <span class="hljs-number">1</span>);    <span class="hljs-comment">// 载入数据失败，返还-100</span>    <span class="hljs-keyword">if</span> (bias_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;     <span class="hljs-comment">// 创建矩阵</span>    a_data.create(channels);    <span class="hljs-keyword">if</span> (a_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;    <span class="hljs-comment">// 创建矩阵</span>    b_data.create(channels);    <span class="hljs-keyword">if</span> (b_data.empty())        <span class="hljs-keyword">return</span> <span class="hljs-number">-100</span>;     <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;channels; i++)    &#123;        <span class="hljs-comment">// sqrt variance</span>        <span class="hljs-keyword">float</span> sqrt_var = <span class="hljs-built_in">sqrt</span>(var_data[i] + eps);        a_data[i] = bias_data[i] - slope_data[i] * mean_data[i] / sqrt_var;        b_data[i] = slope_data[i] / sqrt_var;    &#125;     <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>实际上调用的是ModelBinFromStdio 的load接口：</p><pre><code class="hljs cpp"><span class="hljs-function">Mat <span class="hljs-title">ModelBinFromStdio::load</span><span class="hljs-params">(<span class="hljs-keyword">int</span> w, <span class="hljs-keyword">int</span> type)</span> <span class="hljs-keyword">const</span></span></code></pre><p>后面type对应有四种类型：auto，float32，float16和int8</p><pre><code class="hljs cpp"><span class="hljs-comment">// 0 = auto</span><span class="hljs-comment">// 1 = float32</span><span class="hljs-comment">// 2 = float16</span><span class="hljs-comment">// 3 = int8</span></code></pre><p> 然后，根据这四种类型进行模型参数载入，感觉没什么好说的，主要是里面有个alignSize函数需要做个笔记：</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">size_t</span> <span class="hljs-title">alignSize</span><span class="hljs-params">(<span class="hljs-keyword">size_t</span> sz, <span class="hljs-keyword">int</span> n)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">return</span> (sz + n<span class="hljs-number">-1</span>) &amp; -n;&#125;</code></pre><p>alignSize就是申请sz大小的内存，实际申请内存是 y =(sz+n-1)&amp;-n 大小的内存，y &gt;= sz，且y是n的整数倍，然后对(sz+n-1)&amp; -n的解释是：</p><p>​    假设n为16，-n就是0xfffffff0，(sz+n-1)，加这个n-1一是为了保证sz刚好是16的倍数不会多算，二十为了防止不是16的倍数会少算，如，sz=3, 就是从二进制角度舍弃19小于16部分。</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ncnn源码分析_0</title>
    <link href="/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/"/>
    <url>/2020/09/17/ncnn%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-0/</url>
    
    <content type="html"><![CDATA[<p>ncnn 源码分析第一篇</p><a id="more"></a><p>ncnn 是一个架构比较简单的深度学习推导框架。 其项目目录如下所示:</p><pre><code class="hljs ncnn">.├── CMakeLists.txt├── CONTRIBUTING.md├── Info.plist├── LICENSE.txt├── README.md├── benchmark├── build.sh├── cmake├── docs    &#x2F;&#x2F; 文档├── examples    &#x2F;&#x2F; 实例├── images   &#x2F;&#x2F; 图片├── package.sh├── src      &#x2F;&#x2F; 主要的源代码│   ├── arm &#x2F;&#x2F; 针对于 arm 平台的优化│   ├── mips &#x2F;&#x2F; 针对于 mips 平台的优化│   ├── vulkan &#x2F;&#x2F; GPU 优化代码│   ├── x86 &#x2F;&#x2F; 针对于 x86 平台的优化├── ... &#x2F;&#x2F; 通用平台代码└── xxx.h├── tests  &#x2F;&#x2F; 测试├── toolchains└── tools   &#x2F;&#x2F; 工具: (1) 其他模型 -&gt; ncnn  (2) 模型优化和量化</code></pre><p>本系列旨在于去深入了解 ncnn 的内部机理， 主要分为如下几个部分：</p><p>ncnn 源码分析_1  参数与模型载入</p><p>ncnn 源码分析_2 Extractor</p><p>ncnn 源码分析_3 模型量化原理</p><p>ncnn 源码分析_4 模型量化源码</p><p>ncnn 源码分析_5 添加 layer</p><p>ncnn 源码分析_6 层分析</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>mxnet2ncnn</title>
    <link href="/2020/09/17/mxnet2ncnn/"/>
    <url>/2020/09/17/mxnet2ncnn/</url>
    
    <content type="html"><![CDATA[<p>mxnet2ncnn 部署方案</p><a id="more"></a><h4 id="1-下载并编译-ncnn-框架"><a href="#1-下载并编译-ncnn-框架" class="headerlink" title="1. 下载并编译 ncnn 框架"></a>1. 下载并编译 ncnn 框架</h4><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> install xcode and protobuf</span><span class="hljs-meta">#</span><span class="bash"> install protobuf</span><span class="hljs-meta">$</span><span class="bash"> brew install protobuf</span><span class="hljs-meta">#</span><span class="bash"> build &amp; install ncnn</span><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> &lt;ncnn-root-dir&gt;</span><span class="hljs-meta">$</span><span class="bash"> mkdir -p build</span><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> build</span><span class="hljs-meta">$</span><span class="bash"> cmake -DNCNN_VULKAN=OFF ..</span><span class="hljs-meta">$</span><span class="bash"> make -j4</span><span class="hljs-meta">$</span><span class="bash"> make install</span></code></pre><h4 id="2-model-slim"><a href="#2-model-slim" class="headerlink" title="2. model slim"></a>2. model slim</h4><p>从如下地址下载 mobileface 的文件：</p><p><a href="https://pan.baidu.com/s/1If28BkHde4fiuweJrbicVA"><strong>https://pan.baidu.com/s/1If28BkHde4fiuweJrbicVA</strong></a></p><p>解压可以得到三个文件：  log、model-0000.params 和 model-symbol.json</p><p>执行：</p><pre><code class="hljs shell">python model_slim.py  --model  ../models/model-y1-test2/model,0</code></pre><p>此时 会生成两个文件：../models/model-y1-test2/models-</p><h4 id="3-使用-mxnet2ncnn-工具来转化模型"><a href="#3-使用-mxnet2ncnn-工具来转化模型" class="headerlink" title="3. 使用 mxnet2ncnn 工具来转化模型"></a>3. 使用 mxnet2ncnn 工具来转化模型</h4><pre><code class="hljs shell">cd ncnn/build/tools/mxnet./mxnet2ncnn models-symbol.json models-0000.params mobilefacenet.param mobilefacenet.bin</code></pre><p>生成两个新的文件 mobilefacenet.param ，mobilefacenet.bin，这就是我们部署 ncnn 需要用到的文件。</p><h4 id="4-项目构建"><a href="#4-项目构建" class="headerlink" title="4.  项目构建"></a>4.  项目构建</h4><pre><code class="hljs crystal">arcface 我们的主项目文件image  存储测试图像文件models  存储我们的转换完成的 人脸检测、人脸识别模型ncnn  存放 ncnn 的 <span class="hljs-class"><span class="hljs-keyword">lib</span> 和 <span class="hljs-title">include</span> 文件</span>Makefile 文件</code></pre><p>其中 arcface 存放相关文件和 Makefile 文件。进入主项目文件 make 然后执行 ./main 即可。</p><p>需要重点研究的文件：（1） model_slim.py   （2）arcface 下的 四个 文件 arcface/mtcnn/base/Makefile 文件。</p><p>​    ncnn只是一个前向推断的库，利用它可以快速完成前向传播。在项目中，我们将图片传给MTCNN， 分别经过三个网络Pnet、RNet、ONet，然后产生待检测的人脸， 然后再将待检测的人脸送给facent， 最后比对产生的128D向量的距离。这样就可以完成人脸的识别。具体结合代码来说：</p><p>下面这个函数是MTCNN的主要的接口文件：</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; <span class="hljs-title">MtcnnDetector::Detect</span><span class="hljs-params">(ncnn::Mat img)</span></span>&#123;    <span class="hljs-keyword">int</span> img_w = img.w;  <span class="hljs-comment">// 获取 宽度</span>    <span class="hljs-keyword">int</span> img_h = img.h; <span class="hljs-comment">// 获取高度</span>    <span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; pnet_results = Pnet_Detect(img);  <span class="hljs-comment">// 让图片经过PNet</span>    doNms(pnet_results, <span class="hljs-number">0.7</span>, <span class="hljs-string">&quot;union&quot;</span>);  <span class="hljs-comment">// 对输出的结果进行nms</span>    refine(pnet_results, img_h, img_w, <span class="hljs-literal">true</span>);  <span class="hljs-comment">// refine，把结果放在 pnet_results 中</span>    <span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; rnet_results = Rnet_Detect(img, pnet_results);  <span class="hljs-comment">// 让图片经过 RNet</span>    doNms(rnet_results, <span class="hljs-number">0.7</span>, <span class="hljs-string">&quot;union&quot;</span>); <span class="hljs-comment">// 对输出结果进行 nms</span>    refine(rnet_results, img_h, img_w, <span class="hljs-literal">true</span>); <span class="hljs-comment">// refine， 把结果放在 Rnet_results中</span>    <span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; onet_results = Onet_Detect(img, rnet_results);  <span class="hljs-comment">// 把图片 经过 Onet</span>    refine(onet_results, img_h, img_w, <span class="hljs-literal">false</span>);  <span class="hljs-comment">// refine</span>    doNms(onet_results, <span class="hljs-number">0.7</span>, <span class="hljs-string">&quot;min&quot;</span>);  <span class="hljs-comment">//  对最后的结果进行refine</span>    Lnet_Detect(img, onet_results);  <span class="hljs-comment">// 后处理</span>    <span class="hljs-keyword">return</span> onet_results;  <span class="hljs-comment">// 返回检测结果</span>&#125;</code></pre><p>这个文件是 facenet 的前向推断框架：</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; <span class="hljs-title">Arcface::getFeature</span><span class="hljs-params">(ncnn::Mat img)</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; feature;    ncnn::Mat in = resize(img, <span class="hljs-number">112</span>, <span class="hljs-number">112</span>); <span class="hljs-comment">// 将人脸调整到 112x112</span>    in = bgr2rgb(in); <span class="hljs-comment">// 通道变幻</span>    ncnn::Extractor ex = net.create_extractor();  <span class="hljs-comment">// 设置提取器</span>    ex.set_light_mode(<span class="hljs-literal">true</span>);      ex.input(<span class="hljs-string">&quot;data&quot;</span>, in);  <span class="hljs-comment">// 让图片进入网络</span>    ncnn::Mat out;    ex.extract(<span class="hljs-string">&quot;fc1&quot;</span>, out);  <span class="hljs-comment">// 提取出 fc1 层的结果</span>    feature.resize(<span class="hljs-keyword">this</span>-&gt;feature_dim);  <span class="hljs-comment">// 结果resize</span>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-keyword">this</span>-&gt;feature_dim; i++)         feature[i] = out[i];      normalize(feature); <span class="hljs-comment">// 正则化特征</span>    <span class="hljs-keyword">return</span> feature; <span class="hljs-comment">// 返回特征</span>&#125;</code></pre><p>下面这个文件是 main.cpp， 现在看来非常简单了</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>* argv[])</span></span><span class="hljs-function"></span>&#123;    Mat img1;    Mat img2;    img1 = imread(<span class="hljs-string">&quot;../image/gyy1.jpeg&quot;</span>);  <span class="hljs-comment">// 读取图片</span>    img2 = imread(<span class="hljs-string">&quot;../image/gyy2.jpeg&quot;</span>);    ncnn::Mat ncnn_img1 = ncnn::Mat::from_pixels(img1.data, ncnn::Mat::PIXEL_BGR, img1.cols, img1.rows);  <span class="hljs-comment">// 转换为 ncnn 格式</span>    ncnn::Mat ncnn_img2 = ncnn::Mat::from_pixels(img2.data, ncnn::Mat::PIXEL_BGR, img2.cols, img2.rows);    <span class="hljs-comment">// 检测</span>    <span class="hljs-function">MtcnnDetector <span class="hljs-title">detector</span><span class="hljs-params">(<span class="hljs-string">&quot;../../models&quot;</span>)</span></span>;     <span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; results1 = detector.Detect(ncnn_img1);    <span class="hljs-built_in">vector</span>&lt;FaceInfo&gt; results2 = detector.Detect(ncnn_img2);    <span class="hljs-comment">// 处理检测结果，其实就是提取图片</span>    ncnn::Mat det1 = preprocess(ncnn_img1, results1[<span class="hljs-number">0</span>]);    ncnn::Mat det2 = preprocess(ncnn_img2, results2[<span class="hljs-number">0</span>]);     <span class="hljs-function">Arcface <span class="hljs-title">arc</span><span class="hljs-params">(<span class="hljs-string">&quot;../../models&quot;</span>)</span></span>;    <span class="hljs-comment">// 提取特征</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; feature1 = arc.getFeature(det1);    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">float</span>&gt; feature2 = arc.getFeature(det2);    <span class="hljs-comment">// 特征比较</span>    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">cout</span> &lt;&lt; <span class="hljs-string">&quot;Similarity: &quot;</span> &lt;&lt; calcSimilar(feature1, feature2) &lt;&lt; <span class="hljs-built_in">std</span>::<span class="hljs-built_in">endl</span>;;    imshow(<span class="hljs-string">&quot;det1&quot;</span>, ncnn2cv(det1));    imshow(<span class="hljs-string">&quot;det2&quot;</span>, ncnn2cv(det2));    waitKey(<span class="hljs-number">0</span>);    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>移动端部署要点</p><p>主要的解决方案：将MTCNN 和 facenet 的接口组织成为一个人脸 face_reg 的接口，然后使用 objective-c 调用该C++ 代码，然后在使用swift 调用 objective-c 的代码。之所以这样做是因为，swift 不能调用 C++ 呀。</p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3D点云综述</title>
    <link href="/2020/09/17/3D%E7%82%B9%E4%BA%91%E7%BB%BC%E8%BF%B0/"/>
    <url>/2020/09/17/3D%E7%82%B9%E4%BA%91%E7%BB%BC%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>探索</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>图像处理基础知识</title>
    <link href="/2020/09/17/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2020/09/17/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h3 id="1-基本"><a href="#1-基本" class="headerlink" title="1. 基本"></a>1. 基本</h3><p>🌟 <strong>简述 opencv 中有哪些模块?</strong></p><ul><li><p>core: <strong>核心功能模块(1)</strong>，包括 opnecv 基础数据结构，动态数据结构，绘图函数，数组操作函数等</p></li><li><p>imgproc：<strong>图像处理模块(2)</strong>，包括线性非线性图像滤波， 图像几何变换，直方图相关，特征检测，目标检测。</p></li><li><p>highgui： 高层 GUI 用户界面， 包含媒体输入和输出，图像和视频编码， 图形交互界面的接口等</p></li><li><p>calib3d：<strong>主要是相机校准和三维重建(3)</strong>相关的内容， 包括**基本多视角几何算法， 单个立体摄像头标定，物体姿态估计， 立体相似性算法， 3D信息重建等。</p></li><li><p>features2d:  <strong>2D功能框架，包含特征检测和描述(4)</strong>，特征检测通用接口，描述符提取器通用接口，关键点绘制函数和匹配功能绘制函数等</p></li><li><p>flann: 高维近似近邻快速搜索算法库 ml 机器学习模块       objectect： 目标检测模块，包含级联分类和latent SVM两个部分</p></li><li><p>photo: 包含<strong>图像修复和图像去噪两部分(5)</strong>    <strong>stiching</strong>： 图像拼接模块</p></li><li><p>contrib: 主要包含最近添加的不稳定功能。   <strong>lagacy</strong>: 一些废弃的代码库      nonfree：一些具有专利的算法</p></li><li><p>gpu<strong>： 运用 GPU 加速模块     </strong>ocl: 运用 OpenCL 加速的模块</p></li><li><p>ml: <strong>机器学习算法包(6)</strong></p></li></ul><h3 id="2-图像的读取和显示与-Mat-的理解"><a href="#2-图像的读取和显示与-Mat-的理解" class="headerlink" title="2. 图像的读取和显示与 Mat 的理解"></a>2. 图像的读取和显示与 Mat 的理解</h3><p>🌟 opencv里面为啥是 bgr 存储图片而不是人们常听的 rgb ?</p><p>​    OpenCV<strong>在 1999 年由 Intel 建立，当时主流的摄像头制造商和软件供应商提供的摄像头采集的图像的通道排列顺序为BGR</strong>，另外<strong>对于图片，位图BMP是最简单的，也是Windows显示图片的基本格式，其文件扩展名为*.BMP</strong>。在Windows下，任何格式的图片文件（包括视频播放）都要转化为位图才能显示出来，各种格式的图片文件也都是在位图格式的基础上采用不同的压缩算法生成的，值得注意的是<strong>位图 BMP 的格式就是BGR</strong>。</p><p>🌟 <strong>opencv 如何读取内存图片 ? 如何将 buffer 类型转化为 mat 类型 ？</strong></p><p>可以使用 imdecode 函数, 可以将字节流数据 buf 解码成数组形式的图像</p><pre><code class="hljs cpp"><span class="hljs-built_in">std</span>::<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt; img_data;<span class="hljs-function"><span class="hljs-built_in">std</span>::ifstream <span class="hljs-title">file_contents</span><span class="hljs-params">(<span class="hljs-string">&quot;example.png&quot;</span>)</span></span>;file_contents &gt;&gt; <span class="hljs-built_in">std</span>::noskipws;<span class="hljs-built_in">std</span>::copy(<span class="hljs-built_in">std</span>::istream_iterator&lt;<span class="hljs-keyword">char</span>&gt;(file_contents), <span class="hljs-built_in">std</span>::istream_iterator&lt;<span class="hljs-keyword">char</span>&gt;(), <span class="hljs-built_in">std</span>::back_inserter(img_data));Mat matrixJprg = imdecode(Mat(img_data), IMREAD_COLOR);imwrite(<span class="hljs-string">&quot;result.jpg&quot;</span>, matrixJprg);</code></pre><p>🌟 <strong>opencv 如何读取 png 格式的图片？</strong>  </p><p>使用 imread() 直接读取即可 (png为无损压缩， jpg为有损压缩)</p><p>​      <strong><code>cv::Mat srcImg = cv:imread(const string&amp;filename, int flags)</code></strong></p><p>其中 flags 可以取以下值:</p><p>​    <code>cv::IMREAD_COLOR</code> 三通道图像   <code>cv::IMREAD_GRAYSCALE</code>  单通道图像</p><p>​    <code>cv::IMREAD_ANYCOLOR</code> 通道数为文件实际通道数(不超过3)</p><p>​    <strong><code>cv::IMREAD_ANYDEPTH</code> 允许加载超过 8bit 深度</strong>  </p><p>​    <code>cv::IMREAD_UNCHANGED</code>  通道数为文件实际通道数，且允许超过 8 bit 深度</p><p>🌟 <strong>解释下 raw 图像和 rgb 图像的区别 ？</strong></p><p>​    <strong>Raw 图像就是 CMOS 或者 CCD 图像感应器将捕捉到的光源信号转化为数字信号的原始数据。RAW 文件是一种记录了数码相机传感器的原始信息，同时记录了由相机拍摄所产生的一些原数据(Metadata，如ISO的设置、快门速度、光圈值、白平衡等)的文件。RAW是未经处理、也未经压缩的格式，可以把 RAW 概念化为“原始图像编码数据”或更形象的称为“数字底片”</strong>。</p><p>​    优势: RAW文件几乎是未经过处理而直接从 CCD 或 CMOS 上得到的信息，通过后期处理，摄影师能够最大限度地发挥自己的艺术才华。  RAW 文件并没有白平衡设置，但是真实的数据也没有被改变，就是说作者可以任意的调整色温和白平衡，并且是不会有图像质量损失的。</p><p>​    RGB 结构的意思就是，图片是由 1 个个像素点的数据序列组成，每个像素的数据由RGB各个色值组成。JPG 虽然有压缩算法，但是压缩前的数据依然是基于 RGB 结构进行的。　　</p><p>🌟 <strong>opencv里面 Mat 有哪些构造函数？</strong></p><p><strong>主要分为三种:</strong></p><p>(1) <strong>默认构造函数</strong>   <code>cv::Mat</code></p><p>(2) <strong>指定类型、大小、维度以及初值的 构造函数</strong>  <code>cv::Mat(int rows, int cols, int type)   cv::Mat(int ndims, const int* sizes, int type)</code></p><p>(3) <strong>复制构造函数</strong>  <code>cv::Mat(const Mat&amp;mat)</code></p><p>🌟 <strong>opencv 遍历像素的方式 ？</strong></p><p><strong>1.</strong> <strong>数组遍历   <code>img.at&lt;typename&gt;(i,j)    img.data[index]</code></strong></p><pre><code class="hljs cpp">(<span class="hljs-number">1</span>) uchar b1 = image.at&lt;Vec3b&gt;(i,j)[<span class="hljs-number">0</span>](<span class="hljs-number">2</span>) <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; height; i++)&#123;        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; width; j++)&#123;            <span class="hljs-keyword">int</span> index = i * width + j;    <span class="hljs-keyword">int</span> b1 = (<span class="hljs-keyword">int</span>)backImg.data[<span class="hljs-number">3</span> * index + <span class="hljs-number">0</span>];</code></pre><p><strong>2.</strong> <strong>迭代器遍历</strong></p><pre><code class="hljs cpp"><span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> it = img.begin&lt;Vec3b&gt;(); it != img.end&lt;Vec3b&gt;(); it++)    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> k=<span class="hljs-number">0</span>; k&lt;<span class="hljs-number">3</span>; k++)&#123;        (*it)[k] = ...    &#125;</code></pre><p><strong>3.</strong> <strong>指针遍历</strong></p><pre><code class="hljs cpp"><span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i &lt; rows; i++)&#123;    uchar *p = img.ptr&lt;uchar&gt;(i);</code></pre><p><strong>4.</strong>核心函数LUT</p><p>LUT是最被推荐的用于实现批量图像元素查找和更改操作图像方法。在图像处理中，对于一个给定的值，将其替换成其他的值是一个很常见的操作，OpenCV 提供里一个函数直接实现该操作，并不需要自己扫描图像，就是: operationsOnArrays:LUT() <lut>，一个包含于core module的函数。首先我们建立一个mat型用于查表</lut></p><pre><code class="hljs cpp">operationsOnArrays:LUT() &lt;lut&gt;，一个包含于core <span class="hljs-keyword">module</span>的函数。首先我们建立一个mat型用于查表    <span class="hljs-function">Mat <span class="hljs-title">lookUpTable</span><span class="hljs-params">(<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, CV_8U)</span></span>;    uchar* p = lookUpTable.data;     <span class="hljs-keyword">for</span>( <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">256</span>; ++i)        p[i] = table[i];</code></pre><p>然后我们调用函数 (I 是输入 J 是输出):</p><pre><code class="hljs cpp">LUT(I, lookUpTable, J);</code></pre><p>在以上四种图像遍历方法中，从效率来看使用 OpenCV <strong>内置函数 LUT</strong> 可以获得最快的速度，这是因为OpenCV库可以通过英特尔线程架构启用多线程。<strong>其次，指针遍历最快，迭代器遍历次之，at方法遍历最慢</strong>。一般情况下，我们只有在对任意位置的像素进行读写时才考虑at方法。</p><p>🌟  <strong>说说 opencv 中 Mat 的深拷贝和浅拷贝?</strong></p><p>答: 使用 Mat 的拷贝构造函数或者赋值运算符， 比如:</p><p>   Mat A, C;</p><p>   A = imread(“1.jpg”)</p><p>   Mat B(A);</p><p>   C = A;</p><p>A, B, C 全部指向同一个图像矩阵， 改变其中一个， 另外两个也都会跟着改变</p><p><strong>使用 clone() 或者 copyTo() 则会另外开辟图像存储空间，相互之间没有影响</strong>， 例如:</p><p>   Mat F = A.clone();</p><p>   Mat G;</p><p>   A.copyTo(G);</p><p> 现在改变 F 则不会对G 有影响</p><p>🌟 <strong>opencv 中 CV_8UC3 代表什么意思? opencv 中的 Scalar 类?</strong></p><p>- 8 代表使用8位的 unsigned char 型， 每个像素由三个元素组成三通道， 格式为: CV_[位数][带符号与否][类型前缀]C[通道数]</p><p>- <strong>Scalar() 表示具有4个元素的数组</strong>， 在 opencv 中被大量被用于传递像素值， 比如 GRB 颜色值。 如果用不到第三个参数， 则不需要写出来， 若只写三个参数， 则opencv 会认为只需要传递三个参数。</p><p><strong>3. 颜色空间</strong></p><p>🌟 <strong>简述常见的颜色系统?</strong></p><ul><li>RGB 是最常见的颜色系统，基于颜色的<strong>加法混色原理，从黑色不断叠加Red，Green，Blue的颜色，最终可以得到白色光</strong>。</li><li>HSV 和 HLS 把颜色分解成<strong>色调、饱和度和亮度/明度</strong>，描述颜色更加自然，可以通过抛弃最后一个元素使算法对输入图像的光照条件不敏感</li><li>YCrCb 颜色系统在 JPEG 图像格式中广泛使用。</li><li>LAB: <strong>L为亮度，AB 为两种不同的色度, 前者是明度通道，后者是色彩通道，可以分离色度和亮度</strong>。</li></ul><p>🌟 <strong>图像超分辨率重建中，为什么只使用 YCrCb 中的 Y 通道?</strong>  <strong>参考论文: SRCNN</strong></p><p>​    <strong>图像被转化为 YCbCr 色彩空间，尽管该网络只使用亮度通道(Y)。然后，网络的输出合并已插值的 CbCr 通道，输出最终彩色图像。我们选择这一步骤是因为我们感兴趣的不是颜色变化(存储在 CbCr 通道中的信息)而只是其亮度(Y 通道);根本原因在于相较于色差，人类视觉对亮度变化更为敏感。</strong></p><p>🌟 用 OpenCV 可以方便的将彩色图片转为灰度图，如 cvtColor(imgColor, imgGray, CV_BGR2GRAY)。请问这里彩色到灰度的转换公式是： <strong>gray=0.299R+0.587G+0.114*B.</strong></p><p><strong>4. 滤波器和卷积</strong></p><p>🌟 <strong>常用边缘检测有哪些算子，各有什么特性？</strong></p><p><strong>常见的边缘检测算子有: Sobel 算子、拉普拉斯算子、canny 算子。</strong></p><p><strong>sobel 算子：</strong></p><p><img src="data:image/jpeg;base64,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" alt="垂直方向                   水平方向"></p><p>​    Sobel 算子是一个主要<strong>用于边缘检测</strong>的离散微分算子，结合了高斯平滑和微分求导，用来计算图像灰度函数的近似梯度。在图像的任何一点使用此算子，都会产生对饮的梯度适量或者其法矢量。注意一下，当内核大小为3时，sobel 会产生比较明显的误差，为了解决这个问题，opencv 提供了 scharr 函数， 但是该函数只能作用于大小为3 的内核。该函数运算和sobel 函数一样快，但是结果更加准确。</p><p><strong>拉普拉斯算子:</strong></p><p><img src="data:image/jpeg;base64,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" alt="img"></p><p><strong>Canny 算子:</strong></p><p>​    Canny <strong>边缘检测算子</strong>是 John F.Canny 于 1986 年开发出来的一个多级边缘检测算法。更为重要的是 Canny 创立了边缘检测计算理论（Computational theory ofedge detection），解释了这项技术是如何工作的。Canny 边缘检测算法以 Canny 的名字命名，被很多人推崇为当今最优的边缘检测的算法。</p><p>Canny 边缘检测的步骤：</p><p><strong>1.消除噪声</strong>。 一般情况下，使用<strong>高斯平滑滤波器卷积降噪</strong>。 如下显示了一个 size = 5 的高斯内核示例:</p><p><img src="data:image/jpeg;base64,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" alt="img"></p><p><strong>2.计算梯度幅值和方向。</strong> 此处，按照Sobel滤波器的步骤。</p><p>　　Ⅰ.运用一对卷积阵列 (分别作用于 x 和 y 方向):</p><p>​      </p><p><img src="data:image/jpeg;base64,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" alt="img"></p><p>　　Ⅱ. 使用下列公式计算梯度幅值和方向:</p><p><img src="data:image/jpeg;base64,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" alt="img"></p><p>​      梯度方向近似到四个可能角度之一(一般为0, 45, 90, 135)</p><p> <strong>3.非极大值抑制</strong>。 这一步排除非边缘像素， 仅仅保留了一些细线条(候选边缘)。</p><p> <strong>4.滞后阈值</strong>。最后一步，Canny 使用了滞后阈值，滞后阈值需要两个阈值(高阈值和低阈值):</p><p>　　Ⅰ. 如果某一像素位置的幅值超过 高 阈值, 该像素被保留为边缘像素。</p><p>　　Ⅱ. 如果某一像素位置的幅值小于 低 阈值, 该像素被排除。</p><p>　　Ⅲ. 如果某一像素位置的幅值在两个阈值之间,该像素仅仅在连接到一个高于 高 阈值的像素时被保留。</p><p> tips：对于Canny函数的使用，推荐的高低阈值比在 2:1到3:1之间。</p><p>🌟 <strong>常用去噪滤波器 ？</strong></p><p><strong>均值滤波</strong>: 把每个像素都用周围的8个像素来做均值操作。可以平滑图像速度快，算法简单。<strong>不能很好地保护图像细节，在**</strong>图像去噪的同时也破坏了图像的细节部分，从而使得图像变模糊，不能很好的去除噪声<strong>**。</strong></p><p><strong>中值滤波</strong>: 中值滤波是一种典型的非线性滤波技术， <strong>基本思想是用像素点的邻域灰度值的中值来提到像素点的灰度值，该方法在**</strong>去除脉冲噪声、椒盐噪声的同时又能保留图像的边缘细节**。但对方向性很强的指纹图像进行滤波处理时，有必要引入方向信息，即利用指纹方向图来指导中值滤波的进行。</p><p><strong>高斯滤波：</strong>高斯滤波是对整幅图像进行加权平均的过程， 每一个像素点的值都由其本身和邻域内的其他像素值经过加权平均后得到。 高斯滤波的具体操作是用一个模板(或称为卷积) 扫描图像中的每一个像素， 用模板确定的领域内像素的加权灰度值去代替模板的中心像素点的值。</p><p><strong>双边滤波和使用双边滤波的场景**</strong>?<strong> 双边滤波是一种非线性滤波方法， 同时考虑了空域信息和灰度相似性，</strong>达到保边去噪的目的， 具有简单，非迭代，局部的特点<strong>。 </strong>用在于需要保留边缘信息的图像去噪**。缺点是由于双边滤波保证了边缘信息，所以其保存了过多的高频信息，对于彩色图像的高频噪声，双边滤波不能够干净的滤去，只能对于低频信息进行较好的滤波。</p><p>🌟 <strong>简述一下图像处理中的膨胀和腐蚀操作?</strong></p><p>​    腐蚀和膨胀都是对图像的白色(高亮)部分而言。膨胀是图像中的高亮部分进行膨胀，类似于领域扩张，效果图拥有比原图更大的高亮区域；腐蚀是原图的高亮部分被腐蚀，类似于领域被蚕食，效果图拥有比原图更小的高亮区域。</p><p>​    从数学的角度来说，膨胀就是求局部最大值， 并把这个值赋值给参考点指定像素， 这样会使图中Dev高亮区域逐渐增长，腐蚀与之相反。</p><p>🌟  <strong>简述开运算/闭运算的操作流程和使用场景?</strong></p><p>​    开运算就是先腐蚀后膨胀的过程。可以用来消除小物体， 在纤细点处分离物体，并且在平滑较大物体的边界的同时不明显改变其面积。</p><p>​    闭运算就是先膨胀后腐蚀的过程， 可以用来排除小型黑色区域。</p><p>🌟  <strong>简述顶帽(礼帽)和黑帽运算的定义和使用场景?</strong></p><p>​    <strong>顶帽(礼帽)</strong>是原图像与开运算的结果图之差。因为开运算带来的结果是放大了裂缝或者局部低亮度的区域，因此，从原图中减去开运算后的图，得到的效果图突出了比原图轮廓周围的区域更明亮的区域，且这一操作和选择的核的大小相关。顶帽运算往往用来分离比邻近点亮一些的斑块。当一幅图像具有大幅的背景的时候，而微小物品比较有规律的情况下，可以使用顶帽运算进行背景提取。</p><p>​    <strong>黑帽（Black Hat）</strong>运算为”闭运算“的结果图与原图像之差。黑帽运算后的效果图突出了比原图轮廓周围的区域更暗的区域，且这一操作和选择的核的大小相关。 黑帽运算用来分离比邻近点暗一些的斑块， 效果图有比较好的轮廓。</p><p>🌟  <strong>简述形态学梯度的定义和使用场景?</strong></p><p>​    形态学梯度是膨胀图和腐蚀图之差， 对二值图进行这一操作可以将团块(Blob)的边缘突出出来， 可以用形态学梯度来保留物体的边缘轮廓。</p><p><strong>5. 角点 &amp; 关键点 &amp; 边缘检测</strong></p><p>🌟 <strong>简述 harris 角点检测算法原理和使用场景</strong></p><p>​    harris 角点检测是一种基于灰度图像的角点提取算法，稳定性高，尤其对 L 型角点检测精度高， 但是由于采用高斯滤波，所以运算速度相对较慢，较低信息有丢失和位置偏移的现象，且角点提取有聚簇现象。</p><p>🌟 <strong>说说几种传统算法中常用的特征检测算法?</strong></p><ul><li>FAST: FAST Feature Detector</li><li>STAR: Star Feature Detector</li><li><strong>SIFT</strong>: Scale Invariant Feature Transform</li><li><strong>SURF</strong>: Speeded Up Robust Feature 加速版的具有鲁棒性的特征检测算法</li><li><strong>ORB</strong>： 是 Oriented Brief 的简称， 是 BRIEF 算法的改进版， 综合性能相对比较好的算法。</li></ul><p>🌟 简要阐述一下 SIFT 和 SURF 算法的异同点?</p><div class="table-container"><table><thead><tr><th>比较内容</th><th>SIFT</th><th>SURF</th></tr></thead><tbody><tr><td>尺度空间</td><td>DOG 与不同尺度的图片卷积</td><td>不同尺度的box filters 与原图片卷积</td></tr><tr><td>特征点检测</td><td>先进行非极大值抑制， 再去去除低对比度点。 再通过 Hessian 矩阵去除边缘的点</td><td>先利用Hessian 矩阵确定候选点， 然后进行非极大值抑制</td></tr><tr><td>方向</td><td>在正方形区域内统计梯度的幅值的直方图， 找max 对应的方向。 可以有多个方向</td><td>在圆形区域内， 计算各个扇形范围内的 x, y 方向上的 harr 小波响应， 找模最大的扇形方向</td></tr><tr><td>特征描述子</td><td>16 <em> 16 的采样点划分为 4</em>4 的区域， 计算每个区域的采样点的梯度方向和幅值， 统计成8bin 直方图， 一共 4<em>4</em>8=128维</td><td>20<em>20 的区域划分为 4</em>4 的子区域， 每个区域找 5*5 个采样点， 计算采样点的harr 小波响应， 记录 ∑dx ∑dy ∑\</td><td>dx\</td><td>∑\</td><td>dy\</td><td>, 一共 4<em>4</em>4 = 64 维。</td></tr></tbody></table></div><p>🌟 比较一下 SIFT， HOG 和 LBP 这三个特征提取算法?</p><div class="table-container"><table><thead><tr><th>特征</th><th>优点</th><th>缺点</th><th>适用范围</th></tr></thead><tbody><tr><td>SIFT</td><td>(1) 对于<strong>旋转</strong>、<strong>尺度缩放</strong>、<strong>亮度变化</strong>保持不变(2) 抗遮挡</td><td>计算量大</td><td>图像匹配、三维建模</td></tr><tr><td>HOG</td><td>忽略了光照颜色对图像造成的影响， 使得图像所需要的特征数据的维度降低了</td><td>（1） 描述子生成过程冗长，导致速度慢，实时性差（2） 很难处理遮挡问题（3） 由于梯度的性质， 该描述子对噪点相当敏感</td><td>行人检测</td></tr><tr><td>LBP</td><td>（1） 对光照不敏感（2） 运算速度快</td><td>对方向信息敏感</td><td>人脸识别、图像分类</td></tr></tbody></table></div><p>🌟 LBP 原理？</p><p>🌟 HOG 特征计算过程，介绍一个应用HOG特征的应用？ 讲讲HOG特征？他在dpm里面怎么设计的，你改过吗？HOG能检测边缘吗？里面的核函数是啥？那hog检测边缘和canny有啥区别？</p><p>🌟  SIFT特征提取算法，原理？</p><p>🌟 你说opencv里面的HOG+SVM效果很差？他就直接来了句为啥很差？差了就不改了？差了就要换其他方法？、</p><p>🌟 <strong>简述传统算法中边缘检测的一般步骤</strong></p><p>(1) 滤波: 滤波去除噪声</p><p>(2) 增强: 增强边缘特征</p><p>(3) 检测: 将边缘通过某种方式提取出来， 完成边缘检测</p><p><strong>6. 基本算法</strong></p><p>🌟 <strong>简述一下什么是光流?</strong></p><p>​    光流法是目前图像运动分析的重要方法。 光流用来指定时变图像中模式的运动速度，因为物体在运动时，在图像上对应点的亮度模式也在运动，这种图像亮度模式的表现运动就是光流。 光流表达了图像的变化，包含了目标运动的信息，所以可以被观察者用来确定目标的运动情况。</p><p>🌟 <strong>简单叙述一下漫水填充法？</strong></p><p>​    漫水填充是用一种特定颜色填充连通区域， 通过设置可以连通像素的上下限以及连通方式来达到不同的填充效果的方法。漫水填充经常被用来标记或者分离图像的一部分，以便对其进行进一步处理或分析。简单来说， 就是自动选中和种子点相连的区域，接着讲该区域替换成指定的颜色。</p><p>🌟  <strong>简述霍夫变换的原理？</strong></p><p>🌟 <strong>霍夫圆变换</strong></p><p>​    霍夫圆变换的基本原理和霍夫线变化大体上很相似，<strong>只是对应的二维极径极角空间被三维的圆心点x,y,半径r空间取代</strong>，这就意味着这是一个三维空间，所以需要大量的内存，执行效率低速度慢。</p><p>🌟 <strong>简述一下分水岭算法？</strong></p><p>​    分水岭算法是一种图像区域分割法， 在分割过程中，它会把临近像素间的相似性作为重要的参考依据，从而在空间位置上相近并且灰度值相近(求梯度)的像素点互相连接起来构成一个封闭的轮廓。分水岭算法常用的操作步骤: 彩色图像灰度化， 然后再求梯度，最后在梯度图的基础上进行分水岭算法，求得图像的边缘线。</p><p>🌟 <strong>简述一些图像金字塔的种类和区别？</strong></p><p>一般情况下有两种图像金字塔， 分别是:</p><p><strong>高斯金字塔:</strong> 用来向下采样</p><p><strong>拉普拉斯金字塔:</strong> 用来从金字塔底层图像重建上层未采样图片， 可以对图像进行最大程度的还原，配合高斯金字塔一起使用</p><p>两者的区别在于: 高斯金字塔用来向下采样图像， 拉普拉斯金字塔用来从金字塔底层图像中向上采样，重建一个图像可以将拉普拉斯金字塔理解为高斯金字塔的逆形式。</p><p>🌟 <strong>简述凸包的定义?</strong></p><p>​    给定二维平面上的点集合， 凸包就是将最外层的点连接起来构成凸多边形， 是能包含点集中所有的点。理解物体形状或轮廓的一种比较有用的方法便是计算一个物体的凸包。</p><p>🌟 <strong>简述一下仿射变换的定义？</strong></p><p>​    仿射变换是指在几何中，<strong>一个向量空间进行一次线性变换并接上一个平移， 变换为一个向量空间的变换。</strong>它保持了二维图像的平直性(直线变换后仍然是直线)和平行性。一个任意的仿射变换都能便是为乘以一个矩阵(线性变换)接着再加上一个向量(平移)的形式。</p><p>🌟 <strong>简述反向投影的定义和使用场景?</strong></p><p>​    反向投影就是一种记录给定图像中的像素点如何适应直方图模型像素分布方式的一种方法。<strong>所谓反向投影就是首先计算某一特征的直方图模型，然后使用模型去寻找图像中存在的该特征的方法。</strong>反向投影用于在输入图像(通常较大)中查找特定图像(通常较小) 最匹配的点或者区域， 也就是定位模板图像出现在输入图像的位置。</p><p><strong>7. 基本实现</strong></p><p><strong>注意，一下所有需要写代码的题目，不允许使用OpenCV的Mat类。如果图片内容需要用指针读取。</strong></p><p>给定0-1矩阵，求连通域。（遇到过N次，笔试面试都有，最好做到能徒手hack代码或者伪代码。）</p><p>写一个函数，求灰度图的直方图。</p><p>写一个均值滤波（中值滤波）。</p><p>常用的特征提取方法。</p><p>常用的目标检测方法。</p><p>常用的边缘提取方法。</p><p>常用的插值方法。</p><p>常用的图像分割算法。</p><p>写一个图像resize函数（放大和缩小）。</p><p>彩色图像、灰度图像、二值图像和索引图像区别？（索引图像到底是啥？）</p><p>给定摄像头范围和图像大小求分辨率。</p><p>如何检测图片中的汽车，并识别车型，如果有遮挡怎么办？</p><p>(2) 常用滤波器原理，最好自己会手写一些就简单的</p><p>(3) 图像的仿射变换</p><p>9、用过opencv里面哪些函数? （我顺带回答了一下canny，HR又问opencv里面有c-a-n-n-y有这几个字母的函数吗，尴尬。。。又问我如何自己写canny边缘检测算法）</p><p>13、如何求一张图片的均值？（考虑了溢出和分块求解，貌似不满意。。。回头看看积分图里面如何解决溢出的。）</p><p>14、如何写程序将图像放大缩小？（我回答的插值，不太对。。。比如放大两倍可以插值，那放大1.1倍呢，）—&gt;放大1.1倍也可以插值</p><p>15、如何遍历一遍求一张图片的方差？（回答的是采用积分图，并让我推导这样为啥可行。这个问题以前帮同学解决过。。。）</p><p><strong>8. 工程经验</strong></p><p>🌟  <strong>简述 .hpp 和 .h 的区别?</strong></p><p><strong>.hpp 的本质就是将 .cpp的实现代码混入 .h 头文件当中， 定义与实现都包含在同一文件，则该类的调用者只需要 include该 .hpp 文件即可</strong>，无需再将cpp加入project中进行编译。而实现代码直接编译到调用者的obj文件中， 不再生成单独的obj, 采用 hpp 将大幅度减小调用 project 中的 cpp 文件数和编译次数，也不用再发布 lib 与 dll 文件，因此非常适合用来编写公用的开源库。</p><p>🌟   Cpp 语言如果想用 OpenCV 的模块怎么用 ?</p>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>暗光增强</title>
    <link href="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/"/>
    <url>/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="low-light-enhancement-暗光增强"><a href="#low-light-enhancement-暗光增强" class="headerlink" title="low-light enhancement(暗光增强)"></a>low-light enhancement(暗光增强)</h1><h3 id="1-End2End"><a href="#1-End2End" class="headerlink" title="1. End2End"></a>1. End2End</h3><p>旨在于通过深度学习，对原图进行直接增强。 输入低光照图像，输出正常图像。 代表的方案有 LLCNN、SID、LLNet。</p><h5 id="1-LLCNN"><a href="#1-LLCNN" class="headerlink" title="(1) LLCNN"></a>(1) LLCNN</h5><p><strong>Paper</strong>：《LLCNN: A Convolutional Neural Network for Low-light Image Enhancement》</p><p><strong>code</strong>：<a href="https://github.com/BestJuly/LLCNN">https://github.com/BestJuly/LLCNN</a></p><p><strong>主要贡献</strong></p><p>​        作者提出采用 CNN 进行低光图像增强。作者设计了一种特殊的模块处理多尺度特征同时避免了梯度小时问题。为尽可能保留图像的纹理信息，作者采用 SSIM 损失进行模型训练。基于该方法，低光图像的对比度可以自适应增强。作者通过实验验证了所提方法的有效性。</p><p><img src="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/LLCNN.png" style="zoom:30%;"></p><h5 id="2-LLnet"><a href="#2-LLnet" class="headerlink" title="(2) LLnet"></a>(2) LLnet</h5><p><img src="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/LLNet.png" style="zoom:35%;"></p><p>​        比较早的用深度学习方法完成低光照增强任务的文章，它证明了基于合成数据训练的堆叠稀疏去噪自编码器能够对的低光照有噪声图像进行增强和去噪。模型训练基于图像块（patch），采用 sparsity regularized reconstruction loss 作为损失函数。主要贡献如下：</p><ul><li><p>我们提出了一种训练数据生成方法（即伽马校正和添加高斯噪声）来模拟低光环境。</p></li><li><p>探索了两种类型的网络结构：(a) LLNet,同时学习对比度增强和去噪；(b) S-LLNet,使用两个模块分阶段执行对比度增强和去噪。</p></li><li><p>在真实拍摄到的低光照图像上进行了实验，证明了用合成数据训练的模型的有效性。</p></li><li><p>可视化了网络权值，提供了关于学习到的特征的 insights。</p></li></ul><h5 id="3-SID"><a href="#3-SID" class="headerlink" title="(3) SID"></a>(3) SID</h5><p><img src="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/SID.png" style="zoom:35%;"></p><p>​        关注于极端低光条件和短时间曝光条件下的图像成像系统，它用卷积神经网络去完成 raw 图像到 RGB 图像的处理，实验效果非常惊艳.网络结构基于全卷积网络 FCN，直接通过端到端训练，损失函数采用 L1 loss。此外，文章提出了数据集 see-in-the-dark，由短曝光图像及对应的长曝光参考图像组成。</p><h3 id="2-进阶版本"><a href="#2-进阶版本" class="headerlink" title="2. 进阶版本"></a>2. 进阶版本</h3><p>将低光照重建分为三个部分：光照估计、去噪、增强重建。</p><p>对于光照估计：</p><p>（1）利用 retinex 理论将其分解为光照分量和反射分量的方案。 诸如：RetinexNet、kinD、KinD++</p><p>（2）直接用网络结构(Unet)进行光照估计。 典型的解决方案有：HDRNet、DeepUPE、GLADNet 和 AGLLE。</p><h5 id="1-RetinexNet"><a href="#1-RetinexNet" class="headerlink" title="(1) RetinexNet"></a>(1) RetinexNet</h5><p><strong>Paper</strong>：《Deep Retinex Decomposition for Low-Light Enhancement》</p><p><strong>code</strong>：<a href="https://github.com/weichen582/RetinexNet">https://github.com/weichen582/RetinexNet</a></p><p><strong>主要贡献</strong>：</p><ul><li><p>构建了 paired 的低光照/正常光照<strong>数据集LOL dataset</strong>，应该也是第一个在真实场景下采集的paired dataset。</p></li><li><p>提出了RetinexNet，<strong>它分为两个子网络：DecomNet 能够对图像进行解耦，得到光照图和反射图</strong>；<strong>EnhanceNet对前面得到的光照图进行增强，增强后的光照图和原来的反射图相乘就得到了增强结果</strong>。另外，考虑到噪声问题，采用一种联合去噪和增强的策略，去噪方法采用 <strong>BM3D</strong>。</p></li><li><p>提出一个 structure-aware total variation constraint，就是用 <strong>反射图梯度作为权值对 TV loss</strong>  进行加权，<strong>从而在保证平滑约束的同时不破坏纹理细节和边界信息</strong>。</p></li></ul><p><img src="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/RetinexNet.png" style="zoom:35%;"></p><h5 id="2-kinD"><a href="#2-kinD" class="headerlink" title="(2) kinD"></a>(2) kinD</h5><p><strong>Paper:</strong> 《Kindling the Darkness: A Practical Low-light Image Enhancer》</p><p><strong>code：</strong><a href="https://github.com/zhangyhuaee/KinD">https://github.com/zhangyhuaee/KinD</a></p><p><strong>主要贡献：</strong></p><p>​        文章沿用了 Retinex-Net 的 decomposition-&gt;enhance 的两阶段方式，网络总共分为三个模块：decomposition-net、restoration-net和 adjustment-Net，分别执行图像分解、反射图恢复、光照图调整。一些创新点如下：</p><ul><li>对于Decomposition-Net，其损失函数除了沿用Retinex-Net的重构损失和反射图一致损失外，针对光照图的区域平滑性和相互一致性，还增加了两个新的损失函数。</li><li>对于Restoration-Net，考虑到了低光照情况下反射图往往存在着退化效应，因此使用了良好光照情况下的反射图作为参考。反射图中的退化效应的分布很复杂，高度依赖于光照分布，因此引入光照图信息。</li><li>对于Adjustment-Net，实现了一个能够连续调节光照强度的机制（将增强比率作为特征图和光照图合并后作为输入）。通过和伽马校正进行对比，证明它们的调节方法更符合实际情况。</li></ul><p><img src="/2020/09/17/%E6%9A%97%E5%85%89%E5%A2%9E%E5%BC%BA/kinD.png" style="zoom:30%;"></p><h5 id="3-KinD"><a href="#3-KinD" class="headerlink" title="(3) KinD++"></a>(3) KinD++</h5><h5 id="4-MBLLEN-Low-light-Image-Video-Enhancement-Using-CNNs"><a href="#4-MBLLEN-Low-light-Image-Video-Enhancement-Using-CNNs" class="headerlink" title="(4) MBLLEN (Low-light Image/Video Enhancement Using CNNs)"></a>(4) MBLLEN (Low-light Image/Video Enhancement Using CNNs)</h5><p>​        针对网络中不同层次的特征的提取和融合。提出了针对视频的低光照增强网络，和一帧一帧处理的直接做法不同，它们使用 3D 卷积对网络进行了改进，有效提升了性能。补充说明一下，视频的低光照增强会存在的一种负面情况，闪烁（flickering），即帧与帧之间可能存在不符合预期的亮度跳变。这一问题可以用 AB(avr) 指标 (即平均亮度方差) 来度量。</p><ul><li>网络结构：包括特征提取模块 FEM、增强模块 EM和融合模块 FM。FEM 是有 10 层卷积的单流向网络，每层的输出都会被输入到各个 EM 子模块中分别提取层次特征。最终这些层次特征被拼接到一起并通过 1x1 卷积融合得到最终结果。为了用于视频增强，还需要对网络进行修改，具体可参考原文。</li><li>损失函数：本文不采用常规的 MSE 或者 MAE 损失，而是提了一个新的损失函数，包括三个部分，即结构损失、内容损失和区域损失。结构损失采用 SSIM 和 MS-SSIM 度量相结合的形式；内容损失，就是 VGG 提取的特征应该尽可能相似；区域损失令网络更关注于图像中低光照的区域。</li></ul><h5 id="5-HDRNet、DeepUPE-gt-使用双边卷积"><a href="#5-HDRNet、DeepUPE-gt-使用双边卷积" class="headerlink" title="(5) HDRNet、DeepUPE -&gt; 使用双边卷积"></a>(5) HDRNet、DeepUPE -&gt; 使用双边卷积</h5><h3 id="3-其他"><a href="#3-其他" class="headerlink" title="3. 其他"></a>3. 其他</h3><ul><li>结合热点趋势， 对网络进行补充设计， 典型的结合方案有：transformer、注意力机制、图网络、光场、trsnsformer 模型</li><li>结合 raw 域到 图像域，真实场景、基于 DSP 的设计、手机端 phone的暗光增强 和 轻量级暗光增强设计方案</li><li>几篇较新的论文：GLADNet、DPED、Attention-Based 和 Attention-Guided</li></ul><h3 id="4-Datasets"><a href="#4-Datasets" class="headerlink" title="4. Datasets"></a>4. Datasets</h3><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Download Link</th></tr></thead><tbody><tr><td><strong>LOL</strong></td><td>contains <strong>500 low/normal-light image pairs captured in real scenes</strong> and <strong>1000 synthetic image pairs</strong></td><td><a href="https://daooshee.github.io/BMVC2018website/">https://daooshee.github.io/BMVC2018website/</a></td></tr><tr><td><strong>SID</strong></td><td>contains <strong>5094 raw short-exposure images</strong>, each with a corresponding long-exposure reference image. Images were captured using two cameras: <strong>Sony α7S II</strong> and <strong>Fujifilm X-T2</strong></td><td><a href="http://vladlen.info/publications/learning-see-dark/">http://vladlen.info/publications/learning-see-dark/</a></td></tr><tr><td><strong>MIT-FiveK</strong></td><td><strong>5,000 photos</strong> in DNG format，an Adobe Lightroom catalog with <strong>renditions by 5 experts</strong></td><td><a href="https://data.csail.mit.edu/graphics/fivek/">https://data.csail.mit.edu/graphics/fivek/</a></td></tr><tr><td><strong>DPED</strong></td><td>including <strong>4549 photos</strong> from <strong>Sony smartphone</strong>, <strong>5727</strong> from <strong>iPhone</strong> and <strong>6015 photos</strong> from <strong>BlackBerry</strong></td><td><a href="http://people.ee.ethz.ch/~ihnatova/">http://people.ee.ethz.ch/~ihnatova/</a></td></tr><tr><td><strong>ExDARK</strong></td><td>a collection of <strong>7,363 low-light images</strong> from very low-light environments to twilight with <strong>12 object classes</strong>.</td><td><a href="https://github.com/cs-chan/Exclusively-Dark-Image-Dataset">https://github.com/cs-chan/Exclusively-Dark-Image-Dataset</a></td></tr></tbody></table></div><h3 id="5-上采样方式"><a href="#5-上采样方式" class="headerlink" title="5. 上采样方式"></a>5. 上采样方式</h3><ul><li><p>插值[插值包含双线性插值、三线性插值和最近邻插值]</p><p>常用的方法是：插值 + 卷积。 使用双线性插值和最近邻插值两者所得到的效果并没有什么差异， 因此最建议的方案是：最近邻插值 + 卷积</p></li><li><p>反卷积：使用反卷积会产生棋盘格效应。</p><p>什么时候会出现 ？当卷积核大小不能被步长整除的时候，会出现棋盘现象</p><p>为什么会出现 ？</p></li><li><p>通道重组 pixelshuffle</p></li></ul><h3 id="6-常见的-loss-和评价指标"><a href="#6-常见的-loss-和评价指标" class="headerlink" title="6. 常见的 loss 和评价指标"></a>6. 常见的 loss 和评价指标</h3><h5 id="1-pixel-loss"><a href="#1-pixel-loss" class="headerlink" title="(1) pixel loss"></a>(1) pixel loss</h5><p>​     针对于像素点的损失， 比较常见， 如常见的 l1 loss、l2 loss、charborn loss 等。</p><h5 id="2-retinex-采用了三种损失函数"><a href="#2-retinex-采用了三种损失函数" class="headerlink" title="(2) retinex 采用了三种损失函数"></a>(2) retinex 采用了三种损失函数</h5><ul><li>重建损失(首先将增强后的光照图 * 反射图得到我们需要的图像， 然后和正常的图像求 l1损失即可)</li><li>反射一致性损失(两张分解的反射图求 l1 损失即可)</li><li>光照平滑损失: 根据一些先验知识， 一张自然的图片的梯度是趋于零的， 一张图片，其变化的部分往往很少。这被叫做区域一致性。</li></ul><p>原始的 TV loss 直接定义为如下公式，可以看到使用两个方向上的梯度对其进行卷积，得到的结果取绝对值然后加和。</p><script type="math/tex; mode=display">V(y) = \sum_{i,j} \sqrt{|y_{i+1,j} - y_{i,j}|^2} + \sqrt{|y_{i,j+1} - y_{i,j}|^2} = \sum_{i,j} |y_{i+1,j} - y_{i,j}| + |y_{i,j+1} - y_{i,j}|</script><p>为什么使用这个损失函数?  这样可以尽可能的让图片平滑，因为这里让相邻两个像素点的值相近。 这里的光照平滑损失加权了反射图的 $e^{(-\lambda(\bigtriangledown(反射图))}$。主要目的是让反射图比较平滑的地方在光照图上也比较平滑。当说明反射图越平滑，反射图两个像素点的差值越小，对应的  $e^{(-\lambda(\bigtriangledown(反射图))}$ 越大， 对两点的光照图施加的约束越大。光照图才更平滑。</p><h5 id="3-其他-1"><a href="#3-其他-1" class="headerlink" title="(3) 其他"></a>(3) 其他</h5><ul><li><p>梯度损失 -&gt;  TV(总变分) -&gt; retinex 和 kind 中的光照平滑损失</p></li><li><p>ssim loss：比较的不单单是单一的像素值的差异，其纹理和质感比较重要 !</p><p>给定一张图像， 稍微(加减)像素值， 其结构(strusture) 基本不变， 但是其 psnr 却会发生很大变化，psnr 基于 l2， 所以 l2 损失函数并不适合。对于 暗光增强任务， 其纹理、质感更重要，而亮度应该有所调整。</p></li><li><p>zero loss 、感知损失(texture、content)、gan 损失</p></li></ul><h3 id="7-一些思考"><a href="#7-一些思考" class="headerlink" title="7. 一些思考"></a>7. 一些思考</h3><ul><li><p>暗光增强和 SR / image denoising 有什么不同?<br>SR / DeNoising 退化的图片的像素值在原图附近，而平均像素值几乎不变。</p></li><li><p>为啥没有使用 全局残差连接?     a. 暗光增强(与超分和去噪相比) 退化图像与原图差异大， 因此学习一个残差图非常困难   b. 模块已经存在局部残差连接</p></li><li><p>光照估计(illumination estimation)和低光照增强(low-light enhancement)的区别？</p><p>光照估计是一个专门的底层视觉任务（例如[1,2,6]），它的输出结果可以被用到其它任务中，例如图像增强、图像恢复。而低光照增强是针对照明不足的图像存在的低亮度、低对比度、噪声、伪影等问题进行处理，提升视觉质量。低光照增强方法有两种常见的模式，一种是直接 end-to-end 训练，另一种则包含了光照估计。</p></li><li></li><li></li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>推理引擎设计技巧</title>
    <link href="/2020/09/13/%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7/"/>
    <url>/2020/09/13/%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7/</url>
    
    <content type="html"><![CDATA[<h4 id="1-基于C-C-的基本优化"><a href="#1-基于C-C-的基本优化" class="headerlink" title="1. 基于C/C++的基本优化"></a>1. 基于C/C++的基本优化</h4><ol><li><p>编译器很牛逼，GCC/CLANG 都有运行速度的优化选项，打开这些选项能帮助程序显著提升速度，虽然这还远远不够，但聊胜于无吧。</p><p>下面是 ncnn 示例项目中的一段代码:</p><pre><code class="hljs cmake"><span class="hljs-comment"># ncnn/examples/squeezencnn/jni/Android.mk</span>LOCAL_CFLAGS := -O2 -fvisibility=hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-<span class="hljs-keyword">math</span>LOCAL_CPPFLAGS := -O2 -fvisibility=hidden -fvisibility-inlines-hidden -fomit-frame-pointer -fstrict-aliasing -ffunction-sections -fdata-sections -ffast-<span class="hljs-keyword">math</span>LOCAL_LDFLAGS += -Wl,--gc-sections</code></pre><p>以前工作时候写的CMakeLists 中的代码：</p><pre><code class="hljs cmake"><span class="hljs-comment"># set(CMAKE_BUILD_TYPE Release)</span><span class="hljs-keyword">if</span> (CMAKE_BUILD_TYPE <span class="hljs-keyword">STREQUAL</span> <span class="hljs-string">&quot;Debug&quot;</span>)    <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS_DEBUG <span class="hljs-string">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;</span>)    <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;CMAKE_BUILD_TYPE = Debug&quot;</span>)<span class="hljs-keyword">else</span>()    <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="hljs-string">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)    <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;CMAKE_BUILD_TYPE = Release&quot;</span>)<span class="hljs-keyword">endif</span>()</code></pre></li><li><p>书写高效的C代码。循环展开、内联、分支优化，避免除法，查表等优化小技巧要滚瓜烂熟，信手拈来。</p></li><li><p>必须看得懂汇编，即使你不写，也要知道编译器编译出来的汇编代码效率如何。这样你可以通过调整C/C++代码，让编译器生成你需要的代码。</p></li></ol><h4 id="2-缓存友好"><a href="#2-缓存友好" class="headerlink" title="2. 缓存友好"></a>2. 缓存友好</h4><h5 id="（1）少用内存"><a href="#（1）少用内存" class="headerlink" title="（1）少用内存"></a>（1）少用内存</h5><h5 id="（2）连续访问、对齐访问、合并访问、显示对齐数据加载、缓存预取"><a href="#（2）连续访问、对齐访问、合并访问、显示对齐数据加载、缓存预取" class="headerlink" title="（2）连续访问、对齐访问、合并访问、显示对齐数据加载、缓存预取"></a>（2）连续访问、对齐访问、合并访问、显示对齐数据加载、缓存预取</h5><h4 id="3-多线程"><a href="#3-多线程" class="headerlink" title="3. 多线程"></a>3. 多线程</h4><h5 id="1-OpenMP"><a href="#1-OpenMP" class="headerlink" title="1. OpenMP"></a>1. OpenMP</h5><p>OpenMP会自动为循环分配线程，使用OpenMP加速只需要在串行代码中添加编译指令以及少量API即可。理想情况下，加速比大约能达到0.75*cores。</p><pre><code class="hljs cpp"><span class="hljs-comment">// ncnn/src/layer/relu.cpp</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">ReLU::forward_inplace</span><span class="hljs-params">(Mat&amp; bottom_top_blob, <span class="hljs-keyword">const</span> Option&amp; opt)</span> <span class="hljs-keyword">const</span></span><span class="hljs-function"></span>&#123;    <span class="hljs-keyword">if</span> (bottom_top_blob.elemsize == <span class="hljs-number">1u</span>)        <span class="hljs-keyword">return</span> ReLU::forward_inplace_int8(bottom_top_blob, opt);    <span class="hljs-keyword">int</span> w = bottom_top_blob.w;    <span class="hljs-keyword">int</span> h = bottom_top_blob.h;    <span class="hljs-keyword">int</span> channels = bottom_top_blob.c;    <span class="hljs-keyword">int</span> size = w * h;    <span class="hljs-keyword">if</span> (slope == <span class="hljs-number">0.f</span>)    &#123;        <span class="hljs-meta">#<span class="hljs-meta-keyword">pragma</span> omp parallel for num_threads(opt.num_threads)</span>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)        &#123;            <span class="hljs-keyword">float</span>* ptr = bottom_top_blob.channel(q);            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)            &#123;                <span class="hljs-keyword">if</span> (ptr[i] &lt; <span class="hljs-number">0</span>)                    ptr[i] = <span class="hljs-number">0</span>;            &#125;        &#125;    &#125;    <span class="hljs-keyword">else</span>    &#123;        #pragma omp parallel <span class="hljs-keyword">for</span> num_threads(opt.num_threads)        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> q=<span class="hljs-number">0</span>; q&lt;channels; q++)        &#123;            <span class="hljs-keyword">float</span>* ptr = bottom_top_blob.channel(q);            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i&lt;size; i++)            &#123;                <span class="hljs-keyword">if</span> (ptr[i] &lt; <span class="hljs-number">0</span>)                    ptr[i] *= slope;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><p>​    但并非所有循环都适合做多线程优化，如果每次循环只做了非常少的事情，那么使用多线程会得不偿失。实际运用中，可以通过 <code>#pragma omp parallel for if (cond)</code> 语句来判断runtime过程中是否要启用多线程。</p><h5 id="动态调度"><a href="#动态调度" class="headerlink" title="动态调度"></a>动态调度</h5><h5 id="稀疏化"><a href="#稀疏化" class="headerlink" title="稀疏化"></a>稀疏化</h5><h5 id="定点化"><a href="#定点化" class="headerlink" title="定点化"></a>定点化</h5><h5 id="NEON-汇编"><a href="#NEON-汇编" class="headerlink" title="NEON 汇编"></a>NEON 汇编</h5><h4 id="4-内存精简"><a href="#4-内存精简" class="headerlink" title="4. 内存精简"></a>4. 内存精简</h4><p>每个layer都会产生blob，除了最后的结果和多分支中间结果，大部分blob都可以不保留，开启ncnn的轻模式可以在运算后自动回收，省下内存。  如下图所示：</p><p><img src="/2020/09/13/%E6%8E%A8%E7%90%86%E5%BC%95%E6%93%8E%E8%AE%BE%E8%AE%A1%E6%8A%80%E5%B7%A7/1.png" alt>某网络结构为 <code>Conv</code> -&gt; <code>Bias</code> -&gt; <code>ReLU</code> -&gt; <code>Concat</code>，在轻模式下，向ncnn索要Concat结果时，Conv结果会在运算Bias时自动回收，而Bais结果会在运算ReLU时自动回收，而ReLU结果会在运算Concat时自动回收, 最后只保留Concat结果，后面再需要C结果会直接获得，满足绝大部分深度网络的使用方式。ncnn 开启轻模式仅需要一行代码:</p><pre><code class="hljs cpp">set_light_mode(<span class="hljs-literal">true</span>)</code></pre><p>相关参考资料：</p><p><a href="https://m.facebook.com/notes/facebook-engineering/three-optimization-tips-for-c/10151361643253920">Three-optimization-tips-for-c</a></p><p><a href="https://www.ibm.com/developerworks/cn/aix/library/au-aix-openmp-framework/index.html">通过GCC学习OpenMP框架</a></p><p><a href="https://www.openmp.org/">OPEN MP官网</a></p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>rk3399系统烧写</title>
    <link href="/2020/08/18/rk3399%E7%B3%BB%E7%BB%9F%E7%83%A7%E5%86%99/"/>
    <url>/2020/08/18/rk3399%E7%B3%BB%E7%BB%9F%E7%83%A7%E5%86%99/</url>
    
    <content type="html"><![CDATA[<h4 id="一-相关工具的准备"><a href="#一-相关工具的准备" class="headerlink" title="一. 相关工具的准备"></a>一. 相关工具的准备</h4><ol><li>下载 烧写工具:</li></ol><pre><code class="hljs shell">git clone https://github.com/rockchip-linux/rkbin.git</code></pre><ol><li>下载相关的 ubuntu 镜像。下载地址  <a href="https://github.com/lanseyujie/tn3399_v3/release">https://github.com/lanseyujie/tn3399_v3/release</a></li></ol><h4 id="二-刷机"><a href="#二-刷机" class="headerlink" title="二. 刷机"></a>二. 刷机</h4><ol><li>板卡进入刷机模式</li></ol><p>连接 usb-c 和 PC 主机。断开电源， 按住 recovey 键， 然后插上电源， 让板卡进入刷机模式。</p><ol><li><p>短接板卡反面的两个触点， 进入 maskrom 模式。</p></li><li><p>执行如下命令， 将相应的镜像刷入 板卡</p><pre><code class="hljs apache"><span class="hljs-attribute">sudo</span> rkdeveloptool db rk<span class="hljs-number">3399</span>_loader_v<span class="hljs-number">1</span>.<span class="hljs-number">24</span>.<span class="hljs-number">126</span>.bin<span class="hljs-attribute">sudo</span> rkdeveloptool ef<span class="hljs-attribute">sudo</span> rkdeveloptool wl <span class="hljs-number">0</span>x<span class="hljs-number">0</span> system.img</code></pre></li></ol><h4 id="三-登录"><a href="#三-登录" class="headerlink" title="三. 登录"></a>三. 登录</h4><ol><li><p>重新启动开电脑， 就可以进入 ubuntu 系统， 默认用户名是 root  密码是 1234</p></li><li><p>分区扩容</p><pre><code class="hljs shell">sudo apt install -y partedsudo parted /dev/mmcblk2unit sprintresizepart 5 100%printQsudo resize2fs /dev/mmcblk2p5</code></pre></li><li><p>可以安装 相关的桌面系统， ubuntu 新增账号循环登陆桌面。只是在添加新用户的时候需要使用</p></li></ol><pre><code class="hljs shell">useradd -m usrname # 加 m 参数会创建一个同名文件夹， 如果没有则会导致循环登录</code></pre><h4 id="参考网址"><a href="#参考网址" class="headerlink" title="参考网址:"></a>参考网址:</h4><p><a href="https://github.com/lanseyujie/tn3399_v3">https://github.com/lanseyujie/tn3399_v3</a>     # 很齐全的资料包</p><p><a href="https://naivekun.tk/">https://naivekun.tk/</a></p>]]></content>
    
    
    <categories>
      
      <category>DL_Deploy</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch2ncnn</title>
    <link href="/2020/05/17/pytorch2ncnn/"/>
    <url>/2020/05/17/pytorch2ncnn/</url>
    
    <content type="html"><![CDATA[<p>借助 onnx 实现 pytorch 到 ncnn 的转换</p><a id="more"></a><p><strong>1. 安装 onnx</strong> </p><pre><code class="hljs shell">pip3 install onnx</code></pre><p><strong>2. pytorch model &gt; onnx</strong></p><pre><code class="hljs python"><span class="hljs-keyword">from</span> models.pfld <span class="hljs-keyword">import</span> PFLDInference, AuxiliaryNet<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<span class="hljs-keyword">import</span> onnx<span class="hljs-keyword">import</span> torchcheckpoint = torch.load(<span class="hljs-string">&quot;./checkpoint/snapshot/checkpoint.pth.tar&quot;</span>, map_location=<span class="hljs-string">&#x27;cpu&#x27;</span>)pfld_backbone = PFLDInference()pfld_backbone.load_state_dict(checkpoint[<span class="hljs-string">&#x27;pfld_backbone&#x27;</span>])dummy_input = Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">112</span>, <span class="hljs-number">112</span>)) torch.onnx.export(plfd_backbone, dummy_input, <span class="hljs-string">&quot;output/plfd.onnx&quot;</span>)model = onnx.load(<span class="hljs-string">&#x27;output/pfld.onnx&#x27;</span>)</code></pre><p><strong>3. 安装ncnn</strong></p><p>(1) 安装 protobuf</p><pre><code class="hljs shell">unzip protobuf-all-3.7.1.zipcd protobuf-all-3.7.1./configure --prefix=/usr/localmake -j4make check -j4sudo make installsudo ldconfig</code></pre><p>(2) 安装 opencv， opencv 这里用的是2.4.13.6</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 源码编译</span></span>unzip opencv-2.4.13.6.zipcd opencv-2.4.13.6mkdir buildcd buildcmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..make -j8sudo make installsudo ldconfig</code></pre><p>(3) 安装依赖项</p><pre><code class="hljs shell">sudo apt-get install build-essentialsudo apt-get install cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-devsudo apt-get install  libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev</code></pre><p>(4) 把ncnn的源码clone下来，我们这里主要想使用tools下面的onnx转换工具。</p><p>这里作一点修改，pytorch1.0之后支持0维的张量，这在ncnn转换中会出现问题，修改onnx2ncnn.cpp中Constant和MemoryData的转换，<strong>有2处</strong></p><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> (M.dims_size() == <span class="hljs-number">1</span>) &#123;   <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 0=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">0</span>));&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (M.dims_size() == <span class="hljs-number">2</span>) &#123;    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 0=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">1</span>));    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 1=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">0</span>));&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (M.dims_size() == <span class="hljs-number">3</span>) &#123;    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 0=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">2</span>));    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 1=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">1</span>));    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 2=%d&quot;</span>, (<span class="hljs-keyword">int</span>)M.dims(<span class="hljs-number">0</span>));&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (get_tensor_proto_data_size(M)==<span class="hljs-number">1</span>) &#123;    <span class="hljs-comment">// scalar tensor!!! </span>    <span class="hljs-built_in">fprintf</span>(pp, <span class="hljs-string">&quot; 0=1&quot;</span>);&#125;</code></pre><p>(3) 编译 ncnn</p><pre><code class="hljs shell">cd ncnnmkdir -p buildcd buildcmake ..make -j4</code></pre><p>这样在 build/tools/onnx/ 目录下就有转换工具 onnx2ncnn 了</p><p><strong>4. 简化一些onnx 模型</strong></p><p>先别急着转换，onnx转换模型时有一些冗余，我们用工具简化一些onnx模型</p><pre><code class="hljs shell">pip3 install onnx-simplifierpython3 -m onnxsim pfld.onnx pfld-sim.onnx</code></pre><p><strong>5.  onnx &gt; ncnn</strong></p><pre><code class="hljs shell">cd ~/xxx/ncnn/build/tools/onnx/./onnx2ncnn pfld-sim.onnx pfld-sim.param pfld-sim.bin</code></pre><p>现在就生成了两个文件可以供使用: <strong>pfld-sim.bin</strong> 和 <strong>pfld-sim.param</strong></p><p><strong>6. 编写一个可以供调用的ncnn文件进行调用即可。</strong></p><p><strong>错误信息:</strong></p><p><strong>Q: Python中Import Error: no module named ‘past’错误以及解决方法</strong></p><pre><code class="hljs shell">pip3 install future</code></pre>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RNN</title>
    <link href="/2020/02/06/RNN/"/>
    <url>/2020/02/06/RNN/</url>
    
    <content type="html"><![CDATA[<hr><p>title: RNN<br>date: 2019-03-05 11:49:20<br>tags:</p><h2 id="mathjax-true"><a href="#mathjax-true" class="headerlink" title="mathjax: true"></a>mathjax: true</h2><p>​        <strong>循环神经网络（Recurrent Neural Network）</strong>是用来建模序列化数据的一种主流深度学习模型。我们知道，传统的前馈神经网络一般的输入都是一个定长的向量，无法处理变长的序列信息，即使通过一些方法把序列处理成定长的向量，模型也很难捕捉序列中的长距离依赖关系。RNN则通过将神经元串行起来处理序列化的数据。由于每个神经元都能用它的内部变量保存之前输入的序列信息，因此整个序列被浓缩成抽象的表示，并可以据此进行分类或生成新的序列。近年来RNN在很多领域取得突破性进展 —— 机器翻译、序列标注、图像描述、推荐系统、智能聊天机器人、自动作词作曲等。</p><p>下图展示了一个典型的循环神经网络结构：</p><p><img src="/2020/02/06/RNN/rnn.png" alt></p><p>一个长度为T 的序列用循环神经网络建模，展开之后可以看做是一个T曾的前馈神经网络。其中，第 $t$ 层的隐含状态 $h<em>{t}$ 编码了序列中前 $t$ 个输入的信息，可以通过当前的输入$x</em>{t}$和上一层的状态 $h<em>{t-1}$ 计算得到；最后一层的状态 $h</em>{t}$ 编码了整个序列的信息，因此可以作为整个序列的压缩表示。循环神经网络的前向传播公式为:</p><script type="math/tex; mode=display">net_{t} = Ux_{t} + Wh_{t-1}  \\h_{t} = f(net_{t})  \\y = g(Vh_{t})</script><p>​    其中 $f$ 和 $g$  为激活函数，$U$ 为输入层到隐含层的权重矩阵，$W$ 为隐含层从上一时刻到下一时刻状态转移的权重矩阵。$f$ 可以选取 Tanh 函数 或者 ReLU 函数，$g$ 可以采用 Softmax 函数。</p><h5 id="问题1：循环神经网络的梯度消失问题"><a href="#问题1：循环神经网络的梯度消失问题" class="headerlink" title="问题1：循环神经网络的梯度消失问题"></a>问题1：循环神经网络的梯度消失问题</h5><p>循环神经网络模型的求解可以采用 <strong>BPTT</strong> 算法实现， BPTT 实际上是反向传播算法的变种。这一现象主要源于深度神经网络中的梯度消失。传统的循环神经网络梯度可以写成连乘的形式：</p><script type="math/tex; mode=display">\frac{\partial{net_t}}{\partial{net_1}} = \frac{\partial{net_t}}{\partial{net_{t-1}}}.\frac{\partial{net_{t-1}}}{\partial{net_{t-2}}} ...\frac{\partial{net_{2}}}{\partial{net_{1}}}</script><p>其中，</p><script type="math/tex; mode=display">net_{t} = Ux_{t} + Wh_{t-1} \\h_{t} = f(net_{t}) \\y = g(Vh_{t})</script><script type="math/tex; mode=display">\frac{\partial{net_t}}{\partial{net_{t-1}}} = \frac{\partial{net_t}}{\partial{h_{t-1}}}\frac{\partial{h_{t-1}}}{\partial{net_{t-1}}}= W \cdot diag[f'(net_{t-1})] \\=   \begin{bmatrix}W_{11}f'(net_{t-1}^1)      &  \dots  & W_{1n}f'(net_{t-1}^n) \\\vdots  &  \ddots & \vdots  \\W_{n1}f'(net_{t-1}^1)       &  \dots  & W_{nn}f'(net_{t-1}^n) \end{bmatrix}</script><p>其中 $n$ 为 隐含层 $h<em>{t-1}$  的维度（即隐含单元的个数）， $\frac{\partial{net_1}}{\partial{net</em>{t-1}}}$ 对应 $n*n$ 维矩阵，又被称为雅各比矩阵。</p><p>由于预测误差是沿着神经网络的每一层反向传播的，因此当雅各比矩阵的最大特征值大于1时， 随着离输出越来越远，每层梯度大小会呈指数增长，导致梯度爆炸；反之，若雅各比矩阵的最大特征值小于1， 梯度的大小会呈指数减小，产生梯度消失。</p><p>梯度爆炸的问题可以通过梯度裁剪来缓解，即当梯度的范式大于某个某个给定值时， 对梯度进行等比收缩。而对于梯度消失问题， 可以通过加入门口机制来弥补梯度消失带来的损失。</p><h5 id="问题-2：-在循环神经网络中，是否可以使用-ReLU-作为激活函数？"><a href="#问题-2：-在循环神经网络中，是否可以使用-ReLU-作为激活函数？" class="headerlink" title="问题 2： 在循环神经网络中，是否可以使用 ReLU 作为激活函数？"></a>问题 2： 在循环神经网络中，是否可以使用 ReLU 作为激活函数？</h5><p>可以，但是需要将$W$初始化为单位矩阵。如果不然会引发严重的数值问题和梯度消失或爆炸问题。</p><p><strong>数值问题：</strong></p><p>考虑前向传播公式：</p><script type="math/tex; mode=display">net_{t} = Ux_{t} + Wh_{t-1}  \\h_{t} = f(net_{t})  \\</script><p>根据前向传播公式向前传递一层，可以得到</p><script type="math/tex; mode=display">net_{t} = Ux_{t} + Wh_{t-1} + Wf(Ux_{t-1} + Wh_{t-2})</script><p>如果使用 $ReLU$ 替代公式中的激活函数 $f$， 并且假设 $ReLU$ 处于激活区域（即输入大于0），则有 $f(x)=x, net<em>{t}=Ux</em>{t}+W(Ux<em>{t-1}+Wh</em>{t-2})$, 继续将其展开，$net_{t}$ 的表达式中最终将包含$t$ 个 $W$ 连乘。如果 $W$ 不是单位矩阵，最终的结果将趋于 $0$ 或者无穷，引发严重的数值问题。</p><p><strong>梯度爆炸或梯度消失：</strong></p><p>考虑循环神经网络的梯度计算公式：</p><script type="math/tex; mode=display">\frac{\partial{net_t}}{\partial{net_{t-1}}} = W \cdot diag[f'(net_{t-1})] \\=   \begin{bmatrix}W_{11}f'(net_{t-1}^1)      &  \dots  & W_{1n}f'(net_{t-1}^n) \\\vdots  &  \ddots & \vdots  \\W_{n1}f'(net_{t-1}^1)       &  \dots  & W_{nn}f'(net_{t-1}^n) \end{bmatrix}</script><p>假设采用 $ReLU$ 激活函数，且一开始所有的神经元都处于激活中， 则 $diag[f’(net<em>{t-1})]$ 为单位矩阵， 有 $\frac{\partial{net_t}}{\partial{net</em>{t-1}}}=W$。在梯度经过了$n$ 层之后， $\frac{\partial{net<em>{t}}}{\partial{net</em>{1}}} = W^n$。可以看到即使采用了 $ReLU$ 激活函数，只要$W$ 不是单位矩阵，还是会出现梯度消失或者爆炸的现象。</p><h5 id="问题-3：-LSTM-是如何实现长短期记忆功能的？"><a href="#问题-3：-LSTM-是如何实现长短期记忆功能的？" class="headerlink" title="问题 3： LSTM 是如何实现长短期记忆功能的？"></a>问题 3： LSTM 是如何实现长短期记忆功能的？</h5><p>​    与传统的循环神经网络相比，LSTM 仍然是基于$x<em>t$ 和 $h</em>{t-1}$ 来计算 $h_t$, 只不过对内部的结构进行了更加精心的设计，加入了输入门 $i_t$ 、遗忘门 $f_t$ 以及输出门 $o_t$ 三个门和一个内部记忆单元 $c_t$。</p><p>​    输入门控制当前计算的新状态以多大程度更新到记忆单元中；遗忘门控制前一步记忆单元中的信息有多大程度被遗忘掉；输出门控制当前的输出有多大程度取决于当前的记忆单元。</p><p>经典的LSTM中， 第 $t$ 步的更新计算公式为：</p><script type="math/tex; mode=display">i_t = \sigma(W_{i}x_{t}+U_{i}h_{t-1}+b_{i}) \\f_t = \sigma(W_{f}x_{t}+U_{f}h_{t-1}+b_{f}) \\o_t = \sigma(W_{o}x_{t}+U_{o}h_{t-1}+b_{o}) \\\widetilde{c_{t}} = Tanh(W_{c}x_{t}+U_{c}h_{t-1}) \\c_{t} = f_{t} \odot c_{t-1} + i_{t} \odot \widetilde{c_{t}} \\h_{t} = o_{t} \odot Tanh(c_t)</script><p>其中<strong>输入门  $i<em>{t}$ 是通过输入 $x_t$和上一步的隐含层输出 $h</em>{t-1}$ 来进行线性变换，再经过激活函数 $\sigma$ 得到的</strong>。输入门 $i<em>t$  的结果是向量，其中每个元素是 0 到 1 之间的实数， 用于控制各维度流过阀门的信息量；$W</em>{i}$、$U<em>i$ 两个矩阵核向量 $b_i$ 为输入门的参数，是在训练过程中得到的。**遗忘门 $f</em>{t}$ 和输出门 $o<em>{t}$ 的计算方式与输入门类似，它们有各自的参数 $W$、$U$ 和 $b$ **。 与传统的循环神经网络不通的是，从上一个记忆单元的状态 $c</em>{t-1}$ 到 当前的状态 $c_{t} $ 的转移不一定完全取决于激活函数计算得到的状态，还由输入门和遗忘门来共同控制。</p><p>​    在一个循环好的网络中，当输入的序列中没有重要信息时， $LSTM$ 的遗忘门的值会接近于 1， 输入门的值会接近于0， 此时过去的信息回本保存，从而实现长期记忆功能；当输入序列中出现重要信息时，$LSTM$ 应当将其存入记忆中，此时其输入门的值会接近于1； 当输入的序列出现了重要信息，且该信息意味着之前的记忆不在重要时，输入门的值会接近于1， 而遗忘门的值接近于0， 这样旧的记忆被遗忘，新的重要信息被记忆。经过这样的设计，整个网络更容易学到序列之间的长期依赖。</p><p><img src="/2020/02/06/RNN/lstm_1.png" alt></p><h5 id="问题4：LSTM-里各个模块分别使用什么激活函数，可以使用别的激活函数吗？"><a href="#问题4：LSTM-里各个模块分别使用什么激活函数，可以使用别的激活函数吗？" class="headerlink" title="问题4：LSTM 里各个模块分别使用什么激活函数，可以使用别的激活函数吗？"></a>问题4：LSTM 里各个模块分别使用什么激活函数，可以使用别的激活函数吗？</h5><p>关于激活函数的选取， <strong>在 $LSTM$ 中，遗忘门、输入门和输出门使用 $Sigmoid$ 函数作为激活函数；在生成候选记忆时，使用双曲正切函数 $Tanh$ 作为激活函数。</strong><br> （1）  这两个激活函数都是饱和的，也就是说在输入达到一定值得情况下，输出就不会发生明显变化了。如果使用非饱和的激活函数，例如 $ReLU$，那么将很难实现门控的效果。</p><p>（2） $Sigmoid$ 函数的输出在 0 ~ 1 之间，<strong>符合门控的物理定义</strong>。当输入较大或者较小时， 其输出会非常接近1或 0， 从而保证该门的开关。</p><p>（3）在生成候选记忆时，使用 $Tanh$ 函数，时因为其输出在-1~1 之间，这<strong>与大多数场景下特征分布是0中心吻合</strong>。此外，Tanh 函数在输入为 $0$ 附近相比 $Sigmoid$ 含有有更大的梯度，通常使<strong>模型收敛更快</strong>。</p><p>此外，<strong>在一些对计算能力有限制的设备，诸如可穿戴设备中，由于 $Sigmoid$ 函数求指数需要一定的计算量，此时会使用0/1门$（hard gard）$让门控输出为0或者1的离散值，即当输入小于阈值时，门控输出为0；当输入大于阈值时，输出为1</strong>。从而在性能下降不明显的情况下，减少计算量。</p><h5 id="问题-5：-什么是-Seq2Seq模型？Seq2Seq模型有哪些优点？"><a href="#问题-5：-什么是-Seq2Seq模型？Seq2Seq模型有哪些优点？" class="headerlink" title="问题 5： 什么是 Seq2Seq模型？Seq2Seq模型有哪些优点？"></a>问题 5： 什么是 Seq2Seq模型？Seq2Seq模型有哪些优点？</h5><p>$Seq2Seq$ 模型的核心思想是，<strong>通过深度神经网络将一个作为输入的序列映射为一个作为输出的序列，这一过程由编码输入与解码输出两个环节构成</strong>。在经典的实现中，编码器和解码器各由一个循环神经网络构成，既可以选择传统的循环神经网络结构，也可以使用长短期记忆模型。门控循环单元等。在 $Seq2Seq$ 模型中，两个循环神经网络是共同训练的。典型的循环神经网络编解码结构图如下所示:</p><p><img src="/2020/02/06/RNN/seq2seq_ts.png" alt></p><h5 id="问题-6：-Seq2Seq-模型在解码时，-有哪些常用的方法？"><a href="#问题-6：-Seq2Seq-模型在解码时，-有哪些常用的方法？" class="headerlink" title="问题 6： Seq2Seq 模型在解码时， 有哪些常用的方法？"></a>问题 6： Seq2Seq 模型在解码时， 有哪些常用的方法？</h5><p>$Seq2Seq$ 模型最基础的解码方法是<strong>贪心法</strong>， 即选取一种度量标准后，每次都在当前状态下选择最佳的一个结果， 直到结束。很显然，贪心法获得的是一个局部最优解，由于实际问题的复杂性，该方法往往不能取得更好的效果。<strong>集束搜索(beam search) </strong> 是一种常见的改进算法。该方法会<strong>保存 beam size 个当前的较佳选择，然后解码时每一步根据保存的选择进行下一步扩展和排序，接着选择前 beam size 个进行保存，循环迭代，直到结束时选择最佳的一个作为解码的结果。</strong> 随着 beam size 的增大，其搜索的空间增大，最终效果会有所提升，但需要的计算量也相应增大。在实际应用中，b往往会选择一个适中的范围，以8 ~ 12 为佳。下图是 beam size 为2时的集束搜索示例。</p><p><img src="/2020/02/06/RNN/beam search.png" alt></p><p>解码时使用<strong>堆叠的RNN</strong>、<strong>增加 Dropout机制</strong>、<strong>与编码器之间建立残差连接</strong>、<strong>增加Attention机制</strong>等，均是常见的改进措施。在实际的研究工作中，可以根据不同使用场景，有针对性的选择和实践。</p><h5 id="问题7：Seq2Seq-模型引入注意力机制是为了解决什么问题？-为什么选用双向的循环神经网络模型？"><a href="#问题7：Seq2Seq-模型引入注意力机制是为了解决什么问题？-为什么选用双向的循环神经网络模型？" class="headerlink" title="问题7：Seq2Seq 模型引入注意力机制是为了解决什么问题？ 为什么选用双向的循环神经网络模型？"></a>问题7：Seq2Seq 模型引入注意力机制是为了解决什么问题？ 为什么选用双向的循环神经网络模型？</h5><p>在 Seq2Seq 模型中，当前隐状态以及上一个输出词决定了当前的输出词， 即：</p><script type="math/tex; mode=display">s_{i} = f(y_{i-1}, s_{i-1}) \\p(y_{i} | y_{1}, y_{2}, ..., y_{i-1}) = g(y_{i-1}, s_{i})</script><p><strong>在实际应用中会发现随着序列的增长，模型的性能发生显著下降。这是因为编码时输入序列的全部信息被压缩到一个向量表示中。随着序列增长，句子约前面的信息就丢失的越严重。</strong>$Seq2Seq$ 模型中引入注意力机制就是为了解决这个问题。</p><p><img src="/2020/02/06/RNN/seq2seq_attn.png" alt></p><p>(1)  在编码过程中，我们仍然使用普通的循环神经网络对输入序列进行编码，得到隐状态 $h1, h2, …, h<em>T$。使用一个神经网络 $align$ 上一个输入序列的隐状态 $s</em>{i-1}$ 和输入序列隐状态  $h<em>{j}$ 作为输入，计算出一个 $x</em>{j}, y<em>{i}$ 对齐的值 $e</em>{ij}$， 再归一化得到权重 $\alpha_{ij}$。</p><script type="math/tex; mode=display">e_{ij} = align(s_{i-1}, h_{j})  \\\alpha_{ij} = \frac{exp(e_{ij})}{\sum_{k=1}^{T}{exp(e_{ik})}}</script><p>(2) 计算语境向量 $c_{i}$ , 即是输入序列全部隐状态 $h1, h2, …, h_T$的一个加权和。</p><script type="math/tex; mode=display">c_{i} = \sum_{j=1}^{T}{\alpha_{ij}h_{j}}</script><p>(3) 在解码过程中，每一个输出词都依赖于前一个隐状态以及输入序列每一个对应的隐状态。</p><script type="math/tex; mode=display">s_{i} = f(y_{i-1}, s_{i-1}, x_{i}) \\p(y_{i} | y_{1}, y_{2}, ..., y_{i-1}) = g(y_{i-1}, s_{i}, c_{i})</script>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>leetcode-review</title>
    <link href="/2020/02/03/leetcode-review/"/>
    <url>/2020/02/03/leetcode-review/</url>
    
    <content type="html"><![CDATA[<h3 id="1-CPP-语法快速回顾"><a href="#1-CPP-语法快速回顾" class="headerlink" title="1. CPP 语法快速回顾"></a>1. CPP 语法快速回顾</h3><h5 id="1-声明"><a href="#1-声明" class="headerlink" title="(1) 声明"></a>(1) 声明</h5><pre><code class="hljs cpp"><span class="hljs-comment">// 二维数组的申请</span><span class="hljs-keyword">int</span> m, n;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n, <span class="hljs-number">0</span>))</span></span>;<span class="hljs-comment">// 堆的声明</span><span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, greater&lt;<span class="hljs-keyword">int</span>&gt; &gt; min_heap; <span class="hljs-comment">// 最小堆</span><span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, less&lt;<span class="hljs-keyword">int</span>&gt; &gt; max_heap;  <span class="hljs-comment">// 最大堆</span></code></pre><h5 id="2-常见算法"><a href="#2-常见算法" class="headerlink" title="(2) 常见算法"></a>(2) 常见算法</h5><pre><code class="hljs cpp"><span class="hljs-comment">// 常见的算法：</span>sort、swap、max_element、find、reverse、accumulate、  <span class="hljs-comment">// 字符串函数</span><span class="hljs-built_in">islower</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 是否为小写字母</span><span class="hljs-built_in">isupper</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 是否为大写字母</span><span class="hljs-built_in">isdigit</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 是否为数字</span><span class="hljs-built_in">isalpha</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 是否为字母</span><span class="hljs-built_in">isalnum</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 是否为字母或者数字</span><span class="hljs-built_in">toupper</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 字母小转大</span><span class="hljs-built_in">tolower</span>(<span class="hljs-keyword">char</span> c) <span class="hljs-comment">// 字母大转小  </span>  find_first_not_of <span class="hljs-comment">//</span>find_last_not_of <span class="hljs-comment">// </span>substr <span class="hljs-comment">//</span>    <span class="hljs-comment">// find  ----  返回值为迭代器</span><span class="hljs-comment">// set、map: 自带 find 函数  c.find(val);</span><span class="hljs-comment">// 普通容器     find(c.begin(), c.end(), val);</span></code></pre><h5 id="3-容器"><a href="#3-容器" class="headerlink" title="(3) 容器"></a>(3) 容器</h5><pre><code class="hljs cpp"><span class="hljs-comment">// begin()   end()   empty()   size()</span><span class="hljs-comment">// stack: 栈   push  pop   top</span><span class="hljs-comment">// queue: 队列    push   pop   front</span><span class="hljs-comment">// deque: 双端队列    push_back、push_front、pop_back、pop_front、front、back</span><span class="hljs-comment">// priority_queue: 堆   top、 push、 pop</span><span class="hljs-comment">// vector: 可变数组  pop_back、push_back()、back</span><span class="hljs-comment">// list: 双向链表   func?</span><span class="hljs-comment">// set:   s.insert(key_value)   erase(key_value)   erase(iterator)  </span><span class="hljs-comment">// map、unordered_map:  m[key] = val;    erase(key_value)   erase(iterator)  </span></code></pre><h3 id="2-常见的命名："><a href="#2-常见的命名：" class="headerlink" title="2. 常见的命名："></a>2. 常见的命名：</h3><pre><code class="hljs cpp"><span class="hljs-comment">// 数组</span>begin、endleft、rightstart、endmin_xxx、max_xxxres、nums<span class="hljs-comment">// 堆、栈、队列</span>m_queue、m_stk、m_deque、max_heap/min_heap、arr  <span class="hljs-comment">// 关于链表</span>node、pNode、ptr、p、l1、l2prev、cur、next、head、taildummy<span class="hljs-comment">// 二叉树</span>root、left、right<span class="hljs-comment">// 图</span>matrix、board、gridi, j, k、m、n、row、colpath<span class="hljs-comment">// 哈希表</span>hash_map、key、val<span class="hljs-comment">// 排序、查找、计数</span>search、find、sort、target、cnt、s、sum、freq<span class="hljs-comment">// 递归、回溯、贪心、动规</span>track、backtrack、dp<span class="hljs-comment">// 其他:</span>reverse、partition、range、cache、cand、point、amount、rest、flag、base、coinsprime、fill、cap、delete_node、</code></pre><h3 id="3-高频题目"><a href="#3-高频题目" class="headerlink" title="3. 高频题目"></a>3. 高频题目</h3><ol><li><a href="https://leetcode-cn.com/problems/generate-parentheses">括号生成</a></li></ol><ol><li><a href="https://leetcode-cn.com/problems/reverse-nodes-in-k-group">K 个一组翻转链表</a></li></ol><ol><li><p><a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array">搜索旋转排序数组</a></p><p>先和左端点进行比较(<strong>&gt;=</strong>)、判定区间是否有序， 然后判断 target 是否在有序区间内 ！</p></li><li><p><a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array">在排序数组中查找元素的第一个和最后一个位置</a></p></li><li><p><a href="https://leetcode-cn.com/problems/trapping-rain-water">接雨水</a></p><p>max_element 函数</p></li><li><p><a href="https://leetcode-cn.com/problems/permutations-ii">全排列 II</a></p></li><li><p><a href="https://leetcode-cn.com/problems/n-queens">N 皇后</a></p></li><li><p><a href="https://leetcode-cn.com/problems/jump-game">跳跃游戏</a></p><p>先判断，再跳跃</p></li><li><p><a href="https://leetcode-cn.com/problems/merge-intervals">合并区间</a></p><p>根据区间右端点进行排序， 利用 vector， 需要判定是否进行区间覆盖</p></li><li><p><a href="https://leetcode-cn.com/problems/word-search">单词搜索</a></p></li><li><p><a href="https://leetcode-cn.com/problems/maximal-rectangle">最大矩形</a></p><pre><code class="hljs cpp"><span class="hljs-comment">// 将其转化为接雨水的问题</span><span class="hljs-keyword">while</span>(!m_stk.empty() &amp;&amp; heights[i] &lt; heights[m_stk.top()])&#123;    <span class="hljs-keyword">int</span> h = heights[m_stk.top()];    m_stk.pop();    <span class="hljs-keyword">int</span> w = m_stk.empty() ?  i : i - m_stk.top() - <span class="hljs-number">1</span>;    area = max(area, w * h);&#125;</code></pre></li><li><p><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal">二叉树的层序遍历</a></p><p>在循环外取 size， 然后进行遍历 需要判断左右子树是否为空</p></li><li><p><a href="https://leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal">从前序与中序遍历序列构造二叉树</a></p><p>（1）前序全局、中序取 map  （2）三个参数: pre_root: 根节点在前序遍历中的下标、中序遍历的左侧边界和右侧边界<br>（3）右子树的根节点: 前序遍历的根节点的坐标 + 左子树的个数 + 1</p></li><li><p><a href="https://leetcode-cn.com/problems/binary-tree-maximum-path-sum">二叉树中的最大路径和</a><br>递归处理的几个步骤：何时跳出递归？ 处理部分？ 递归部分 ？ 返回值<br>helper 函数的作用： 求从根节点出发的最大路径！</p></li><li><p><a href="https://leetcode-cn.com/problems/copy-list-with-random-pointer">复制带随机指针的链表</a><br>（1） 一个 node 的 vec、一个 node 2 idx 的 map  （2） 别忘记 push_back(0)</p></li><li><p><a href="https://leetcode-cn.com/problems/linked-list-cycle-ii">环形链表 II</a><br>(1) 会证明吗?    （2）fast、slow 初始化均为 head， 然后先移动，后判定是否相等</p></li><li><p><a href="https://leetcode-cn.com/problems/binary-tree-preorder-traversal">二叉树的前序遍历</a><br>前序遍历和中序遍历的区别在 push_back 的位置</p></li><li><p><a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array">寻找旋转排序数组中的最小值</a><br>和右端点进行比较， 如果大于 left = mid + 1； 如果小于 right = mid;  如果等于 right—;</p></li><li><p><a href="https://leetcode-cn.com/problems/palindrome-linked-list">回文链表</a><br>(1) 求中间值， 翻转，判断回文 (2) 将中间节点的前置节点的 next 指针置零   (3) 两个指针均不为空 </p></li><li><p><a href="https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree">二叉树的最近公共祖先</a><br><code>if(left &amp;&amp; right) return root;   return left ? left : right;</code></p></li><li><p><a href="https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons">用最少数量的箭引爆气球</a><br>按照左端点进行排序</p></li><li><p><a href="https://leetcode-cn.com/problems/sort-an-array">排序数组</a><br>几个条件不同：<code>while(left != right)</code> 、 <code>left &lt; right</code> 、<code>nums[left] &gt;= pivot</code> （2） return left</p></li><li><p><a href="https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof">最小的k个数</a><br>最小的k个数， 用最大堆， 声明时用 less； 最大的k个数， 用最小堆， 声明时用 greater</p></li><li><p><a href="https://leetcode-cn.com/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof">数据流中的中位数</a><br><img src="/2020/02/03/leetcode-review/1.png" style="zoom:40%;"></p></li><li><p><a href="https://leetcode-cn.com/problems/er-cha-shu-zhong-he-wei-mou-yi-zhi-de-lu-jing-lcof">二叉树中和为某一值的路径</a></p></li><li><p><a href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof">数组中的逆序对</a></p></li><li><p><a href="https://leetcode-cn.com/problems/hua-dong-chuang-kou-de-zui-da-zhi-lcof">滑动窗口的最大值</a></p><p>先进行弹出队列头元素的判断(i - q.front() &gt;= k)，再进行添加 (i &gt;= k-1)   res 添加的是坐标，而不是元素           </p></li><li><p><a href="https://leetcode-cn.com/problems/lru-cache-lcci">LRU 缓存</a></p><p>以对 cache 的操作为主，对 map 的操作只有满了的时候删除 <code>m_map.erase(cache.back().first)</code> 和 两个操作的更改指向 <code>m_map[key] = cache.begin()</code>。 其余的基本是对cache 进行操作。</p></li><li><p>BN 操作的实现</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">bn_forward</span>(<span class="hljs-params">x, gamma, beta, eps</span>):</span>    x_mean = np.mean(x, axis=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>), keepdims=true)    x_var = np.var(x, axis=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>), keepdims=true)        hat_x = (x - x_mean) / np.sqrt(x_var + eps)    out_x = gamma * hat_x + beta        <span class="hljs-keyword">return</span> out_x</code></pre></li><li><p>nms 实现</p><p>最核心的几个操作: 解析出来 x1，y1，x2， y2， scores 和 求 iou<br>排序:   <code>order = scores.argsort()[::-1]</code></p><p>对 iou 的选择：</p><pre><code class="hljs python">iou = ...ids = order[iou &lt; thresh][<span class="hljs-number">0</span>]order = order[ids + <span class="hljs-number">1</span>]</code></pre></li></ol><h3 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4. 参考资料"></a>4. 参考资料</h3><ol><li><a href="https://leetcode.com/">https://leetcode.com/</a></li><li>《剑指 offer》</li><li>《Cracking the Coding Interview: 150 Programming Interview Questions and Solutions》</li><li><a href="https://cspiration.com/leetcodeClassification">https://cspiration.com/leetcodeClassification</a></li><li><a href="https://greyireland.gitbook.io/algorithm-pattern/">https://greyireland.gitbook.io/algorithm-pattern/</a></li><li>leetcode 刷题班 <a href="https://www.bilibili.com/video/BV1GW411Q77S">https://www.bilibili.com/video/BV1GW411Q77S</a></li><li><a href="https://greyireland.gitbook.io/algorithm-pattern/">https://greyireland.gitbook.io/algorithm-pattern/</a></li><li><a href="https://github.com/donnemartin/interactive-coding-challenges">https://github.com/donnemartin/interactive-coding-challenges</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>leetcode-work</title>
    <link href="/2020/02/03/leetcode-work/"/>
    <url>/2020/02/03/leetcode-work/</url>
    
    <content type="html"><![CDATA[<a id="more"></a><h3 id="一些工作中经常会用到的算法"><a href="#一些工作中经常会用到的算法" class="headerlink" title="一些工作中经常会用到的算法"></a>一些工作中经常会用到的算法</h3><ul><li><p>IOU 的计算</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isRectangleOverlap</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; rec1, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; rec2)</span> </span>&#123;    <span class="hljs-keyword">int</span> area_rec1 = (rec1[<span class="hljs-number">3</span>] - rec1[<span class="hljs-number">1</span>]) * (rec1[<span class="hljs-number">2</span>] - rec1[<span class="hljs-number">0</span>]);    <span class="hljs-keyword">int</span> aera_rec2 = (rec2[<span class="hljs-number">3</span>] - rec2[<span class="hljs-number">1</span>]) * (rec2[<span class="hljs-number">2</span>] - rec2[<span class="hljs-number">0</span>]);    <span class="hljs-keyword">int</span> w = max(<span class="hljs-number">0.0</span>, min(rec1[<span class="hljs-number">2</span>], rec2[<span class="hljs-number">2</span>]) - max(rec1[<span class="hljs-number">0</span>], rec2[<span class="hljs-number">0</span>]));    <span class="hljs-keyword">int</span> h = max(<span class="hljs-number">0.0</span>, min(rec1[<span class="hljs-number">3</span>], rec2[<span class="hljs-number">3</span>]) - max(rec1[<span class="hljs-number">1</span>], rec2[<span class="hljs-number">1</span>]));    <span class="hljs-keyword">int</span> intersect = w * h;    <span class="hljs-keyword">return</span> intersect /(rec1_area + rec1_area - intersect);&#125;</code></pre></li><li><p>resnet 残差(pytorch)</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BasicBlock</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; 假设输入通道和输出通道一致 &quot;&quot;&quot;</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels</span>):</span>        super(BasicBlock, self).__init__()        self.conv1 = nn.Conv2d(in_channels, out_channels, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)        self.bn1 = nn.BatchNorm(out_channels)        self.relu = nn.ReLU(inplace = <span class="hljs-literal">True</span>);                self.conv2 = nn.Conv2d(out_channels, out_channels, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)        self.bn2 = nn.BatchNorm(out_channels)                self.shortcut = nn.Sequential()        <span class="hljs-keyword">if</span> in_channels != out_channels:          self.short_cut = nn.Sequential(nn.Conv2d(in_channels, out_channels, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>),                                         nn.BatchNorm(out_channels))            <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        out = self.relu(self.bn1(self.conv1(x)))        out = self.bn2(self.conv2(x))        out += self.shortcut(x)        <span class="hljs-keyword">return</span> self.relu(out)</code></pre></li><li><p>翻转图像、反转图像、旋转矩阵、图像渲染、图像重叠</p><pre><code class="hljs cpp"><span class="hljs-comment">// 832. 翻转图像</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">flipAndInvertImage</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; A)</span> </span>&#123;    <span class="hljs-keyword">if</span>(A.size() == <span class="hljs-number">0</span> || A[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> A;    <span class="hljs-keyword">int</span> m = A.size();    <span class="hljs-keyword">int</span> n = A[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n/<span class="hljs-number">2</span>; j++)&#123;            swap(A[i][j], A[i][n-j<span class="hljs-number">-1</span>]);        &#125;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;            A[i][j] = <span class="hljs-number">1</span> - A[i][j];        &#125;    &#125;    <span class="hljs-keyword">return</span> A;&#125;<span class="hljs-comment">// 48. 旋转矩阵</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">rotate</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;    <span class="hljs-keyword">if</span>(matrix.size() == <span class="hljs-number">0</span> || matrix[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">int</span> row = matrix.size(), col = matrix[<span class="hljs-number">0</span>].size();    <span class="hljs-comment">// 沿主对角线对折</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = i; j &lt; col; j++)&#123;            swap(matrix[i][j], matrix[j][i]);        &#125;    &#125;    <span class="hljs-comment">// 水平翻转</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; col / <span class="hljs-number">2</span>; j++)&#123;            swap(matrix[i][j], matrix[i][col<span class="hljs-number">-1</span>-j]);        &#125;    &#125;    <span class="hljs-keyword">return</span>;&#125;<span class="hljs-comment">// 733.图像渲染 颜色填充</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">floodFill</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; image, <span class="hljs-keyword">int</span> sr, <span class="hljs-keyword">int</span> sc, <span class="hljs-keyword">int</span> newColor)</span> </span>&#123;    <span class="hljs-keyword">if</span>(image.size() == <span class="hljs-number">0</span> || image[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> image;    <span class="hljs-keyword">int</span> oriColor = image[sr][sc];    bfs(image, sr, sc, newColor, oriColor);    <span class="hljs-keyword">return</span> image;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; image, <span class="hljs-keyword">int</span> sr, <span class="hljs-keyword">int</span> sc, <span class="hljs-keyword">int</span> newColor, <span class="hljs-keyword">int</span> oriColor)</span></span>&#123;    <span class="hljs-keyword">if</span>(sr &gt;= image.size() || sc &gt;= image[<span class="hljs-number">0</span>].size()  || sc &lt; <span class="hljs-number">0</span> || sr &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">if</span>(image[sr][sc] == oriColor &amp;&amp; image[sr][sc] != newColor)&#123;        image[sr][sc] = newColor;        bfs(image, sr<span class="hljs-number">-1</span>, sc, newColor, oriColor);        bfs(image, sr+<span class="hljs-number">1</span>, sc, newColor, oriColor);        bfs(image, sr, sc<span class="hljs-number">-1</span>, newColor, oriColor);        bfs(image, sr, sc+<span class="hljs-number">1</span>, newColor, oriColor);    &#125;&#125;</code></pre></li><li><p>BN 层的实现</p><pre><code class="hljs python"><span class="hljs-comment"># 简化版</span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">batchnorm_forward</span>(<span class="hljs-params">x, gamma, beta, eps</span>):</span>    <span class="hljs-comment"># calculate mean &amp; var</span>    batch_mean = np.mean(x, axis=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdims=<span class="hljs-literal">True</span>)    batch_var = np.var(x, axis=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdims=<span class="hljs-literal">True</span>)    <span class="hljs-comment"># normalize</span>    x_hat = (inp - batch_mean) / np.sqrt(batch_var + eps)    <span class="hljs-comment"># scale &amp; shift</span>    out = x_hat * gamma + beta    <span class="hljs-keyword">return</span> out</code></pre><pre><code class="hljs python"><span class="hljs-comment"># 复杂版本</span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">batchnorm_forward</span>(<span class="hljs-params">x, gamma, beta, bn_param</span>):</span>    mode = bn_param[<span class="hljs-string">&#x27;mode&#x27;</span>]    eps = bn_param.get(<span class="hljs-string">&#x27;eps&#x27;</span>, <span class="hljs-number">1e-5</span>)     momentum = bn_param.get(<span class="hljs-string">&#x27;momentum&#x27;</span>, <span class="hljs-number">0.9</span>)        N, D = s.shape  <span class="hljs-comment"># N is batch_size * H * W, D is channels</span>    running_mean = bn_param.get(<span class="hljs-string">&#x27;running_mean&#x27;</span>, np.zeros(D, dtype=x.dtype))    running_var = bn_param.get(<span class="hljs-string">&#x27;running_var&#x27;</span>, np.zeros(D, dtype=x.dtype))        out, cahce = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>    <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>:            batch_mean = np.mean(x, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)        batch_var = np.var(x, axis=<span class="hljs-number">0</span>, keepdims=<span class="hljs-literal">True</span>)         x_norm = (inp - batch_mean) / np.sqrt(batch_var + eps)        out = x_norm * gamma + beta        <span class="hljs-comment"># store variables in cache</span>        cache = (x, x_norm, gamma, beta, eps, batch_mean, batch_var)        <span class="hljs-comment"># update running_mean &amp; running var</span>        running_mean = momentum * running_mean + (<span class="hljs-number">1</span> - momentum) * batch_mean        running_var = momentum * running_var + (<span class="hljs-number">1</span> - momentum) * batch_var    <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;test&#x27;</span>:        x_norm = (x - running_mean) / np.sqrt(running_var + eps)        out = x_norm * gamma + beta            bn_param[<span class="hljs-string">&#x27;running_mean&#x27;</span>] = running_mean    bn_param[<span class="hljs-string">&#x27;running_var&#x27;</span>] = running_var    <span class="hljs-keyword">return</span> out, cache</code></pre></li><li><p>kmeans算法</p><pre><code class="hljs python"></code></pre></li><li><p>手写 nms 算法</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">pu_cpu_nms</span>(<span class="hljs-params">dets, thresh</span>):</span>    <span class="hljs-comment"># 提取四边形并计算区域面积</span>    x1 = dets[:, <span class="hljs-number">0</span>]    y1 = dets[:, <span class="hljs-number">1</span>]    x2 = dets[:, <span class="hljs-number">2</span>]    y2 = dets[:, <span class="hljs-number">3</span>]    area = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)    <span class="hljs-comment"># 提取 scores 并进行排序</span>    scores = dets[:, <span class="hljs-number">4</span>]    order = scores.argsort()[::<span class="hljs-number">-1</span>]        keep = []    <span class="hljs-keyword">while</span> order.size &gt; <span class="hljs-number">0</span>:        <span class="hljs-comment"># 计算 iou</span>        i = order[<span class="hljs-number">0</span>]        keep.append(i)        xx1 = np.maximum(x1[i], x1[<span class="hljs-number">1</span>:])        yy1 = np.maximun(y1[i], y1[<span class="hljs-number">1</span>:])        xx2 = np.minimum(x2[i], x2[<span class="hljs-number">1</span>:])        yy2 = np.minimum(y2[i], y2[<span class="hljs-number">1</span>:])                w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)                inter = w * h        ovr = inter / (area[i] + area[order[<span class="hljs-number">1</span>:]] - inter)                <span class="hljs-comment"># 保留小于 thresh 的 bbox</span>        inds = np.where(ovr &lt;= thresh)[<span class="hljs-number">0</span>]        order = order[inds + <span class="hljs-number">1</span>]            <span class="hljs-keyword">return</span> keep</code></pre></li><li><p>最大的岛屿面积</p><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid, <span class="hljs-keyword">int</span> r, <span class="hljs-keyword">int</span> c, <span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span></span>&#123;    <span class="hljs-keyword">if</span>(r &lt; <span class="hljs-number">0</span> || c &lt; <span class="hljs-number">0</span> || r &gt;= m || c &gt;= n || grid[r][c] == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    grid[r][c] = <span class="hljs-number">0</span>;    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + bfs(grid, r<span class="hljs-number">-1</span>, c, m, n) + bfs(grid, r+<span class="hljs-number">1</span>, c, m, n)                 + bfs(grid, r, c<span class="hljs-number">-1</span>, m, n) + bfs(grid, r, c+<span class="hljs-number">1</span>, m, n);&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxAreaOfIsland</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;    <span class="hljs-keyword">int</span> max_area = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(grid.size() == <span class="hljs-number">0</span> || grid[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = grid.size();    <span class="hljs-keyword">int</span> n = grid[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(grid[i][j] == <span class="hljs-number">1</span>) &#123;                <span class="hljs-keyword">int</span> cur_area = bfs(grid, i, j, m, n);                max_area = max(max_area, cur_area);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> max_area;&#125;</code></pre></li><li><p>手写卷积</p><pre><code class="hljs cpp"></code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>leetcode-algorithm</title>
    <link href="/2020/02/03/leetcode-algorithm/"/>
    <url>/2020/02/03/leetcode-algorithm/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h3 id="1-位运算"><a href="#1-位运算" class="headerlink" title="1. 位运算"></a>1. 位运算</h3><p><img src="/2020/02/03/leetcode-algorithm/bit.png" alt></p><h4 id="1-常见技巧总结"><a href="#1-常见技巧总结" class="headerlink" title="(1) 常见技巧总结"></a>(1) 常见技巧总结</h4><ol><li><p>等号的优先级是大于位运算的!  n &amp; (n-1) == 0 等价于 n &amp; ((n-1) == 0) 而不是 (n &amp; (n-1)) == 0</p></li><li><p>对 32bit 位分别进行运算是一种思想 !</p></li></ol><pre><code class="hljs cpp"><span class="hljs-comment">// &amp;   与    |   或    ~  非      ^   异或</span><span class="hljs-comment">// 最常见的几个用法</span><span class="hljs-comment">// (1) </span>n &amp; (n<span class="hljs-number">-1</span>)  <span class="hljs-comment">// 将二进制 n 的最后一位 由 1 变成 0</span>n ^ (n &amp; (n<span class="hljs-number">-1</span>)) <span class="hljs-comment">// 只保留最后一个 bit 位， 将 n = 1110 变为 n = 0010</span><span class="hljs-comment">// (2) </span><span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) ret ^= num;  <span class="hljs-comment">// 利用 n ^ n = 0 进行去重  </span><span class="hljs-comment">// (3) 取位和置位</span>n |= <span class="hljs-number">1</span> &lt;&lt; bit<span class="hljs-comment">// 置位操作: 将 n 的 bit 位设置为 1, 1 &lt;&lt; bit 产生一个只有 bit 位为 1， 其他均为 0 的数</span>n &amp;= ~(<span class="hljs-number">1</span> &lt;&lt; bit) <span class="hljs-comment">// 置位操作， 将 n 的 bit 位置 0</span>n &amp; <span class="hljs-number">1</span> &lt;&lt; bit   <span class="hljs-comment">// 取位操作: 判断 n 的 bit 位是否是 1</span></code></pre><h4 id="2-典型例题"><a href="#2-典型例题" class="headerlink" title="(2) 典型例题"></a>(2) 典型例题</h4><h5 id="①-使用位运算替换-、-gt-、swap-操作"><a href="#①-使用位运算替换-、-gt-、swap-操作" class="headerlink" title="① 使用位运算替换 +、&gt;、swap 操作"></a>① 使用位运算替换 +、&gt;、swap 操作</h5><h6 id="371-https-leetcode-cn-com-problems-sum-of-two-integers"><a href="#371-https-leetcode-cn-com-problems-sum-of-two-integers" class="headerlink" title="[371] https://leetcode-cn.com/problems/sum-of-two-integers/"></a>[371] <a href="https://leetcode-cn.com/problems/sum-of-two-integers/">https://leetcode-cn.com/problems/sum-of-two-integers/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">getSum</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span> </span>&#123;    <span class="hljs-keyword">while</span>(b)&#123;        <span class="hljs-keyword">int</span> carry = (<span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>)(a &amp; b) &lt;&lt; <span class="hljs-number">1</span>;        a = a ^ b;        b = carry;    &#125;    <span class="hljs-keyword">return</span> a;&#125;</code></pre><h5 id="②-n-amp-n-1-将二进制-n-的最后一位-1-变成-0"><a href="#②-n-amp-n-1-将二进制-n-的最后一位-1-变成-0" class="headerlink" title="② n &amp; (n - 1) 将二进制 n 的最后一位 1 变成 0"></a>② n &amp; (n - 1) 将二进制 n 的最后一位 1 变成 0</h5><h6 id="191-https-leetcode-cn-com-problems-number-of-1-bits"><a href="#191-https-leetcode-cn-com-problems-number-of-1-bits" class="headerlink" title="[191] https://leetcode-cn.com/problems/number-of-1-bits/"></a>[191] <a href="https://leetcode-cn.com/problems/number-of-1-bits/">https://leetcode-cn.com/problems/number-of-1-bits/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">hammingWeight</span><span class="hljs-params">(<span class="hljs-keyword">uint32_t</span> n)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">0</span>)&#123;        n = n &amp; (n<span class="hljs-number">-1</span>);        res++;    &#125;    <span class="hljs-keyword">return</span> res; &#125;</code></pre><h6 id="338-https-leetcode-com-problems-counting-bits-🌟🌟"><a href="#338-https-leetcode-com-problems-counting-bits-🌟🌟" class="headerlink" title="[338] https://leetcode.com/problems/counting-bits/    🌟🌟"></a>[338] <a href="https://leetcode.com/problems/counting-bits/">https://leetcode.com/problems/counting-bits/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// i &amp; (i - 1) 可以去掉 i 最右边的一个1(如果有)，</span><span class="hljs-comment">// 所以 i 的1的个数就是 i &amp; (i - 1)的1的个数加上1</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">countBits</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(num + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= num; i++)&#123;        dp[i] = dp[i &amp; (i<span class="hljs-number">-1</span>)] + <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> dp;&#125;</code></pre><h6 id="461-https-leetcode-cn-com-problems-hamming-distance"><a href="#461-https-leetcode-cn-com-problems-hamming-distance" class="headerlink" title="[461] https://leetcode-cn.com/problems/hamming-distance/"></a>[461] <a href="https://leetcode-cn.com/problems/hamming-distance/">https://leetcode-cn.com/problems/hamming-distance/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 求异或结果的 1 的个数</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">hammingDistance</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x, <span class="hljs-keyword">int</span> y)</span> </span>&#123;    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>, n = x ^ y;    <span class="hljs-keyword">while</span>(n)&#123;        n &amp;= (n<span class="hljs-number">-1</span>);        cnt++;    &#125;    <span class="hljs-keyword">return</span> cnt;&#125;</code></pre><h6 id="477-https-leetcode-cn-com-problems-total-hamming-distance"><a href="#477-https-leetcode-cn-com-problems-total-hamming-distance" class="headerlink" title="[477] https://leetcode-cn.com/problems/total-hamming-distance/"></a>[477] <a href="https://leetcode-cn.com/problems/total-hamming-distance/">https://leetcode-cn.com/problems/total-hamming-distance/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// !! 对 32 bit 的每一位进行处理，这是一种思想</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">totalHammingDistance</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">32</span>; i++)&#123;        <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) <span class="hljs-keyword">if</span>(n &amp; (<span class="hljs-number">1</span> &lt;&lt; i)) cnt += <span class="hljs-number">1</span>;        res += (cnt) * (nums.size() - cnt);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="231-https-leetcode-cn-com-problems-power-of-two-🌟🌟"><a href="#231-https-leetcode-cn-com-problems-power-of-two-🌟🌟" class="headerlink" title="[231] https://leetcode-cn.com/problems/power-of-two/  🌟🌟"></a>[231] <a href="https://leetcode-cn.com/problems/power-of-two/">https://leetcode-cn.com/problems/power-of-two/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 如果一个数是2的幂，那么其二进制中只有一位数为 1</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPowerOfTwo</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n &lt;= <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">return</span> (n &amp; (n<span class="hljs-number">-1</span>)) == <span class="hljs-number">0</span>;&#125;</code></pre><h6 id="326-https-leetcode-cn-com-problems-power-of-three"><a href="#326-https-leetcode-cn-com-problems-power-of-three" class="headerlink" title="[326] https://leetcode-cn.com/problems/power-of-three/"></a>[326] <a href="https://leetcode-cn.com/problems/power-of-three/">https://leetcode-cn.com/problems/power-of-three/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPowerOfThree</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n &lt; <span class="hljs-number">3</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">while</span>( n % <span class="hljs-number">3</span> == <span class="hljs-number">0</span>)&#123;        n /= <span class="hljs-number">3</span>;    &#125;    <span class="hljs-keyword">return</span> n == <span class="hljs-number">1</span>;&#125;</code></pre><h6 id="342-https-leetcode-cn-com-problems-power-of-four"><a href="#342-https-leetcode-cn-com-problems-power-of-four" class="headerlink" title="[342] https://leetcode-cn.com/problems/power-of-four/"></a>[342] <a href="https://leetcode-cn.com/problems/power-of-four/">https://leetcode-cn.com/problems/power-of-four/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// !!! 等号的优先级是要大于 位运算的</span><span class="hljs-comment">// power of four的特点是其二进制表示除了只有1位为1外，</span><span class="hljs-comment">// 其二进制为1的数在奇数数位，所以可以根据 num &amp; 0xaaaaaaaa 来获取结果</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPowerOfFour</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num)</span> </span>&#123;    <span class="hljs-keyword">return</span> (num &gt; <span class="hljs-number">0</span>) &amp;&amp; (num &amp; (num - <span class="hljs-number">1</span>)) == <span class="hljs-number">0</span> &amp;&amp; (num &amp; <span class="hljs-number">0xaaaaaaaa</span>) == <span class="hljs-number">0</span>; &#125;</code></pre><h5 id="③-异或运算-n-n-利用-n-n-0-来去重"><a href="#③-异或运算-n-n-利用-n-n-0-来去重" class="headerlink" title="③ 异或运算  n ^ n, 利用 n ^ n = 0 来去重"></a>③ 异或运算  n ^ n, 利用 n ^ n = 0 来去重</h5><pre><code class="hljs cpp"><span class="hljs-comment">// 常见用法</span><span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) ret ^= num;</code></pre><h6 id="136-https-leetcode-com-problems-single-number-🌟🌟"><a href="#136-https-leetcode-com-problems-single-number-🌟🌟" class="headerlink" title="[136] https://leetcode.com/problems/single-number/      🌟🌟"></a>[136] <a href="https://leetcode.com/problems/single-number/">https://leetcode.com/problems/single-number/</a>      🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">singleNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) res ^= n;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="389-https-leetcode-com-problems-find-the-difference"><a href="#389-https-leetcode-com-problems-find-the-difference" class="headerlink" title="[389] https://leetcode.com/problems/find-the-difference/"></a>[389] <a href="https://leetcode.com/problems/find-the-difference/">https://leetcode.com/problems/find-the-difference/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">char</span> <span class="hljs-title">findTheDifference</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s, <span class="hljs-built_in">string</span> t)</span> </span>&#123;    <span class="hljs-keyword">char</span> res = t[<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; s.size(); i++) res ^= s[i];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; t.size(); i++) res ^= t[i];    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="268-https-leetcode-com-problems-missing-number"><a href="#268-https-leetcode-com-problems-missing-number" class="headerlink" title="[268] https://leetcode.com/problems/missing-number/"></a>[268] <a href="https://leetcode.com/problems/missing-number/">https://leetcode.com/problems/missing-number/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">missingNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> len = nums.size()， res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt;= len; i++)   res ^= i;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; len; i++)  res ^= nums[i];    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-comment">// 解法二: 求和 0-n, 然后减去数组中所有的数</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">missingNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt;= nums.size(); i++) res ^= i;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++) res ^= nums[i];    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="260-https-leetcode-cn-com-problems-single-number-iii-🌟🌟"><a href="#260-https-leetcode-cn-com-problems-single-number-iii-🌟🌟" class="headerlink" title="[260] https://leetcode-cn.com/problems/single-number-iii/     🌟🌟"></a>[260] <a href="https://leetcode-cn.com/problems/single-number-iii/">https://leetcode-cn.com/problems/single-number-iii/</a>     🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">singleNumbers</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> diff = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) diff ^= n;    <span class="hljs-keyword">int</span> last_diff = (diff &amp; (diff - <span class="hljs-number">1</span>)) ^ diff;    <span class="hljs-keyword">int</span> resA = <span class="hljs-number">0</span>, resB = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] &amp; last_diff) resA ^= nums[i];        <span class="hljs-keyword">else</span> resB ^= nums[i];    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &#123;resA, resB&#125;;&#125;</code></pre><h6 id="169-https-leetcode-cn-com-problems-majority-element-🌟🌟"><a href="#169-https-leetcode-cn-com-problems-majority-element-🌟🌟" class="headerlink" title="[169] https://leetcode-cn.com/problems/majority-element/   🌟🌟"></a>[169] <a href="https://leetcode-cn.com/problems/majority-element/">https://leetcode-cn.com/problems/majority-element/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 没有用到 位运算， 但是大部分题目都会将其放到位运算这个类别当中</span><span class="hljs-comment">// 解法二: 摩尔投票法</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">majorityElement</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> cur = nums[<span class="hljs-number">0</span>];    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] != cur)&#123;            --cnt;            <span class="hljs-keyword">if</span>(cnt &lt;= <span class="hljs-number">0</span>)&#123;                cur = nums[i];                cnt = <span class="hljs-number">1</span>;            &#125;        &#125;<span class="hljs-keyword">else</span>&#123;            cnt += <span class="hljs-number">1</span>;         &#125;    &#125;    <span class="hljs-keyword">return</span> cur;&#125;</code></pre><h5 id="④-取位和-置位操作"><a href="#④-取位和-置位操作" class="headerlink" title="④  取位和 置位操作"></a>④  取位和 置位操作</h5><pre><code class="hljs cpp">n |= <span class="hljs-number">1</span> &lt;&lt; bit<span class="hljs-comment">// 置位操作: 将 n 的 bit 位设置为 1, 1 &lt;&lt; bit 产生一个只有 bit 位为 1， 其他均为 0 的数</span>n &amp;= ~(<span class="hljs-number">1</span> &lt;&lt; bit) <span class="hljs-comment">// 置位操作， 将 n 的 bit 位置 0</span>n &amp; <span class="hljs-number">1</span> &lt;&lt; bit   <span class="hljs-comment">// 取位操作: 判断 n 的 bit 位是否是 1</span></code></pre><h6 id="190-https-leetcode-com-problems-reverse-bits"><a href="#190-https-leetcode-com-problems-reverse-bits" class="headerlink" title="[190] https://leetcode.com/problems/reverse-bits/"></a>[190] <a href="https://leetcode.com/problems/reverse-bits/">https://leetcode.com/problems/reverse-bits/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// A &amp; (1 &lt;&lt; i)  获取 i 位的 bit</span><span class="hljs-comment">// A |= (1 &lt;&lt; i)  将 i 位 设置为 bit</span><span class="hljs-function"><span class="hljs-keyword">uint32_t</span> <span class="hljs-title">reverseBits</span><span class="hljs-params">(<span class="hljs-keyword">uint32_t</span> n)</span> </span>&#123;    <span class="hljs-keyword">uint32_t</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">32</span>; i++)&#123;        <span class="hljs-keyword">bool</span> bit = (<span class="hljs-number">1</span> &lt;&lt; i) &amp; n; <span class="hljs-comment">// get</span>        res |= (bit &lt;&lt; (<span class="hljs-number">32</span> - i - <span class="hljs-number">1</span>)); <span class="hljs-comment">// set</span>    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="137-https-leetcode-com-problems-single-number-ii"><a href="#137-https-leetcode-com-problems-single-number-ii" class="headerlink" title="[137] https://leetcode.com/problems/single-number-ii/"></a>[137] <a href="https://leetcode.com/problems/single-number-ii/">https://leetcode.com/problems/single-number-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">singleNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">32</span>; i++)&#123;        <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums) <span class="hljs-keyword">if</span>((<span class="hljs-number">1</span> &lt;&lt; i) &amp; n) cnt+=<span class="hljs-number">1</span>;        <span class="hljs-keyword">if</span>(cnt % <span class="hljs-number">3</span> == <span class="hljs-number">1</span>) res += (<span class="hljs-number">1</span> &lt;&lt; i);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h5 id="⑤-其他"><a href="#⑤-其他" class="headerlink" title="⑤ 其他"></a>⑤ 其他</h5><h6 id="89-https-leetcode-cn-com-problems-gray-code"><a href="#89-https-leetcode-cn-com-problems-gray-code" class="headerlink" title="[89] https://leetcode-cn.com/problems/gray-code/"></a>[89] <a href="https://leetcode-cn.com/problems/gray-code/">https://leetcode-cn.com/problems/gray-code/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">grayCode</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">int</span> max = <span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>, n);    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; max; i++)&#123;        res.push_back((i &gt;&gt; <span class="hljs-number">1</span>) ^ i); <span class="hljs-comment">// 格雷码运算</span>    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="201-https-leetcode-cn-com-problems-bitwise-and-of-numbers-range"><a href="#201-https-leetcode-cn-com-problems-bitwise-and-of-numbers-range" class="headerlink" title="[201] https://leetcode-cn.com/problems/bitwise-and-of-numbers-range/"></a>[201] <a href="https://leetcode-cn.com/problems/bitwise-and-of-numbers-range/">https://leetcode-cn.com/problems/bitwise-and-of-numbers-range/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">rangeBitwiseAnd</span><span class="hljs-params">(<span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = n;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = m; i &lt; n &amp; res != <span class="hljs-number">0</span>; i++)&#123;  <span class="hljs-comment">// 添加一个 res != 0 防止超时</span>        res &amp;= i;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h3 id="4-数学和归纳总结"><a href="#4-数学和归纳总结" class="headerlink" title="4. 数学和归纳总结"></a>4. 数学和归纳总结</h3><h6 id="7-整数反转-https-leetcode-cn-com-problems-reverse-integer"><a href="#7-整数反转-https-leetcode-cn-com-problems-reverse-integer" class="headerlink" title="[7] 整数反转 https://leetcode-cn.com/problems/reverse-integer/"></a>[7] 整数反转 <a href="https://leetcode-cn.com/problems/reverse-integer/">https://leetcode-cn.com/problems/reverse-integer/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">reverse</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span> </span>&#123;    <span class="hljs-keyword">long</span> res = <span class="hljs-number">0</span>;    <span class="hljs-comment">// 可以处理负数的情况</span>    <span class="hljs-keyword">while</span>(x != <span class="hljs-number">0</span>)&#123;        res = res * <span class="hljs-number">10</span> + x % <span class="hljs-number">10</span>;        x /= <span class="hljs-number">10</span>;    &#125;    <span class="hljs-keyword">if</span>(res &gt; INT_MAX || res &lt; INT_MIN) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">return</span> res;  &#125;</code></pre><h6 id="lcof-65-https-leetcode-cn-com-problems-bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof"><a href="#lcof-65-https-leetcode-cn-com-problems-bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof" class="headerlink" title="[lcof 65] https://leetcode-cn.com/problems/bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof/"></a>[lcof 65] <a href="https://leetcode-cn.com/problems/bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof/">https://leetcode-cn.com/problems/bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">add</span><span class="hljs-params">(<span class="hljs-keyword">int</span> a, <span class="hljs-keyword">int</span> b)</span> </span>&#123;    <span class="hljs-keyword">while</span>(b)&#123;        <span class="hljs-keyword">int</span> c_in = (<span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>) (a &amp; b) &lt;&lt; <span class="hljs-number">1</span>; <span class="hljs-comment">// 进位</span>        a = a ^ b; <span class="hljs-comment">// 相加</span>        b = c_in; <span class="hljs-comment">// 赋值</span>    &#125;    <span class="hljs-keyword">return</span> a;&#125;</code></pre><h6 id="292-Nim-游戏-https-leetcode-cn-com-problems-nim-game"><a href="#292-Nim-游戏-https-leetcode-cn-com-problems-nim-game" class="headerlink" title="[292] Nim 游戏 https://leetcode-cn.com/problems/nim-game/"></a>[292] Nim 游戏 <a href="https://leetcode-cn.com/problems/nim-game/">https://leetcode-cn.com/problems/nim-game/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">canWinNim</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-comment">// 巴什博奕，n % (m+1) != 0 时，先手总是会赢的</span>    <span class="hljs-keyword">return</span> n % <span class="hljs-number">4</span> != <span class="hljs-number">0</span>;&#125;</code></pre><h6 id="50-Pow-x-n-https-leetcode-cn-com-problems-powx-n-🌟🌟🌟"><a href="#50-Pow-x-n-https-leetcode-cn-com-problems-powx-n-🌟🌟🌟" class="headerlink" title="[50]. Pow(x, n)] https://leetcode-cn.com/problems/powx-n/   🌟🌟🌟"></a>[50]. Pow(x, n)] <a href="https://leetcode-cn.com/problems/powx-n/">https://leetcode-cn.com/problems/powx-n/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">myPow</span><span class="hljs-params">(<span class="hljs-keyword">double</span> x, <span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">double</span> res = <span class="hljs-number">1.0</span>;    <span class="hljs-comment">// 录用快速幂进行解题:</span>    <span class="hljs-comment">//  pow = x^n = </span>    <span class="hljs-comment">//    (x^2)^(n//2), n为偶数</span>    <span class="hljs-comment">//   x(x^2)^(n//2), n为奇数</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = n; i != <span class="hljs-number">0</span>; i /= <span class="hljs-number">2</span>)&#123;        <span class="hljs-keyword">if</span>(i % <span class="hljs-number">2</span> != <span class="hljs-number">0</span>)&#123; <span class="hljs-comment">// 这里用 i % 2 ！= 0 可以同时处理 正负两种情况!</span>            res *= x;        &#125;        x *= x;    &#125;    <span class="hljs-keyword">return</span> n &gt; <span class="hljs-number">0</span> ? res : <span class="hljs-number">1.0</span> / res;&#125;</code></pre><h3 id="2-回溯、贪心、分治、递归"><a href="#2-回溯、贪心、分治、递归" class="headerlink" title="2. 回溯、贪心、分治、递归"></a>2. 回溯、贪心、分治、递归</h3><h4 id="2-1-回溯"><a href="#2-1-回溯" class="headerlink" title="2.1 回溯"></a>2.1 回溯</h4><p>​        回溯法又称为试探法， <strong>但当探索到某一步时， 发现原先选择达不到目标，就退回一步重新选择，这种走不通就退回再走的技术</strong>称为回溯法。 常见的题目有：子集、组合、全排列、括号生成、电话号码的字母组合</p><ul><li><p>记住：传递引用、排序、去重(利用集合去重)。 这其中， 排序和去重可以用于降低复杂度</p></li><li><p>剪枝:</p><p>(1) 当容器长度等于深度的时候</p><p>(2) <code>find(path.begin(), path.end(), nums[i]) == path.end()</code>  只有不在 track 中才添加</p><p>(3) 使用 flag 进行标记  -&gt; vistited</p></li><li><p>一般传递的几个参数：res、track、depth、nums(原有数组)</p></li><li><p>模板</p><pre><code class="hljs cpp">result = []def backtrack(路径, 选择列表):    <span class="hljs-keyword">if</span> 不满足条件: <span class="hljs-keyword">return</span>        <span class="hljs-keyword">if</span> 满足结束条件:        result.add(路径)        <span class="hljs-keyword">return</span>          <span class="hljs-keyword">for</span> 选择 in 选择列表:        做选择        backtrack(路径, 选择列表)        撤销选择</code></pre></li><li><p>思考的过程就是构建决策树的过程， 要有这个思维</p></li></ul><h6 id="78-子集-https-leetcode-cn-com-problems-subsets"><a href="#78-子集-https-leetcode-cn-com-problems-subsets" class="headerlink" title="[78. 子集] https://leetcode-cn.com/problems/subsets/"></a>[78. 子集] <a href="https://leetcode-cn.com/problems/subsets/">https://leetcode-cn.com/problems/subsets/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">subsets</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;   <span class="hljs-comment">// 存储最终结果的 res</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span> &gt; track;         <span class="hljs-comment">// 回溯时候的各个子集元素</span>    backtrack(nums, <span class="hljs-number">0</span>, res, track);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">backtrack</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> start, </span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;&amp; res, </span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; track)</span></span>&#123;    res.push_back(track);    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start; i &lt; nums.size(); i++)&#123;        track.push_back(nums[i]);  <span class="hljs-comment">// 做选择</span>        backtrack(nums, i+<span class="hljs-number">1</span>, res, track);  <span class="hljs-comment">// 回溯</span>        track.pop_back();  <span class="hljs-comment">// 撤销选择</span>    &#125;&#125;</code></pre><blockquote><p><strong>回溯</strong>的执行步骤如下所示：</p><p>初始化时为空集合</p><p>当第一次递归时， 分别添加 [1]、[2]、[3] 三个集合</p><p>当第二次递归时， 对于集合 [1]， 添加 [2] 组成 [1, 2]， 添加 [3]  组成 [1, 3]</p><p>​                                对于集合 [2]， 添加 [3] 组成 [2, 3]</p><p>第三次递归时， 对于集合 [1, 2]， 添加 [3] 组成 [1, 2, 3] 即可</p></blockquote><p>回溯模板</p><pre><code class="hljs python">result = []<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">backtrack</span>(<span class="hljs-params">路径, 选择列表</span>):</span>    <span class="hljs-keyword">if</span> 不满足条件: <span class="hljs-keyword">return</span>        <span class="hljs-keyword">if</span> 满足结束条件:        result.add(路径)        <span class="hljs-keyword">return</span>          <span class="hljs-keyword">for</span> 选择 <span class="hljs-keyword">in</span> 选择列表:        做选择        backtrack(路径, 选择列表)        撤销选择</code></pre><h6 id="90-子集-II-https-leetcode-cn-com-problems-subsets-ii"><a href="#90-子集-II-https-leetcode-cn-com-problems-subsets-ii" class="headerlink" title="[90. 子集 II] https://leetcode-cn.com/problems/subsets-ii/"></a>[90. 子集 II] <a href="https://leetcode-cn.com/problems/subsets-ii/">https://leetcode-cn.com/problems/subsets-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">subsetsWithDup</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; track;    sort(nums.begin(), nums.end());  <span class="hljs-comment">// 预处理：排序</span>    backtrack(nums, <span class="hljs-number">0</span>, res, track);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">backtrack</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; nums, <span class="hljs-keyword">int</span> start,</span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;&amp; res,</span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span> &gt;&amp; track)</span></span>&#123;   <span class="hljs-keyword">if</span>(find(res.begin(), res.end(), track) == res.end()) res.push_back(track);  <span class="hljs-comment">// 剪枝， 排除重复元素</span>   <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start; i &lt; nums.size(); i++)&#123;       track.push_back(nums[i]);       backtrack(nums, i+<span class="hljs-number">1</span>, res, track);       track.pop_back();   &#125;&#125;</code></pre><h6 id="46-全排列-https-leetcode-cn-com-problems-permutations-🌟🌟🌟-🌟"><a href="#46-全排列-https-leetcode-cn-com-problems-permutations-🌟🌟🌟-🌟" class="headerlink" title="[46] 全排列 https://leetcode-cn.com/problems/permutations/  🌟🌟🌟 🌟"></a>[46] 全排列 <a href="https://leetcode-cn.com/problems/permutations/">https://leetcode-cn.com/problems/permutations/</a>  🌟🌟🌟 🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">permute</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; track;    <span class="hljs-keyword">int</span> n = nums.size();    trackback(track, res, <span class="hljs-number">0</span>, nums);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">trackback</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; track, </span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;&amp; res,</span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-keyword">int</span> depth,</span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; nums</span></span><span class="hljs-function"><span class="hljs-params">              )</span></span>&#123;    <span class="hljs-keyword">int</span> n = nums.size();    <span class="hljs-keyword">if</span>(depth == n) res.push_back(track);    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;        <span class="hljs-keyword">if</span>(find(track.begin(), track.end(), nums[i]) == track.end())&#123; <span class="hljs-comment">// 防止出现重复元素</span>            track.push_back(nums[i]);            trackback(track, res, depth+<span class="hljs-number">1</span>, nums);            track.pop_back();        &#125;    &#125;&#125;</code></pre><h6 id="47-全排列-II-https-leetcode-cn-com-problems-permutations-ii-🌟🌟🌟-🌟"><a href="#47-全排列-II-https-leetcode-cn-com-problems-permutations-ii-🌟🌟🌟-🌟" class="headerlink" title="[47] 全排列 II https://leetcode-cn.com/problems/permutations-ii/   🌟🌟🌟 🌟"></a>[47] 全排列 II <a href="https://leetcode-cn.com/problems/permutations-ii/">https://leetcode-cn.com/problems/permutations-ii/</a>   🌟🌟🌟 🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">backtrack</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; track, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; res, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt; &amp; flag)</span> </span>&#123;    <span class="hljs-keyword">if</span> (track.size() == nums.size() &amp;&amp;          find(res.begin(), res.end(), track) == res.end()) &#123;        res.push_back(track);        <span class="hljs-keyword">return</span>;    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); ++i) &#123;        <span class="hljs-comment">// 剪枝 !!</span>        <span class="hljs-keyword">if</span>(i &gt; <span class="hljs-number">0</span> &amp;&amp; nums[i] == nums[i<span class="hljs-number">-1</span>] &amp;&amp; flag[i<span class="hljs-number">-1</span>])&#123;            <span class="hljs-keyword">continue</span>;        &#125;        <span class="hljs-keyword">if</span>(flag[i] == <span class="hljs-literal">false</span>)&#123;            track.push_back(nums[i]);            flag[i] = <span class="hljs-literal">true</span>;            backtrack(nums, track, res, flag);            flag[i] = <span class="hljs-literal">false</span>;            track.pop_back();        &#125;    &#125;&#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">permuteUnique</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; track;    sort(nums.begin(), nums.end());    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt; <span class="hljs-title">flag</span><span class="hljs-params">(nums.size(), <span class="hljs-literal">false</span>)</span></span>;    backtrack(nums, track, res, flag);    <span class="hljs-keyword">return</span> res;   &#125;</code></pre><h6 id="lcof-剑指-Offer-38-字符串的排列-https-leetcode-cn-com-problems-zi-fu-chuan-de-pai-lie-lcof"><a href="#lcof-剑指-Offer-38-字符串的排列-https-leetcode-cn-com-problems-zi-fu-chuan-de-pai-lie-lcof" class="headerlink" title="[lcof] 剑指 Offer 38. 字符串的排列 https://leetcode-cn.com/problems/zi-fu-chuan-de-pai-lie-lcof/"></a>[lcof] 剑指 Offer 38. 字符串的排列 <a href="https://leetcode-cn.com/problems/zi-fu-chuan-de-pai-lie-lcof/">https://leetcode-cn.com/problems/zi-fu-chuan-de-pai-lie-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">trackback</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s, <span class="hljs-keyword">int</span> depth, <span class="hljs-built_in">string</span> track, </span></span><span class="hljs-function"><span class="hljs-params">               <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt; flag, <span class="hljs-built_in">set</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; res)</span></span>&#123;    <span class="hljs-keyword">if</span>(depth == s.size())&#123;        res.insert(track);        <span class="hljs-keyword">return</span>;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; s.size(); i++)&#123;        <span class="hljs-keyword">if</span>(!flag[i])&#123;            track.push_back(s[i]);            flag[i] = <span class="hljs-literal">true</span>;            trackback(s, depth+<span class="hljs-number">1</span>, track, flag, res);            track.pop_back();            flag[i] = <span class="hljs-literal">false</span>;        &#125;    &#125;&#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; <span class="hljs-title">permutation</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-built_in">string</span>&gt; res; <span class="hljs-comment">// 使用 set 来降低复杂度</span>    <span class="hljs-built_in">string</span> track;    <span class="hljs-keyword">int</span> depth = <span class="hljs-number">0</span>;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt; <span class="hljs-title">flag</span><span class="hljs-params">(s.size(), <span class="hljs-number">0</span>)</span></span>; <span class="hljs-comment">// 使用 flag 来标记是否遍历过</span>    trackback(s, depth, track, flag, res);    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;(res.begin(), res.end());&#125;</code></pre><h6 id="22-括号生成-https-leetcode-cn-com-problems-generate-parentheses"><a href="#22-括号生成-https-leetcode-cn-com-problems-generate-parentheses" class="headerlink" title="[22] 括号生成 https://leetcode-cn.com/problems/generate-parentheses/"></a>[22] 括号生成 <a href="https://leetcode-cn.com/problems/generate-parentheses/">https://leetcode-cn.com/problems/generate-parentheses/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; <span class="hljs-title">generateParenthesis</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; res;    <span class="hljs-built_in">string</span> str;    backtrace(n, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, res, str);   <span class="hljs-comment">// 已经放置了 0 个 left 和 0 个 right</span>    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">backtrace</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> left, <span class="hljs-keyword">int</span> right, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; res, <span class="hljs-built_in">string</span> str)</span></span>&#123;    <span class="hljs-comment">// 当右括号大于左括号 或者 左括号大于n 或者 右括号大于n 的时候，不符合条件 -&gt; 剪枝</span>    <span class="hljs-keyword">if</span>(right &gt; left || right &gt; n || left &gt; n) <span class="hljs-keyword">return</span>;    <span class="hljs-comment">// 当 左括号数目 == 右括号数目， 且左括号 = n 时， 满足条件 -&gt; 保存</span>    <span class="hljs-keyword">if</span>(right == left &amp;&amp; left == n)&#123;        res.push_back(str);        <span class="hljs-keyword">return</span>;    &#125;    <span class="hljs-comment">// 递归进行</span>    backtrace(n, left+<span class="hljs-number">1</span>, right, res, str + <span class="hljs-string">&#x27;(&#x27;</span>);    backtrace(n, left, right+<span class="hljs-number">1</span>, res, str + <span class="hljs-string">&#x27;)&#x27;</span>);&#125;</code></pre><h6 id="17-电话号码的字母组合https-leetcode-cn-com-problems-letter-combinations-of-a-phone-number"><a href="#17-电话号码的字母组合https-leetcode-cn-com-problems-letter-combinations-of-a-phone-number" class="headerlink" title="[17] 电话号码的字母组合https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number/"></a>[17] 电话号码的字母组合<a href="https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number/">https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number/</a></h6><pre><code class="hljs cpp"><span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">string</span>&gt; m_map = &#123;    &#123;<span class="hljs-number">2</span>,<span class="hljs-string">&quot;abc&quot;</span>&#125;, &#123;<span class="hljs-number">3</span>,<span class="hljs-string">&quot;def&quot;</span>&#125;, &#123;<span class="hljs-number">4</span>,<span class="hljs-string">&quot;ghi&quot;</span>&#125;, &#123;<span class="hljs-number">5</span>,<span class="hljs-string">&quot;jkl&quot;</span>&#125;,    &#123;<span class="hljs-number">6</span>, <span class="hljs-string">&quot;mno&quot;</span>&#125;, &#123;<span class="hljs-number">7</span>,<span class="hljs-string">&quot;pqrs&quot;</span>&#125;, &#123;<span class="hljs-number">8</span>,<span class="hljs-string">&quot;tuv&quot;</span>&#125;, &#123;<span class="hljs-number">9</span>,<span class="hljs-string">&quot;wxyz&quot;</span>&#125;&#125;;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; <span class="hljs-title">letterCombinations</span><span class="hljs-params">(<span class="hljs-built_in">string</span> digits)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; res;    <span class="hljs-keyword">if</span>(digits.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">string</span> str = <span class="hljs-string">&quot;&quot;</span>;    trackback(res, <span class="hljs-number">0</span>, digits, str);    <span class="hljs-keyword">return</span> res;&#125;       <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">trackback</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; res, <span class="hljs-keyword">int</span> depth, <span class="hljs-built_in">string</span> digits, <span class="hljs-built_in">string</span>&amp; str)</span></span>&#123;    <span class="hljs-comment">// res 存储对应的 结果</span>    <span class="hljs-comment">// depth 不断加深树的深度 digits</span>    <span class="hljs-comment">// 利用 depth &amp; digits 可以获取当前的选择[这里是某个字符]</span>    <span class="hljs-comment">// str 是遍历处的字符串值</span>    <span class="hljs-keyword">if</span>(str.size() == digits.size()) res.push_back(str);    <span class="hljs-built_in">string</span> choose = m_map[digits[depth] - <span class="hljs-string">&#x27;0&#x27;</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; choose.size(); i++)&#123;       str += choose[i]; <span class="hljs-comment">// 选择</span>       trackback(res, depth+<span class="hljs-number">1</span>, digits, str); <span class="hljs-comment">// 回溯</span>       str.erase(str.end() - <span class="hljs-number">1</span>); <span class="hljs-comment">// 撤销  </span>    &#125;&#125;</code></pre><h6 id="39-组合总和-https-leetcode-cn-com-problems-combination-sum"><a href="#39-组合总和-https-leetcode-cn-com-problems-combination-sum" class="headerlink" title="[39] 组合总和 https://leetcode-cn.com/problems/combination-sum/"></a>[39] 组合总和 <a href="https://leetcode-cn.com/problems/combination-sum/">https://leetcode-cn.com/problems/combination-sum/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">trackback</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; res, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; track, <span class="hljs-keyword">int</span> start, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; candidates, <span class="hljs-keyword">int</span> target)</span></span>&#123;    <span class="hljs-keyword">int</span> s = accumulate(track.begin(), track.end(), <span class="hljs-number">0</span>);    <span class="hljs-keyword">if</span>(s &gt; target) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">if</span>(s == target)  res.push_back(track);    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start; i &lt; candidates.size(); i++)&#123;        track.push_back(candidates[i]);        trackback(res, track, i, candidates, target);        track.pop_back();    &#125;    &#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">combinationSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; candidates, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; track;    trackback(res, track, <span class="hljs-number">0</span>, candidates, target);    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="77-组合-https-leetcode-cn-com-problems-combinations"><a href="#77-组合-https-leetcode-cn-com-problems-combinations" class="headerlink" title="[77] 组合 https://leetcode-cn.com/problems/combinations/"></a>[77] 组合 <a href="https://leetcode-cn.com/problems/combinations/">https://leetcode-cn.com/problems/combinations/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">combine</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; track;    trackback(res, track, <span class="hljs-number">0</span>, n, k);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">trackback</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;&amp; res, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &amp; track, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> n, <span class="hljs-keyword">int</span> k)</span></span>&#123;    <span class="hljs-keyword">if</span>(track.size() &gt; k) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">if</span>(track.size() == k) res.push_back(track);    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start; i &lt; n; i++)&#123;        track.push_back(i+<span class="hljs-number">1</span>);        trackback(res, track, i+<span class="hljs-number">1</span>, n, k);        track.pop_back();    &#125;&#125;</code></pre><h6 id="79-单词搜索-https-leetcode-cn-com-problems-word-search"><a href="#79-单词搜索-https-leetcode-cn-com-problems-word-search" class="headerlink" title="[79] 单词搜索 https://leetcode-cn.com/problems/word-search/"></a>[79] 单词搜索 <a href="https://leetcode-cn.com/problems/word-search/">https://leetcode-cn.com/problems/word-search/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-keyword">int</span> r, <span class="hljs-keyword">int</span> c, <span class="hljs-keyword">int</span> idx)</span></span>&#123;    <span class="hljs-comment">// 判断非法退出条件</span>    <span class="hljs-keyword">if</span>(r &lt; <span class="hljs-number">0</span> || r &gt;= m || c &lt; <span class="hljs-number">0</span> || c &gt;= n        || g_word[idx] != g_board[r][c]) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-comment">// 判定符合条件</span>    <span class="hljs-keyword">if</span>(idx == g_word.size() - <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;   <span class="hljs-comment">// 四个方向的回溯</span>    <span class="hljs-keyword">char</span> t = g_board[r][c];    g_board[r][c] = <span class="hljs-string">&#x27;$&#x27;</span>;    <span class="hljs-keyword">if</span>(bfs(r<span class="hljs-number">-1</span>, c, idx+<span class="hljs-number">1</span>)      ||bfs(r+<span class="hljs-number">1</span>, c, idx+<span class="hljs-number">1</span>)      || bfs(r, c<span class="hljs-number">-1</span>, idx+<span class="hljs-number">1</span>)      || bfs(r, c+<span class="hljs-number">1</span>, idx+<span class="hljs-number">1</span>)) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    g_board[r][c] = t;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">exist</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; board, <span class="hljs-built_in">string</span> word)</span> </span>&#123;    g_board = board;    g_word = word;    m = board.size();    n = board[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(bfs(i, j, <span class="hljs-number">0</span>)) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;<span class="hljs-keyword">int</span> m, n;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt; &gt; g_board;<span class="hljs-built_in">string</span> g_word;</code></pre><h6 id="51-N-皇后-https-leetcode-cn-com-problems-n-queens"><a href="#51-N-皇后-https-leetcode-cn-com-problems-n-queens" class="headerlink" title="[51] N 皇后 https://leetcode-cn.com/problems/n-queens/"></a>[51] N 皇后 <a href="https://leetcode-cn.com/problems/n-queens/">https://leetcode-cn.com/problems/n-queens/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isValid</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; board, <span class="hljs-keyword">int</span> row, <span class="hljs-keyword">int</span> col, <span class="hljs-keyword">int</span> n)</span></span>&#123;    <span class="hljs-keyword">if</span>(row &lt; <span class="hljs-number">0</span> || row &gt;= n || col &lt; <span class="hljs-number">0</span> || col &gt;= n) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++)&#123;        <span class="hljs-keyword">if</span>(board[i][col] == <span class="hljs-string">&#x27;Q&#x27;</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = row<span class="hljs-number">-1</span>, j = col+<span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span> &amp;&amp; j &lt; n;i--, j++)&#123;        <span class="hljs-keyword">if</span>(board[i][j] == <span class="hljs-string">&#x27;Q&#x27;</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = row<span class="hljs-number">-1</span>, j = col<span class="hljs-number">-1</span>; i &gt;= <span class="hljs-number">0</span> &amp;&amp; j &gt;= <span class="hljs-number">0</span>;i--, j--)&#123;        <span class="hljs-keyword">if</span>(board[i][j] == <span class="hljs-string">&#x27;Q&#x27;</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">backtrack</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; board, <span class="hljs-keyword">int</span> row, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&gt;&amp; res, <span class="hljs-keyword">int</span> n)</span></span>&#123;    <span class="hljs-keyword">if</span>(row == board.size())&#123;        res.push_back(board);        <span class="hljs-keyword">return</span>;    &#125;    <span class="hljs-comment">// 棋盘的遍历: 列遍历是通过for 循环实现的， 行遍历是通过递归实现的</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> col = <span class="hljs-number">0</span>; col &lt; n; col++)&#123;        <span class="hljs-keyword">if</span>(!isValid(board, row, col, n)) <span class="hljs-keyword">continue</span>;        board[row][col] = <span class="hljs-string">&#x27;Q&#x27;</span>;        backtrack(board, row+<span class="hljs-number">1</span>, res, n);        board[row][col] = <span class="hljs-string">&#x27;.&#x27;</span>;    &#125;&#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&gt; <span class="hljs-title">solveNQueens</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&gt; res;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; <span class="hljs-title">board</span><span class="hljs-params">(n, <span class="hljs-built_in">string</span>(n, <span class="hljs-string">&#x27;.&#x27;</span>))</span></span>;    backtrack(board, <span class="hljs-number">0</span>, res, n);    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="37-解数独-https-leetcode-cn-com-problems-sudoku-solver"><a href="#37-解数独-https-leetcode-cn-com-problems-sudoku-solver" class="headerlink" title="[37] 解数独 https://leetcode-cn.com/problems/sudoku-solver/"></a>[37] 解数独 <a href="https://leetcode-cn.com/problems/sudoku-solver/">https://leetcode-cn.com/problems/sudoku-solver/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isValid</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; board, <span class="hljs-keyword">int</span> row, <span class="hljs-keyword">int</span> col, <span class="hljs-keyword">int</span> val)</span></span>&#123;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span>; i++)  <span class="hljs-keyword">if</span>(board[row][i] == val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 判断行是否有重复</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">9</span>; i++)  <span class="hljs-keyword">if</span>(board[i][col] == val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 判断列是否有重复</span>    <span class="hljs-keyword">int</span> startRow =  row / <span class="hljs-number">3</span> * <span class="hljs-number">3</span>;    <span class="hljs-keyword">int</span> startCol = col / <span class="hljs-number">3</span> * <span class="hljs-number">3</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = startRow; i &lt; startRow + <span class="hljs-number">3</span>; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = startCol; j &lt; startCol + <span class="hljs-number">3</span>; j++)&#123;            <span class="hljs-keyword">if</span>(board[i][j] == val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">backtrack</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; board)</span></span>&#123;    <span class="hljs-keyword">int</span> m = board.size();    <span class="hljs-keyword">int</span> n = board[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123; <span class="hljs-comment">// 遍历行</span>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123; <span class="hljs-comment">// 遍历列</span>            <span class="hljs-keyword">if</span>(board[i][j] != <span class="hljs-string">&#x27;.&#x27;</span>) <span class="hljs-keyword">continue</span>;             <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> k = <span class="hljs-string">&#x27;1&#x27;</span>; k &lt;= <span class="hljs-string">&#x27;9&#x27;</span>; k++)&#123;                 <span class="hljs-keyword">if</span>(isValid(board, i, j, k))&#123; <span class="hljs-comment">// (i, j) 这个位置放 k 是否合适</span>                    board[i][j] = k; <span class="hljs-comment">// 放置 k</span>                    <span class="hljs-keyword">if</span>(backtrack(board)) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;  <span class="hljs-comment">// 找到一组合适的就立刻返回</span>                    board[i][j] = <span class="hljs-string">&#x27;.&#x27;</span>; <span class="hljs-comment">// 回溯， 撤销k</span>                 &#125;            &#125;            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; <span class="hljs-comment">// 9个数字都尝试完了，没有合适的，返回 false</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>; <span class="hljs-comment">// 填充完毕, 没有返回 false， 说明找到合适棋盘位置了</span>&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">solveSudoku</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; board)</span> </span>&#123;    backtrack(board);&#125;</code></pre><h4 id="2-2-贪心"><a href="#2-2-贪心" class="headerlink" title="2.2 贪心"></a>2.2 贪心</h4><p><strong>核心要点</strong></p><p>​    <strong>使用贪心算法需要满足贪心选择的性质， 简单说就是：每一步都做出一个局部最优的选择，最终的结果就是全局最优。</strong></p><p>最关键的是分析出第一步如何是最优解</p><h5 id="1-类型一"><a href="#1-类型一" class="headerlink" title="(1) 类型一"></a>(1) 类型一</h5><h6 id="多数元素-🌟🌟🌟"><a href="#多数元素-🌟🌟🌟" class="headerlink" title="多数元素  🌟🌟🌟"></a>多数元素  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 摩尔投票法：有最优解的思想在里面</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">majorityElement</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> cur = nums[<span class="hljs-number">0</span>];    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(cur == nums[i]) cnt++;        <span class="hljs-keyword">else</span>&#123;            cnt--;            <span class="hljs-keyword">if</span>(cnt == <span class="hljs-number">0</span>)&#123;                cur = nums[i];                cnt = <span class="hljs-number">1</span>;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> cur;&#125;</code></pre><h5 id="2-类型二"><a href="#2-类型二" class="headerlink" title="(2) 类型二"></a>(2) 类型二</h5><h6 id="买卖股票的最佳时机-🌟🌟🌟"><a href="#买卖股票的最佳时机-🌟🌟🌟" class="headerlink" title="买卖股票的最佳时机   🌟🌟🌟"></a>买卖股票的最佳时机   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 第i天的收益为 profit = prices[i] - prices[i-1]</span><span class="hljs-comment">//（1）当 profit &gt; 0 时，当天买入卖出</span><span class="hljs-comment">//（2）当 profit &lt;= 0 时，当天不进行交易</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; prices)</span> </span>&#123;    <span class="hljs-keyword">int</span> profit = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(prices.size() &lt;= <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; prices.size(); i++)&#123;        <span class="hljs-keyword">if</span>(prices[i] &gt; prices[i<span class="hljs-number">-1</span>])            profit += (prices[i] - prices[i<span class="hljs-number">-1</span>]);    &#125;    <span class="hljs-keyword">return</span> profit;&#125;</code></pre><h6 id="121-https-leetcode-cn-com-problems-best-time-to-buy-and-sell-stock"><a href="#121-https-leetcode-cn-com-problems-best-time-to-buy-and-sell-stock" class="headerlink" title="[121] https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/"></a>[121] <a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/">https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; prices)</span> </span>&#123;    <span class="hljs-keyword">int</span> max_profit = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> min_val = INT_MAX;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; prices.size(); i++)&#123;        min_val = min(min_val, prices[i]); <span class="hljs-comment">// 保存之前的最小值</span>        max_profit = max(max_profit, prices[i] - min_val);  <span class="hljs-comment">// 当前与最小值的差</span>    &#125;    <span class="hljs-keyword">return</span> max_profit;&#125;</code></pre><h6 id="加油站"><a href="#加油站" class="headerlink" title="加油站"></a>加油站</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">canCompleteCircuit</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; gas, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; cost)</span> </span>&#123;    <span class="hljs-keyword">int</span> min_spare = INT_MAX; <span class="hljs-comment">// 最少剩余油量</span>    <span class="hljs-keyword">int</span> pos = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> spare = <span class="hljs-number">0</span>; <span class="hljs-comment">// 当前剩余油量</span>    <span class="hljs-comment">// 环绕一圈， 最终油量大于等于零即可实现绕环行驶，标记最少的位置</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; gas.size(); i++)&#123;        spare += (gas[i] - cost[i]);        <span class="hljs-keyword">if</span>(spare &lt; min_spare)&#123;            min_spare = spare;            pos = i; <span class="hljs-comment">// 标记油量最少的位置</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> spare &lt; <span class="hljs-number">0</span> ? <span class="hljs-number">-1</span> : (pos + <span class="hljs-number">1</span>) % gas.size();&#125;</code></pre><h5 id="3-类型三"><a href="#3-类型三" class="headerlink" title="(3) 类型三"></a>(3) 类型三</h5><h6 id="455-分发饼干-https-leetcode-cn-com-problems-assign-cookies"><a href="#455-分发饼干-https-leetcode-cn-com-problems-assign-cookies" class="headerlink" title="[455] 分发饼干 https://leetcode-cn.com/problems/assign-cookies/"></a>[455] 分发饼干 <a href="https://leetcode-cn.com/problems/assign-cookies/">https://leetcode-cn.com/problems/assign-cookies/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 尽量先满足胃口值小的孩子，因为这样的孩子容易满足。</span><span class="hljs-comment">// 尽可能选用尺寸小的，这样大尺寸饼干可以用来满足胃口值大的孩子。</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findContentChildren</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; g, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; s)</span> </span>&#123;    <span class="hljs-keyword">if</span>(s.size() == <span class="hljs-number">0</span> || g.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    sort(g.begin(), g.end());    sort(s.begin(), s.end());    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; i &lt; g.size() &amp;&amp; j &lt; s.size(); ++j)&#123;        <span class="hljs-keyword">if</span>(s[j] &gt;= g[i]) i++;     &#125;    <span class="hljs-keyword">return</span> i &gt; g.size() ? g.size() : i;&#125;</code></pre><h6 id="55-跳跃游戏-45-跳跃游戏-II"><a href="#55-跳跃游戏-45-跳跃游戏-II" class="headerlink" title="[55] 跳跃游戏 [45] 跳跃游戏 II"></a>[55] 跳跃游戏 [45] 跳跃游戏 II</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">canJump</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-comment">// 核心思想: 如果一个位置能够到达，那么这个位置左侧所有位置都能到达</span>    <span class="hljs-comment">//          每一步都选择都选择从当前所在位置出发可以到达的最远距离</span>    <span class="hljs-keyword">int</span> k = <span class="hljs-number">0</span>; <span class="hljs-comment">// 代表当前遍历的节点最远可以跳到何位置</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-comment">// 如果当前最远可以跳过超出 nums.size(), 则可以到达最后</span>        <span class="hljs-keyword">if</span>(k &gt; nums.size()) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;        <span class="hljs-comment">// 如果 i 大于当前最远的距离，证明 当前位置不可达， 返回 false</span>        <span class="hljs-keyword">if</span>(i &gt; k) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;        <span class="hljs-comment">// 更新当前最远位置</span>        k = max(k, i + nums[i]);    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;</code></pre><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">jump</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-comment">// 挨个跳跃就行</span>    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>; <span class="hljs-comment">// 跳跃次数</span>    <span class="hljs-keyword">int</span> max_pos = <span class="hljs-number">0</span>; <span class="hljs-comment">// 标记最大位置</span>    <span class="hljs-keyword">int</span> end = <span class="hljs-number">0</span>; <span class="hljs-comment">// 最后的跳跃位置</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size()<span class="hljs-number">-1</span>; i++)&#123;        max_pos = max(nums[i] + i, max_pos);         <span class="hljs-keyword">if</span>(i == end)&#123;            end = max_pos;            res++;        &#125;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="402-移掉K位数字-https-leetcode-cn-com-problems-remove-k-digits"><a href="#402-移掉K位数字-https-leetcode-cn-com-problems-remove-k-digits" class="headerlink" title="[402] 移掉K位数字 https://leetcode-cn.com/problems/remove-k-digits/"></a>[402] 移掉K位数字 <a href="https://leetcode-cn.com/problems/remove-k-digits/">https://leetcode-cn.com/problems/remove-k-digits/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 用 string 来表示一个单调栈:</span><span class="hljs-comment">//   当前数字大于最后一个时候， 将最后一个字母弹出，并k计数减一</span><span class="hljs-comment">// 当前数字追加</span><span class="hljs-comment">// </span><span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">removeKdigits</span><span class="hljs-params">(<span class="hljs-built_in">string</span> num, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">string</span> res; <span class="hljs-comment">// 默认是一个空串</span>    <span class="hljs-keyword">int</span> n = num.size(), m = n - k;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">char</span> c:num)&#123;        <span class="hljs-keyword">while</span>(k &amp;&amp; res.size() &amp;&amp; res.back() &gt; c)&#123;            res.pop_back();            --k;        &#125;        res.push_back(c);    &#125;    res.resize(m); <span class="hljs-comment">// 调整大小</span>    res.erase(<span class="hljs-number">0</span>, res.find_first_not_of(<span class="hljs-string">&quot;0&quot;</span>)); <span class="hljs-comment">// 去除前导零</span>    <span class="hljs-keyword">return</span> res.empty() ? <span class="hljs-string">&quot;0&quot;</span> : res; <span class="hljs-comment">// &quot;0&quot; 错误</span>&#125;</code></pre><h5 id="4-类型四"><a href="#4-类型四" class="headerlink" title="(4) 类型四"></a>(4) 类型四</h5><ul><li>可能需要进行排序作为预处理</li><li>一般对排序后的容器进行遍历， 贪心的找出局部最优解</li></ul><h6 id="435-无重叠区间"><a href="#435-无重叠区间" class="headerlink" title="[435] 无重叠区间"></a>[435] 无重叠区间</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">eraseOverlapIntervals</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; intervals)</span> </span>&#123;    <span class="hljs-keyword">if</span>(intervals.size() &lt; <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-comment">// 排序</span>    sort(intervals.begin(), intervals.end(), [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; b)&#123;<span class="hljs-keyword">return</span> a[<span class="hljs-number">1</span>] &lt; b[<span class="hljs-number">1</span>];&#125;);    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> tail = intervals[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>];    <span class="hljs-comment">// 贪心的每一步: 选择未被排除的区间中 [右区间 坐标最小] 的那个作为选定区间</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; intervals.size(); i++)&#123;        <span class="hljs-comment">// 如果有交集， 去掉该区间</span>       <span class="hljs-keyword">if</span>(intervals[i][<span class="hljs-number">0</span>] &lt; tail) cnt++;        <span class="hljs-comment">// 没有交集，选择该区间</span>       <span class="hljs-keyword">else</span> tail = intervals[i][<span class="hljs-number">1</span>];    &#125;    <span class="hljs-keyword">return</span>  cnt;&#125; </code></pre><h6 id="646-最长数对链-https-leetcode-cn-com-problems-maximum-length-of-pair-chain"><a href="#646-最长数对链-https-leetcode-cn-com-problems-maximum-length-of-pair-chain" class="headerlink" title="[646]. 最长数对链 https://leetcode-cn.com/problems/maximum-length-of-pair-chain/)"></a>[646]. 最长数对链 <a href="https://leetcode-cn.com/problems/maximum-length-of-pair-chain/">https://leetcode-cn.com/problems/maximum-length-of-pair-chain/</a>)</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 还是按照 区间末尾进行排序!!</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findLongestChain</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; pairs)</span> </span>&#123;    sort(pairs.begin(), pairs.end(),             [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; b)&#123;                <span class="hljs-keyword">return</span> a[<span class="hljs-number">1</span>] &lt; b[<span class="hljs-number">1</span>];            &#125;);    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(i &lt; pairs.size())&#123;        <span class="hljs-keyword">int</span> j = i + <span class="hljs-number">1</span>;        <span class="hljs-keyword">while</span>(j &lt; pairs.size() &amp;&amp; pairs[i][<span class="hljs-number">1</span>] &gt;= pairs[j][<span class="hljs-number">0</span>]) j++;        i = j;        res += <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="452-用最少数量的箭引爆气球-https-leetcode-cn-com-problems-minimum-number-of-arrows-to-burst-balloons"><a href="#452-用最少数量的箭引爆气球-https-leetcode-cn-com-problems-minimum-number-of-arrows-to-burst-balloons" class="headerlink" title="[452] 用最少数量的箭引爆气球 https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons/"></a>[452] 用最少数量的箭引爆气球 <a href="https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons/">https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 此题和上一道题目思路相似</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findMinArrowShots</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; points)</span> </span>&#123;    <span class="hljs-keyword">if</span>(points.size() &lt; <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    sort(points.begin(), points.end(), [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; b)&#123;<span class="hljs-keyword">return</span> a[<span class="hljs-number">1</span>] &lt; b[<span class="hljs-number">1</span>];&#125;);    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> tail = points[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; points.size(); i++)&#123;        <span class="hljs-comment">// 当 左区间 大于 这个区间的右区间时， 需要一根弓箭</span>        <span class="hljs-keyword">if</span>(points[i][<span class="hljs-number">0</span>] &gt; tail)&#123;            tail = points[i][<span class="hljs-number">1</span>];            cnt++;        &#125;    &#125;    <span class="hljs-keyword">return</span> cnt;&#125;</code></pre><h6 id="253-会议室-II-https-leetcode-cn-com-problems-meeting-rooms-ii-🌟🌟🌟"><a href="#253-会议室-II-https-leetcode-cn-com-problems-meeting-rooms-ii-🌟🌟🌟" class="headerlink" title="[253] 会议室 II https://leetcode-cn.com/problems/meeting-rooms-ii/  🌟🌟🌟"></a>[253] 会议室 II <a href="https://leetcode-cn.com/problems/meeting-rooms-ii/">https://leetcode-cn.com/problems/meeting-rooms-ii/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minMeetingRooms</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; intervals)</span> </span>&#123;    <span class="hljs-comment">// 按照开始时间排序</span>    sort(intervals.begin(), intervals.end());    <span class="hljs-comment">// 最小堆， 用来存储room 的结束时间</span>    <span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, greater&lt;<span class="hljs-keyword">int</span>&gt; &gt;rooms;    <span class="hljs-comment">// </span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; intervals.size(); i++)&#123;        <span class="hljs-comment">// 如果堆为空， 则直接插入</span>        <span class="hljs-keyword">if</span>(rooms.empty()) rooms.push(intervals[i][<span class="hljs-number">1</span>]);         <span class="hljs-comment">// 堆不空</span>        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-comment">// 如果开始时间大于最小的结束时间， 直接替换掉堆顶即可</span>            <span class="hljs-keyword">if</span>(rooms.top() &lt;= intervals[i][<span class="hljs-number">0</span>])                rooms.pop();            <span class="hljs-comment">// 否则再开辟一个新的房间</span>            rooms.push(intervals[i][<span class="hljs-number">1</span>]);        &#125;    &#125;    <span class="hljs-keyword">return</span> rooms.size();&#125;</code></pre><h6 id="根据身高重建队列"><a href="#根据身高重建队列" class="headerlink" title="根据身高重建队列"></a>根据身高重建队列</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">reconstructQueue</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; people)</span> </span>&#123;    <span class="hljs-comment">// 先排序</span>    <span class="hljs-comment">// [7,0], [7,1], [6,1], [5,0], [5,2], [4,4]</span>    sort(people.begin(), people.end(),             [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;b)            &#123;<span class="hljs-keyword">return</span> (a[<span class="hljs-number">0</span>] &gt; b[<span class="hljs-number">0</span>]) || (a[<span class="hljs-number">0</span>] == b[<span class="hljs-number">0</span>] &amp;&amp; a[<span class="hljs-number">1</span>] &lt; b[<span class="hljs-number">1</span>]);&#125;);    <span class="hljs-comment">// 再一个一个插入, 插入位置为第二个元素的大小</span>    <span class="hljs-comment">// [7,0]</span>    <span class="hljs-comment">// [7,0], [7,1]</span>    <span class="hljs-comment">// [7,0], [6,1], [7,1]</span>    <span class="hljs-comment">// [5,0], [7,0], [6,1], [7,1]</span>    <span class="hljs-comment">// [5,0], [7,0], [5,2], [6,1], [7,1]</span>    <span class="hljs-comment">// [5,0], [7,0], [5,2], [6,1], [4,4], [7,1]</span>    <span class="hljs-built_in">list</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; li;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> elem:people)&#123;        <span class="hljs-keyword">auto</span> pos = li.begin(); <span class="hljs-comment">// 找到列表头</span>        advance(pos, elem[<span class="hljs-number">1</span>]);   <span class="hljs-comment">// 移动 elem[1]</span>        li.insert(pos, elem);    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;(li.begin(), li.end());&#125;</code></pre><h6 id="56-合并区间-https-leetcode-cn-com-problems-merge-intervals-🌟🌟🌟"><a href="#56-合并区间-https-leetcode-cn-com-problems-merge-intervals-🌟🌟🌟" class="headerlink" title="[56] 合并区间 https://leetcode-cn.com/problems/merge-intervals/   🌟🌟🌟"></a>[56] 合并区间 <a href="https://leetcode-cn.com/problems/merge-intervals/">https://leetcode-cn.com/problems/merge-intervals/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">merge</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; intervals)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-keyword">if</span>(intervals.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-comment">// !! 按照左端点进行排序: 方便后序处理 有交集并且是包含关系的情况</span>    sort(intervals.begin(), intervals.end(),         [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;b)&#123; <span class="hljs-keyword">return</span> a[<span class="hljs-number">0</span>] &lt; b[<span class="hljs-number">0</span>];&#125;);    <span class="hljs-keyword">int</span> cur = <span class="hljs-number">0</span>;    res.push_back(intervals[<span class="hljs-number">0</span>]);    <span class="hljs-comment">// 需要考虑两种情况:(1) 有无交集 &amp; 是否是包含关系</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; intervals.size(); i++)&#123;        <span class="hljs-keyword">if</span>(intervals[i][<span class="hljs-number">0</span>] &gt; res.back()[<span class="hljs-number">1</span>])&#123;  <span class="hljs-comment">// 无交集</span>            res.push_back(intervals[i]);        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(intervals[i][<span class="hljs-number">1</span>] &gt; res.back()[<span class="hljs-number">1</span>])&#123;  <span class="hljs-comment">// 有交集 且 不是包含关系</span>            res.back()[<span class="hljs-number">1</span>] = intervals[i][<span class="hljs-number">1</span>];        &#125;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h3 id="3-动态规划"><a href="#3-动态规划" class="headerlink" title="3. 动态规划"></a>3. 动态规划</h3><h4 id="1-常用技巧总结"><a href="#1-常用技巧总结" class="headerlink" title="(1) 常用技巧总结"></a>(1) 常用技巧总结</h4><p>动态规划在面试中占据了绝对的重要的地位，值得重点突破。下面是动态规划解题的基本步骤：</p><p>（1） 确定状态: 确定 $dp[i]$  代表什么 ?  可以从考虑子问题和最后一步进行考虑</p><p>（2） 确定转移方程  $dp[i] = f(dp[i-1])$</p><p>（3）初始条件和边界情况：起始值的赋值 &amp; 最后一步</p><p>（4） 计算顺序: 消除冗余，加速计算     $f[0],  f[1],  f[2],  … $</p><p>常用技巧：</p><ul><li><p>如何确定某个题目是动态规划类的题目:</p><ul><li><p>count 计数：有多少种方式走到右下角、有多少种方式选出 k 个数使得和是 sum</p></li><li><p>min/max求最大最小值：从左上角到右下角路径的最大数字和、最长上升子序列长度</p></li><li><p>yes/no 求存在性：取石子游戏， 先手是否必胜、能不能选出k个数使得和是Sum</p></li></ul></li><li><p>对于字符串的相关问题(回文、公共子串、上升子串)， 一个很常见的操作就是，用字符串构造矩阵，然后进行状态转移。</p></li><li>解题步骤中：确定状态和确定转移方程是最重要的。</li><li>没有思路的时候可以从起始状态进行模拟，或者取其中一个特殊的状态进行模拟。</li></ul><h4 id="2-典型例题-1"><a href="#2-典型例题-1" class="headerlink" title="(2) 典型例题"></a>(2) 典型例题</h4><h5 id="类型一-简单一维-DP"><a href="#类型一-简单一维-DP" class="headerlink" title="类型一 简单一维 DP"></a>类型一 简单一维 DP</h5><h6 id="509-斐波那契数-https-leetcode-cn-com-problems-fibonacci-number"><a href="#509-斐波那契数-https-leetcode-cn-com-problems-fibonacci-number" class="headerlink" title="[509] 斐波那契数 https://leetcode-cn.com/problems/fibonacci-number/"></a>[509] 斐波那契数 <a href="https://leetcode-cn.com/problems/fibonacci-number/">https://leetcode-cn.com/problems/fibonacci-number/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 使用 prev 和 cur 来消除了 DP 数组的使用</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">fib</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> prev = <span class="hljs-number">0</span>, cur = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">2</span>; i &lt;= n; i++)&#123;        <span class="hljs-keyword">int</span> s = (prev + cur) % <span class="hljs-number">1000000007</span>;        prev = cur;        cur = s;    &#125;    <span class="hljs-keyword">return</span> cur;&#125;</code></pre><h6 id="70-爬楼梯-https-leetcode-cn-com-problems-climbing-stairs"><a href="#70-爬楼梯-https-leetcode-cn-com-problems-climbing-stairs" class="headerlink" title="[70] 爬楼梯 https://leetcode-cn.com/problems/climbing-stairs/"></a>[70] 爬楼梯 <a href="https://leetcode-cn.com/problems/climbing-stairs/">https://leetcode-cn.com/problems/climbing-stairs/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">numWays</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n &lt;= <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;    <span class="hljs-keyword">int</span> prev = <span class="hljs-number">1</span>, cur = <span class="hljs-number">2</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">3</span>; i &lt;= n; i++)&#123;        <span class="hljs-keyword">int</span> s= (prev + cur) % <span class="hljs-number">1000000007</span>;        prev = cur;        cur = s;    &#125;    <span class="hljs-keyword">return</span> cur;&#125;</code></pre><h6 id="198-https-leetcode-com-problems-house-robber"><a href="#198-https-leetcode-com-problems-house-robber" class="headerlink" title="[198] https://leetcode.com/problems/house-robber/"></a>[198] <a href="https://leetcode.com/problems/house-robber/">https://leetcode.com/problems/house-robber/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">rob</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> nums[<span class="hljs-number">0</span>];    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> max(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span> &gt; <span class="hljs-title">dp</span><span class="hljs-params">(nums.size(), <span class="hljs-number">0</span>)</span></span>;    dp[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];    dp[<span class="hljs-number">1</span>] = max(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);    <span class="hljs-keyword">int</span> res = <span class="hljs-number">2</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">2</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-comment">// 转移方程只和前两个状态有关:</span>        <span class="hljs-comment">// (1) 选择当前的房子: dp[i-2] + nums[i]</span>        <span class="hljs-comment">// (2) 不选当前房子: dp[i-1]</span>        dp[i] = max(dp[i<span class="hljs-number">-2</span>] + nums[i], dp[i<span class="hljs-number">-1</span>]);    &#125;    <span class="hljs-keyword">return</span> dp[nums.size()<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="264-https-leetcode-cn-com-problems-ugly-number-ii-🌟🌟🌟"><a href="#264-https-leetcode-cn-com-problems-ugly-number-ii-🌟🌟🌟" class="headerlink" title="[264] https://leetcode-cn.com/problems/ugly-number-ii/    🌟🌟🌟"></a>[264] <a href="https://leetcode-cn.com/problems/ugly-number-ii/">https://leetcode-cn.com/problems/ugly-number-ii/</a>    🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 其实就是不断的求数组 A， B， C 的最小值</span><span class="hljs-comment">// A: &#123;1*2，2*2，3*2，4*2，5*2，6*2，8*2，10*2......&#125;</span><span class="hljs-comment">// B: &#123;1*3，2*3，3*3，4*3，5*3，6*3，8*3，10*3......&#125;</span><span class="hljs-comment">// C: &#123;1*5，2*5，3*5，4*5，5*5，6*5，8*5，10*5......&#125;</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">nthUglyNumber</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, <span class="hljs-number">0</span>)</span></span>;    dp[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> p2 = <span class="hljs-number">0</span>, p3 = <span class="hljs-number">0</span>, p5 = <span class="hljs-number">0</span>; <span class="hljs-comment">// 这里是三个指针，分别指向三个数组</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;        <span class="hljs-comment">// 只和之前的三个变量有关系</span>        dp[i] = min(min(dp[p2]*<span class="hljs-number">2</span>, dp[p3]*<span class="hljs-number">3</span>), dp[p5]*<span class="hljs-number">5</span>);          <span class="hljs-keyword">if</span>(dp[i]/dp[p2] == <span class="hljs-number">2</span>) p2++;        <span class="hljs-keyword">if</span>(dp[i]/dp[p3] == <span class="hljs-number">3</span>) p3++;        <span class="hljs-keyword">if</span>(dp[i]/dp[p5] == <span class="hljs-number">5</span>) p5++;    &#125;    <span class="hljs-keyword">return</span> dp[n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="53-最大子序和-https-leetcode-cn-com-problems-maximum-subarray-🌟🌟"><a href="#53-最大子序和-https-leetcode-cn-com-problems-maximum-subarray-🌟🌟" class="headerlink" title="[53] 最大子序和 https://leetcode-cn.com/problems/maximum-subarray/   🌟🌟"></a>[53] 最大子序和 <a href="https://leetcode-cn.com/problems/maximum-subarray/">https://leetcode-cn.com/problems/maximum-subarray/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxSubArray</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> res = nums[<span class="hljs-number">0</span>];    <span class="hljs-comment">// 以 dp 为结束的最大子序列的和</span>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(nums.size(), <span class="hljs-number">0</span>)</span></span>;     dp[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; nums.size(); i++)&#123;        dp[i] = dp[i<span class="hljs-number">-1</span>] &gt; <span class="hljs-number">0</span> ? dp[i<span class="hljs-number">-1</span>] + nums[i] : nums[i];        res = max(res, dp[i]);    &#125;    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-comment">// 这道题和上面那道几乎相同: dp[i] 的定义类似，转移方程也类似</span></code></pre><h5 id="类型二-一维-DP：-与之前的所有的-dp-状态均有关系"><a href="#类型二-一维-DP：-与之前的所有的-dp-状态均有关系" class="headerlink" title="类型二 一维 DP： 与之前的所有的 dp 状态均有关系"></a>类型二 一维 DP： 与之前的所有的 dp 状态均有关系</h5><p>接下来几道题目虽然形式各异，但是当前的状态和之前的所有状态均有联系。</p><h6 id="lcof-14-I-剪绳子-https-leetcode-cn-com-problems-jian-sheng-zi-lcof"><a href="#lcof-14-I-剪绳子-https-leetcode-cn-com-problems-jian-sheng-zi-lcof" class="headerlink" title="[lcof 14- I] 剪绳子 https://leetcode-cn.com/problems/jian-sheng-zi-lcof/"></a>[lcof 14- I] 剪绳子 <a href="https://leetcode-cn.com/problems/jian-sheng-zi-lcof/">https://leetcode-cn.com/problems/jian-sheng-zi-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">cuttingRope</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n &lt;= <span class="hljs-number">3</span>) <span class="hljs-keyword">return</span> n<span class="hljs-number">-1</span>;    <span class="hljs-comment">// dp[n] 表示长度为 n 的绳子，剪成若干段之后，乘积的最大值</span>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span></span>;    <span class="hljs-comment">// 如果某个长度的绳子，剪了一下之后，其中一段的长度在 [0,3] 的区间内，就不要再剪这一段了</span>    <span class="hljs-comment">// 因为剪了之后，乘积会变小</span>    dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;    dp[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span>;    dp[<span class="hljs-number">2</span>] = <span class="hljs-number">2</span>;    dp[<span class="hljs-number">3</span>] = <span class="hljs-number">3</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">4</span>;  i &lt;= n; i++)&#123;   <span class="hljs-comment">// 逐渐增加 dp 数组的长度 </span>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= i / <span class="hljs-number">2</span>; j++)&#123;     <span class="hljs-comment">// 第一刀剪在什么地方?</span>            <span class="hljs-comment">//  剩下的两段为 j 和 i-j， 求这两段的最大值即可</span>            dp[i] = max(dp[i], dp[j] * dp[i-j]);        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[n];&#125;</code></pre><h6 id="300-最长上升子序列-🌟🌟🌟"><a href="#300-最长上升子序列-🌟🌟🌟" class="headerlink" title="300]. 最长上升子序列    🌟🌟🌟"></a><a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/">300]. 最长上升子序列</a>    🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 核心思想：</span><span class="hljs-comment">// 当 nums[j] &gt; nums[i] 时： nums[j] 可以接在 nums[i] 之后，此情况下最长上升子序列长度为 dp[i] + 1 ；</span><span class="hljs-comment">// 否则 无法接在 nums[i]之后，此情况上升子序列不成立，跳过。</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">lengthOfLIS</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> n = nums.size();    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, <span class="hljs-number">1</span>)</span></span>;    dp[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n<span class="hljs-number">-1</span>; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = i+<span class="hljs-number">1</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(nums[j] &gt; nums[i])                dp[j] = max(dp[j], dp[i]+<span class="hljs-number">1</span>);        &#125;    &#125;    <span class="hljs-keyword">return</span> *max_element(dp.begin(), dp.end());&#125;</code></pre><h6 id="354-俄罗斯套娃信封问题-https-leetcode-cn-com-problems-russian-doll-envelopes"><a href="#354-俄罗斯套娃信封问题-https-leetcode-cn-com-problems-russian-doll-envelopes" class="headerlink" title="[354] 俄罗斯套娃信封问题 (https://leetcode-cn.com/problems/russian-doll-envelopes/)"></a>[354] 俄罗斯套娃信封问题 (<a href="https://leetcode-cn.com/problems/russian-doll-envelopes/">https://leetcode-cn.com/problems/russian-doll-envelopes/</a>)</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 先将信封按照第一个元素升序，第二个元素降序进行排列， 然后求所有第二个元素的最长递增子序列</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxEnvelopes</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; envelopes)</span> </span>&#123;    sort(envelopes.begin(), envelopes.end(), [](<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; b)&#123;        <span class="hljs-keyword">return</span> (a[<span class="hljs-number">0</span>] &lt; b[<span class="hljs-number">0</span>]) || (a[<span class="hljs-number">0</span>] == b[<span class="hljs-number">0</span>] &amp;&amp; a[<span class="hljs-number">1</span>] &gt; b[<span class="hljs-number">1</span>]);    &#125;);        <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; nums;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> envelope: envelopes) nums.push_back(envelope[<span class="hljs-number">1</span>]);    <span class="hljs-keyword">return</span> lengthOfLIS(nums);&#125;</code></pre><p>接下来这两道题目虽然没有直接的 dp 形式，但是蕴含的  dp 思想，而且是可以写成 dp 的。</p><h6 id="152-乘积最大子数组-https-leetcode-cn-com-problems-maximum-product-subarray"><a href="#152-乘积最大子数组-https-leetcode-cn-com-problems-maximum-product-subarray" class="headerlink" title="[152] 乘积最大子数组 https://leetcode-cn.com/problems/maximum-product-subarray/"></a>[152] 乘积最大子数组 <a href="https://leetcode-cn.com/problems/maximum-product-subarray/">https://leetcode-cn.com/problems/maximum-product-subarray/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 这个题目是 dp 的思想在解决， 但是不是用的 dp</span><span class="hljs-comment">// 维持一个最大值和一个最小值的数组</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProduct</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = INT_MIN;    <span class="hljs-keyword">int</span> min_val = <span class="hljs-number">1</span>, max_val = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums)&#123;        <span class="hljs-keyword">if</span>(n &lt; <span class="hljs-number">0</span>) swap(max_val, min_val);  <span class="hljs-comment">// 如果当前值小于零，则对最大值和最小值进行互换</span>        min_val = min(min_val * n, n);        max_val = max(max_val * n, n);        res = max(res, max_val);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="376-摆动序列-https-leetcode-cn-com-problems-wiggle-subsequence-🌟🌟"><a href="#376-摆动序列-https-leetcode-cn-com-problems-wiggle-subsequence-🌟🌟" class="headerlink" title="[376] 摆动序列 https://leetcode-cn.com/problems/wiggle-subsequence/      🌟🌟"></a>[376] 摆动序列 <a href="https://leetcode-cn.com/problems/wiggle-subsequence/">https://leetcode-cn.com/problems/wiggle-subsequence/</a>      🌟🌟</h6><pre><code class="hljs c"><span class="hljs-comment">// 思路参考: https://leetcode-cn.com/problems/wiggle-subsequence/solution/tan-xin-si-lu-qing-xi-er-zheng-que-de-ti-jie-by-lg/</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">wiggleMaxLength</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> up = <span class="hljs-number">1</span>, down = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>;  i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] &gt; nums[i<span class="hljs-number">-1</span>]) up = down + <span class="hljs-number">1</span>;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[i] &lt; nums[i<span class="hljs-number">-1</span>]) down = up + <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> max(up, down);&#125;</code></pre><h5 id="类型三：-二维-DP"><a href="#类型三：-二维-DP" class="headerlink" title="类型三： 二维 DP"></a>类型三： 二维 DP</h5><h6 id="62-不同路径-https-leetcode-cn-com-problems-unique-paths"><a href="#62-不同路径-https-leetcode-cn-com-problems-unique-paths" class="headerlink" title="[62]  不同路径 https://leetcode-cn.com/problems/unique-paths/"></a>[62]  不同路径 <a href="https://leetcode-cn.com/problems/unique-paths/">https://leetcode-cn.com/problems/unique-paths/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uniquePaths</span><span class="hljs-params">(<span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n, <span class="hljs-number">1</span>))</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt; n; j++)&#123;            dp[i][j] = dp[i<span class="hljs-number">-1</span>][j] + dp[i][j<span class="hljs-number">-1</span>];        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m<span class="hljs-number">-1</span>][n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="63-不同路径-II-https-leetcode-cn-com-problems-unique-paths-ii-🌟🌟"><a href="#63-不同路径-II-https-leetcode-cn-com-problems-unique-paths-ii-🌟🌟" class="headerlink" title="[63] 不同路径 II https://leetcode-cn.com/problems/unique-paths-ii/      🌟🌟"></a>[63] 不同路径 II <a href="https://leetcode-cn.com/problems/unique-paths-ii/">https://leetcode-cn.com/problems/unique-paths-ii/</a>      🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">uniquePathsWithObstacles</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; obstacleGrid)</span> </span>&#123;    <span class="hljs-keyword">if</span>(obstacleGrid.size() == <span class="hljs-number">0</span> || obstacleGrid[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = obstacleGrid.size(), n = obstacleGrid[<span class="hljs-number">0</span>].size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n, <span class="hljs-number">1</span>))</span></span>;    dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = obstacleGrid[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] == <span class="hljs-number">1</span> ? <span class="hljs-number">0</span> : <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)  dp[i][<span class="hljs-number">0</span>] = obstacleGrid[i][<span class="hljs-number">0</span>] == <span class="hljs-number">1</span> ? <span class="hljs-number">0</span> : dp[i<span class="hljs-number">-1</span>][<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt; n; j++)  dp[<span class="hljs-number">0</span>][j] = obstacleGrid[<span class="hljs-number">0</span>][j] == <span class="hljs-number">1</span> ? <span class="hljs-number">0</span> : dp[<span class="hljs-number">0</span>][j<span class="hljs-number">-1</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>;  j &lt; n; j++)&#123;            dp[i][j] = obstacleGrid[i][j] == <span class="hljs-number">1</span> ? <span class="hljs-number">0</span> : dp[i<span class="hljs-number">-1</span>][j] + dp[i][j<span class="hljs-number">-1</span>];        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m<span class="hljs-number">-1</span>][n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="64-最小路径和-https-leetcode-cn-com-problems-minimum-path-sum"><a href="#64-最小路径和-https-leetcode-cn-com-problems-minimum-path-sum" class="headerlink" title="[64] 最小路径和 https://leetcode-cn.com/problems/minimum-path-sum/"></a>[64] 最小路径和 <a href="https://leetcode-cn.com/problems/minimum-path-sum/">https://leetcode-cn.com/problems/minimum-path-sum/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minPathSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;    <span class="hljs-keyword">if</span>(grid.size() == <span class="hljs-number">0</span> || grid[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = grid.size();    <span class="hljs-keyword">int</span> n = grid[<span class="hljs-number">0</span>].size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n, <span class="hljs-number">0</span>))</span></span>;        dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = grid[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++) dp[<span class="hljs-number">0</span>][i] = dp[<span class="hljs-number">0</span>][i<span class="hljs-number">-1</span>] + grid[<span class="hljs-number">0</span>][i];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++) dp[i][<span class="hljs-number">0</span>] = dp[i<span class="hljs-number">-1</span>][<span class="hljs-number">0</span>] + grid[i][<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt; n; j++)&#123;            dp[i][j] = min(dp[i<span class="hljs-number">-1</span>][j], dp[i][j<span class="hljs-number">-1</span>]) + grid[i][j];        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m<span class="hljs-number">-1</span>][n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="lcof-47-https-leetcode-cn-com-problems-li-wu-de-zui-da-jie-zhi-lcof"><a href="#lcof-47-https-leetcode-cn-com-problems-li-wu-de-zui-da-jie-zhi-lcof" class="headerlink" title="[lcof 47] https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/"></a>[lcof 47] <a href="https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/">https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxValue</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;    <span class="hljs-keyword">int</span> m = grid.size();    <span class="hljs-keyword">int</span> n = grid[<span class="hljs-number">0</span>].size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n))</span></span>;   <span class="hljs-comment">// 这个语法使用错了  vector</span>    dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = grid[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++) dp[i][<span class="hljs-number">0</span>] = dp[i<span class="hljs-number">-1</span>][<span class="hljs-number">0</span>] + grid[i][<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt; n; j++) dp[<span class="hljs-number">0</span>][j] = dp[<span class="hljs-number">0</span>][j<span class="hljs-number">-1</span>] + grid[<span class="hljs-number">0</span>][j];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>;  j &lt; n; j++)&#123;            dp[i][j] = max(dp[i<span class="hljs-number">-1</span>][j], dp[i][j<span class="hljs-number">-1</span>]) + grid[i][j];        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m<span class="hljs-number">-1</span>][n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="120-三角形最小路径和-https-leetcode-cn-com-problems-triangle"><a href="#120-三角形最小路径和-https-leetcode-cn-com-problems-triangle" class="headerlink" title="[120] 三角形最小路径和 https://leetcode-cn.com/problems/triangle/"></a>[120] 三角形最小路径和 <a href="https://leetcode-cn.com/problems/triangle/">https://leetcode-cn.com/problems/triangle/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 直接在原数组上更改</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minimumTotal</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; triangle)</span> </span>&#123;    <span class="hljs-keyword">if</span>(triangle.size() == <span class="hljs-number">0</span> || triangle[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> n = triangle.size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt;= i; j++)&#123;            <span class="hljs-keyword">if</span>(j == <span class="hljs-number">0</span>) triangle[i][<span class="hljs-number">0</span>] = triangle[i<span class="hljs-number">-1</span>][<span class="hljs-number">0</span>] + triangle[i][j];            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(j == i) triangle[i][i] = triangle[i<span class="hljs-number">-1</span>][i<span class="hljs-number">-1</span>] + triangle[i][j];            <span class="hljs-keyword">else</span>&#123;                triangle[i][j] = min(triangle[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>], triangle[i<span class="hljs-number">-1</span>][j]) + triangle[i][j];            &#125;        &#125;    &#125;    <span class="hljs-keyword">int</span> res = INT_MAX;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)  res = min(res, triangle[n<span class="hljs-number">-1</span>][i]);    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h5 id="类型四：-子串和子序列问题：上升、摆动、回文、公共"><a href="#类型四：-子串和子序列问题：上升、摆动、回文、公共" class="headerlink" title="类型四： 子串和子序列问题：上升、摆动、回文、公共"></a>类型四： 子串和子序列问题：上升、摆动、回文、公共</h5><p>这些题目的共同解法是以其中一个字符作为行， 另一个字符作为列， 然后创建二维数组进行遍历。</p><ul><li>最长公共子串/子序列</li></ul><h6 id="718-最长重复子数组-https-leetcode-cn-com-problems-maximum-length-of-repeated-subarray"><a href="#718-最长重复子数组-https-leetcode-cn-com-problems-maximum-length-of-repeated-subarray" class="headerlink" title="[718] 最长重复子数组 https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/"></a>[718] 最长重复子数组 <a href="https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/">https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findLength</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; A, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; B)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = A.size(), n = B.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n, <span class="hljs-number">0</span>))</span></span>;    <span class="hljs-comment">// init</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)         <span class="hljs-keyword">if</span>(A[i] == B[<span class="hljs-number">0</span>]) dp[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;  i &lt; n; i++)        <span class="hljs-keyword">if</span>(A[<span class="hljs-number">0</span>] == B[i]) dp[<span class="hljs-number">0</span>][i] = <span class="hljs-number">1</span>;    <span class="hljs-comment">// transform</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>;  j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(A[i] == B[j])                 dp[i][j] = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>] + <span class="hljs-number">1</span>;                res = max(res, dp[i][j]);        &#125;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="1143-最长公共子序列-https-leetcode-cn-com-problems-longest-common-subsequence-🌟🌟🌟"><a href="#1143-最长公共子序列-https-leetcode-cn-com-problems-longest-common-subsequence-🌟🌟🌟" class="headerlink" title="[1143] 最长公共子序列 https://leetcode-cn.com/problems/longest-common-subsequence/    🌟🌟🌟"></a>[1143] 最长公共子序列 <a href="https://leetcode-cn.com/problems/longest-common-subsequence/">https://leetcode-cn.com/problems/longest-common-subsequence/</a>    🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">longestCommonSubsequence</span><span class="hljs-params">(<span class="hljs-built_in">string</span> text1, <span class="hljs-built_in">string</span> text2)</span> </span>&#123;    <span class="hljs-keyword">int</span> m = text1.size();    <span class="hljs-keyword">int</span> n = text2.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m+<span class="hljs-number">1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n+<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j&lt;= n; j++)&#123;            <span class="hljs-comment">// 因为矩阵大小为 (m+1)(n+1),  所以 i-1, j-1 对应的 dp的 i,j</span>            <span class="hljs-keyword">if</span>(text1[i<span class="hljs-number">-1</span>] == text2[j<span class="hljs-number">-1</span>])&#123;                dp[i][j] = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>] + <span class="hljs-number">1</span>;            &#125;<span class="hljs-keyword">else</span>&#123;                dp[i][j] = max(dp[i<span class="hljs-number">-1</span>][j], dp[i][j<span class="hljs-number">-1</span>]);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m][n];&#125;</code></pre><ul><li>最长回文子串/子序列</li></ul><h6 id="5-最长回文子串-https-leetcode-cn-com-problems-longest-palindromic-substring-🌟🌟"><a href="#5-最长回文子串-https-leetcode-cn-com-problems-longest-palindromic-substring-🌟🌟" class="headerlink" title="[5] 最长回文子串 https://leetcode-cn.com/problems/longest-palindromic-substring/    🌟🌟"></a>[5] 最长回文子串 <a href="https://leetcode-cn.com/problems/longest-palindromic-substring/">https://leetcode-cn.com/problems/longest-palindromic-substring/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">palindrome</span><span class="hljs-params">(<span class="hljs-built_in">string</span> str, <span class="hljs-keyword">int</span> i, <span class="hljs-keyword">int</span> j, <span class="hljs-keyword">int</span> base)</span></span>&#123;    <span class="hljs-keyword">for</span>(;i &gt;= <span class="hljs-number">0</span> &amp;&amp; j &lt; str.size() &amp;&amp; str[i] == str[j]; i--, j++)   len += <span class="hljs-number">2</span>;    <span class="hljs-keyword">return</span> str.substr(i+<span class="hljs-number">1</span>, base);&#125;<span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">longestPalindrome</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-built_in">string</span> res = <span class="hljs-string">&quot;&quot;</span>;    <span class="hljs-keyword">if</span>(s.size() == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> s;    <span class="hljs-built_in">string</span> s1, s2;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; s.size(); i++)&#123;        s1 = palindrome(s, i<span class="hljs-number">-1</span>, i+<span class="hljs-number">1</span>, <span class="hljs-number">1</span>);        s2 = palindrome(s, i<span class="hljs-number">-1</span>, i, <span class="hljs-number">0</span>);        <span class="hljs-built_in">string</span> max_str = s1.size() &gt; s2.size() ? s1 : s2;        res = res.size() &gt; max_str.size() ? res : max_str;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="516-最长回文子序列-https-leetcode-cn-com-problems-longest-palindromic-subsequence-🌟🌟🌟"><a href="#516-最长回文子序列-https-leetcode-cn-com-problems-longest-palindromic-subsequence-🌟🌟🌟" class="headerlink" title="[516] 最长回文子序列 https://leetcode-cn.com/problems/longest-palindromic-subsequence/    🌟🌟🌟"></a>[516] 最长回文子序列 <a href="https://leetcode-cn.com/problems/longest-palindromic-subsequence/">https://leetcode-cn.com/problems/longest-palindromic-subsequence/</a>    🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">longestPalindromeSubseq</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-keyword">int</span> n = s.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n))</span></span>;    <span class="hljs-comment">// dp[i][j]: j-&gt;i 最大回文子串的长度</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) dp[i][i] = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = n<span class="hljs-number">-1</span>; i &gt;= <span class="hljs-number">0</span>; i--)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = i+<span class="hljs-number">1</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(s[i] == s[j])                 dp[i][j] = dp[i+<span class="hljs-number">1</span>][j<span class="hljs-number">-1</span>] + <span class="hljs-number">2</span>;            <span class="hljs-keyword">else</span>                dp[i][j] = max(dp[i+<span class="hljs-number">1</span>][j], dp[i][j<span class="hljs-number">-1</span>]);        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[<span class="hljs-number">0</span>][n<span class="hljs-number">-1</span>];&#125;</code></pre><h6 id="583-两个字符串的删除操作-https-leetcode-cn-com-problems-delete-operation-for-two-strings"><a href="#583-两个字符串的删除操作-https-leetcode-cn-com-problems-delete-operation-for-two-strings" class="headerlink" title="[583] 两个字符串的删除操作 https://leetcode-cn.com/problems/delete-operation-for-two-strings/"></a>[583] 两个字符串的删除操作 <a href="https://leetcode-cn.com/problems/delete-operation-for-two-strings/">https://leetcode-cn.com/problems/delete-operation-for-two-strings/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minDistance</span><span class="hljs-params">(<span class="hljs-built_in">string</span> word1, <span class="hljs-built_in">string</span> word2)</span> </span>&#123;    <span class="hljs-comment">// 可以转换为求公共子串的问题</span>    <span class="hljs-keyword">if</span>(word1.size() == <span class="hljs-number">0</span> || word2.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> m = word1.size();    <span class="hljs-keyword">int</span> n = word2.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m+<span class="hljs-number">1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n+<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++)&#123;            <span class="hljs-keyword">if</span>(word1[i<span class="hljs-number">-1</span>] == word2[j<span class="hljs-number">-1</span>])&#123;                dp[i][j] = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>] + <span class="hljs-number">1</span>;            &#125;<span class="hljs-keyword">else</span>&#123;                dp[i][j] = max(dp[i<span class="hljs-number">-1</span>][j], dp[i][j<span class="hljs-number">-1</span>]);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> m + n - <span class="hljs-number">2</span>*dp[m][n];&#125;</code></pre><h6 id="72-编辑距离-https-leetcode-cn-com-problems-edit-distance-🌟🌟🌟"><a href="#72-编辑距离-https-leetcode-cn-com-problems-edit-distance-🌟🌟🌟" class="headerlink" title="[72] 编辑距离 https://leetcode-cn.com/problems/edit-distance/   🌟🌟🌟"></a>[72] 编辑距离 <a href="https://leetcode-cn.com/problems/edit-distance/">https://leetcode-cn.com/problems/edit-distance/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minDistance</span><span class="hljs-params">(<span class="hljs-built_in">string</span> word1, <span class="hljs-built_in">string</span> word2)</span> </span>&#123;    <span class="hljs-keyword">if</span>(word1.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> word2.size();    <span class="hljs-keyword">if</span>(word2.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> word1.size();    <span class="hljs-keyword">int</span> m = word1.size(), n = word2.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">dp</span><span class="hljs-params">(m+<span class="hljs-number">1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n+<span class="hljs-number">1</span>, <span class="hljs-number">0</span>))</span></span>;    dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= m; i++)   dp[i][<span class="hljs-number">0</span>] = i;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++) dp[<span class="hljs-number">0</span>][j] = j;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>;  i &lt;= m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt;= n; j++)&#123;            <span class="hljs-keyword">if</span>(word1[i<span class="hljs-number">-1</span>] == word2[j<span class="hljs-number">-1</span>])                dp[i][j] = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>];            <span class="hljs-keyword">else</span>&#123;                dp[i][j] = min(dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>], min(dp[i<span class="hljs-number">-1</span>][j], dp[i][j<span class="hljs-number">-1</span>])) + <span class="hljs-number">1</span>;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[m][n];&#125;</code></pre><h5 id="类型五-股票交易"><a href="#类型五-股票交易" class="headerlink" title="类型五: 股票交易"></a>类型五: 股票交易</h5><p>股票交易问题主要包括以下几道题目： 原始的买卖股票121、无限次操作122、只能进行两次操作123、最多 k 次188、含冷冻期 309、含手续费 <a href="https://leetcode-cn.com/problemset/50/">714</a></p><h6 id="121-买卖股票的最佳时机-https-leetcode-cn-com-problems-best-time-to-buy-and-sell-stock-🌟🌟🌟"><a href="#121-买卖股票的最佳时机-https-leetcode-cn-com-problems-best-time-to-buy-and-sell-stock-🌟🌟🌟" class="headerlink" title="[121]  买卖股票的最佳时机 https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/  🌟🌟🌟"></a>[121]  买卖股票的最佳时机 <a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/">https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 寻找 vector 的最小值，用后面的值减去之前的最小值</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; prices)</span> </span>&#123;    <span class="hljs-keyword">int</span> min_val = INT_MAX;    <span class="hljs-keyword">int</span> max_profit = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; prices.size(); i++)&#123;        min_val = min(min_val, prices[i]);        max_profit = max(max_profit, prices[i] - min_val);    &#125;    <span class="hljs-keyword">return</span> max_profit &lt;=<span class="hljs-number">0</span> ? <span class="hljs-number">0</span> : max_profit;&#125;</code></pre><h6 id="122-买卖股票的最佳时机"><a href="#122-买卖股票的最佳时机" class="headerlink" title="[122] 买卖股票的最佳时机"></a>[122] 买卖股票的最佳时机</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 第 i 天的收益为 profit = prices[i] - prices[i-1]</span><span class="hljs-comment">//（1）当 profit &gt; 0 时，当天买入卖出</span><span class="hljs-comment">//（2）当 profit &lt;= 0 时，当天不进行交易</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; prices)</span> </span>&#123;    <span class="hljs-keyword">int</span> profit = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(prices.size() &lt;= <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; prices.size(); i++)&#123;        <span class="hljs-keyword">if</span>(prices[i] &gt; prices[i<span class="hljs-number">-1</span>])            profit += (prices[i] - prices[i<span class="hljs-number">-1</span>]);    &#125;    <span class="hljs-keyword">return</span> profit;&#125;</code></pre><h5 id="类型七：-分割整数"><a href="#类型七：-分割整数" class="headerlink" title="类型七： 分割整数"></a>类型七： 分割整数</h5><h6 id="343-https-leetcode-cn-com-problems-integer-break-🌟🌟"><a href="#343-https-leetcode-cn-com-problems-integer-break-🌟🌟" class="headerlink" title="[343] https://leetcode-cn.com/problems/integer-break/  🌟🌟"></a>[343] <a href="https://leetcode-cn.com/problems/integer-break/">https://leetcode-cn.com/problems/integer-break/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">cuttingRope</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;    <span class="hljs-keyword">if</span>(n == <span class="hljs-number">3</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;    <span class="hljs-keyword">int</span> mod = (<span class="hljs-keyword">int</span>)<span class="hljs-number">1e9</span> + <span class="hljs-number">7</span>;    <span class="hljs-keyword">long</span> res = <span class="hljs-number">1</span>;    <span class="hljs-comment">// 当大于 4 时候， 优先剪成 3, 之后乘以剩下的一段</span>    <span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">4</span>)&#123;        res *= <span class="hljs-number">3</span>;        res %= mod;        n-=<span class="hljs-number">3</span>;    &#125;    res = (n * res) % mod;    <span class="hljs-keyword">return</span> res;  &#125;</code></pre><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><h6 id="lcof46-https-leetcode-cn-com-problems-li-wu-de-zui-da-jie-zhi-lcof-🌟🌟"><a href="#lcof46-https-leetcode-cn-com-problems-li-wu-de-zui-da-jie-zhi-lcof-🌟🌟" class="headerlink" title="[lcof46] https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/  🌟🌟"></a>[lcof46] <a href="https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/">https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">translateNum</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num)</span> </span>&#123;    <span class="hljs-built_in">string</span> str = to_string(num);    <span class="hljs-keyword">int</span> n = str.size();    <span class="hljs-comment">// dp[i] 表示前 i 位 可以有几种翻译方法</span>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n + <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;        <span class="hljs-comment">// 如果前一个是 0， 或者 前一个和当前 &gt; 25， 那么不能组成一个新字母</span>        <span class="hljs-keyword">if</span> (str[i<span class="hljs-number">-1</span>] == <span class="hljs-string">&#x27;0&#x27;</span> || str.substr(i<span class="hljs-number">-1</span>, <span class="hljs-number">2</span>) &gt; <span class="hljs-string">&quot;25&quot;</span> ) &#123;            dp[i+<span class="hljs-number">1</span>] = dp[i];        &#125; <span class="hljs-keyword">else</span> &#123;            dp[i+<span class="hljs-number">1</span>] = dp[i] + dp[i<span class="hljs-number">-1</span>];        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[str.size()];&#125;</code></pre><h5 id="类型三-背包问题"><a href="#类型三-背包问题" class="headerlink" title="类型三 背包问题"></a>类型三 背包问题</h5><h6 id="322-零钱兑换-https-leetcode-cn-com-problems-coin-change-🌟🌟🌟"><a href="#322-零钱兑换-https-leetcode-cn-com-problems-coin-change-🌟🌟🌟" class="headerlink" title="[322] 零钱兑换 https://leetcode-cn.com/problems/coin-change/  🌟🌟🌟"></a>[322] 零钱兑换 <a href="https://leetcode-cn.com/problems/coin-change/">https://leetcode-cn.com/problems/coin-change/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">coinChange</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; coins, <span class="hljs-keyword">int</span> amount)</span> </span>&#123;    <span class="hljs-comment">//  dp[i]: 金额为i时候的最小使用张数 -&gt; 初始化为 amount+1</span>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(amount + <span class="hljs-number">1</span>, amount + <span class="hljs-number">1</span>)</span></span>;        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt;= amount; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> coin:coins)&#123;            <span class="hljs-keyword">if</span>(i &gt;= coin)  dp[i] = min(dp[i], dp[i-coin] + <span class="hljs-number">1</span>);        &#125;    &#125;    <span class="hljs-keyword">return</span> dp[amount] == amount + <span class="hljs-number">1</span> ? <span class="hljs-number">-1</span> : dp[amount];&#125;</code></pre><h3 id="4-搜索-DFS-BFS-二分-和排序-5"><a href="#4-搜索-DFS-BFS-二分-和排序-5" class="headerlink" title="4. 搜索(DFS/BFS/二分)和排序  5"></a>4. 搜索(DFS/BFS/二分)和排序  5</h3><h4 id="4-1-二分查找"><a href="#4-1-二分查找" class="headerlink" title="4.1 二分查找"></a>4.1 二分查找</h4><p>二分查找的核心思想在于怎么排除一半不符合条件的元素， 让搜寻的目标出现在限定范围内</p><p>基本的题目包含：二分查找、查找插入位置、旋转数组的查找、查找第一个和最后一个</p><pre><code class="hljs cpp"><span class="hljs-comment">// 二分查找</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">search</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">int</span> left = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> right = nums.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(left &lt;= right)&#123;  <span class="hljs-comment">// 等号</span>        <span class="hljs-keyword">int</span> mid = left + (right - left) / <span class="hljs-number">2</span>; <span class="hljs-comment">// 防止溢出</span>        <span class="hljs-keyword">if</span>(nums[mid] == target) <span class="hljs-keyword">return</span> mid;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[mid] &gt; target)&#123;            right = mid - <span class="hljs-number">1</span>;  <span class="hljs-comment">// -1</span>        &#125;<span class="hljs-keyword">else</span>&#123;            left = mid + <span class="hljs-number">1</span>;   <span class="hljs-comment">// + 1</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;</code></pre><h6 id="35-搜索插入位置-https-leetcode-cn-com-problems-search-insert-position"><a href="#35-搜索插入位置-https-leetcode-cn-com-problems-search-insert-position" class="headerlink" title="[35] 搜索插入位置 https://leetcode-cn.com/problems/search-insert-position/"></a>[35] 搜索插入位置 <a href="https://leetcode-cn.com/problems/search-insert-position/">https://leetcode-cn.com/problems/search-insert-position/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">searchInsert</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = nums.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(begin &lt;= end)&#123;        <span class="hljs-keyword">int</span> mid = begin + (end - begin) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span>(nums[mid] == target) <span class="hljs-keyword">return</span> mid;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[mid] &gt; target) end = mid - <span class="hljs-number">1</span>;        <span class="hljs-keyword">else</span> begin = mid + <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> begin;&#125;</code></pre><h6 id="33-搜索旋转排序数组-https-leetcode-cn-com-problems-search-in-rotated-sorted-array-🌟🌟🌟"><a href="#33-搜索旋转排序数组-https-leetcode-cn-com-problems-search-in-rotated-sorted-array-🌟🌟🌟" class="headerlink" title="[33] 搜索旋转排序数组 https://leetcode-cn.com/problems/search-in-rotated-sorted-array/   🌟🌟🌟"></a>[33] 搜索旋转排序数组 <a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">https://leetcode-cn.com/problems/search-in-rotated-sorted-array/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 核心思想是： 先和nums[begin] 进行比较确定那一段有序</span><span class="hljs-comment">//            然后判定是否在有序数组之中， 进而确定二分到哪段?</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">search</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = nums.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(begin &lt;= end)&#123;  <span class="hljs-comment">// ! 等号</span>        <span class="hljs-keyword">int</span> mid = begin + (end - begin) / <span class="hljs-number">2</span>; <span class="hljs-comment">// ! 防止溢出</span>        <span class="hljs-keyword">if</span>(nums[mid] == target) <span class="hljs-keyword">return</span> mid;                  <span class="hljs-keyword">if</span>(nums[mid] &gt;= nums[begin])&#123;  <span class="hljs-comment">// left is short ! &gt;=</span>            <span class="hljs-keyword">if</span>(nums[begin] &lt;= target &amp;&amp; target &lt; nums[mid]) end = mid<span class="hljs-number">-1</span>;            <span class="hljs-keyword">else</span> begin = mid + <span class="hljs-number">1</span>;        &#125; <span class="hljs-keyword">else</span> &#123;   <span class="hljs-comment">// right is sorted</span>            <span class="hljs-keyword">if</span>(nums[mid] &lt; target &amp;&amp; target &lt;= nums[end]) begin = mid+<span class="hljs-number">1</span>;            <span class="hljs-keyword">else</span> end = mid - <span class="hljs-number">1</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;</code></pre><h6 id="34-在排序数组中查找元素的第一个和最后一个位置-https-leetcode-cn-com-problems-find-first-and-last-position-of-element-in-sorted-array"><a href="#34-在排序数组中查找元素的第一个和最后一个位置-https-leetcode-cn-com-problems-find-first-and-last-position-of-element-in-sorted-array" class="headerlink" title="[34] 在排序数组中查找元素的第一个和最后一个位置 https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/)"></a>[34] 在排序数组中查找元素的第一个和最后一个位置 <a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/">https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/</a>)</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findFirstTarget</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span></span>&#123;    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = nums.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(begin &lt;= end)&#123;        <span class="hljs-keyword">int</span> mid = begin + (end - begin) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span>(nums[mid] == target)&#123;            <span class="hljs-keyword">if</span>(mid == <span class="hljs-number">0</span> || nums[mid<span class="hljs-number">-1</span>] != target) <span class="hljs-keyword">return</span> mid;            <span class="hljs-keyword">else</span>  end = mid<span class="hljs-number">-1</span>;        &#125;        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">if</span>(nums[mid] &gt; target) end = mid<span class="hljs-number">-1</span>;            <span class="hljs-keyword">else</span> begin = mid + <span class="hljs-number">1</span>;         &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findLastTarget</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span></span>&#123;    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = nums.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(begin &lt;= end)&#123;        <span class="hljs-keyword">int</span> mid = begin + (end - begin) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span>(nums[mid] == target)&#123;            <span class="hljs-keyword">if</span>(mid == nums.size()<span class="hljs-number">-1</span> || nums[mid+<span class="hljs-number">1</span>] != target) <span class="hljs-keyword">return</span> mid;            <span class="hljs-keyword">else</span>  begin = mid+<span class="hljs-number">1</span>;        &#125;        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">if</span>(nums[mid] &gt; target) end = mid<span class="hljs-number">-1</span>;            <span class="hljs-keyword">else</span> begin = mid + <span class="hljs-number">1</span>;         &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;&#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">searchRange</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> &#123;<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>&#125;;    <span class="hljs-keyword">int</span> first = findFirstTarget(nums, target);    <span class="hljs-keyword">int</span> last = findLastTarget(nums, target);    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&#123;first, last&#125;;&#125;</code></pre><h6 id="lcof-11-旋转数组的最小数字-https-leetcode-cn-com-problems-xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof"><a href="#lcof-11-旋转数组的最小数字-https-leetcode-cn-com-problems-xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof" class="headerlink" title="[lcof 11] 旋转数组的最小数字 https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/"></a>[lcof 11] 旋转数组的最小数字 <a href="https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/">https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">minArray</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; numbers)</span> </span>&#123;    <span class="hljs-keyword">int</span> left = <span class="hljs-number">0</span>, right = numbers.size() <span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(left &lt; right)&#123;   <span class="hljs-comment">// 这里没有等号</span>        <span class="hljs-keyword">int</span> mid = left + (right - left) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span>(numbers[mid] &gt; numbers[right])&#123;            left = mid + <span class="hljs-number">1</span>;        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(numbers[mid] &lt; numbers[right])&#123;            right = mid;        &#125;<span class="hljs-keyword">else</span>&#123;            right -= <span class="hljs-number">1</span>;  <span class="hljs-comment">// 这里要分三种情况的， 等于的时候 right -= 1 即可</span>        &#125;    &#125;    <span class="hljs-keyword">return</span> numbers[left];&#125;</code></pre><h6 id="69-x-的平方根-https-leetcode-cn-com-problems-sqrtx-🌟🌟🌟"><a href="#69-x-的平方根-https-leetcode-cn-com-problems-sqrtx-🌟🌟🌟" class="headerlink" title="[69] x 的平方根 https://leetcode-cn.com/problems/sqrtx/   🌟🌟🌟"></a>[69] x 的平方根 <a href="https://leetcode-cn.com/problems/sqrtx/">https://leetcode-cn.com/problems/sqrtx/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">mySqrt</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span> </span>&#123;    <span class="hljs-keyword">int</span> low = <span class="hljs-number">0</span>, high = x;     <span class="hljs-comment">// (1) 以 x 为上界</span>    <span class="hljs-keyword">while</span>(low &lt;= high)&#123;        <span class="hljs-keyword">int</span> mid = low + (high-low) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span> ((<span class="hljs-keyword">long</span> <span class="hljs-keyword">long</span>)mid * mid &gt; x)&#123;   <span class="hljs-comment">// (2) 使用 long long 防止溢出</span>                high = mid - <span class="hljs-number">1</span>;        &#125; <span class="hljs-keyword">else</span> &#123;                low = mid + <span class="hljs-number">1</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> high;   <span class="hljs-comment">// (3) 返回 high</span>&#125;</code></pre><h6 id="162-寻找峰值"><a href="#162-寻找峰值" class="headerlink" title="[162] 寻找峰值"></a>[162] 寻找峰值</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findPeakElement</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> l = <span class="hljs-number">0</span>, r = nums.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(l &lt; r)&#123;        <span class="hljs-keyword">int</span> mid = l + (r - l) / <span class="hljs-number">2</span>;        <span class="hljs-keyword">if</span>(nums[mid] &gt; nums[mid+<span class="hljs-number">1</span>])  r = mid;        <span class="hljs-keyword">else</span> l = mid + <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> l;&#125;</code></pre><h4 id="4-2-搜索-BFS-amp-DFS"><a href="#4-2-搜索-BFS-amp-DFS" class="headerlink" title="4.2  搜索 BFS &amp; DFS"></a>4.2  搜索 BFS &amp; DFS</h4><h6 id="733-图像渲染-https-leetcode-cn-com-problems-flood-fill"><a href="#733-图像渲染-https-leetcode-cn-com-problems-flood-fill" class="headerlink" title="[733]  图像渲染 https://leetcode-cn.com/problems/flood-fill/"></a>[733]  图像渲染 <a href="https://leetcode-cn.com/problems/flood-fill/">https://leetcode-cn.com/problems/flood-fill/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">floodFill</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; image, <span class="hljs-keyword">int</span> sr, <span class="hljs-keyword">int</span> sc, <span class="hljs-keyword">int</span> newColor)</span> </span>&#123;    <span class="hljs-keyword">if</span>(image.size() == <span class="hljs-number">0</span> || image[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> image;    <span class="hljs-keyword">int</span> oriColor = image[sr][sc];    bfs(image, sr, sc, newColor, oriColor);    <span class="hljs-keyword">return</span> image;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; image, <span class="hljs-keyword">int</span> sr, <span class="hljs-keyword">int</span> sc, <span class="hljs-keyword">int</span> newColor, <span class="hljs-keyword">int</span> oriColor)</span></span>&#123;    <span class="hljs-keyword">if</span>(sr &gt;= image.size() || sc &gt;= image[<span class="hljs-number">0</span>].size()  || sc &lt; <span class="hljs-number">0</span> || sr &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">if</span>(image[sr][sc] == oriColor &amp;&amp; image[sr][sc] != newColor)&#123;        image[sr][sc] = newColor;        bfs(image, sr<span class="hljs-number">-1</span>, sc, newColor, oriColor);        bfs(image, sr+<span class="hljs-number">1</span>, sc, newColor, oriColor);        bfs(image, sr, sc<span class="hljs-number">-1</span>, newColor, oriColor);        bfs(image, sr, sc+<span class="hljs-number">1</span>, newColor, oriColor);    &#125;&#125;</code></pre><h6 id="200-岛屿数量-https-leetcode-cn-com-problems-number-of-islands-🌟🌟🌟"><a href="#200-岛屿数量-https-leetcode-cn-com-problems-number-of-islands-🌟🌟🌟" class="headerlink" title="[200] 岛屿数量 https://leetcode-cn.com/problems/number-of-islands/  🌟🌟🌟"></a>[200] 岛屿数量 <a href="https://leetcode-cn.com/problems/number-of-islands/">https://leetcode-cn.com/problems/number-of-islands/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; grid, <span class="hljs-keyword">int</span> i, <span class="hljs-keyword">int</span> j, <span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span></span>&#123;    <span class="hljs-comment">// 递归退出条件</span>    <span class="hljs-keyword">if</span>(i &lt; <span class="hljs-number">0</span> || j &lt; <span class="hljs-number">0</span> || i &gt;= m || j &gt;= n || grid[i][j] == <span class="hljs-string">&#x27;0&#x27;</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-comment">// op</span>    grid[i][j] = <span class="hljs-string">&#x27;0&#x27;</span>;    bfs(grid, i+<span class="hljs-number">1</span>, j, m, n);    bfs(grid, i<span class="hljs-number">-1</span>, j, m, n);    bfs(grid, i, j+<span class="hljs-number">1</span>, m, n);    bfs(grid, i, j<span class="hljs-number">-1</span>, m, n);&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">numIslands</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; grid)</span> </span>&#123;    <span class="hljs-keyword">if</span>(grid.size() == <span class="hljs-number">0</span> || grid[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = grid.size();    <span class="hljs-keyword">int</span> n = grid[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(grid[i][j] == <span class="hljs-string">&#x27;1&#x27;</span>)&#123;                bfs(grid, i, j, m, n);                cnt++;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> cnt;&#125;</code></pre><h6 id="695-岛屿的最大面积-https-leetcode-cn-com-problems-max-area-of-island"><a href="#695-岛屿的最大面积-https-leetcode-cn-com-problems-max-area-of-island" class="headerlink" title="[695] 岛屿的最大面积 https://leetcode-cn.com/problems/max-area-of-island/"></a>[695] 岛屿的最大面积 <a href="https://leetcode-cn.com/problems/max-area-of-island/">https://leetcode-cn.com/problems/max-area-of-island/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">bfs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid, <span class="hljs-keyword">int</span> r, <span class="hljs-keyword">int</span> c, <span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span></span>&#123;    <span class="hljs-keyword">if</span>(r &lt; <span class="hljs-number">0</span> || c &lt; <span class="hljs-number">0</span> || r &gt;= m || c &gt;= n || grid[r][c] == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    grid[r][c] = <span class="hljs-number">0</span>;    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + bfs(grid, r<span class="hljs-number">-1</span>, c, m, n) + bfs(grid, r+<span class="hljs-number">1</span>, c, m, n)                 + bfs(grid, r, c<span class="hljs-number">-1</span>, m, n) + bfs(grid, r, c+<span class="hljs-number">1</span>, m, n);&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxAreaOfIsland</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;    <span class="hljs-keyword">int</span> max_area = <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(grid.size() == <span class="hljs-number">0</span> || grid[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> m = grid.size();    <span class="hljs-keyword">int</span> n = grid[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(grid[i][j] == <span class="hljs-number">1</span>) &#123;                <span class="hljs-keyword">int</span> cur_area = bfs(grid, i, j, m, n);                max_area = max(max_area, cur_area);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> max_area;&#125;</code></pre><h4 id="4-3-排序"><a href="#4-3-排序" class="headerlink" title="4.3 排序"></a>4.3 排序</h4><p>主要集中在<strong>归并排序</strong>、<strong>快速排序</strong>和<strong>堆排序</strong>几种排序方法上</p><p>sort 函数的一些要点：</p><ul><li><p>接口</p><pre><code class="hljs cpp"><span class="hljs-keyword">template</span> &lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomAccessIterator</span>&gt;</span><span class="hljs-class">  <span class="hljs-title">void</span> <span class="hljs-title">sort</span> (<span class="hljs-title">RandomAccessIterator</span> <span class="hljs-title">first</span>, <span class="hljs-title">RandomAccessIterator</span> <span class="hljs-title">last</span>);</span><span class="hljs-keyword">template</span> &lt;<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomAccessIterator</span>, <span class="hljs-title">class</span> <span class="hljs-title">Compare</span>&gt;</span><span class="hljs-class">  <span class="hljs-title">void</span> <span class="hljs-title">sort</span> (<span class="hljs-title">RandomAccessIterator</span> <span class="hljs-title">first</span>, <span class="hljs-title">RandomAccessIterator</span> <span class="hljs-title">last</span>, <span class="hljs-title">Compare</span> <span class="hljs-title">comp</span>);</span></code></pre></li><li><p>并非所有容器都使用sort算法</p><ul><li>关系型容器拥有自动排序功能，因为底层采用 rb-tree，所以不需要用到 sort 算法。</li><li>序列式容器中的 stack、queue 和 priority-queue 都有特定的出入口，不允许用户对元素排序。</li><li>只有 vector、deque，适用 sort 算法</li></ul><p>对于不能排序的容器，一般需要转化为 vector 进行排序。 比如</p><pre><code class="hljs cpp">vector&lt;pair&lt;int, int&gt; &gt; pair_vec(m_map.begin(), m_map.end());sort(pair_vec.begin(), pair_vec.end(),      [](<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; b)&#123;<span class="hljs-keyword">return</span> a.second &gt; b.second;&#125;);</code></pre></li><li><p>底层实现： STL 的 sort 算法，数据量大时采用 QuickSort 快排算法。一旦分段后的数据量小于某个阈值(16)，为避免 QuickSort 快排的递归调用带来过大的额外负荷，就改用 Insertion Sort 插入排序。如果递归层次过深，还会改用 HeapSort 堆排序。</p></li><li><p>sort 接受一个用户指定的函数 cmp。可以使外部定义的函数， 也可以是内嵌的 lambda 函数。 要求: 对于排序后的每两个相邻元素都要满足使 cmp 结果为 TRUE。也就是说，在进行比较运算的时候拿用户定义的比较函数来替代原有的比较运算符。</p></li></ul><h6 id="lcof-51-逆序数-https-leetcode-cn-com-problems-shu-zu-zhong-de-ni-xu-dui-lcof-🌟🌟🌟🌟"><a href="#lcof-51-逆序数-https-leetcode-cn-com-problems-shu-zu-zhong-de-ni-xu-dui-lcof-🌟🌟🌟🌟" class="headerlink" title="[lcof 51] 逆序数  https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/   🌟🌟🌟🌟"></a>[lcof 51] 逆序数  <a href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/">https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/</a>   🌟🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">mergeSort</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; tmp, <span class="hljs-keyword">int</span> l, <span class="hljs-keyword">int</span> r)</span> </span>&#123;    <span class="hljs-keyword">if</span> (l &gt;= r)   <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">int</span> mid = l + (r-l) / <span class="hljs-number">2</span>;    mergeSort(nums, tmp, l, mid);    mergeSort(nums, tmp, mid + <span class="hljs-number">1</span>, r);    <span class="hljs-keyword">int</span> i = l, j = mid + <span class="hljs-number">1</span>, pos = l;    <span class="hljs-keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= r) &#123;        <span class="hljs-keyword">if</span> (nums[i] &lt;= nums[j]) &#123;            tmp[pos++] = nums[i];            ++i;            inv_count += (j - (mid + <span class="hljs-number">1</span>));        &#125;        <span class="hljs-keyword">else</span> &#123;            tmp[pos++] = nums[j];            ++j;        &#125;    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = i; k &lt;= mid; ++k) &#123;        tmp[pos++] = nums[k];        inv_count += (j - (mid + <span class="hljs-number">1</span>));    &#125;    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> k = j; k &lt;= r; ++k)  tmp[pos++] = nums[k];    copy(tmp.begin() + l, tmp.begin() + r + <span class="hljs-number">1</span>, nums.begin() + l);&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">reversePairs</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> n = nums.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">tmp</span><span class="hljs-params">(n)</span></span>;    <span class="hljs-keyword">return</span> mergeSort(nums, tmp, <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span>);&#125;</code></pre><h6 id="912-排序数组-https-leetcode-cn-com-problems-sort-an-array-🌟🌟🌟🌟🌟"><a href="#912-排序数组-https-leetcode-cn-com-problems-sort-an-array-🌟🌟🌟🌟🌟" class="headerlink" title="[912] 排序数组 https://leetcode-cn.com/problems/sort-an-array/    🌟🌟🌟🌟🌟"></a>[912] 排序数组 <a href="https://leetcode-cn.com/problems/sort-an-array/">https://leetcode-cn.com/problems/sort-an-array/</a>    🌟🌟🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">partition</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &amp; nums, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> end)</span></span>&#123;    <span class="hljs-keyword">int</span> index = start + (end - start) / <span class="hljs-number">2</span>;   <span class="hljs-comment">// 获取中间值的下标</span>    swap(nums[start], nums[index]);  <span class="hljs-comment">// 交换</span>    <span class="hljs-keyword">int</span> pivot = nums[start];  <span class="hljs-comment">// 取轴</span>    <span class="hljs-keyword">int</span> left = start, right = end;  <span class="hljs-comment">// 定左右</span>    <span class="hljs-keyword">while</span>(left != right)&#123;        <span class="hljs-comment">// 注意: 下面两行的顺序是不能换的!</span>        <span class="hljs-keyword">while</span>(left &lt; right &amp;&amp; nums[right] &gt;= pivot) right--;        <span class="hljs-keyword">while</span>(left &lt; right &amp;&amp; nums[left] &lt;= pivot) left++;        <span class="hljs-keyword">if</span>(left &lt; right) swap(nums[left], nums[right]);    &#125;    swap(nums[start], nums[left]);  <span class="hljs-comment">// 再次交换</span>    <span class="hljs-keyword">return</span> left;   <span class="hljs-comment">// ! 注意返回 left</span>&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">quickSort</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> end)</span></span>&#123;    <span class="hljs-keyword">if</span>(start &lt; end)&#123;        <span class="hljs-keyword">int</span> index = partition(nums, start, end);        quickSort(nums, start, index<span class="hljs-number">-1</span>);        quickSort(nums, index+<span class="hljs-number">1</span>, end);    &#125;&#125;<span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">sortArray</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span></span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> nums;    quickSort(nums, <span class="hljs-number">0</span>, nums.size()<span class="hljs-number">-1</span>);    <span class="hljs-keyword">return</span> nums;&#125;</code></pre><h3 id="5-系统-多线程-与设计"><a href="#5-系统-多线程-与设计" class="headerlink" title="5. 系统(多线程)与设计"></a>5. 系统(多线程)与设计</h3><h6 id="面试题-16-25-LRU缓存-https-leetcode-cn-com-problems-lru-cache-lcci-🌟🌟🌟🌟🌟🌟"><a href="#面试题-16-25-LRU缓存-https-leetcode-cn-com-problems-lru-cache-lcci-🌟🌟🌟🌟🌟🌟" class="headerlink" title="[面试题 16.25. LRU缓存] https://leetcode-cn.com/problems/lru-cache-lcci/  🌟🌟🌟🌟🌟🌟"></a>[面试题 16.25. LRU缓存] <a href="https://leetcode-cn.com/problems/lru-cache-lcci/">https://leetcode-cn.com/problems/lru-cache-lcci/</a>  🌟🌟🌟🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 使用 哈希双向链表</span><span class="hljs-comment">// 注意三个数据结构不同的操作方法， 别弄混了就可以了。</span><span class="hljs-comment">// map:  添加/修改 map[key]   删除: erase(x)</span><span class="hljs-comment">// list:  删除: cache.erase()</span><span class="hljs-comment">//        back()    front()    pop_x()   push_x()  </span><span class="hljs-comment">//        获取迭代器: .begin()     .end()</span><span class="hljs-comment">//        通过迭代器获取值  *iter   </span><span class="hljs-comment">// pair:  获取值 kv.second  kv.first</span><span class="hljs-keyword">public</span>:    LRUCache(<span class="hljs-keyword">int</span> capacity) &#123;        max_capacity = capacity;    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">get</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key)</span> </span>&#123;        <span class="hljs-keyword">if</span>(m_map.find(key) != m_map.end())&#123;            <span class="hljs-keyword">auto</span> kv = *m_map[key]; <span class="hljs-comment">// 获取</span>                      cache.erase(m_map[key]);  <span class="hljs-comment">// 删除</span>            cache.push_front(kv);  <span class="hljs-comment">// 添加</span>            m_map[key] = cache.begin(); <span class="hljs-comment">// 更改指向</span>            <span class="hljs-keyword">return</span> kv.second;        &#125;        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">put</span><span class="hljs-params">(<span class="hljs-keyword">int</span> key, <span class="hljs-keyword">int</span> value)</span> </span>&#123;        <span class="hljs-keyword">if</span> (m_map.find(key) == m_map.end()) &#123;            <span class="hljs-keyword">if</span> (cache.size() == max_capacity) &#123;                m_map.erase(cache.back().first);  <span class="hljs-comment">// 删除   !!! 需要删除 key 值</span>                cache.pop_back(); <span class="hljs-comment">// </span>            &#125;        &#125;        <span class="hljs-keyword">else</span> &#123;            cache.erase(m_map[key]);        &#125;        cache.push_front(&#123;key, value&#125;);        m_map[key] = cache.begin();    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">int</span> max_capacity;    <span class="hljs-built_in">list</span>&lt;<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt; cache;    <span class="hljs-built_in">unordered_map</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">list</span>&lt;<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt;&gt;::iterator&gt; m_map; <span class="hljs-comment">// int-迭代</span></code></pre><h5 id="补充几道多线程的题目"><a href="#补充几道多线程的题目" class="headerlink" title="!!!! 补充几道多线程的题目"></a>!!!! 补充几道多线程的题目</h5>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>leetcode-ds</title>
    <link href="/2020/02/03/leetcode-ds/"/>
    <url>/2020/02/03/leetcode-ds/</url>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h3 id="1-数组-含二维-和字符串"><a href="#1-数组-含二维-和字符串" class="headerlink" title="1. 数组(含二维)和字符串"></a>1. 数组(含二维)和字符串</h3><h5 id="题型一-同向双指针"><a href="#题型一-同向双指针" class="headerlink" title="题型一: 同向双指针"></a>题型一: 同向双指针</h5><h6 id="283-移动零-https-leetcode-cn-com-problems-move-zeroes-🌟🌟"><a href="#283-移动零-https-leetcode-cn-com-problems-move-zeroes-🌟🌟" class="headerlink" title="[283] 移动零 https://leetcode-cn.com/problems/move-zeroes/   🌟🌟"></a>[283] 移动零 <a href="https://leetcode-cn.com/problems/move-zeroes/">https://leetcode-cn.com/problems/move-zeroes/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 经典双指针</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">moveZeroes</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; nums.size(); j++)&#123;        <span class="hljs-keyword">if</span>(nums[j] != <span class="hljs-number">0</span>)&#123;   <span class="hljs-comment">// 当不为零的时候，</span>            nums[i] = nums[j];   <span class="hljs-comment">// 直接进行替换</span>            i++;        &#125;    &#125;    <span class="hljs-keyword">while</span>(i &lt; nums.size()) nums[i++] = <span class="hljs-number">0</span>; &#125;</code></pre><h6 id="27-移除元素-https-leetcode-cn-com-problems-remove-element"><a href="#27-移除元素-https-leetcode-cn-com-problems-remove-element" class="headerlink" title="[27] 移除元素 https://leetcode-cn.com/problems/remove-element/"></a>[27] 移除元素 <a href="https://leetcode-cn.com/problems/remove-element/">https://leetcode-cn.com/problems/remove-element/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">removeElement</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> val)</span> </span>&#123;    <span class="hljs-keyword">int</span>  i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; nums.size(); j++)&#123;        <span class="hljs-keyword">if</span>(nums[j] != val)&#123;            nums[i] = nums[j];            i++;        &#125;    &#125;    <span class="hljs-keyword">return</span> i;&#125;</code></pre><h6 id="26-删除排序数组中的重复项"><a href="#26-删除排序数组中的重复项" class="headerlink" title="26]. 删除排序数组中的重复项"></a><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array/">26]. 删除排序数组中的重复项</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">removeDuplicates</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; nums.size(); j++)&#123;        <span class="hljs-keyword">if</span>(nums[i] != nums[j])&#123;            i++;            nums[i] = nums[j];        &#125;    &#125;    <span class="hljs-keyword">return</span> i+<span class="hljs-number">1</span>;&#125;</code></pre><h6 id="80-删除排序数组中的重复项-II-https-leetcode-cn-com-problems-remove-duplicates-from-sorted-array-ii"><a href="#80-删除排序数组中的重复项-II-https-leetcode-cn-com-problems-remove-duplicates-from-sorted-array-ii" class="headerlink" title="[80] 删除排序数组中的重复项 II https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/"></a>[80] 删除排序数组中的重复项 II <a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/">https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">removeDuplicates</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() &lt;= <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> nums.size();    <span class="hljs-keyword">int</span> p = <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] == nums[i<span class="hljs-number">-1</span>]) cnt++;        <span class="hljs-keyword">else</span> cnt = <span class="hljs-number">1</span>;          <span class="hljs-keyword">if</span>(cnt &lt;= <span class="hljs-number">2</span>) nums[p++] = nums[i];    &#125;    <span class="hljs-keyword">return</span> p;&#125;</code></pre><h6 id="58-最后一个单词的长度-https-leetcode-cn-com-problems-length-of-last-word"><a href="#58-最后一个单词的长度-https-leetcode-cn-com-problems-length-of-last-word" class="headerlink" title="[58] 最后一个单词的长度 https://leetcode-cn.com/problems/length-of-last-word/"></a>[58] 最后一个单词的长度 <a href="https://leetcode-cn.com/problems/length-of-last-word/">https://leetcode-cn.com/problems/length-of-last-word/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">lengthOfLastWord</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> pos = s.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(pos &gt;= <span class="hljs-number">0</span> &amp;&amp; s[pos] == <span class="hljs-string">&#x27; &#x27;</span>) pos--;    <span class="hljs-keyword">while</span>(pos &gt;= <span class="hljs-number">0</span> &amp;&amp; s[pos--] != <span class="hljs-string">&#x27; &#x27;</span>) res++;        <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="lcof-21-调整数组顺序使奇数位于偶数前面-https-leetcode-cn-com-problems-diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof"><a href="#lcof-21-调整数组顺序使奇数位于偶数前面-https-leetcode-cn-com-problems-diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof" class="headerlink" title="[lcof 21] 调整数组顺序使奇数位于偶数前面 https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/)"></a>[lcof 21] 调整数组顺序使奇数位于偶数前面 <a href="https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/">https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/</a>)</h6><pre><code class="hljs matlab">vector&lt;int&gt; exchange(vector&lt;int&gt;&amp; nums) &#123;    int <span class="hljs-built_in">i</span> = <span class="hljs-number">0</span>, <span class="hljs-built_in">j</span> = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(<span class="hljs-built_in">i</span> &lt; <span class="hljs-built_in">j</span>)&#123;        <span class="hljs-keyword">while</span>(<span class="hljs-built_in">i</span> &lt;<span class="hljs-built_in">j</span> &amp;&amp; nums[<span class="hljs-built_in">i</span>] <span class="hljs-comment">% 2 == 1) i++;</span>        <span class="hljs-keyword">while</span>(<span class="hljs-built_in">i</span> &lt; <span class="hljs-built_in">j</span> &amp;&amp; nums[<span class="hljs-built_in">j</span>] <span class="hljs-comment">% 2 == 0) j--;</span>        swap(nums[<span class="hljs-built_in">i</span>++], nums[<span class="hljs-built_in">j</span>--]);    &#125;    <span class="hljs-keyword">return</span> nums;&#125;</code></pre><h5 id="题型二-相向双指针"><a href="#题型二-相向双指针" class="headerlink" title="题型二: 相向双指针"></a>题型二: 相向双指针</h5><h6 id="167-两数之和-II-输入有序数组-https-leetcode-cn-com-problems-two-sum-ii-input-array-is-sorted-🌟🌟"><a href="#167-两数之和-II-输入有序数组-https-leetcode-cn-com-problems-two-sum-ii-input-array-is-sorted-🌟🌟" class="headerlink" title="[167] 两数之和 II - 输入有序数组 https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/    🌟🌟"></a>[167] 两数之和 II - 输入有序数组 <a href="https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/">https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">twoSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; numbers, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = numbers.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(begin &lt; end)&#123;        <span class="hljs-keyword">int</span> s = numbers[begin] + numbers[end];        <span class="hljs-keyword">if</span>(s == target) <span class="hljs-keyword">return</span> &#123;begin+<span class="hljs-number">1</span>, end+<span class="hljs-number">1</span>&#125;;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(s &gt; target) end--;        <span class="hljs-keyword">else</span> begin++;    &#125;    <span class="hljs-keyword">return</span> &#123;<span class="hljs-number">-1</span>, <span class="hljs-number">-1</span>&#125;;&#125;</code></pre><h6 id="15-三数之和-https-leetcode-cn-com-problems-3sum-🌟🌟"><a href="#15-三数之和-https-leetcode-cn-com-problems-3sum-🌟🌟" class="headerlink" title="[15] 三数之和 https://leetcode-cn.com/problems/3sum/   🌟🌟"></a>[15] 三数之和 <a href="https://leetcode-cn.com/problems/3sum/">https://leetcode-cn.com/problems/3sum/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">threeSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;  res;  <span class="hljs-comment">// set 去重</span>    <span class="hljs-keyword">if</span>(nums.size()==<span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> &#123;&#125;;    sort(nums.begin(), nums.end());    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size() - <span class="hljs-number">1</span>; i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] &gt; <span class="hljs-number">0</span>) <span class="hljs-keyword">continue</span>;  <span class="hljs-comment">// 剪枝</span>        <span class="hljs-keyword">if</span>(i &gt; <span class="hljs-number">0</span> &amp;&amp; nums[i] == nums[i<span class="hljs-number">-1</span>]) <span class="hljs-keyword">continue</span>;        <span class="hljs-keyword">int</span> l = i + <span class="hljs-number">1</span>, r = nums.size()<span class="hljs-number">-1</span>;        <span class="hljs-keyword">while</span>(l &lt; r)&#123;            <span class="hljs-keyword">if</span>(nums[l] + nums[r] == <span class="hljs-number">-1</span> * nums[i])&#123;                res.insert(&#123;nums[i], nums[l], nums[r]&#125;);                l++;                r--;            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[l] + nums[r] &gt; <span class="hljs-number">-1</span> * nums[i])&#123;                r--;            &#125;<span class="hljs-keyword">else</span>&#123;                l++;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;(res.begin(), res.end());&#125;</code></pre><h6 id="18-四数之和-https-leetcode-cn-com-problems-4sum"><a href="#18-四数之和-https-leetcode-cn-com-problems-4sum" class="headerlink" title="[18] 四数之和 https://leetcode-cn.com/problems/4sum/"></a>[18] 四数之和 <a href="https://leetcode-cn.com/problems/4sum/">https://leetcode-cn.com/problems/4sum/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">fourSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-keyword">if</span>(nums.size() &lt; <span class="hljs-number">3</span>) <span class="hljs-keyword">return</span> &#123;&#125;;    sort(nums.begin(), nums.end());    <span class="hljs-keyword">int</span> n = nums.size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n - <span class="hljs-number">3</span>; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = i + <span class="hljs-number">1</span>; j &lt; n<span class="hljs-number">-2</span>; j++)&#123;            <span class="hljs-keyword">int</span> t = target - (nums[i] + nums[j]);            <span class="hljs-keyword">int</span> l = j + <span class="hljs-number">1</span>, r = n<span class="hljs-number">-1</span>;            <span class="hljs-keyword">while</span>(l &lt; r)&#123;                <span class="hljs-keyword">if</span>(nums[l] + nums[r] == t)&#123;                    res.insert(&#123;nums[i], nums[j], nums[l], nums[r]&#125;);                    l++;                    r--;                &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(nums[l] + nums[r] &gt; t)&#123;                    r--;                &#125;<span class="hljs-keyword">else</span>&#123;                    l++;                &#125;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt;(res.begin(), res.end());&#125;</code></pre><h6 id="16-最接近的三数之和-https-leetcode-cn-com-problems-3sum-closest"><a href="#16-最接近的三数之和-https-leetcode-cn-com-problems-3sum-closest" class="headerlink" title="[16] 最接近的三数之和 https://leetcode-cn.com/problems/3sum-closest/"></a>[16] 最接近的三数之和 <a href="https://leetcode-cn.com/problems/3sum-closest/">https://leetcode-cn.com/problems/3sum-closest/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">threeSumClosest</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> min_diff  = INT_MAX;        sort(nums.begin(), nums.end());    <span class="hljs-keyword">int</span> n = nums.size();    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n<span class="hljs-number">-2</span>; i++)&#123;        <span class="hljs-keyword">int</span> l = i+<span class="hljs-number">1</span>, r = n<span class="hljs-number">-1</span>;        <span class="hljs-keyword">while</span>(l &lt; r)&#123;            <span class="hljs-keyword">int</span> s = nums[i] + nums[l] + nums[r];            <span class="hljs-keyword">if</span>(<span class="hljs-built_in">abs</span>(s - target) &lt; min_diff)&#123;                min_diff = <span class="hljs-built_in">abs</span>(s - target);                res = s;            &#125;            <span class="hljs-keyword">if</span>(s == target)&#123;                l++;r--;            &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(s &gt; target)&#123;                r--;            &#125;<span class="hljs-keyword">else</span>&#123;                l++;            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="11-盛最多水的容器-https-leetcode-cn-com-problems-container-with-most-water"><a href="#11-盛最多水的容器-https-leetcode-cn-com-problems-container-with-most-water" class="headerlink" title="[11] 盛最多水的容器 https://leetcode-cn.com/problems/container-with-most-water/"></a>[11] 盛最多水的容器 <a href="https://leetcode-cn.com/problems/container-with-most-water/">https://leetcode-cn.com/problems/container-with-most-water/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxArea</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; height)</span> </span>&#123;    <span class="hljs-keyword">int</span> l = <span class="hljs-number">0</span>, r = height.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">int</span> max_water = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(l &lt; r)&#123;        <span class="hljs-keyword">int</span> water = (r-l) * min(height[l], height[r]);        max_water = max(max_water, water);        <span class="hljs-keyword">if</span>(height[l] &lt; height[r]) l++; <span class="hljs-comment">// 移动短板即可 !!</span>        <span class="hljs-keyword">else</span> r--;    &#125;    <span class="hljs-keyword">return</span> max_water;&#125;</code></pre><h5 id="题型三-二维矩阵"><a href="#题型三-二维矩阵" class="headerlink" title="题型三: 二维矩阵"></a>题型三: 二维矩阵</h5><h6 id="59-螺旋矩阵-II-https-leetcode-cn-com-problems-spiral-matrix-ii"><a href="#59-螺旋矩阵-II-https-leetcode-cn-com-problems-spiral-matrix-ii" class="headerlink" title="[59]. 螺旋矩阵 II https://leetcode-cn.com/problems/spiral-matrix-ii/"></a>[59]. 螺旋矩阵 II <a href="https://leetcode-cn.com/problems/spiral-matrix-ii/">https://leetcode-cn.com/problems/spiral-matrix-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">generateMatrix</span><span class="hljs-params">(<span class="hljs-keyword">int</span> n)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; <span class="hljs-title">matrix</span><span class="hljs-params">(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;(n))</span></span>;    <span class="hljs-keyword">int</span> row_b = <span class="hljs-number">0</span>, row_e = n - <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> col_b = <span class="hljs-number">0</span>, col_e= n - <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> val = <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(row_b&lt;= row_e &amp;&amp; col_b &lt;= col_e)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = col_b; i &lt;= col_e; i++)  matrix[row_b][i] = val++;        row_b++;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = row_b; i &lt;= row_e; i++)  matrix[i][col_e] = val++;        col_e--;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = col_e; i &gt;= col_b; i--)  matrix[row_e][i] = val++;        row_e--;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = row_e; i &gt;= row_b; i--)  matrix[i][col_b] = val++;        col_b++;    &#125;    <span class="hljs-keyword">return</span> matrix;&#125;</code></pre><h6 id="54-螺旋矩阵-https-leetcode-cn-com-problems-spiral-matrix"><a href="#54-螺旋矩阵-https-leetcode-cn-com-problems-spiral-matrix" class="headerlink" title="[54] 螺旋矩阵 https://leetcode-cn.com/problems/spiral-matrix/"></a>[54] 螺旋矩阵 <a href="https://leetcode-cn.com/problems/spiral-matrix/">https://leetcode-cn.com/problems/spiral-matrix/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 行列不同，可以在每一行/列 都进行一次弹出判断</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">spiralOrder</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">if</span>(matrix.size() == <span class="hljs-number">0</span> || matrix[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-keyword">int</span> start_r = <span class="hljs-number">0</span>,  end_r = matrix.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">int</span> start_c = <span class="hljs-number">0</span>, end_c = matrix[<span class="hljs-number">0</span>].size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>)&#123; <span class="hljs-comment">// 这里退出的条件放在每个内层循环里面</span>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start_c; i &lt;= end_c; i++) res.push_back(matrix[start_r][i]);        <span class="hljs-keyword">if</span>(++start_r &gt; end_r) <span class="hljs-keyword">break</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = start_r; i &lt;= end_r; i++) res.push_back(matrix[i][end_c]);         <span class="hljs-keyword">if</span>(--end_c &lt; start_c) <span class="hljs-keyword">break</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = end_c; i &gt;= start_c; i--) res.push_back(matrix[end_r][i]);        <span class="hljs-keyword">if</span>(--end_r &lt; start_r) <span class="hljs-keyword">break</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = end_r; i &gt;= start_r; i--) res.push_back(matrix[i][start_c]);        <span class="hljs-keyword">if</span>(++start_c &gt; end_c)  <span class="hljs-keyword">break</span>;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="74-搜索二维矩阵-https-leetcode-cn-com-problems-search-a-2d-matrix"><a href="#74-搜索二维矩阵-https-leetcode-cn-com-problems-search-a-2d-matrix" class="headerlink" title="[74] 搜索二维矩阵 https://leetcode-cn.com/problems/search-a-2d-matrix/"></a>[74] 搜索二维矩阵 <a href="https://leetcode-cn.com/problems/search-a-2d-matrix/">https://leetcode-cn.com/problems/search-a-2d-matrix/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">searchMatrix</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; matrix, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-keyword">if</span>(matrix.size() == <span class="hljs-number">0</span> || matrix[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">int</span> raw = matrix.size(), col = matrix[<span class="hljs-number">0</span>].size();    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>, j = col - <span class="hljs-number">1</span>;    <span class="hljs-keyword">while</span>(i &lt; raw &amp;&amp; j &gt;= <span class="hljs-number">0</span>)&#123;        <span class="hljs-keyword">if</span>(matrix[i][j] == target) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(matrix[i][j] &gt; target) j--;        <span class="hljs-keyword">else</span> i++;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>; &#125;</code></pre><h6 id="48-旋转图像-https-leetcode-cn-com-problems-rotate-image-🌟🌟"><a href="#48-旋转图像-https-leetcode-cn-com-problems-rotate-image-🌟🌟" class="headerlink" title="[48] 旋转图像 https://leetcode-cn.com/problems/rotate-image/   🌟🌟"></a>[48] 旋转图像 <a href="https://leetcode-cn.com/problems/rotate-image/">https://leetcode-cn.com/problems/rotate-image/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">rotate</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;    <span class="hljs-keyword">if</span>(matrix.size() == <span class="hljs-number">0</span> || matrix[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-keyword">int</span> row = matrix.size(), col = matrix[<span class="hljs-number">0</span>].size();    <span class="hljs-comment">// 沿主对角线对折</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = i; j &lt; col; j++)&#123;            swap(matrix[i][j], matrix[j][i]);        &#125;    &#125;    <span class="hljs-comment">// 水平翻转</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; row; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; col / <span class="hljs-number">2</span>; j++)&#123;            swap(matrix[i][j], matrix[i][col<span class="hljs-number">-1</span>-j]);        &#125;    &#125;    <span class="hljs-keyword">return</span>;&#125;</code></pre><h6 id="73-矩阵置零-https-leetcode-cn-com-problems-set-matrix-zeroes"><a href="#73-矩阵置零-https-leetcode-cn-com-problems-set-matrix-zeroes" class="headerlink" title="[73]. 矩阵置零 https://leetcode-cn.com/problems/set-matrix-zeroes/"></a>[73]. 矩阵置零 <a href="https://leetcode-cn.com/problems/set-matrix-zeroes/">https://leetcode-cn.com/problems/set-matrix-zeroes/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">setZeroes</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;    <span class="hljs-keyword">int</span> m = matrix.size(); <span class="hljs-comment">// 行</span>    <span class="hljs-keyword">int</span> n = matrix[<span class="hljs-number">0</span>].size(); <span class="hljs-comment">// 列</span>    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">raw</span><span class="hljs-params">(m, <span class="hljs-number">0</span>)</span></span>;     <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">col</span><span class="hljs-params">(n, <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>;  j &lt; n; j++)&#123;            <span class="hljs-keyword">if</span>(matrix[i][j] == <span class="hljs-number">0</span>) raw[i]=<span class="hljs-number">1</span>;            <span class="hljs-keyword">if</span>(matrix[i][j] == <span class="hljs-number">0</span>) col[j]=<span class="hljs-number">1</span>;        &#125;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; raw.size(); i++)&#123;        <span class="hljs-keyword">if</span>(raw[i])            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)   matrix[i][j] = <span class="hljs-number">0</span>;    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; col.size(); j++)&#123;        <span class="hljs-keyword">if</span>(col[j])            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)   matrix[i][j] = <span class="hljs-number">0</span>;    &#125;  &#125;</code></pre><h5 id="题型四-回文与翻转"><a href="#题型四-回文与翻转" class="headerlink" title="题型四: 回文与翻转"></a>题型四: 回文与翻转</h5><h6 id="9-回文数-https-leetcode-cn-com-problems-palindrome-number"><a href="#9-回文数-https-leetcode-cn-com-problems-palindrome-number" class="headerlink" title="[9] 回文数 https://leetcode-cn.com/problems/palindrome-number/"></a>[9] 回文数 <a href="https://leetcode-cn.com/problems/palindrome-number/">https://leetcode-cn.com/problems/palindrome-number/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPalindrome</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span> </span>&#123;    <span class="hljs-built_in">string</span> str = to_string(x);    <span class="hljs-keyword">int</span> begin = <span class="hljs-number">0</span>, end = str.size()<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(begin &lt; end)&#123;        <span class="hljs-keyword">if</span>(str[begin++] != str[end--]) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;</code></pre><h6 id="lcof-58-https-leetcode-cn-com-problems-zuo-xuan-zhuan-zi-fu-chuan-lcof-🌟🌟"><a href="#lcof-58-https-leetcode-cn-com-problems-zuo-xuan-zhuan-zi-fu-chuan-lcof-🌟🌟" class="headerlink" title="[lcof 58] https://leetcode-cn.com/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/   🌟🌟"></a>[lcof 58] <a href="https://leetcode-cn.com/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/">https://leetcode-cn.com/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/</a>   🌟🌟</h6><pre><code class="hljs angelscript"><span class="hljs-built_in">void</span> reverse(<span class="hljs-built_in">string</span>&amp; s, <span class="hljs-built_in">int</span> i, <span class="hljs-built_in">int</span> j)&#123;    <span class="hljs-keyword">while</span>(i &lt; j)&#123;        swap(s[i++], s[j--]);    &#125;&#125;<span class="hljs-built_in">string</span> reverseLeftWords(<span class="hljs-built_in">string</span> s, <span class="hljs-built_in">int</span> n) &#123;    reverse(s, <span class="hljs-number">0</span>, n<span class="hljs-number">-1</span>);    reverse(s, n, s.size() - <span class="hljs-number">1</span>);    reverse(s, <span class="hljs-number">0</span>, s.size() - <span class="hljs-number">1</span>);    <span class="hljs-keyword">return</span> s;&#125;</code></pre><h6 id="557-反转字符串中的单词-III-https-leetcode-cn-com-problems-reverse-words-in-a-string-iii"><a href="#557-反转字符串中的单词-III-https-leetcode-cn-com-problems-reverse-words-in-a-string-iii" class="headerlink" title="[557] 反转字符串中的单词 III https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/"></a>[557] 反转字符串中的单词 III <a href="https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/">https://leetcode-cn.com/problems/reverse-words-in-a-string-iii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">reverse</span><span class="hljs-params">(<span class="hljs-built_in">string</span>&amp; a, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> end)</span></span>&#123;    <span class="hljs-keyword">while</span>(start &lt; end)&#123;        swap(a[start++], a[end--]);    &#125;&#125;<span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">reverseWords</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; s.size(); i++)&#123;        <span class="hljs-keyword">while</span>(i &lt; s.size() &amp;&amp; s[i] == <span class="hljs-string">&#x27; &#x27;</span>) i++; <span class="hljs-comment">// 指向非空</span>        <span class="hljs-keyword">int</span> j = i+<span class="hljs-number">1</span>;        <span class="hljs-keyword">while</span>(j &lt; s.size() &amp;&amp; s[j] != <span class="hljs-string">&#x27; &#x27;</span>) j++;        reverse(s, i, j<span class="hljs-number">-1</span>);        i = j;    &#125;    <span class="hljs-keyword">return</span> s;&#125;</code></pre><h6 id="lcof-58-翻转单词顺序-https-leetcode-cn-com-problems-fan-zhuan-dan-ci-shun-xu-lcof"><a href="#lcof-58-翻转单词顺序-https-leetcode-cn-com-problems-fan-zhuan-dan-ci-shun-xu-lcof" class="headerlink" title="[lcof 58] 翻转单词顺序 https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/"></a>[lcof 58] 翻转单词顺序 <a href="https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/">https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 全手写: 有点繁琐</span><span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">reverseWords</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-comment">// 预处理: 去除首尾字符</span>    s.erase(<span class="hljs-number">0</span>, s.find_first_not_of(<span class="hljs-string">&quot; &quot;</span>));      s.erase(s.find_last_not_of(<span class="hljs-string">&quot; &quot;</span>) + <span class="hljs-number">1</span>);    <span class="hljs-keyword">if</span>(s.empty()) <span class="hljs-keyword">return</span> s; <span class="hljs-comment">// 可以防止多空格的情况</span>    <span class="hljs-comment">// 单词拆分</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; vec_word;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; s.size();)&#123;        <span class="hljs-keyword">int</span> j = i + <span class="hljs-number">1</span>;        <span class="hljs-keyword">while</span>(j &lt; s.size() &amp;&amp; s[j] != <span class="hljs-string">&#x27; &#x27;</span>) j++;        vec_word.push_back(s.substr(i, j-i));        <span class="hljs-keyword">while</span>(j &lt; s.size() &amp;&amp; s[j] == <span class="hljs-string">&#x27; &#x27;</span>) j++;        i = j;    &#125;    <span class="hljs-comment">// 连接</span>    <span class="hljs-built_in">string</span> res;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = vec_word.size()<span class="hljs-number">-1</span>; i &gt; <span class="hljs-number">0</span>; i--)&#123;        res += vec_word[i];        res += <span class="hljs-string">&quot; &quot;</span>;    &#125;    res += vec_word[<span class="hljs-number">0</span>];    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h5 id="题型五-字符串和数字交互"><a href="#题型五-字符串和数字交互" class="headerlink" title="题型五: 字符串和数字交互"></a>题型五: 字符串和数字交互</h5><h6 id="8-字符串转换整数-atoi-https-leetcode-cn-com-problems-string-to-integer-atoi"><a href="#8-字符串转换整数-atoi-https-leetcode-cn-com-problems-string-to-integer-atoi" class="headerlink" title="[8] 字符串转换整数 (atoi) https://leetcode-cn.com/problems/string-to-integer-atoi/"></a>[8] 字符串转换整数 (atoi) <a href="https://leetcode-cn.com/problems/string-to-integer-atoi/">https://leetcode-cn.com/problems/string-to-integer-atoi/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">myAtoi</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-keyword">int</span> pos = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(s[pos] == <span class="hljs-string">&#x27; &#x27;</span>) pos++;    <span class="hljs-keyword">int</span> positive = <span class="hljs-literal">true</span>;    <span class="hljs-keyword">if</span>(s[pos] == <span class="hljs-string">&#x27;+&#x27;</span>)&#123;        positive = <span class="hljs-literal">true</span>;        pos++;    &#125;    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(s[pos] == <span class="hljs-string">&#x27;-&#x27;</span>)&#123;        positive = <span class="hljs-literal">false</span>;        pos++;    &#125;    <span class="hljs-keyword">long</span> res = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(<span class="hljs-built_in">isdigit</span>(s[pos]))&#123;        res = res * <span class="hljs-number">10</span> + (s[pos] - <span class="hljs-string">&#x27;0&#x27;</span>);        <span class="hljs-keyword">if</span>(res &gt; INT_MAX || res &lt; INT_MIN) <span class="hljs-keyword">break</span>;        pos++;    &#125;    res = positive ? res : <span class="hljs-number">-1</span> * res;    <span class="hljs-keyword">if</span>(res &gt; INT_MAX) <span class="hljs-keyword">return</span> INT_MAX;    <span class="hljs-keyword">if</span>(res &lt; INT_MIN) <span class="hljs-keyword">return</span> INT_MIN;    <span class="hljs-keyword">return</span> (<span class="hljs-keyword">int</span>)res;&#125;</code></pre><h6 id="数组中重复的数字"><a href="#数组中重复的数字" class="headerlink" title="数组中重复的数字"></a>数组中重复的数字</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findRepeatNumber</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-keyword">int</span>&gt; m_set;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums)&#123;        <span class="hljs-keyword">if</span>(m_set.find(n) == m_set.end())            m_set.insert(n);        <span class="hljs-keyword">else</span>            <span class="hljs-keyword">return</span> n;    &#125;     <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h6 id="lcof-66-构建乘积数组-https-leetcode-cn-com-problems-gou-jian-cheng-ji-shu-zu-lcof"><a href="#lcof-66-构建乘积数组-https-leetcode-cn-com-problems-gou-jian-cheng-ji-shu-zu-lcof" class="headerlink" title="[lcof 66] 构建乘积数组 https://leetcode-cn.com/problems/gou-jian-cheng-ji-shu-zu-lcof/"></a>[lcof 66] 构建乘积数组 <a href="https://leetcode-cn.com/problems/gou-jian-cheng-ji-shu-zu-lcof/">https://leetcode-cn.com/problems/gou-jian-cheng-ji-shu-zu-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">constructArr</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; a)</span> </span>&#123;    <span class="hljs-keyword">if</span>(a.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> &#123;&#125;;    <span class="hljs-keyword">int</span> len = a.size();    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">res</span><span class="hljs-params">(a.size(), a[len<span class="hljs-number">-1</span>])</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = len - <span class="hljs-number">2</span>; i &gt;= <span class="hljs-number">0</span>; i--)        res[i] = res[i+<span class="hljs-number">1</span>] * a[i];    <span class="hljs-keyword">int</span> m = <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;  i &lt; a.size()<span class="hljs-number">-1</span>; i++)&#123;        res[i] = m * res[i+<span class="hljs-number">1</span>];        m *= a[i];    &#125;    res[a.size()<span class="hljs-number">-1</span>] = m;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="415-字符串相加-https-leetcode-cn-com-problems-add-strings-🌟🌟"><a href="#415-字符串相加-https-leetcode-cn-com-problems-add-strings-🌟🌟" class="headerlink" title="[415] 字符串相加 https://leetcode-cn.com/problems/add-strings/   🌟🌟"></a>[415] 字符串相加 <a href="https://leetcode-cn.com/problems/add-strings/">https://leetcode-cn.com/problems/add-strings/</a>   🌟🌟</h6><pre><code class="hljs arduino"><span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">addStrings</span><span class="hljs-params">(<span class="hljs-built_in">string</span> num1, <span class="hljs-built_in">string</span> num2)</span> </span>&#123;    reverse(num1.<span class="hljs-built_in">begin</span>(), num1.<span class="hljs-built_in">end</span>());    reverse(num2.<span class="hljs-built_in">begin</span>(), num2.<span class="hljs-built_in">end</span>());    <span class="hljs-built_in">string</span> res = <span class="hljs-string">&quot;&quot;</span>;    <span class="hljs-keyword">int</span> c_in = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(i &lt; num1.<span class="hljs-built_in">size</span>() || i &lt; num2.<span class="hljs-built_in">size</span>())&#123;        <span class="hljs-keyword">int</span> n1 = i &lt; num1.<span class="hljs-built_in">size</span>() ? num1[i] - <span class="hljs-string">&#x27;0&#x27;</span>:<span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> n2 = i &lt; num2.<span class="hljs-built_in">size</span>() ? num2[i] - <span class="hljs-string">&#x27;0&#x27;</span>:<span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> s = n1 + n2 + c_in;        c_in = s / <span class="hljs-number">10</span>;        res = res + to_string(s % <span class="hljs-number">10</span>);        i++;    &#125;    <span class="hljs-keyword">if</span>(c_in) res += to_string(c_in);    reverse(res.<span class="hljs-built_in">begin</span>(), res.<span class="hljs-built_in">end</span>());    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="14-最长公共前缀-https-leetcode-cn-com-problems-longest-common-prefix"><a href="#14-最长公共前缀-https-leetcode-cn-com-problems-longest-common-prefix" class="headerlink" title="[14] 最长公共前缀 https://leetcode-cn.com/problems/longest-common-prefix/"></a>[14] 最长公共前缀 <a href="https://leetcode-cn.com/problems/longest-common-prefix/">https://leetcode-cn.com/problems/longest-common-prefix/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">string</span> <span class="hljs-title">longestCommonPrefix</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; strs)</span> </span>&#123;    <span class="hljs-keyword">if</span>(strs.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>;    <span class="hljs-keyword">if</span>(strs.size() == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; strs[<span class="hljs-number">0</span>].size(); i++)&#123;        <span class="hljs-keyword">char</span> c = strs[<span class="hljs-number">0</span>][i];        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">1</span>; j &lt; strs.size(); j++)&#123;            <span class="hljs-keyword">if</span>(strs[j].size() &lt; i) <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>].substr(<span class="hljs-number">0</span>, i);            <span class="hljs-keyword">if</span>(strs[j][i] != c) <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>].substr(<span class="hljs-number">0</span>, i);        &#125;    &#125;    <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>];&#125;</code></pre><h6 id="88-合并两个有序数组-https-leetcode-cn-com-problems-merge-sorted-array-🌟🌟"><a href="#88-合并两个有序数组-https-leetcode-cn-com-problems-merge-sorted-array-🌟🌟" class="headerlink" title="[88] 合并两个有序数组 https://leetcode-cn.com/problems/merge-sorted-array/   🌟🌟"></a>[88] 合并两个有序数组 <a href="https://leetcode-cn.com/problems/merge-sorted-array/">https://leetcode-cn.com/problems/merge-sorted-array/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">merge</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums1, <span class="hljs-keyword">int</span> m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums2, <span class="hljs-keyword">int</span> n)</span> </span>&#123;    nums1.resize(m+n);    <span class="hljs-keyword">int</span> i = m<span class="hljs-number">-1</span>, j = n<span class="hljs-number">-1</span>, k = m+n<span class="hljs-number">-1</span>;    <span class="hljs-keyword">while</span>(i &gt;= <span class="hljs-number">0</span> &amp;&amp; j &gt;= <span class="hljs-number">0</span>)&#123;        <span class="hljs-keyword">if</span>(nums1[i] &lt; nums2[j]) nums1[k--] = nums2[j--];        <span class="hljs-keyword">else</span> nums1[k--] = nums1[i--];    &#125;    <span class="hljs-keyword">while</span>(j &gt;= <span class="hljs-number">0</span>)  nums1[k--] = nums2[j--];&#125;</code></pre><h6 id="217-存在重复元素-https-leetcode-cn-com-problems-contains-duplicate"><a href="#217-存在重复元素-https-leetcode-cn-com-problems-contains-duplicate" class="headerlink" title="[217] 存在重复元素 https://leetcode-cn.com/problems/contains-duplicate/"></a>[217] 存在重复元素 <a href="https://leetcode-cn.com/problems/contains-duplicate/">https://leetcode-cn.com/problems/contains-duplicate/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">containsDuplicate</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">set</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">m_set</span><span class="hljs-params">(nums.begin(), nums.end())</span></span>;    <span class="hljs-keyword">return</span> nums.size() &gt; m_set.size();&#125;</code></pre><h5 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h5><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">lengthOfLongestSubstring</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">char</span>, <span class="hljs-keyword">int</span>&gt; m_map;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> max_len = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; s.size(); j++)&#123;        <span class="hljs-keyword">if</span>(m_map.find(s[j]) == m_map.end() || m_map[s[j]] &lt; i )&#123;            max_len = max(max_len, j-i+<span class="hljs-number">1</span>);         &#125;<span class="hljs-keyword">else</span>&#123;            i = m_map[s[j]] + <span class="hljs-number">1</span>;        &#125;        m_map[s[j]] = j;    &#125;    <span class="hljs-keyword">return</span> max_len;&#125;</code></pre><h6 id="31-下一个排列-https-leetcode-cn-com-problems-next-permutation"><a href="#31-下一个排列-https-leetcode-cn-com-problems-next-permutation" class="headerlink" title="[31] 下一个排列 https://leetcode-cn.com/problems/next-permutation/"></a>[31] 下一个排列 <a href="https://leetcode-cn.com/problems/next-permutation/">https://leetcode-cn.com/problems/next-permutation/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">nextPermutation</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-comment">// 1. 先找出最大的索引 k 满足 nums[k] &lt; nums[k+1]，如果不存在，就翻转整个数组</span>    <span class="hljs-keyword">int</span> index1 = <span class="hljs-number">-1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = nums.size()<span class="hljs-number">-2</span>; i &gt;= <span class="hljs-number">0</span>; i--)&#123;        <span class="hljs-keyword">if</span>(nums[i] &lt; nums[i+<span class="hljs-number">1</span>])&#123;            index1 = i;            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-keyword">if</span>(index1 == <span class="hljs-number">-1</span>)&#123;        reverse(nums, <span class="hljs-number">0</span>, nums.size()<span class="hljs-number">-1</span>);        <span class="hljs-keyword">return</span>;    &#125;    <span class="hljs-comment">// 2. 再找出另一个最大索引 l 满足 nums[l] &gt; nums[k]；</span>    <span class="hljs-keyword">int</span> index2 = <span class="hljs-number">-1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = nums.size()<span class="hljs-number">-1</span>; i &gt;= <span class="hljs-number">0</span>; i--)&#123;        <span class="hljs-keyword">if</span>(nums[i] &gt; nums[index1])&#123;            index2 = i;            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-comment">//  3. 交换 nums[l] 和 nums[k]；</span>    swap(nums[index1], nums[index2]);    <span class="hljs-comment">//  4. 最后翻转 nums[k+1:]。</span>    reverse(nums, index1+<span class="hljs-number">1</span>, nums.size()<span class="hljs-number">-1</span>); &#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">reverse</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &amp; nums, <span class="hljs-keyword">int</span> start, <span class="hljs-keyword">int</span> end)</span></span>&#123;    <span class="hljs-keyword">while</span>(start &lt; end)&#123;        swap(nums[start++], nums[end--]);    &#125;&#125;</code></pre><h6 id="3-无重复字符的最长子串-https-leetcode-cn-com-problems-longest-substring-without-repeating-characters-🌟🌟🌟"><a href="#3-无重复字符的最长子串-https-leetcode-cn-com-problems-longest-substring-without-repeating-characters-🌟🌟🌟" class="headerlink" title="[3] 无重复字符的最长子串 https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/)    🌟🌟🌟"></a>[3] 无重复字符的最长子串 <a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/">https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/</a>)    🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">lengthOfLongestSubstring</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-comment">// 用 lookup 来替代滑动窗口， 实现高效去重查询</span>    <span class="hljs-built_in">unordered_set</span>&lt;<span class="hljs-keyword">int</span>&gt; lookup;    <span class="hljs-keyword">int</span> left = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; s.size(); i++)&#123;        <span class="hljs-keyword">while</span>(lookup.find(s[i]) != lookup.end())&#123;            lookup.erase(s[left]);            left++;        &#125;        res = max(res, i - left + <span class="hljs-number">1</span>);        lookup.insert(s[i]);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h3 id="2-栈、堆、队列"><a href="#2-栈、堆、队列" class="headerlink" title="2. 栈、堆、队列"></a>2. 栈、堆、队列</h3><p>常见题目类型：</p><ul><li>设计题就是用栈实现队列、用队列实现栈、设计最小栈</li><li>基于这几种数据结构来实现某些功能， 比如数据流的中位数、滑动窗口的最大值、第k个最大值</li><li>单调栈(队列)的应用： 比如接雨水、直方图中的最大矩形</li></ul><h4 id="1-常见技巧总结"><a href="#1-常见技巧总结" class="headerlink" title="(1) 常见技巧总结"></a>(1) 常见技巧总结</h4><ul><li>不要对空容器(栈、堆、队列进行操作)</li><li>单调栈/队列的应用是一个挺重要的点。</li><li>有时入栈的元素时下标 index， 而不是 value，这样更方便操作。因为数组可以直接按照下标进行索引。</li></ul><p><strong>栈 : 先进后出</strong></p><pre><code class="hljs c++"><span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stack;   m_stack.size()    m_stack.empty()    m_stack.push()    m_stack.pop()    m_stack.top()</code></pre><p><strong>队列：先进先出</strong></p><pre><code class="hljs cpp"><span class="hljs-built_in">queue</span>&lt;<span class="hljs-keyword">int</span>&gt; m_queue;   m_queue.size()    m_queue.empty()   m_queue.push()    m_queue.pop()    m_queue.front()</code></pre><p><strong>双端队列</strong></p><pre><code class="hljs cpp"><span class="hljs-built_in">deque</span>&lt;<span class="hljs-keyword">int</span>&gt; m_deque;    m_deque.size()    m_deque.empty()   m_deque.front()    m_deque.back()m_deque.push_back()   m_deque.pop_back()    m_deque.push_front()   m_deque.pop_front()</code></pre><p><strong>优先队列</strong></p><p>实现：二叉堆， 最大(小)值 先出的完全二叉树</p><pre><code class="hljs cpp"><span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>&gt; max_heap;              <span class="hljs-comment">// 默认构造最大堆</span><span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, less&lt;<span class="hljs-keyword">int</span>&gt; &gt; max_heap;     <span class="hljs-comment">// 构造最大堆:less -&gt; max_heap</span><span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, greater&lt;<span class="hljs-keyword">int</span>&gt; &gt; min_heap;   <span class="hljs-comment">// 构造最小堆:greater -&gt; min_heap</span>max_heap.size()    max_heap.empty()     max_heap.push()      max_heap.pop()     max_heap.top()  <span class="hljs-comment">// 虽然它是一个队列，但是这里去元素不是 front 方法, 而是 top 方法: 返回堆顶</span></code></pre><h4 id="2-典型例题"><a href="#2-典型例题" class="headerlink" title="(2) 典型例题"></a>(2) 典型例题</h4><h5 id="类型一-常规题目"><a href="#类型一-常规题目" class="headerlink" title="类型一: 常规题目"></a>类型一: 常规题目</h5><h6 id="155-https-leetcode-cn-com-problems-min-stack-🌟🌟"><a href="#155-https-leetcode-cn-com-problems-min-stack-🌟🌟" class="headerlink" title="[155] https://leetcode-cn.com/problems/min-stack/   🌟🌟"></a>[155] <a href="https://leetcode-cn.com/problems/min-stack/">https://leetcode-cn.com/problems/min-stack/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 解题思路:</span><span class="hljs-comment">// 使用辅助栈记录栈的最小值</span><span class="hljs-comment">// 当添加元素时， 将待添加元素与辅助栈栈顶元素进行比较</span><span class="hljs-comment">//     当栈顶元素小于待添加元素 -&gt; 辅助栈添加栈顶元素</span><span class="hljs-comment">//     当栈顶元素大于待添加元素 -&gt; 辅助栈添加待添加元素</span><span class="hljs-comment">// !! 题目默认各种操作合法:即不回对空栈进行top、min和 pop 操作，所以代码中没有进行相关判定</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MinStack</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">/** initialize your data structure here. */</span>    MinStack() &#123;    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span> </span>&#123;        m_stk.push(x);        <span class="hljs-keyword">if</span>(min_stk.empty())   min_stk.push(x);        <span class="hljs-keyword">else</span> min_stk.push(<span class="hljs-built_in">std</span>::min(min_stk.top(), x));    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;        m_stk.pop();        min_stk.pop();    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">top</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> m_stk.top();    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">min</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> min_stk.top();    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; min_stk;    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stk;&#125;;</code></pre><h6 id="232-https-leetcode-com-problems-implement-queue-using-stacks-🌟🌟"><a href="#232-https-leetcode-com-problems-implement-queue-using-stacks-🌟🌟" class="headerlink" title="[232] https://leetcode.com/problems/implement-queue-using-stacks/  🌟🌟"></a>[232] <a href="https://leetcode.com/problems/implement-queue-using-stacks/">https://leetcode.com/problems/implement-queue-using-stacks/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 解题思路:</span><span class="hljs-comment">// (1) 申请两个栈 data_stack 和 m_stack</span><span class="hljs-comment">// (2) 当入队(添加数据)时, 执行如下三个步骤</span><span class="hljs-comment">//      - 将 data_stack 中的数据逐个 放到 m_stack 中</span><span class="hljs-comment">//      - 将 value 添加到 m_stack 中</span><span class="hljs-comment">//      - 将 m_stack 中的数据 逐个放入到 data_stack 中 </span><span class="hljs-comment">// (3) 当出队(删除数据)时， 直接弹出 data_stack 栈顶数据即可    </span><span class="hljs-keyword">private</span>:    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; data_stack;    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stack;<span class="hljs-keyword">public</span>:    CQueue() &#123;    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">appendTail</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;        <span class="hljs-keyword">while</span>(!data_stack.empty())&#123;            m_stack.push(data_stack.top());            data_stack.pop();        &#125;        data_stack.push(value);        <span class="hljs-keyword">while</span>(!m_stack.empty())&#123;            data_stack.push(m_stack.top());            m_stack.pop();        &#125;    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">deleteHead</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">if</span>(data_stack.empty()) <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>; <span class="hljs-comment">// 边界条件!  栈空!</span>              <span class="hljs-keyword">int</span> x = data_stack.top();        data_stack.pop();        <span class="hljs-keyword">return</span> x;    &#125;</code></pre><h6 id="225-用队列实现栈-https-leetcode-cn-com-problems-implement-stack-using-queues-🌟🌟"><a href="#225-用队列实现栈-https-leetcode-cn-com-problems-implement-stack-using-queues-🌟🌟" class="headerlink" title="[225] 用队列实现栈 https://leetcode-cn.com/problems/implement-stack-using-queues/  🌟🌟"></a>[225] 用队列实现栈 <a href="https://leetcode-cn.com/problems/implement-stack-using-queues/">https://leetcode-cn.com/problems/implement-stack-using-queues/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">/** Initialize your data structure here. */</span>MyStack() &#123;&#125;<span class="hljs-comment">/** Push element x onto stack. */</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span> </span>&#123;    <span class="hljs-keyword">if</span>(data_queue.empty()) data_queue.push(x);    <span class="hljs-keyword">else</span>&#123;        <span class="hljs-keyword">while</span>(!data_queue.empty())&#123;            temp_queue.push(data_queue.front());            data_queue.pop();        &#125;        data_queue.push(x);        <span class="hljs-keyword">while</span>(!temp_queue.empty())&#123;            data_queue.push(temp_queue.front());            temp_queue.pop();        &#125;    &#125;&#125;<span class="hljs-comment">/** Removes the element on top of the stack and returns that element. */</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;    <span class="hljs-keyword">int</span> x = data_queue.front();    data_queue.pop();    <span class="hljs-keyword">return</span> x;&#125;<span class="hljs-comment">/** Get the top element. */</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">top</span><span class="hljs-params">()</span> </span>&#123;    <span class="hljs-keyword">return</span> data_queue.front();&#125;<span class="hljs-comment">/** Returns whether the stack is empty. */</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">empty</span><span class="hljs-params">()</span> </span>&#123;    <span class="hljs-keyword">return</span> data_queue.empty();&#125;<span class="hljs-keyword">private</span>:<span class="hljs-built_in">queue</span>&lt;<span class="hljs-keyword">int</span>&gt; data_queue;<span class="hljs-built_in">queue</span>&lt;<span class="hljs-keyword">int</span>&gt; temp_queue;</code></pre><h6 id="946-https-leetcode-cn-com-problems-validate-stack-sequences"><a href="#946-https-leetcode-cn-com-problems-validate-stack-sequences" class="headerlink" title="[946] https://leetcode-cn.com/problems/validate-stack-sequences/"></a>[946] <a href="https://leetcode-cn.com/problems/validate-stack-sequences/">https://leetcode-cn.com/problems/validate-stack-sequences/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">validateStackSequences</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; pushed, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; popped)</span> </span>&#123;    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stk;    <span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;  i &lt; pushed.size(); i++)&#123;        m_stk.push(pushed[i]);        <span class="hljs-keyword">while</span>(!m_stk.empty() &amp;&amp; m_stk.top() == popped[j])&#123;            j++;            m_stk.pop();        &#125;    &#125;    <span class="hljs-keyword">return</span> m_stk.empty();&#125;</code></pre><h5 id="类型二：-利用容器实现某种功能"><a href="#类型二：-利用容器实现某种功能" class="headerlink" title="类型二： 利用容器实现某种功能"></a>类型二： 利用容器实现某种功能</h5><h6 id="215-https-leetcode-cn-com-problems-kth-largest-element-in-an-array"><a href="#215-https-leetcode-cn-com-problems-kth-largest-element-in-an-array" class="headerlink" title="[215] https://leetcode-cn.com/problems/kth-largest-element-in-an-array/"></a>[215] <a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/">https://leetcode-cn.com/problems/kth-largest-element-in-an-array/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 查找最大 k 个值： 用最小堆, 声明的第三个类型是 greater&lt;int&gt;</span><span class="hljs-comment">// 查找最小 k 个值： 用最大堆, 声明的第三个类型是 less &lt;int&gt;</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">findKthLargest</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, greater&lt;<span class="hljs-keyword">int</span>&gt; &gt; min_heap;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(i &lt; k) min_heap.push(nums[i]);        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">if</span>(nums[i] &gt; min_heap.top())&#123;                min_heap.pop();                min_heap.push(nums[i]);            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> min_heap.top();&#125;</code></pre><h6 id="lcci-17-14-最小K个数-https-leetcode-cn-com-problems-smallest-k-lcci-🌟🌟"><a href="#lcci-17-14-最小K个数-https-leetcode-cn-com-problems-smallest-k-lcci-🌟🌟" class="headerlink" title="[lcci 17.14] 最小K个数 https://leetcode-cn.com/problems/smallest-k-lcci/     🌟🌟"></a>[lcci 17.14] 最小K个数 <a href="https://leetcode-cn.com/problems/smallest-k-lcci/">https://leetcode-cn.com/problems/smallest-k-lcci/</a>     🌟🌟</h6><p>类题 : 347  Top K Frequent Elements   —&gt; 可以使用哈希表解决</p><pre><code class="hljs cpp"><span class="hljs-comment">// 和 leetcode 215 几乎一样, 最小值， 用最大堆!!</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">smallestK</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; arr, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">if</span>(arr.size() == <span class="hljs-number">0</span> || k == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">priority_queue</span>&lt;<span class="hljs-keyword">int</span>&gt; max_heap;   <span class="hljs-comment">// 最大堆</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; arr.size(); i++)&#123;        <span class="hljs-keyword">if</span>(i &lt; k) max_heap.push(arr[i]);        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">if</span>(arr[i] &lt; max_heap.top())&#123;                max_heap.pop();                max_heap.push(arr[i]);            &#125;        &#125;    &#125;    <span class="hljs-keyword">while</span>(!max_heap.empty())&#123;        res.push_back(max_heap.top());        max_heap.pop();    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="259-https-leetcode-cn-com-problems-find-median-from-data-stream-🌟🌟"><a href="#259-https-leetcode-cn-com-problems-find-median-from-data-stream-🌟🌟" class="headerlink" title="[259] https://leetcode-cn.com/problems/find-median-from-data-stream/  🌟🌟"></a>[259] <a href="https://leetcode-cn.com/problems/find-median-from-data-stream/">https://leetcode-cn.com/problems/find-median-from-data-stream/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// ！ 非常经典的一道题目， 借助数据结构，降低算法复杂度</span><span class="hljs-keyword">public</span>:    <span class="hljs-comment">/** initialize your data structure here. */</span>    MedianFinder() &#123;    &#125;        <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">addNum</span><span class="hljs-params">(<span class="hljs-keyword">int</span> num)</span> </span>&#123;        <span class="hljs-comment">// 确保加入之后，最大堆的元素值都是小于最小堆的  </span>        max_heap.push(num);        min_heap.push(max_heap.top());        max_heap.pop();              <span class="hljs-comment">// 平衡两个堆得元素个数</span>        <span class="hljs-keyword">while</span>(min_heap.size() &gt; max_heap.size())&#123;            max_heap.push(min_heap.top());            min_heap.pop();        &#125;    &#125;        <span class="hljs-function"><span class="hljs-keyword">double</span> <span class="hljs-title">findMedian</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">return</span> max_heap.size() &gt; min_heap.size() ? <span class="hljs-keyword">double</span>(max_heap.top())                                                   : (max_heap.top() + min_heap.top()) * <span class="hljs-number">0.5</span>;    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-comment">// 保持大顶堆的元素数目大于小顶堆得元素数目</span>    <span class="hljs-built_in">priority_queue</span> &lt;<span class="hljs-keyword">int</span>&gt; max_heap; <span class="hljs-comment">// 大顶堆</span>    <span class="hljs-built_in">priority_queue</span> &lt;<span class="hljs-keyword">int</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;, greater&lt;<span class="hljs-keyword">int</span>&gt; &gt; min_heap; <span class="hljs-comment">// 小顶堆</span></code></pre><h5 id="类型三：-单调栈-队列"><a href="#类型三：-单调栈-队列" class="headerlink" title="类型三： 单调栈/队列"></a>类型三： 单调栈/队列</h5><h6 id="lcof-59-https-leetcode-cn-com-problems-dui-lie-de-zui-da-zhi-lcof"><a href="#lcof-59-https-leetcode-cn-com-problems-dui-lie-de-zui-da-zhi-lcof" class="headerlink" title="[lcof 59] https://leetcode-cn.com/problems/dui-lie-de-zui-da-zhi-lcof/"></a>[lcof 59] <a href="https://leetcode-cn.com/problems/dui-lie-de-zui-da-zhi-lcof/">https://leetcode-cn.com/problems/dui-lie-de-zui-da-zhi-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// ! 使用单调的双向队列</span><span class="hljs-keyword">public</span>:    MaxQueue() &#123;    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">max_value</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">if</span>(max_deq.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        <span class="hljs-keyword">return</span> max_deq.front();    &#125;         <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">push_back</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span> </span>&#123;        data.push(value);        <span class="hljs-keyword">while</span>(max_deq.size() &amp;&amp; max_deq.back() &lt; value)            max_deq.pop_back();        max_deq.push_back(value);    &#125;        <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">pop_front</span><span class="hljs-params">()</span> </span>&#123;        <span class="hljs-keyword">if</span>(data.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;        <span class="hljs-keyword">int</span> n = data.front();           data.pop();        <span class="hljs-keyword">if</span>(max_deq.size() &amp;&amp; max_deq.front() == n)            max_deq.pop_front();        <span class="hljs-keyword">return</span> n;    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-built_in">queue</span>&lt;<span class="hljs-keyword">int</span>&gt; data;    <span class="hljs-built_in">deque</span>&lt;<span class="hljs-keyword">int</span>&gt; max_deq;</code></pre><h6 id="739-https-leetcode-cn-com-problems-daily-temperatures"><a href="#739-https-leetcode-cn-com-problems-daily-temperatures" class="headerlink" title="[739] https://leetcode-cn.com/problems/daily-temperatures/"></a>[739] <a href="https://leetcode-cn.com/problems/daily-temperatures/">https://leetcode-cn.com/problems/daily-temperatures/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dailyTemperatures</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; T)</span> </span>&#123;    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stk;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">m_vec</span><span class="hljs-params">(T.size(), <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; T.size(); i++)&#123;        <span class="hljs-keyword">if</span>(m_stk.empty()) m_stk.push(i);        <span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">while</span>(!m_stk.empty() &amp;&amp; T[i] &gt; T[m_stk.top()])&#123;                m_vec[m_stk.top()] = i - m_stk.top();                m_stk.pop();            &#125;            m_stk.push(i);        &#125;    &#125;      <span class="hljs-keyword">while</span>(!m_stk.empty())&#123;       <span class="hljs-comment">// 其实这几行不需要， 初始化就是 0</span>        m_vec[m_stk.top()] = <span class="hljs-number">0</span>;        m_stk.pop();    &#125;    <span class="hljs-keyword">return</span> m_vec;&#125;</code></pre><h6 id="239-https-leetcode-cn-com-problems-sliding-window-maximum-🌟🌟🌟"><a href="#239-https-leetcode-cn-com-problems-sliding-window-maximum-🌟🌟🌟" class="headerlink" title="[239] https://leetcode-cn.com/problems/sliding-window-maximum/   🌟🌟🌟"></a>[239] <a href="https://leetcode-cn.com/problems/sliding-window-maximum/">https://leetcode-cn.com/problems/sliding-window-maximum/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// ! 使用了单调双向队列: 这是经常考查的重点</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">maxSlidingWindow</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-built_in">deque</span>&lt;<span class="hljs-keyword">int</span>&gt; m_deque;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">while</span>(!m_deque.empty() &amp;&amp; nums[i] &gt; nums[m_deque.back()])&#123;            m_deque.pop_back();        &#125;        m_deque.push_back(i);    <span class="hljs-comment">// 这里进入队列的是 index， 而不是 value</span>        <span class="hljs-keyword">if</span>(i - m_deque.front() &gt;= k) m_deque.pop_front();        <span class="hljs-comment">// 开始添加!</span>        <span class="hljs-keyword">if</span>(i &gt;= k<span class="hljs-number">-1</span>) res.push_back(nums[m_deque.front()]);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="42-接雨水-https-leetcode-cn-com-problems-trapping-rain-water-🌟🌟🌟"><a href="#42-接雨水-https-leetcode-cn-com-problems-trapping-rain-water-🌟🌟🌟" class="headerlink" title="[42] 接雨水 https://leetcode-cn.com/problems/trapping-rain-water/   🌟🌟🌟"></a>[42] 接雨水 <a href="https://leetcode-cn.com/problems/trapping-rain-water/">https://leetcode-cn.com/problems/trapping-rain-water/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">trap</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; height)</span> </span>&#123;    <span class="hljs-keyword">if</span>(height.size() &lt;= <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    <span class="hljs-comment">// 首先找到最高的值的下标</span>    <span class="hljs-keyword">int</span> max_ind = max_element(height.begin(), height.end()) - height.begin();    <span class="hljs-comment">// 从左向右开始遍历：如果当前值比(之前的最大值)的小，那么可以积雨水； 否则更新当前值</span>    <span class="hljs-keyword">int</span> cur = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">1</span>; i &lt; max_ind; i++)&#123;        <span class="hljs-keyword">if</span>(height[i] &lt; height[cur])  res += (height[cur] - height[i]);        <span class="hljs-keyword">else</span> cur = i;    &#125;    <span class="hljs-comment">// 从右向左开始遍历</span>    cur = height.size() - <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = cur - <span class="hljs-number">1</span>; i &gt; max_ind; i--)&#123;        <span class="hljs-keyword">if</span>(height[i] &lt; height[cur]) res += (height[cur] - height[i]);        <span class="hljs-keyword">else</span> cur = i;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="84-Largest-Rectangle-in-Histogram-https-leetcode-com-problems-largest-rectangle-in-histogram-description-🌟🌟🌟"><a href="#84-Largest-Rectangle-in-Histogram-https-leetcode-com-problems-largest-rectangle-in-histogram-description-🌟🌟🌟" class="headerlink" title="[84] Largest Rectangle in Histogram https://leetcode.com/problems/largest-rectangle-in-histogram/description/  🌟🌟🌟"></a>[84] Largest Rectangle in Histogram <a href="https://leetcode.com/problems/largest-rectangle-in-histogram/description/">https://leetcode.com/problems/largest-rectangle-in-histogram/description/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">largestRectangleArea</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; heights)</span> </span>&#123;    <span class="hljs-keyword">int</span> cur_area = <span class="hljs-number">0</span>;    <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; m_stk;    <span class="hljs-comment">// (1) 让最后的栈内元素都可以弹出 !</span>    heights.push_back(<span class="hljs-number">0</span>);     <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>;  i &lt; heights.size(); i++)&#123;        <span class="hljs-comment">// (1) 当当前的值比栈顶元素小的时候， 可以计算以栈顶元素为高的最大矩形的长度</span>        <span class="hljs-keyword">while</span>(!m_stk.empty() &amp;&amp; heights[i] &lt; heights[m_stk.top()])&#123;            <span class="hljs-keyword">int</span> height = heights[m_stk.top()];  <span class="hljs-comment">// 高</span>            m_stk.pop();            <span class="hljs-comment">// 当前的元素 和 弹出元素后的栈顶 差值为 宽</span>            <span class="hljs-comment">// 注意! 弹出后可能栈为空</span>            <span class="hljs-keyword">int</span> width = m_stk.empty() ? i : i - m_stk.top() - <span class="hljs-number">1</span>;             cur_area = max(height * width, cur_area);        &#125;        m_stk.push(i);    &#125;    <span class="hljs-keyword">return</span> cur_area;&#125;<span class="hljs-comment">// 最大矩形</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maximalRectangle</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt;&gt;&amp; matrix)</span> </span>&#123;    <span class="hljs-keyword">if</span>(matrix.size() == <span class="hljs-number">0</span> || matrix[<span class="hljs-number">0</span>].size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> n = matrix[<span class="hljs-number">0</span>].size();      <span class="hljs-keyword">int</span> max_area = <span class="hljs-number">0</span>;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">heights</span><span class="hljs-params">(n, <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; matrix.size(); i++)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; matrix[<span class="hljs-number">0</span>].size(); j++)&#123;            <span class="hljs-keyword">if</span>(matrix[i][j] == <span class="hljs-string">&#x27;1&#x27;</span>) heights[j]++;            <span class="hljs-keyword">else</span> heights[j] = <span class="hljs-number">0</span>;        &#125;        max_area = max(largestRectangleArea(heights), max_area);    &#125;    <span class="hljs-keyword">return</span> max_area;&#125;</code></pre><h3 id="3-链表"><a href="#3-链表" class="headerlink" title="3. 链表"></a>3. 链表</h3><p><img src="/2020/02/03/leetcode-ds/linklist.png" style="zoom:50%;"></p><h4 id="1-常用技巧总结"><a href="#1-常用技巧总结" class="headerlink" title="(1) 常用技巧总结"></a>(1) 常用技巧总结</h4><ul><li><p>添加哑节点</p><pre><code class="hljs c++"><span class="hljs-comment">// 建立</span>ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);dummy -&gt; next = head;<span class="hljs-comment">// 释放:</span>ListNode * res = dummy -&gt; next;<span class="hljs-keyword">delete</span> dummy;<span class="hljs-keyword">return</span> res;</code></pre></li><li><p>头指针一般不可以随意改变， 可以申请一个指向头指针的指针</p><pre><code class="hljs abnf">ListNode * p = head<span class="hljs-comment">;</span></code></pre></li><li><p>不要让链表断开了， 适当的在纸上模拟一下对应的链表指向操作。</p></li><li><p>注意一下常见的边界条件：头结点 和 尾结点， 链表为空， 只有一个节点。</p></li><li><p>使用快慢指针、建立一个 Node2index 的 映射</p></li><li><p>注意些小细节：删除节点的释放，末尾指针不要乱指</p></li></ul><h4 id="2-典型例题-1"><a href="#2-典型例题-1" class="headerlink" title="(2) 典型例题"></a>(2) 典型例题</h4><h5 id="①-性质判定"><a href="#①-性质判定" class="headerlink" title="① 性质判定"></a>① 性质判定</h5><h6 id="141-https-leetcode-com-problems-linked-list-cycle-🌟🌟"><a href="#141-https-leetcode-com-problems-linked-list-cycle-🌟🌟" class="headerlink" title="[141] https://leetcode.com/problems/linked-list-cycle/  🌟🌟"></a>[141] <a href="https://leetcode.com/problems/linked-list-cycle/">https://leetcode.com/problems/linked-list-cycle/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">hasCycle</span><span class="hljs-params">(ListNode *head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    ListNode * slow = head;  <span class="hljs-comment">// (1) 两个节点初始时候均指向 head</span>    ListNode * fast = head;    <span class="hljs-keyword">while</span>(fast &amp;&amp; fast -&gt; next)&#123;        <span class="hljs-comment">// (2) 先移动， 再判断</span>        slow = slow -&gt; next;        fast = fast -&gt; next -&gt; next;        <span class="hljs-keyword">if</span>(slow == fast) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;&#125;</code></pre><h6 id="142-https-leetcode-cn-com-problems-linked-list-cycle-ii-🌟🌟"><a href="#142-https-leetcode-cn-com-problems-linked-list-cycle-ii-🌟🌟" class="headerlink" title="[142] https://leetcode-cn.com/problems/linked-list-cycle-ii/    🌟🌟"></a>[142] <a href="https://leetcode-cn.com/problems/linked-list-cycle-ii/">https://leetcode-cn.com/problems/linked-list-cycle-ii/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode *<span class="hljs-title">detectCycle</span><span class="hljs-params">(ListNode *head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    ListNode * slow = head;     ListNode * fast = head;    <span class="hljs-keyword">while</span>(fast &amp;&amp; fast -&gt; next)&#123;        slow = slow -&gt; next;        fast = fast -&gt; next -&gt; next;        <span class="hljs-keyword">if</span>(fast == slow) <span class="hljs-keyword">break</span>;    &#125;    <span class="hljs-keyword">if</span>(fast == <span class="hljs-literal">NULL</span> || fast -&gt; next == <span class="hljs-literal">NULL</span>)        <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;      <span class="hljs-comment">// (3) 一个指针从相遇节点开始， 另一个指针从头开始，两者如果相遇</span>    <span class="hljs-comment">// 则该节点即为入环节点</span>    slow = head;    <span class="hljs-keyword">while</span>(slow != fast)&#123;        slow = slow -&gt; next;        fast = fast -&gt; next;    &#125;    <span class="hljs-keyword">return</span> fast;  &#125;</code></pre><h6 id="234-https-leetcode-cn-com-problems-palindrome-linked-list"><a href="#234-https-leetcode-cn-com-problems-palindrome-linked-list" class="headerlink" title="[234] https://leetcode-cn.com/problems/palindrome-linked-list/"></a>[234] <a href="https://leetcode-cn.com/problems/palindrome-linked-list/">https://leetcode-cn.com/problems/palindrome-linked-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode * <span class="hljs-title">reverseLinkList</span><span class="hljs-params">(ListNode * head)</span></span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    ListNode * prev = <span class="hljs-literal">NULL</span>;    ListNode * cur = head;    <span class="hljs-keyword">while</span>(cur)&#123;        ListNode * next = cur -&gt; next;        cur -&gt; next = prev;        prev = cur;        cur = next;    &#125;    <span class="hljs-keyword">return</span> prev;&#125;<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isPalindrome</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-comment">// (1) 找到中间节点</span>    ListNode * p = head;     <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(p)&#123;        cnt += <span class="hljs-number">1</span>;        p = p -&gt; next;    &#125;    cnt /= <span class="hljs-number">2</span>;    p = head;    <span class="hljs-keyword">while</span>(cnt--)  p = p -&gt; next;         <span class="hljs-comment">// (2) 翻转后半部分</span>    ListNode * q = reverseLinkList(p);       <span class="hljs-comment">// (3) 判断是否相等</span>    <span class="hljs-keyword">while</span>(q &amp;&amp; head)&#123;         <span class="hljs-keyword">if</span>(head -&gt; val != q -&gt; val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;        q = q -&gt; next;        head = head -&gt; next;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;</code></pre><h5 id="②获取指定节点"><a href="#②获取指定节点" class="headerlink" title="②获取指定节点"></a>②获取指定节点</h5><h6 id="19-https-leetcode-com-problems-remove-nth-node-from-end-of-list-🌟🌟"><a href="#19-https-leetcode-com-problems-remove-nth-node-from-end-of-list-🌟🌟" class="headerlink" title="[19] https://leetcode.com/problems/remove-nth-node-from-end-of-list/     🌟🌟"></a>[19] <a href="https://leetcode.com/problems/remove-nth-node-from-end-of-list/">https://leetcode.com/problems/remove-nth-node-from-end-of-list/</a>     🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">removeNthFromEnd</span><span class="hljs-params">(ListNode* head, <span class="hljs-keyword">int</span> n)</span> </span>&#123;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    dummy -&gt; next = head;    ListNode * fast = dummy;    ListNode * slow = dummy;    <span class="hljs-comment">// (1) fast 多走一步, slow 少走一步</span>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n+<span class="hljs-number">1</span>; i++)&#123;         fast = fast -&gt; next;        &#125;    <span class="hljs-keyword">while</span>(fast)&#123;        fast = fast -&gt; next;        slow = slow -&gt; next;    &#125;    <span class="hljs-comment">// (2) 释放删除节点</span>    ListNode * del = slow -&gt; next;    slow -&gt; next = slow -&gt; next -&gt; next;    <span class="hljs-keyword">delete</span> del;    <span class="hljs-comment">// (3) 释放申请的 ListNode</span>    ListNode * res = dummy -&gt; next;    <span class="hljs-keyword">delete</span> dummy;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="160-https-leetcode-cn-com-problems-intersection-of-two-linked-lists-🌟🌟"><a href="#160-https-leetcode-cn-com-problems-intersection-of-two-linked-lists-🌟🌟" class="headerlink" title="[160] https://leetcode-cn.com/problems/intersection-of-two-linked-lists/    🌟🌟"></a>[160] <a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/">https://leetcode-cn.com/problems/intersection-of-two-linked-lists/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">getLengh</span><span class="hljs-params">(ListNode * head)</span></span>&#123;    ListNode * cur = head;    <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(cur)&#123;        cnt += <span class="hljs-number">1</span>;        cur = cur -&gt; next;    &#125;    <span class="hljs-keyword">return</span> cnt;&#125;<span class="hljs-function">ListNode *<span class="hljs-title">getIntersectionNode</span><span class="hljs-params">(ListNode *headA, ListNode *headB)</span> </span>&#123;    <span class="hljs-keyword">int</span> lenA = getLengh(headA);    <span class="hljs-keyword">int</span> lenB = getLengh(headB);    <span class="hljs-keyword">int</span> diff = <span class="hljs-built_in">abs</span>(lenB - lenA);    ListNode * pA = headA;    ListNode * pB = headB;    <span class="hljs-keyword">if</span>(lenA &gt; lenB)&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; diff; i++)  pA = pA -&gt; next;    &#125;<span class="hljs-keyword">else</span>&#123;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; diff; i++) pB = pB -&gt; next;    &#125;    <span class="hljs-keyword">while</span>(pA &amp;&amp; pB &amp;&amp; pA != pB)&#123;        pA = pA -&gt; next;        pB = pB -&gt; next;    &#125;    <span class="hljs-keyword">if</span>(pA == <span class="hljs-literal">NULL</span> || pB == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">return</span> pA;   &#125;</code></pre><h5 id="③-链表节点顺序的调整"><a href="#③-链表节点顺序的调整" class="headerlink" title="③ 链表节点顺序的调整"></a>③ 链表节点顺序的调整</h5><h6 id="206-https-leetcode-com-problems-reverse-linked-list-🌟🌟🌟"><a href="#206-https-leetcode-com-problems-reverse-linked-list-🌟🌟🌟" class="headerlink" title="[206] https://leetcode.com/problems/reverse-linked-list  🌟🌟🌟"></a>[206] <a href="https://leetcode.com/problems/reverse-linked-list">https://leetcode.com/problems/reverse-linked-list</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">reverseList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    ListNode * prev = <span class="hljs-literal">NULL</span>;    ListNode * cur = head;    <span class="hljs-keyword">while</span>(cur)&#123;        ListNode * next = cur -&gt; next;        cur -&gt; next = prev;        prev = cur;        cur = next;    &#125;    <span class="hljs-keyword">return</span> prev;&#125;</code></pre><h6 id="328-https-leetcode-com-problems-odd-even-linked-list"><a href="#328-https-leetcode-com-problems-odd-even-linked-list" class="headerlink" title="[328] https://leetcode.com/problems/odd-even-linked-list/"></a>[328] <a href="https://leetcode.com/problems/odd-even-linked-list/">https://leetcode.com/problems/odd-even-linked-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">oddEvenList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    ListNode * oddhead = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * evenhead = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);      ListNode * p_odd = oddhead;    ListNode * p_even = evenhead;    ListNode * p = head;    <span class="hljs-keyword">int</span> index = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(p)&#123;        <span class="hljs-keyword">if</span>(index % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>)&#123;            p_even -&gt; next = p;            p_even = p_even -&gt; next;        &#125;<span class="hljs-keyword">else</span>&#123;            p_odd -&gt; next = p;            p_odd = p_odd -&gt; next;        &#125;        p = p -&gt; next;          index += <span class="hljs-number">1</span>;       &#125;    p_even -&gt; next = oddhead -&gt; next;    p_odd -&gt; next = <span class="hljs-literal">NULL</span>;    <span class="hljs-comment">// !! 不要忘记将这个链表 next 置零 &lt;--- 否则会产生死循环! 计算超时</span>      <span class="hljs-comment">// ! 删除申请的结点</span>    <span class="hljs-keyword">delete</span> evenhead;    ListNode * res = oddhead -&gt; next;    <span class="hljs-keyword">delete</span> oddhead;    <span class="hljs-keyword">return</span> evenhead -&gt; next; &#125;</code></pre><h6 id="86-https-leetcode-cn-com-problems-partition-list-🌟🌟"><a href="#86-https-leetcode-cn-com-problems-partition-list-🌟🌟" class="headerlink" title="[86] https://leetcode-cn.com/problems/partition-list/    🌟🌟"></a>[86] <a href="https://leetcode-cn.com/problems/partition-list/">https://leetcode-cn.com/problems/partition-list/</a>    🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">partition</span><span class="hljs-params">(ListNode* head, <span class="hljs-keyword">int</span> x)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    ListNode * before = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * p1 = before;    ListNode * after = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * p2 = after;    ListNode * p = head;    <span class="hljs-keyword">while</span>(p)&#123;        <span class="hljs-keyword">if</span>(p -&gt; val &lt; x)&#123;            p1 -&gt; next = p;            p1 = p1 -&gt; next;        &#125;<span class="hljs-keyword">else</span>&#123;            p2 -&gt; next = p;            p2 = p2 -&gt; next;        &#125;            p = p -&gt; next;    &#125;    p1 -&gt; next = after -&gt; next;    p2 -&gt; next = <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">return</span> before -&gt; next;&#125;</code></pre><h6 id="143-https-leetcode-cn-com-problems-reorder-list"><a href="#143-https-leetcode-cn-com-problems-reorder-list" class="headerlink" title="[143] https://leetcode-cn.com/problems/reorder-list/"></a>[143] <a href="https://leetcode-cn.com/problems/reorder-list/">https://leetcode-cn.com/problems/reorder-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">reorderList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-comment">// 获取链表长度</span>    ListNode * p = head;    <span class="hljs-keyword">int</span> len = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(p)&#123;        len++;        p = p -&gt; next;    &#125;    <span class="hljs-comment">// 翻转后半部分</span>    <span class="hljs-keyword">int</span> mid = len / <span class="hljs-number">2</span>;    p = head;    <span class="hljs-keyword">while</span>(mid--)  p = p -&gt; next;    ListNode * rhead = reverseList(p-&gt;next);    p -&gt; next = <span class="hljs-literal">NULL</span>;  <span class="hljs-comment">// !!! </span>    <span class="hljs-comment">// 合并两个链表</span>    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * ptr = dummy;    <span class="hljs-keyword">while</span>(rhead &amp;&amp; head)&#123;        ptr -&gt; next = head;        head = head -&gt; next;        ptr = ptr -&gt; next;        ptr -&gt; next = rhead;        rhead = rhead -&gt; next;        ptr = ptr -&gt; next;    &#125;    <span class="hljs-keyword">if</span>(rhead != <span class="hljs-literal">NULL</span>) ptr -&gt; next = rhead;    <span class="hljs-keyword">if</span>(head != <span class="hljs-literal">NULL</span>) ptr -&gt; next = head;    head = dummy -&gt; next;&#125;</code></pre><h6 id="61-https-leetcode-cn-com-problems-rotate-list"><a href="#61-https-leetcode-cn-com-problems-rotate-list" class="headerlink" title="[61] https://leetcode-cn.com/problems/rotate-list/"></a>[61] <a href="https://leetcode-cn.com/problems/rotate-list/">https://leetcode-cn.com/problems/rotate-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">rotateRight</span><span class="hljs-params">(ListNode* head, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;        <span class="hljs-keyword">int</span> cnt = <span class="hljs-number">1</span>;    ListNode * ptr = head;    <span class="hljs-keyword">while</span>(ptr -&gt; next)&#123;        ptr = ptr -&gt; next;        ++cnt;    &#125;    <span class="hljs-comment">// 做环</span>    ptr -&gt; next = head;    <span class="hljs-comment">// 移动</span>    k = cnt - k % cnt;    <span class="hljs-keyword">while</span>(k<span class="hljs-number">-1</span>)&#123;        k--;        head = head -&gt; next;    &#125;    <span class="hljs-comment">// 修改指针</span>    ptr = head;    head = head -&gt; next;    ptr -&gt; next = <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">return</span> head; &#125;</code></pre><h6 id="24-两两交换链表中的节点-https-leetcode-cn-com-problems-swap-nodes-in-pairs-🌟🌟"><a href="#24-两两交换链表中的节点-https-leetcode-cn-com-problems-swap-nodes-in-pairs-🌟🌟" class="headerlink" title="[24]. 两两交换链表中的节点 https://leetcode-cn.com/problems/swap-nodes-in-pairs/   🌟🌟"></a>[24]. 两两交换链表中的节点 <a href="https://leetcode-cn.com/problems/swap-nodes-in-pairs/">https://leetcode-cn.com/problems/swap-nodes-in-pairs/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">swapPairs</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    dummy -&gt; next = head;    ListNode * prev = dummy;    ListNode * cur = prev -&gt; next;    <span class="hljs-keyword">while</span>(cur &amp;&amp; cur -&gt; next)&#123;        ListNode * next = cur -&gt; next -&gt; next;        <span class="hljs-comment">// 翻转</span>        prev -&gt; next = cur -&gt; next;        cur -&gt; next -&gt; next = cur;        cur -&gt; next = next;        <span class="hljs-comment">// 移动</span>        prev = cur;        cur = next;    &#125;    <span class="hljs-keyword">return</span> dummy-&gt; next; &#125;</code></pre><h6 id="92-反转链表-II-https-leetcode-cn-com-problems-reverse-linked-list-ii-🌟🌟"><a href="#92-反转链表-II-https-leetcode-cn-com-problems-reverse-linked-list-ii-🌟🌟" class="headerlink" title="[92] 反转链表 II https://leetcode-cn.com/problems/reverse-linked-list-ii/   🌟🌟"></a>[92] 反转链表 II <a href="https://leetcode-cn.com/problems/reverse-linked-list-ii/">https://leetcode-cn.com/problems/reverse-linked-list-ii/</a>   🌟🌟</h6><pre><code class="hljs cpp">    <span class="hljs-function">ListNode * <span class="hljs-title">reverseLists</span><span class="hljs-params">(ListNode * head)</span></span>&#123;        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span> || head -&gt; next == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;        ListNode * prev = <span class="hljs-literal">NULL</span>;        ListNode * cur = head;        <span class="hljs-keyword">while</span>(cur)&#123;            ListNode * next = cur -&gt; next;            cur -&gt; next = prev;            prev = cur;            cur =  next;        &#125;        <span class="hljs-keyword">return</span> prev;    &#125;<span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode* <span class="hljs-title">reverseBetween</span><span class="hljs-params">(ListNode* head, <span class="hljs-keyword">int</span> m, <span class="hljs-keyword">int</span> n)</span> </span>&#123;        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;        ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);        dummy -&gt; next = head;        <span class="hljs-comment">// 查找翻转之前的节点， 记录为 prev</span>        ListNode * pNode = dummy;        <span class="hljs-keyword">int</span> i;        <span class="hljs-keyword">for</span>(i = <span class="hljs-number">0</span>; i &lt; m<span class="hljs-number">-1</span>; i++)  pNode = pNode -&gt; next;        ListNode * prev = pNode;        <span class="hljs-comment">// 记录翻转之后的节点， 记录为 next</span>        <span class="hljs-keyword">for</span>(; i &lt; n; i++)  pNode = pNode -&gt; next;        ListNode * next = pNode -&gt; next;        pNode -&gt; next = <span class="hljs-literal">NULL</span>;        <span class="hljs-comment">// 翻转</span>        ListNode * newhead = reverseLists(prev -&gt; next);        prev -&gt; next = newhead;        <span class="hljs-comment">// 连接断掉的链表</span>        <span class="hljs-keyword">while</span>(prev -&gt; next) prev = prev -&gt; next;        prev -&gt; next = next;        <span class="hljs-keyword">return</span> dummy -&gt; next;    &#125;</code></pre><h5 id="④-删除链表中的节点"><a href="#④-删除链表中的节点" class="headerlink" title="④ 删除链表中的节点"></a>④ 删除链表中的节点</h5><h6 id="237-https-leetcode-com-problems-delete-node-in-a-linked-list"><a href="#237-https-leetcode-com-problems-delete-node-in-a-linked-list" class="headerlink" title="[237] https://leetcode.com/problems/delete-node-in-a-linked-list/"></a>[237] <a href="https://leetcode.com/problems/delete-node-in-a-linked-list/">https://leetcode.com/problems/delete-node-in-a-linked-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">deleteNode</span><span class="hljs-params">(ListNode* node)</span> </span>&#123;    node -&gt; val = node -&gt; next -&gt; val;    node -&gt; next = node -&gt; next -&gt; next;&#125;</code></pre><h6 id="面试题-02-01-移除重复节点-https-leetcode-cn-com-problems-remove-duplicate-node-lcci"><a href="#面试题-02-01-移除重复节点-https-leetcode-cn-com-problems-remove-duplicate-node-lcci" class="headerlink" title="[面试题 02.01] 移除重复节点 https://leetcode-cn.com/problems/remove-duplicate-node-lcci/"></a>[面试题 02.01] 移除重复节点 <a href="https://leetcode-cn.com/problems/remove-duplicate-node-lcci/">https://leetcode-cn.com/problems/remove-duplicate-node-lcci/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">removeDuplicateNodes</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span> || head -&gt; next == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-keyword">int</span>&gt; m_set = &#123; head-&gt;val &#125;;    ListNode * prev = head;    ListNode * cur = head -&gt; next;    <span class="hljs-keyword">while</span>(cur)&#123;        <span class="hljs-keyword">if</span>(m_set.find(cur -&gt; val) == m_set.end())&#123;            m_set.insert(cur-&gt;val);            prev = cur;        &#125;<span class="hljs-keyword">else</span>&#123;            prev -&gt; next = cur -&gt; next;        &#125;        cur = cur -&gt; next;    &#125;    <span class="hljs-keyword">return</span> head;&#125;</code></pre><h6 id="203-https-leetcode-com-problems-remove-linked-list-elements"><a href="#203-https-leetcode-com-problems-remove-linked-list-elements" class="headerlink" title="[203] https://leetcode.com/problems/remove-linked-list-elements/"></a>[203] <a href="https://leetcode.com/problems/remove-linked-list-elements/">https://leetcode.com/problems/remove-linked-list-elements/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">deleteNode</span><span class="hljs-params">(ListNode* head, <span class="hljs-keyword">int</span> val)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    <span class="hljs-comment">// 添加哑节点</span>    ListNode * newhead = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    newhead -&gt; next = head;    ListNode * p = newhead;    <span class="hljs-keyword">while</span>(p -&gt; next)&#123;        <span class="hljs-keyword">if</span>(p -&gt; next -&gt; val == val)&#123;            ListNode * tmp = p -&gt; next;            p -&gt; next = p -&gt; next -&gt; next;            <span class="hljs-keyword">delete</span> tmp;  <span class="hljs-comment">// 删除无用节点</span>        &#125;         <span class="hljs-keyword">else</span>            p = p -&gt; next;    &#125;    <span class="hljs-keyword">return</span> newhead -&gt; next;&#125;</code></pre><h6 id="83-https-leetcode-com-problems-remove-duplicates-from-sorted-list-🌟🌟"><a href="#83-https-leetcode-com-problems-remove-duplicates-from-sorted-list-🌟🌟" class="headerlink" title="[83] https://leetcode.com/problems/remove-duplicates-from-sorted-list/  🌟🌟"></a>[83] <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list/">https://leetcode.com/problems/remove-duplicates-from-sorted-list/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">deleteDuplicates</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    dummy -&gt; next = head;    ListNode * ptr = head;    <span class="hljs-keyword">while</span>(ptr &amp;&amp; ptr -&gt; next)&#123;        <span class="hljs-keyword">if</span>(ptr-&gt;val == ptr-&gt;next-&gt;val)&#123;            ListNode * tmp = ptr -&gt; next;            ptr -&gt; next = ptr -&gt; next -&gt; next;            <span class="hljs-keyword">delete</span> tmp;        &#125;<span class="hljs-keyword">else</span>&#123;            ptr = ptr -&gt; next;        &#125;    &#125;    <span class="hljs-keyword">return</span> dummy -&gt; next;&#125;</code></pre><h6 id="82-删除排序链表中的重复元素-II-https-leetcode-cn-com-problems-remove-duplicates-from-sorted-list-ii"><a href="#82-删除排序链表中的重复元素-II-https-leetcode-cn-com-problems-remove-duplicates-from-sorted-list-ii" class="headerlink" title="[82] 删除排序链表中的重复元素 II https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/"></a>[82] 删除排序链表中的重复元素 II <a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/">https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">deleteDuplicates</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    dummy -&gt; next = head;    ListNode * prev = dummy;        ListNode * cur = head;    <span class="hljs-keyword">while</span>(cur &amp;&amp; cur -&gt; next)&#123;        ListNode * next = cur -&gt; next;        <span class="hljs-keyword">if</span>(cur -&gt; val != next -&gt; val)&#123;            prev = cur;            cur = next;        &#125;<span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">while</span>(next &amp;&amp; cur -&gt; val == next -&gt; val)   <span class="hljs-comment">// 找到下一个非重复字符</span>                next = next -&gt; next;            prev -&gt; next = next == <span class="hljs-literal">NULL</span> ? <span class="hljs-literal">NULL</span> : next;            cur = next;          &#125;    &#125;    <span class="hljs-keyword">return</span> dummy -&gt; next;&#125;</code></pre><h5 id="⑤-合并有序链表"><a href="#⑤-合并有序链表" class="headerlink" title="⑤ 合并有序链表"></a>⑤ 合并有序链表</h5><h6 id="21-https-leetcode-cn-com-problems-merge-two-sorted-lists-🌟🌟🌟🌟"><a href="#21-https-leetcode-cn-com-problems-merge-two-sorted-lists-🌟🌟🌟🌟" class="headerlink" title="[21] https://leetcode-cn.com/problems/merge-two-sorted-lists/   🌟🌟🌟🌟"></a>[21] <a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/">https://leetcode-cn.com/problems/merge-two-sorted-lists/</a>   🌟🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">mergeTwoLists</span><span class="hljs-params">(ListNode* l1, ListNode* l2)</span> </span>&#123;    ListNode * newhead = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * p = newhead;    ListNode * p_l1 = l1, * p_l2 = l2;    <span class="hljs-keyword">while</span>(p_l1 &amp;&amp; p_l2)&#123;        <span class="hljs-keyword">if</span>(p_l1 -&gt; val &gt; p_l2 -&gt; val)&#123;            p -&gt; next = p_l2;            p_l2 = p_l2 -&gt; next;            p = p -&gt; next;        &#125;<span class="hljs-keyword">else</span>&#123;            p -&gt; next = p_l1;            p_l1 = p_l1 -&gt; next;            p = p -&gt; next;         &#125;    &#125;    <span class="hljs-keyword">if</span>(p_l1 == <span class="hljs-literal">NULL</span>) p-&gt;next = p_l2;    <span class="hljs-keyword">else</span> p-&gt; next = p_l1;    <span class="hljs-comment">// 注意: 这里要删除申请的 new head 节点, 否则会产生内存泄漏</span>    ListNode * res = newhead;    <span class="hljs-keyword">delete</span> newhead;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="23-https-leetcode-cn-com-problems-merge-k-sorted-lists-🌟🌟🌟"><a href="#23-https-leetcode-cn-com-problems-merge-k-sorted-lists-🌟🌟🌟" class="headerlink" title="[23] https://leetcode-cn.com/problems/merge-k-sorted-lists/      🌟🌟🌟"></a>[23] <a href="https://leetcode-cn.com/problems/merge-k-sorted-lists/">https://leetcode-cn.com/problems/merge-k-sorted-lists/</a>      🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">mergeKLists</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;ListNode*&gt;&amp; lists)</span> </span>&#123;    <span class="hljs-keyword">if</span>(lists.size() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">if</span>(lists.size() == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> lists[<span class="hljs-number">0</span>];    <span class="hljs-keyword">if</span>(lists.size() == <span class="hljs-number">2</span>) <span class="hljs-keyword">return</span> mergeTwoLists(lists[<span class="hljs-number">0</span>], lists[<span class="hljs-number">1</span>]);    <span class="hljs-keyword">int</span> len = lists.size();    <span class="hljs-keyword">int</span> mid = len / <span class="hljs-number">2</span>;    <span class="hljs-built_in">vector</span>&lt;ListNode* &gt; lists1;    <span class="hljs-built_in">vector</span>&lt;ListNode* &gt; lists2;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; mid; i++)  lists1.push_back(lists[i]);      <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = mid; i &lt; len; i++)  lists2.push_back(lists[i]);    ListNode * p1 = mergeKLists(lists1);    ListNode * p2 = mergeKLists(lists2);    <span class="hljs-keyword">return</span> mergeTwoLists(p1, p2);  &#125;</code></pre><h5 id="⑥-模拟数学运算-两数相加、链表-1"><a href="#⑥-模拟数学运算-两数相加、链表-1" class="headerlink" title="⑥ 模拟数学运算(两数相加、链表+1)"></a>⑥ 模拟数学运算(两数相加、链表+1)</h5><h6 id="2-https-leetcode-com-problems-add-two-numbers"><a href="#2-https-leetcode-com-problems-add-two-numbers" class="headerlink" title="[2] https://leetcode.com/problems/add-two-numbers/"></a>[2] <a href="https://leetcode.com/problems/add-two-numbers/">https://leetcode.com/problems/add-two-numbers/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 模拟常见的加法操作: 需要注意，当一条链表为空时候，仍然在此框架下相加，最后还需要添加 c_in</span><span class="hljs-function">ListNode* <span class="hljs-title">addTwoNumbers</span><span class="hljs-params">(ListNode* l1, ListNode* l2)</span> </span>&#123;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * p = dummy;    <span class="hljs-keyword">int</span> c_in = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(l1 != <span class="hljs-literal">NULL</span> || l2 != <span class="hljs-literal">NULL</span>)&#123;        <span class="hljs-keyword">int</span> val1 = l1 != <span class="hljs-literal">NULL</span> ? l1 -&gt; val : <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> val2 = l2 != <span class="hljs-literal">NULL</span> ? l2 -&gt; val : <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> res = val1 + val2 + c_in;        ListNode * newNode =  <span class="hljs-keyword">new</span> ListNode(res % <span class="hljs-number">10</span>);        c_in = res / <span class="hljs-number">10</span>;        p -&gt; next = newNode;        p = p -&gt; next;        <span class="hljs-keyword">if</span>(l1 != <span class="hljs-literal">NULL</span>) l1 = l1 -&gt; next;        <span class="hljs-keyword">if</span>(l2 != <span class="hljs-literal">NULL</span>) l2 = l2 -&gt; next;                                                 &#125;    <span class="hljs-keyword">if</span>(c_in)&#123;        ListNode * newNode = <span class="hljs-keyword">new</span> ListNode(c_in);        p -&gt; next = newNode;        p = p -&gt; next;    &#125;    <span class="hljs-keyword">return</span> dummy -&gt; next;  &#125;</code></pre><h6 id="445-两数相加-II-https-leetcode-cn-com-problems-add-two-numbers-ii"><a href="#445-两数相加-II-https-leetcode-cn-com-problems-add-two-numbers-ii" class="headerlink" title="[445] 两数相加 II https://leetcode-cn.com/problems/add-two-numbers-ii/"></a>[445] 两数相加 II <a href="https://leetcode-cn.com/problems/add-two-numbers-ii/">https://leetcode-cn.com/problems/add-two-numbers-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">ListNode* <span class="hljs-title">addTwoNumbers</span><span class="hljs-params">(ListNode* l1, ListNode* l2)</span> </span>&#123;    <span class="hljs-keyword">if</span>(l1 == <span class="hljs-literal">NULL</span> || l2 == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> l1 == <span class="hljs-literal">NULL</span> ? l2 : l1;        <span class="hljs-built_in">stack</span>&lt;<span class="hljs-keyword">int</span>&gt; stk_1,stk_2;    <span class="hljs-keyword">while</span>(l1)&#123;        stk_1.push(l1 -&gt; val);        l1 = l1 -&gt; next;    &#125;    <span class="hljs-keyword">while</span>(l2)&#123;        stk_2.push(l2 -&gt; val);        l2 = l2-&gt;next;    &#125;        <span class="hljs-keyword">int</span> c_in = <span class="hljs-number">0</span>;    ListNode * dummy = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">0</span>);    ListNode * ptr = dummy;    <span class="hljs-keyword">while</span>(!stk_1.empty() || !stk_2.empty())&#123;        <span class="hljs-keyword">int</span> n1 = stk_1.empty() ? <span class="hljs-number">0</span> : stk_1.top();        <span class="hljs-keyword">int</span> n2 = stk_2.empty() ? <span class="hljs-number">0</span> : stk_2.top();                <span class="hljs-keyword">int</span> s = n1 + n2 + c_in;                ListNode * pNode = <span class="hljs-keyword">new</span> ListNode(s % <span class="hljs-number">10</span>);        c_in = s / <span class="hljs-number">10</span>;        <span class="hljs-comment">// 头插法: 可以反向插入节点</span>        pNode -&gt; next = ptr -&gt; next;        ptr -&gt; next = pNode;        <span class="hljs-keyword">if</span>(!stk_1.empty()) stk_1.pop();        <span class="hljs-keyword">if</span>(!stk_2.empty())  stk_2.pop();    &#125;    <span class="hljs-keyword">if</span>(c_in)&#123;        ListNode * pNode = <span class="hljs-keyword">new</span> ListNode(c_in);        pNode -&gt; next = ptr -&gt; next;        ptr -&gt; next = pNode;      &#125;    ListNode* res = dummy-&gt;next;    <span class="hljs-keyword">delete</span> dummy;        <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="369-https-leetcode-com-problems-plus-one-linked-list"><a href="#369-https-leetcode-com-problems-plus-one-linked-list" class="headerlink" title="[369] https://leetcode.com/problems/plus-one-linked-list/"></a>[369] <a href="https://leetcode.com/problems/plus-one-linked-list/">https://leetcode.com/problems/plus-one-linked-list/</a></h6><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Solution</span> &#123;</span><span class="hljs-keyword">public</span>:    <span class="hljs-function">ListNode * <span class="hljs-title">reverseList</span><span class="hljs-params">(ListNode * head)</span></span>&#123;        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;        ListNode * prev = <span class="hljs-literal">NULL</span>;        <span class="hljs-keyword">while</span>(head)&#123;            ListNode * next = head -&gt; next;            head -&gt; next = prev;            prev = head;            head = next;        &#125;        <span class="hljs-keyword">return</span> prev;            &#125;        <span class="hljs-function">ListNode* <span class="hljs-title">plusOne</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;        <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;        head = reverseList(head);                <span class="hljs-keyword">int</span> c_in = <span class="hljs-number">1</span>;        ListNode * ptr = head;        ListNode * prev = head;        <span class="hljs-keyword">while</span>(ptr)&#123;            <span class="hljs-keyword">int</span> res = ptr -&gt; val + c_in;            c_in = res / <span class="hljs-number">10</span>;            ptr -&gt; val = res % <span class="hljs-number">10</span>;            prev = ptr;            ptr = ptr -&gt; next;        &#125;                <span class="hljs-keyword">if</span>(c_in)  prev -&gt; next = <span class="hljs-keyword">new</span> ListNode(<span class="hljs-number">1</span>);                <span class="hljs-keyword">return</span> reverseList(head);            &#125;&#125;;</code></pre><h6 id="148-排序链表-https-leetcode-cn-com-problems-sort-list-🌟🌟🌟"><a href="#148-排序链表-https-leetcode-cn-com-problems-sort-list-🌟🌟🌟" class="headerlink" title="[148] 排序链表 https://leetcode-cn.com/problems/sort-list/   🌟🌟🌟"></a>[148] 排序链表 <a href="https://leetcode-cn.com/problems/sort-list/">https://leetcode-cn.com/problems/sort-list/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 复杂度 nlogn 的链表排序</span><span class="hljs-function">ListNode* <span class="hljs-title">merge</span><span class="hljs-params">(ListNode * p1, ListNode * p2)</span></span>&#123;    <span class="hljs-keyword">if</span>(p1 == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> p2;    <span class="hljs-keyword">if</span>(p2 == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> p1;    <span class="hljs-keyword">if</span>(p1 -&gt; val &gt; p2 -&gt; val)&#123;        p2 -&gt; next = merge(p2-&gt;next, p1);        <span class="hljs-keyword">return</span> p2;    &#125;<span class="hljs-keyword">else</span>&#123;        p1 -&gt; next = merge(p1-&gt;next, p2);        <span class="hljs-keyword">return</span> p1;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;&#125;<span class="hljs-function">ListNode* <span class="hljs-title">sortList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span> || head -&gt; next == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> head;    ListNode * fast = head;    ListNode * slow = head;    ListNode * pre = head;    <span class="hljs-keyword">while</span>(fast &amp;&amp; fast -&gt; next)&#123;        pre = slow;        fast = fast -&gt; next -&gt; next;        slow = slow -&gt; next;    &#125;    pre -&gt; next = <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">return</span> merge(sortList(head), sortList(slow));&#125;</code></pre><h5 id="⑦-复杂链表的复制-🌟🌟🌟🌟"><a href="#⑦-复杂链表的复制-🌟🌟🌟🌟" class="headerlink" title="⑦  复杂链表的复制  🌟🌟🌟🌟"></a>⑦  复杂链表的复制  🌟🌟🌟🌟</h5><pre><code class="hljs cpp"><span class="hljs-comment">// (1) 存储原链表的 node -&gt; index map</span><span class="hljs-comment">// (2) 数组存储新建的 结点</span><span class="hljs-function">Node* <span class="hljs-title">copyRandomList</span><span class="hljs-params">(Node* head)</span> </span>&#123;      <span class="hljs-built_in">map</span>&lt;Node*, <span class="hljs-keyword">int</span>&gt; node_map;    <span class="hljs-built_in">vector</span>&lt;Node *&gt; node_vec;    Node * ptr = head;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(ptr)&#123;        node_vec.push_back(<span class="hljs-keyword">new</span> Node(ptr-&gt;val));        node_map[ptr] = i;        ptr = ptr -&gt; next;        i += <span class="hljs-number">1</span>;    &#125;    node_vec.push_back(<span class="hljs-number">0</span>);    ptr = head;    i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(ptr)&#123;        node_vec[i] -&gt; next = node_vec[i+<span class="hljs-number">1</span>]; <span class="hljs-comment">// next</span>        <span class="hljs-keyword">if</span>(ptr-&gt;random)&#123; <span class="hljs-comment">// random</span>            node_vec[i] -&gt; random = node_vec[node_map[ptr-&gt;random]];        &#125;        ptr = ptr -&gt; next;        i += <span class="hljs-number">1</span>;    &#125;    <span class="hljs-keyword">return</span> node_vec[<span class="hljs-number">0</span>];&#125;</code></pre><h3 id="4-树和二叉树"><a href="#4-树和二叉树" class="headerlink" title="4. 树和二叉树"></a>4. 树和二叉树</h3><h4 id="1-基础题型总结"><a href="#1-基础题型总结" class="headerlink" title="(1) 基础题型总结"></a>(1) 基础题型总结</h4><ul><li>[遍历] 前序、中序、后序、层序遍历(常规、按层、之字型)</li><li>[性质判定] 最大深度、最小深度、对称二叉树、翻转二叉树、相同的树、平衡树、左叶子之和</li><li>[公共祖先] 最近公共祖先(二叉树、二叉搜索树)</li><li>[路径和]  二叉树的路径和、所有路径、最大路径</li><li>[vector 和 tree 交互] 序列化和反序列化二叉树、有序链表重建二叉搜索树、重建二叉树</li></ul><p><strong>一些常规思路：</strong></p><ul><li><p>leetcode的测试集经常会有 [] ,  [0]，所以很多题目先要考虑判断是否为空，return None 或者 return [ ]。</p></li><li><p>时刻要考虑这个节点是否为空， 空节点是不能访问左子树和右子树的。</p></li><li><p>当返回值非 void 时，考虑到递归的返回值问题，大部分需要设置一个 helper 函数。但是不是绝对，可以利用这个返回值。</p></li><li><p>递归的基本思想</p><pre><code class="hljs cpp"><span class="hljs-function">def <span class="hljs-title">func</span><span class="hljs-params">(root)</span>:</span>    if 满足条件: 退出或进行相关操作        <span class="hljs-comment">// 相关操作1;</span>    func(root-&gt;left); <span class="hljs-comment">// 递归左子树</span>    <span class="hljs-comment">// 相关操作2;</span>    func(root-&gt;right);  <span class="hljs-comment">//递归右子树</span>    <span class="hljs-comment">// 相关操作3;</span></code></pre></li><li><p>递归相较于迭代：浪费资源反复调用函数</p><ul><li>递归是一个树结构，每个分支都探究到最远，发现无法继续的时候往回走，每个节点只会访问一次</li><li>迭代是一个环结构，每次迭代都是一个圈，不会拉掉其中的某一步，然后不断循环，每个节点都会被循环访问</li></ul></li><li><p>思考的顺序:</p><ul><li>关于递归：退出条件、递归任务、返回值</li><li>关于子树：根节点、左子树、右子树</li><li>关于特殊条件处理：节点 root 为空， 叶子节点<code>root-&gt;left &amp;&amp; root-&gt;right</code> 为空、 单子树为空 <code>root-&gt;left || root-&gt;right</code> 、正常节点</li></ul></li></ul><h4 id="2-典型例题-2"><a href="#2-典型例题-2" class="headerlink" title="(2) 典型例题"></a>(2) 典型例题</h4><h5 id="类型一-遍历"><a href="#类型一-遍历" class="headerlink" title="类型一. 遍历"></a>类型一. 遍历</h5><h6 id="144-二叉树的前序遍历-https-leetcode-cn-com-problems-binary-tree-preorder-traversal-🌟🌟"><a href="#144-二叉树的前序遍历-https-leetcode-cn-com-problems-binary-tree-preorder-traversal-🌟🌟" class="headerlink" title="[144] 二叉树的前序遍历 https://leetcode-cn.com/problems/binary-tree-preorder-traversal/ 🌟🌟"></a>[144] 二叉树的前序遍历 <a href="https://leetcode-cn.com/problems/binary-tree-preorder-traversal/">https://leetcode-cn.com/problems/binary-tree-preorder-traversal/</a> 🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 前序</span><span class="hljs-comment">// 递归写法</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">preorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    helper(root, res);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode * root, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; res)</span></span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    res.push_back(root-&gt;val);    helper(root-&gt;left, res);    helper(root-&gt;right, res);&#125;<span class="hljs-comment">// 迭代写法</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">preorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    TreeNode * p = root;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-built_in">stack</span>&lt;TreeNode *&gt; m_stack;    <span class="hljs-keyword">while</span>(p || !m_stack.empty())&#123;        <span class="hljs-keyword">if</span>(p)&#123;  <span class="hljs-comment">// 如果当前节点不空，将其入栈， 并移动指针到左节点</span>            m_stack.push(p);            res.push_back(p-&gt;val);  <span class="hljs-comment">// 在此写入结果</span>            p = p -&gt; left;        &#125;<span class="hljs-keyword">else</span>&#123;   <span class="hljs-comment">// 否则将栈顶弹出，其值写入结果，并将指针指向其右节点</span>            p = m_stack.top();            m_stack.pop();            p = p -&gt; right;        &#125;    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="94-二叉树的中序遍历-https-leetcode-cn-com-problems-binary-tree-inorder-traversal"><a href="#94-二叉树的中序遍历-https-leetcode-cn-com-problems-binary-tree-inorder-traversal" class="headerlink" title="[94] 二叉树的中序遍历 https://leetcode-cn.com/problems/binary-tree-inorder-traversal/"></a>[94] 二叉树的中序遍历 <a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/">https://leetcode-cn.com/problems/binary-tree-inorder-traversal/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 中序</span><span class="hljs-comment">//递归解法</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">inorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    helper(root, res);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode* root, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; res)</span></span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    helper(root-&gt;left, res);    res.push_back(root-&gt;val);    helper(root-&gt;right, res);&#125;<span class="hljs-comment">// 迭代写法:</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">inorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    TreeNode * p = root;    <span class="hljs-built_in">stack</span>&lt;TreeNode *&gt; m_stack;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">while</span>(p || !m_stack.empty())&#123;        <span class="hljs-keyword">if</span>(p)&#123;  <span class="hljs-comment">// 如果当前节点不空，将其入栈， 并移动指针到左节点</span>            m_stack.push(p);            p = p-&gt;left;        &#125;<span class="hljs-keyword">else</span>&#123;  <span class="hljs-comment">// 否则将栈顶弹出，其值写入结果，并将指针指向其右节点</span>            p = m_stack.top();            res.push_back(p-&gt;val); <span class="hljs-comment">// 在此写入结果</span>            m_stack.pop();            p = p -&gt; right;        &#125;    &#125;    <span class="hljs-keyword">return</span> res; &#125;</code></pre><h6 id="145-https-leetcode-cn-com-problems-binary-tree-postorder-traversal"><a href="#145-https-leetcode-cn-com-problems-binary-tree-postorder-traversal" class="headerlink" title="[145] https://leetcode-cn.com/problems/binary-tree-postorder-traversal/"></a>[145] <a href="https://leetcode-cn.com/problems/binary-tree-postorder-traversal/">https://leetcode-cn.com/problems/binary-tree-postorder-traversal/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">postorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-comment">// 怎么和层序遍历的代码差不多呀， 把 queue 改为 stack</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">stack</span>&lt;TreeNode *&gt; m_stk;    TreeNode * p = root;    m_stk.push(p);    <span class="hljs-keyword">while</span>(!m_stk.empty())&#123;        TreeNode * cur = m_stk.top();        m_stk.pop();        res.push_back(cur-&gt;val);        <span class="hljs-keyword">if</span>(cur -&gt; left) m_stk.push(cur-&gt;left);        <span class="hljs-keyword">if</span>(cur-&gt;right) m_stk.push(cur-&gt;right);    &#125;    reverse(res.begin(), res.end());    <span class="hljs-keyword">return</span> res; &#125;</code></pre><h6 id="102-https-leetcode-cn-com-problems-binary-tree-level-order-traversal-🌟🌟"><a href="#102-https-leetcode-cn-com-problems-binary-tree-level-order-traversal-🌟🌟" class="headerlink" title="[102] https://leetcode-cn.com/problems/binary-tree-level-order-traversal/  🌟🌟"></a>[102] <a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/">https://leetcode-cn.com/problems/binary-tree-level-order-traversal/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">levelOrder</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">queue</span>&lt;TreeNode *&gt; m_queue;    m_queue.push(root);    <span class="hljs-keyword">while</span>(!m_queue.empty())&#123;        <span class="hljs-keyword">int</span> n = m_queue.size();        <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; raw;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;            raw.push_back(m_queue.front() -&gt; val);            <span class="hljs-keyword">if</span>(m_queue.front() -&gt;left) m_queue.push(m_queue.front() -&gt; left);            <span class="hljs-keyword">if</span>(m_queue.front() -&gt; right) m_queue.push(m_queue.front() -&gt; right);            m_queue.pop();        &#125;        res.push_back(raw);    &#125;     <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="lcof-32-https-leetcode-cn-com-problems-cong-shang-dao-xia-da-yin-er-cha-shu-lcof"><a href="#lcof-32-https-leetcode-cn-com-problems-cong-shang-dao-xia-da-yin-er-cha-shu-lcof" class="headerlink" title="[lcof 32] https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/"></a>[lcof 32] <a href="https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/">https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">levelOrder</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">queue</span>&lt;TreeNode *&gt; m_queue;    m_queue.push(root);    <span class="hljs-keyword">while</span>(!m_queue.empty())&#123;        res.push_back(m_queue.front() -&gt; val);        <span class="hljs-keyword">if</span>(m_queue.front() -&gt; left) m_queue.push(m_queue.front() -&gt; left);        <span class="hljs-keyword">if</span>(m_queue.front() -&gt; right) m_queue.push(m_queue.front() -&gt; right);        m_queue.pop();    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="103-二叉树的锯齿形层次遍历-https-leetcode-cn-com-problems-binary-tree-zigzag-level-order-traversal"><a href="#103-二叉树的锯齿形层次遍历-https-leetcode-cn-com-problems-binary-tree-zigzag-level-order-traversal" class="headerlink" title="[103] 二叉树的锯齿形层次遍历 https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal/"></a>[103] 二叉树的锯齿形层次遍历 <a href="https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal/">https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">levelOrder</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">deque</span>&lt;TreeNode * &gt; m_deque;    m_deque.push_front(root);    <span class="hljs-keyword">bool</span> flag = <span class="hljs-literal">true</span>;    <span class="hljs-keyword">while</span>(!m_deque.empty())&#123;        <span class="hljs-keyword">int</span> n = m_deque.size();        <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; raw;        <span class="hljs-keyword">if</span>(flag)&#123;      <span class="hljs-comment">// 一个从头出来， 一个从尾部出来</span>            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;                raw.push_back(m_deque.front()-&gt;val);                <span class="hljs-keyword">if</span>(m_deque.front()-&gt;left) m_deque.push_back(m_deque.front()-&gt;left);                <span class="hljs-keyword">if</span>(m_deque.front()-&gt;right) m_deque.push_back(m_deque.front()-&gt;right);                m_deque.pop_front();            &#125;        &#125;<span class="hljs-keyword">else</span>&#123;            <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;                raw.push_back(m_deque.back()-&gt;val);                <span class="hljs-keyword">if</span>(m_deque.back()-&gt;right) m_deque.push_front(m_deque.back()-&gt;right);                <span class="hljs-keyword">if</span>(m_deque.back()-&gt;left) m_deque.push_front(m_deque.back()-&gt;left);                m_deque.pop_back();            &#125;        &#125;        flag = ! flag;        res.push_back(raw);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="199-二叉树的右视图-https-leetcode-cn-com-problems-binary-tree-right-side-view"><a href="#199-二叉树的右视图-https-leetcode-cn-com-problems-binary-tree-right-side-view" class="headerlink" title="[199] 二叉树的右视图 https://leetcode-cn.com/problems/binary-tree-right-side-view/"></a>[199] 二叉树的右视图 <a href="https://leetcode-cn.com/problems/binary-tree-right-side-view/">https://leetcode-cn.com/problems/binary-tree-right-side-view/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">rightSideView</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">queue</span>&lt;TreeNode *&gt; m_queue;    m_queue.push(root);    <span class="hljs-keyword">while</span>(!m_queue.empty())&#123;        <span class="hljs-keyword">int</span> n = m_queue.size();        <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; row;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;            TreeNode * pNode = m_queue.front();            <span class="hljs-keyword">if</span>(pNode-&gt;right) m_queue.push(pNode-&gt;right);            <span class="hljs-keyword">if</span>(pNode-&gt;left) m_queue.push(pNode-&gt;left);            m_queue.pop();            row.push_back(pNode-&gt;val);        &#125;        res.push_back(row[<span class="hljs-number">0</span>]);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="230-https-leetcode-cn-com-problems-kth-smallest-element-in-a-bst"><a href="#230-https-leetcode-cn-com-problems-kth-smallest-element-in-a-bst" class="headerlink" title="[230] https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/"></a>[230] <a href="https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/">https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">kthSmallest</span><span class="hljs-params">(TreeNode* root, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-comment">// 中序遍历的第k个元素</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-built_in">stack</span>&lt;TreeNode *&gt; m_stk;    TreeNode * cur = root;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(cur || !m_stk.empty())&#123;        <span class="hljs-keyword">if</span>(cur)&#123;            m_stk.push(cur);            cur = cur -&gt; left;        &#125;<span class="hljs-keyword">else</span>&#123;            cur = m_stk.top();            i++;            <span class="hljs-keyword">if</span>(i == k) <span class="hljs-keyword">return</span> cur -&gt; val;            m_stk.pop();            cur =  cur-&gt; right;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>; &#125;</code></pre><h6 id="lcof-52-https-leetcode-cn-com-problems-er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof"><a href="#lcof-52-https-leetcode-cn-com-problems-er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof" class="headerlink" title="[lcof 52] https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/"></a>[lcof 52] <a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/">https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">kthLargest</span><span class="hljs-params">(TreeNode* root, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-comment">// 反中序遍历， 满足条件即输出</span>    <span class="hljs-built_in">stack</span>&lt;TreeNode *&gt; m_stk;    TreeNode * p = root;    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">while</span>(p || !m_stk.empty())&#123;        <span class="hljs-keyword">if</span>(p)&#123;            m_stk.push(p);            p = p -&gt; right;        &#125;<span class="hljs-keyword">else</span>        &#123;            p = m_stk.top();            <span class="hljs-keyword">if</span>(++i == k) <span class="hljs-keyword">return</span> p-&gt;val;            m_stk.pop();            p = p -&gt; left;                    &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre><h5 id="类型二-性质判定"><a href="#类型二-性质判定" class="headerlink" title="类型二  性质判定"></a>类型二  性质判定</h5><h6 id="111-二叉树的最小深度-https-leetcode-cn-com-problems-minimum-depth-of-binary-tree-🌟🌟"><a href="#111-二叉树的最小深度-https-leetcode-cn-com-problems-minimum-depth-of-binary-tree-🌟🌟" class="headerlink" title="[111] 二叉树的最小深度 https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/   🌟🌟"></a>[111] 二叉树的最小深度 <a href="https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/">https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/</a>   🌟🌟</h6><pre><code class="hljs coq">int minDepth(TreeNode* root) &#123;    <span class="hljs-keyword">if</span>(root == NULL) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">if</span>(root-&gt;<span class="hljs-built_in">left</span> == NULL &amp;&amp; root -&gt; <span class="hljs-built_in">right</span> == NULL) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;    <span class="hljs-keyword">if</span>(root-&gt;<span class="hljs-built_in">left</span> == NULL) <span class="hljs-keyword">return</span> minDepth(root-&gt;<span class="hljs-built_in">right</span>) + <span class="hljs-number">1</span>;    <span class="hljs-keyword">if</span>(root-&gt;<span class="hljs-built_in">right</span> == NULL) <span class="hljs-keyword">return</span> minDepth(root-&gt;<span class="hljs-built_in">left</span>) + <span class="hljs-number">1</span>;    <span class="hljs-keyword">return</span> min(minDepth(root-&gt;<span class="hljs-built_in">left</span>), minDepth(root-&gt;<span class="hljs-built_in">right</span>)) + <span class="hljs-number">1</span>;&#125;</code></pre><h6 id="104-https-leetcode-cn-com-problems-maximum-depth-of-binary-tree"><a href="#104-https-leetcode-cn-com-problems-maximum-depth-of-binary-tree" class="headerlink" title="[104] https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/"></a>[104] <a href="https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/">https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxDepth</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + max(maxDepth(root-&gt;left), maxDepth(root-&gt;right));&#125;</code></pre><h6 id="226-https-leetcode-cn-com-problems-er-cha-shu-de-jing-xiang-lcof"><a href="#226-https-leetcode-cn-com-problems-er-cha-shu-de-jing-xiang-lcof" class="headerlink" title="[226] https://leetcode-cn.com/problems/er-cha-shu-de-jing-xiang-lcof/"></a>[226] <a href="https://leetcode-cn.com/problems/er-cha-shu-de-jing-xiang-lcof/">https://leetcode-cn.com/problems/er-cha-shu-de-jing-xiang-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">TreeNode* <span class="hljs-title">mirrorTree</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> root;    exchangeTreeNode(root);    <span class="hljs-keyword">return</span> root;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">exchangeTreeNode</span><span class="hljs-params">(TreeNode * root)</span></span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    TreeNode * tmp = root -&gt; left;    root -&gt; left = root -&gt; right;    root -&gt; right = tmp;        exchangeTreeNode(root -&gt; left);    exchangeTreeNode(root -&gt; right);&#125;</code></pre><h6 id="110-https-leetcode-cn-com-problems-balanced-binary-tree"><a href="#110-https-leetcode-cn-com-problems-balanced-binary-tree" class="headerlink" title="[110] https://leetcode-cn.com/problems/balanced-binary-tree/"></a>[110] <a href="https://leetcode-cn.com/problems/balanced-binary-tree/">https://leetcode-cn.com/problems/balanced-binary-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">getDepth</span><span class="hljs-params">(TreeNode * root)</span></span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">return</span> max(getDepth(root-&gt;left), getDepth(root-&gt;right)) + <span class="hljs-number">1</span>;&#125;<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isBalanced</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-comment">// 递归的解决方案， 先看退出条件比较好!</span>    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <span class="hljs-keyword">int</span> left_depth = getDepth(root-&gt;left);    <span class="hljs-keyword">int</span> right_depth = getDepth(root-&gt;right);    <span class="hljs-keyword">return</span> <span class="hljs-built_in">abs</span>(left_depth - right_depth) &lt;= <span class="hljs-number">1</span> &amp;&amp; isBalanced(root -&gt; left) &amp;&amp; isBalanced(root -&gt; right); &#125;</code></pre><h6 id="101-https-leetcode-cn-com-problems-symmetric-tree"><a href="#101-https-leetcode-cn-com-problems-symmetric-tree" class="headerlink" title="[101] https://leetcode-cn.com/problems/symmetric-tree/"></a>[101] <a href="https://leetcode-cn.com/problems/symmetric-tree/">https://leetcode-cn.com/problems/symmetric-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode* left, TreeNode * right)</span></span>&#123;    <span class="hljs-keyword">if</span>(left == <span class="hljs-literal">NULL</span> &amp;&amp; right == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <span class="hljs-keyword">if</span>(left == <span class="hljs-literal">NULL</span> || right == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">return</span> left -&gt; val == right -&gt; val &amp;&amp; helper(left-&gt;left, right-&gt;right) &amp;&amp; helper(left-&gt;right, right-&gt;left);&#125;<span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isSymmetric</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <span class="hljs-keyword">return</span> helper(root-&gt;left, root-&gt;right);&#125;</code></pre><h6 id="100-https-leetcode-cn-com-problems-same-tree"><a href="#100-https-leetcode-cn-com-problems-same-tree" class="headerlink" title="[100] https://leetcode-cn.com/problems/same-tree/"></a>[100] <a href="https://leetcode-cn.com/problems/same-tree/">https://leetcode-cn.com/problems/same-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isSameTree</span><span class="hljs-params">(TreeNode* p, TreeNode* q)</span> </span>&#123;    <span class="hljs-keyword">if</span>(p == <span class="hljs-literal">NULL</span> &amp;&amp; q == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <span class="hljs-keyword">if</span>((p == <span class="hljs-literal">NULL</span> || q == <span class="hljs-literal">NULL</span>)) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">return</span> p-&gt;val == q-&gt;val &amp;&amp;             isSameTree(p-&gt;left, q-&gt;left) &amp;&amp;  isSameTree(p-&gt;right, q-&gt;right); &#125;</code></pre><h6 id="98-Validate-Binary-Search-Tree-https-leetcode-com-problems-validate-binary-search-tree-description"><a href="#98-Validate-Binary-Search-Tree-https-leetcode-com-problems-validate-binary-search-tree-description" class="headerlink" title="[98] Validate Binary Search Tree https://leetcode.com/problems/validate-binary-search-tree/description/"></a>[98] Validate Binary Search Tree <a href="https://leetcode.com/problems/validate-binary-search-tree/description/">https://leetcode.com/problems/validate-binary-search-tree/description/</a></h6><pre><code class="hljs cpp"><span class="hljs-keyword">long</span> pre = LONG_MIN; <span class="hljs-comment">// 超级坑的边界条件</span><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isValidBST</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>; <span class="hljs-comment">// 先写退出条件</span>    <span class="hljs-keyword">bool</span> left = isValidBST(root-&gt;left); <span class="hljs-comment">// 左子树</span>    <span class="hljs-comment">// 中间处理过程</span>    <span class="hljs-keyword">if</span>(pre &gt;= root-&gt;val) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">else</span> pre = root-&gt;val;    <span class="hljs-keyword">bool</span> right = isValidBST(root-&gt;right); <span class="hljs-comment">// 右子树</span>    <span class="hljs-keyword">return</span>  left &amp;&amp; right;  &#125;</code></pre><h6 id="404-左叶子之和-https-leetcode-cn-com-problems-sum-of-left-leaves-🌟🌟"><a href="#404-左叶子之和-https-leetcode-cn-com-problems-sum-of-left-leaves-🌟🌟" class="headerlink" title="[404] 左叶子之和 https://leetcode-cn.com/problems/sum-of-left-leaves/  🌟🌟"></a>[404] 左叶子之和 <a href="https://leetcode-cn.com/problems/sum-of-left-leaves/">https://leetcode-cn.com/problems/sum-of-left-leaves/</a>  🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 递归写法</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">sumOfLeftLeaves</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    helper(root, <span class="hljs-literal">false</span>, res);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-comment">// 不要捉急，先写一个递归遍历函数， 然后考虑怎么在这个的基础上进行修改</span><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode * root, <span class="hljs-keyword">bool</span> flag, <span class="hljs-keyword">int</span>&amp; res)</span></span>&#123;    <span class="hljs-comment">// 递归退出条件</span>    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-comment">// 满足对应的操作， 执行对应的流程</span>    <span class="hljs-keyword">if</span>(flag &amp;&amp; root-&gt;left == <span class="hljs-literal">NULL</span> &amp;&amp; root-&gt;right == <span class="hljs-literal">NULL</span>)         res +=  root-&gt;val;    <span class="hljs-comment">// 递归遍历两颗子树</span>    helper(root-&gt;left, <span class="hljs-literal">true</span>, res);    helper(root-&gt;right, <span class="hljs-literal">false</span>, res);&#125;<span class="hljs-comment">// 非递归</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">sumOfLeftLeaves</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">int</span> s;    <span class="hljs-built_in">stack</span>&lt;TreeNode * &gt; m_stk;    TreeNode * p = root;    <span class="hljs-keyword">while</span>(p || !m_stk.empty())&#123;        <span class="hljs-keyword">if</span>(p)&#123;             m_stk.push(p);             p = p -&gt; left;             <span class="hljs-keyword">if</span>(p &amp;&amp; p -&gt; left == <span class="hljs-literal">NULL</span> &amp;&amp; p -&gt; right == <span class="hljs-literal">NULL</span>) s += p-&gt;val;        &#125;<span class="hljs-keyword">else</span>&#123;             p = m_stk.top();             m_stk.pop();             p = p -&gt; right;        &#125;    &#125;    <span class="hljs-keyword">return</span> s;&#125;</code></pre><h5 id="类型三-路径与路径和"><a href="#类型三-路径与路径和" class="headerlink" title="类型三 路径与路径和"></a>类型三 路径与路径和</h5><h6 id="113-https-leetcode-cn-com-problems-path-sum-ii"><a href="#113-https-leetcode-cn-com-problems-path-sum-ii" class="headerlink" title="[113] https://leetcode-cn.com/problems/path-sum-ii/"></a>[113] <a href="https://leetcode-cn.com/problems/path-sum-ii/">https://leetcode-cn.com/problems/path-sum-ii/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt; <span class="hljs-title">pathSum</span><span class="hljs-params">(TreeNode* root, <span class="hljs-keyword">int</span> sum)</span> </span>&#123;    <span class="hljs-comment">// 总入口函数规定输入和输出</span>    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; &gt; res;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> res;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span> &gt; path;    recur(root, path, res, sum);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">recur</span><span class="hljs-params">(TreeNode * root, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; path, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&gt;&amp; res, <span class="hljs-keyword">int</span> sum)</span></span>&#123;    <span class="hljs-comment">// 如果为空， 返回!</span>    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    <span class="hljs-comment">// 执行操作</span>    path.push_back(root-&gt;val);    <span class="hljs-comment">// 满足条件的操作</span>    <span class="hljs-keyword">if</span>(root-&gt;val == sum &amp;&amp; root-&gt;left == <span class="hljs-literal">NULL</span> &amp;&amp; root-&gt;right == <span class="hljs-literal">NULL</span>)&#123;        res.push_back(path);    &#125;    <span class="hljs-comment">// 两次递归!</span>    recur(root-&gt;left, path, res, sum - root-&gt;val);    recur(root-&gt;right, path, res, sum - root-&gt;val);    <span class="hljs-comment">// 仔细考虑此处是不是应该添加!</span>    path.pop_back();&#125;</code></pre><h6 id="112-https-leetcode-cn-com-problems-path-sum"><a href="#112-https-leetcode-cn-com-problems-path-sum" class="headerlink" title="[112] https://leetcode-cn.com/problems/path-sum/"></a>[112] <a href="https://leetcode-cn.com/problems/path-sum/">https://leetcode-cn.com/problems/path-sum/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">hasPathSum</span><span class="hljs-params">(TreeNode* root, <span class="hljs-keyword">int</span> sum)</span> </span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">if</span>(sum == root-&gt;val &amp;&amp; root-&gt;left == <span class="hljs-literal">NULL</span> &amp;&amp; root-&gt;right == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;    <span class="hljs-keyword">bool</span> left = hasPathSum(root-&gt;left, sum - root-&gt;val);    <span class="hljs-keyword">bool</span> right = hasPathSum(root-&gt;right, sum - root-&gt;val);    <span class="hljs-keyword">return</span> left || right;&#125;</code></pre><h6 id="129-https-leetcode-cn-com-problems-sum-root-to-leaf-numbers-🌟🌟🌟"><a href="#129-https-leetcode-cn-com-problems-sum-root-to-leaf-numbers-🌟🌟🌟" class="headerlink" title="[129] https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/   🌟🌟🌟"></a>[129] <a href="https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/">https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">sumNumbers</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;    TreeNode * cur = root;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; path;    recur(cur, res, path);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">recur</span><span class="hljs-params">(TreeNode * root,<span class="hljs-keyword">int</span>&amp; res, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; path)</span></span>&#123;    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span>;    path.push_back(root-&gt;val);    <span class="hljs-keyword">if</span>(root -&gt; left == <span class="hljs-literal">NULL</span> &amp;&amp; root -&gt; right == <span class="hljs-literal">NULL</span>)&#123; <span class="hljs-comment">// 叶子节点</span>        <span class="hljs-keyword">int</span> pathsum = <span class="hljs-number">0</span>;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n: path) pathsum = pathsum * <span class="hljs-number">10</span> + n;        res += pathsum;    &#125;    recur(root-&gt;left, res, path);    recur(root-&gt;right, res, path);    path.pop_back();&#125;</code></pre><h6 id="543-二叉树的直径-https-leetcode-cn-com-problems-diameter-of-binary-tree"><a href="#543-二叉树的直径-https-leetcode-cn-com-problems-diameter-of-binary-tree" class="headerlink" title="[543] 二叉树的直径 https://leetcode-cn.com/problems/diameter-of-binary-tree/"></a>[543] 二叉树的直径 <a href="https://leetcode-cn.com/problems/diameter-of-binary-tree/">https://leetcode-cn.com/problems/diameter-of-binary-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 直径是边的长度， 而不是节点数。通过观察可以看出， 这里的直径一定是某个节点的左子树的深度 + 右子树的深度。</span><span class="hljs-comment">// 基于这个逻辑。 可以对求深度的代码进行更改即可</span><span class="hljs-keyword">public</span>:    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">diameterOfBinaryTree</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;        <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;        <span class="hljs-keyword">int</span> max_depth = depth(root);        <span class="hljs-keyword">return</span> res;    &#125;    <span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">depth</span><span class="hljs-params">(TreeNode * root)</span></span>&#123;        <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;                <span class="hljs-keyword">int</span> left = depth(root-&gt;left);        <span class="hljs-keyword">int</span> right = depth(root-&gt;right);        <span class="hljs-comment">// 考虑一个问题： 为什么使用后序? 因为要先获得两个子节点的深度</span>        res = max(res, left + right); <span class="hljs-comment">// (1) 如果不考虑这行， 该函数是求该节点的最大的深度</span>                                      <span class="hljs-comment">// (2) 这行是去求之前的最大直径， 和经过该节点的最大路径</span>                    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + max(left, right);    &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-keyword">int</span> res = <span class="hljs-number">0</span>;</code></pre><h6 id="124-Binary-Tree-Maximum-Path-Sum-https-leetcode-com-problems-binary-tree-maximum-path-sum-description-🌟🌟🌟"><a href="#124-Binary-Tree-Maximum-Path-Sum-https-leetcode-com-problems-binary-tree-maximum-path-sum-description-🌟🌟🌟" class="headerlink" title="[124] Binary Tree Maximum Path Sum https://leetcode.com/problems/binary-tree-maximum-path-sum/description/   🌟🌟🌟"></a>[124] Binary Tree Maximum Path Sum <a href="https://leetcode.com/problems/binary-tree-maximum-path-sum/description/">https://leetcode.com/problems/binary-tree-maximum-path-sum/description/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 这道题目和上一道很类似</span><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">maxPathSum</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;    helper(root);    <span class="hljs-keyword">return</span> res;&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode * root)</span></span>&#123;    <span class="hljs-comment">// 求 以 root 为出发点的 最大路径和</span>    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;    <span class="hljs-keyword">int</span> left = helper(root-&gt;left);    <span class="hljs-keyword">int</span> right = helper(root-&gt;right);    <span class="hljs-comment">// 分三种情况:</span>    <span class="hljs-comment">// (1) root-&gt;val  根节点</span>    <span class="hljs-comment">// (2) root-&gt;val + max(root-&gt;left, roor-&gt;right) 根节点 + 左子树 or 右子树</span>    <span class="hljs-comment">// (3) root-&gt;val + root-&gt;left + root-&gt;left 根节点 + 左子树 + 右子树</span>    <span class="hljs-keyword">int</span> max_path_sum = max(root-&gt;val ,                            max(root-&gt;val + max(left, right),                                root-&gt;val + left + right)))    res = max(res,  max_path_sum);    <span class="hljs-comment">// 分两种情况:</span>    <span class="hljs-comment">// (1) 孤立的单一节点</span>    <span class="hljs-comment">// (2) 根节点 + 左右子树的最大值</span>    <span class="hljs-keyword">return</span> max(root-&gt;val, max(left, right) + root-&gt;val);&#125;<span class="hljs-keyword">int</span> res = INT_MIN;</code></pre><h5 id="类型四：-重建二叉树"><a href="#类型四：-重建二叉树" class="headerlink" title="类型四： 重建二叉树"></a>类型四： 重建二叉树</h5><h6 id="617-https-leetcode-com-problems-merge-two-binary-trees"><a href="#617-https-leetcode-com-problems-merge-two-binary-trees" class="headerlink" title="[617] https://leetcode.com/problems/merge-two-binary-trees/"></a>[617] <a href="https://leetcode.com/problems/merge-two-binary-trees/">https://leetcode.com/problems/merge-two-binary-trees/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">TreeNode* <span class="hljs-title">mergeTrees</span><span class="hljs-params">(TreeNode* t1, TreeNode* t2)</span> </span>&#123;    <span class="hljs-keyword">if</span>(t1 == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> t2;    <span class="hljs-keyword">if</span>(t2 == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> t1;    TreeNode * pNode = <span class="hljs-keyword">new</span> TreeNode(t1-&gt;val + t2-&gt;val);    pNode -&gt; left = mergeTrees(t1-&gt;left, t2-&gt;left);    pNode -&gt; right = mergeTrees(t1-&gt;right, t2-&gt;right);    <span class="hljs-keyword">return</span> pNode;&#125;</code></pre><h6 id="105-https-leetcode-cn-com-problems-construct-binary-tree-from-preorder-and-inorder-traversal-🌟🌟🌟"><a href="#105-https-leetcode-cn-com-problems-construct-binary-tree-from-preorder-and-inorder-traversal-🌟🌟🌟" class="headerlink" title="[105] https://leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/   🌟🌟🌟"></a>[105] <a href="https://leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/">https://leetcode-cn.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/</a>   🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-keyword">public</span>:    <span class="hljs-function">TreeNode* <span class="hljs-title">buildTree</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; preorder, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; inorder)</span> </span>&#123;        po = preorder; <span class="hljs-comment">// 前序序列全局化</span>        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;  i &lt; inorder.size(); i++) <span class="hljs-comment">// 中序序列 map 化</span>            m_map[inorder[i]] = i;        <span class="hljs-keyword">return</span> helper(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, inorder.size()<span class="hljs-number">-1</span>); <span class="hljs-comment">// call</span>    &#125;    <span class="hljs-function">TreeNode * <span class="hljs-title">helper</span><span class="hljs-params">(<span class="hljs-keyword">int</span> pre_root, <span class="hljs-keyword">int</span> left, <span class="hljs-keyword">int</span> right)</span></span>&#123;        <span class="hljs-comment">/* pre_root: 根节点在前序遍历中的下表</span><span class="hljs-comment">           left: 中序遍历的左侧边界</span><span class="hljs-comment">           right: 中序遍历的右侧边界  */</span>        <span class="hljs-keyword">if</span>(left &gt; right) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>; <span class="hljs-comment">// 退出条件</span>        TreeNode * root = <span class="hljs-keyword">new</span> TreeNode(po[pre_root]);        <span class="hljs-keyword">int</span> i  = m_map[po[pre_root]]; <span class="hljs-comment">// 找到根节点在中序遍历 index 作为划分标准</span>        root -&gt; left = helper(pre_root+<span class="hljs-number">1</span>, left, i<span class="hljs-number">-1</span>);        <span class="hljs-comment">// 找到右子树的根节点: 前序遍历的根节点的坐标 + 左子树的个数 + 1</span>        root -&gt; right = helper(pre_root + (i-left)+<span class="hljs-number">1</span>, i+<span class="hljs-number">1</span>, right);        <span class="hljs-keyword">return</span> root;     &#125;<span class="hljs-keyword">private</span>:    <span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; m_map;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; po;</code></pre><h6 id="108-Convert-Sorted-Array-to-Binary-Search-Tree"><a href="#108-Convert-Sorted-Array-to-Binary-Search-Tree" class="headerlink" title="[108] Convert Sorted Array to Binary Search Tree"></a>[108] Convert Sorted Array to Binary Search Tree</h6><pre><code class="hljs cpp"><span class="hljs-comment">// 将二叉树和二分查找结合的一道题目</span><span class="hljs-function">TreeNode* <span class="hljs-title">sortedArrayToBST</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-keyword">if</span>(nums.size() == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">return</span> heler(nums, <span class="hljs-number">0</span>, nums.size()<span class="hljs-number">-1</span>);&#125;<span class="hljs-function">TreeNode* <span class="hljs-title">heler</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; nums, <span class="hljs-keyword">int</span> begin, <span class="hljs-keyword">int</span> end)</span></span>&#123;    <span class="hljs-keyword">if</span>(begin &gt; end) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-keyword">int</span> mid = begin + (end - begin) / <span class="hljs-number">2</span>;    TreeNode * root = <span class="hljs-keyword">new</span> TreeNode(nums[mid]);    root-&gt;left = heler(nums, begin, mid<span class="hljs-number">-1</span>);    root-&gt;right = heler(nums, mid+<span class="hljs-number">1</span>, end);    <span class="hljs-keyword">return</span> root;&#125;&#125;;</code></pre><h6 id="109-有序链表转换二叉搜索树-https-leetcode-cn-com-problems-convert-sorted-list-to-binary-search-tree-🌟🌟"><a href="#109-有序链表转换二叉搜索树-https-leetcode-cn-com-problems-convert-sorted-list-to-binary-search-tree-🌟🌟" class="headerlink" title="[109] 有序链表转换二叉搜索树 https://leetcode-cn.com/problems/convert-sorted-list-to-binary-search-tree/   🌟🌟"></a>[109] 有序链表转换二叉搜索树 <a href="https://leetcode-cn.com/problems/convert-sorted-list-to-binary-search-tree/">https://leetcode-cn.com/problems/convert-sorted-list-to-binary-search-tree/</a>   🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">TreeNode* <span class="hljs-title">sortedListToBST</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;    <span class="hljs-keyword">if</span>(head == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;    <span class="hljs-comment">//  第一遍写的时候，这个条件没有处理好</span>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(head -&gt; next == <span class="hljs-literal">NULL</span>) <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> TreeNode(head-&gt;val);         ListNode * fast = head;    ListNode * slow = head;    ListNode * prev = head;    <span class="hljs-keyword">while</span>(fast &amp;&amp; fast -&gt; next)&#123;        prev = slow;        fast = fast -&gt; next -&gt; next;        slow = slow -&gt; next;    &#125;    prev -&gt; next = <span class="hljs-literal">NULL</span>;    TreeNode * root = <span class="hljs-keyword">new</span> TreeNode(slow-&gt;val);    root-&gt;left = sortedListToBST(head);    root-&gt;right = sortedListToBST(slow-&gt;next);    <span class="hljs-keyword">return</span> root;   &#125;</code></pre><h5 id="类型五：最低公共祖先"><a href="#类型五：最低公共祖先" class="headerlink" title="类型五：最低公共祖先"></a>类型五：最低公共祖先</h5><h6 id="235-https-leetcode-cn-com-problems-lowest-common-ancestor-of-a-binary-search-tree"><a href="#235-https-leetcode-cn-com-problems-lowest-common-ancestor-of-a-binary-search-tree" class="headerlink" title="[235] https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-search-tree/"></a>[235] <a href="https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-search-tree/">https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-search-tree/</a></h6><pre><code class="hljs cpp"><span class="hljs-function">TreeNode* <span class="hljs-title">lowestCommonAncestor</span><span class="hljs-params">(TreeNode* root, TreeNode* p, TreeNode* q)</span> </span>&#123;    <span class="hljs-keyword">if</span>(p-&gt;val &gt; root-&gt;val &amp;&amp; q-&gt;val &gt; root-&gt;val)&#123;        <span class="hljs-keyword">return</span> lowestCommonAncestor(root-&gt;right, p, q);    &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(p-&gt;val &lt; root-&gt;val &amp;&amp; q-&gt;val &lt; root-&gt;val)&#123;        <span class="hljs-keyword">return</span> lowestCommonAncestor(root-&gt;left, p, q);    &#125;    <span class="hljs-keyword">return</span> root;&#125;</code></pre><h6 id="236-二叉树的最近公共祖先-https-leetcode-cn-com-problems-lowest-common-ancestor-of-a-binary-tree-🌟🌟🌟"><a href="#236-二叉树的最近公共祖先-https-leetcode-cn-com-problems-lowest-common-ancestor-of-a-binary-tree-🌟🌟🌟" class="headerlink" title="[236] 二叉树的最近公共祖先 https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/  🌟🌟🌟"></a>[236] 二叉树的最近公共祖先 <a href="https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/">https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/</a>  🌟🌟🌟</h6><pre><code class="hljs cpp"><span class="hljs-function">TreeNode* <span class="hljs-title">lowestCommonAncestor</span><span class="hljs-params">(TreeNode* root, TreeNode* p, TreeNode* q)</span> </span>&#123;    <span class="hljs-comment">// exit: 根节点为空， 或者找到 p节点 或者 q节点</span>    <span class="hljs-keyword">if</span>(root == <span class="hljs-literal">NULL</span> || p == root || q == root) <span class="hljs-keyword">return</span> root;    <span class="hljs-comment">// 递归式：从根节点的左右子树寻找p、q的节点</span>    TreeNode * left = lowestCommonAncestor(root-&gt;left, p, q);    TreeNode * right = lowestCommonAncestor(root-&gt;right, p, q);    <span class="hljs-comment">// 判断其祖先位置</span>    <span class="hljs-keyword">if</span>(left &amp;&amp; right) <span class="hljs-keyword">return</span> root; <span class="hljs-comment">// 分别出现在左右子树， 则该节点为最低公共祖先</span>    <span class="hljs-keyword">return</span> left ? left : right; &#125;</code></pre><h3 id="5-图"><a href="#5-图" class="headerlink" title="5. 图"></a>5. 图</h3><h3 id="6-字典-map-的使用"><a href="#6-字典-map-的使用" class="headerlink" title="6. 字典 map 的使用"></a>6. 字典 map 的使用</h3><ul><li><p>STL 提供了  Map/MultiMap 和 Unordered Map/Multi-Map 来进行字典操作， 其中前者的底层是红黑树，后者的底层才是 哈希表</p></li><li><p>进行索引时， 如果没有 key， 则会自动插入 key， 且如果 value 为 int， 则初始化为 0</p><pre><code class="hljs cpp"><span class="hljs-keyword">for</span> k in keys:    m_map[k]++;</code></pre></li><li><p>经常会使用数组来代替hashmap， 形成 index -&gt; value 这样一种映射， 这种操作在字符串中尤为常见。 </p></li><li><p>常见的 set/map API</p><pre><code class="hljs cpp">begin()   end()   empty()   size()erase(iterator)       erase(key_value)find()s.insert(key_value); <span class="hljs-comment">// set  </span>m[key] = val;  <span class="hljs-comment">// map</span></code></pre></li></ul><h6 id="347-前-K-个高频元素-https-leetcode-cn-com-problems-top-k-frequent-elements"><a href="#347-前-K-个高频元素-https-leetcode-cn-com-problems-top-k-frequent-elements" class="headerlink" title="[347] 前 K 个高频元素 https://leetcode-cn.com/problems/top-k-frequent-elements/"></a>[347] 前 K 个高频元素 <a href="https://leetcode-cn.com/problems/top-k-frequent-elements/">https://leetcode-cn.com/problems/top-k-frequent-elements/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">topKFrequent</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> k)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-built_in">map</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; m_map;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n:nums)  m_map[n]++; <span class="hljs-comment">// 如果 key 不存在，则自动添加， 且 value 初始化为 0</span>    <span class="hljs-comment">// 将 map 转化为 vector 进行排序</span>    vector&lt;pair&lt;int, int&gt; &gt; pair_vec(m_map.begin(), m_map.end());     sort(pair_vec.begin(), pair_vec.end(),             [](<span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; a, <span class="hljs-built_in">pair</span>&lt;<span class="hljs-keyword">int</span>, <span class="hljs-keyword">int</span>&gt; b)&#123;<span class="hljs-keyword">return</span> a.second &gt; b.second;&#125;);  <span class="hljs-comment">// lambda 算子</span>    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> p: pair_vec)&#123;        <span class="hljs-keyword">if</span>(i++ &lt; k) res.push_back(p.first);     &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="387-字符串中的第一个唯一字符-https-leetcode-cn-com-problems-first-unique-character-in-a-string"><a href="#387-字符串中的第一个唯一字符-https-leetcode-cn-com-problems-first-unique-character-in-a-string" class="headerlink" title="[387] 字符串中的第一个唯一字符 https://leetcode-cn.com/problems/first-unique-character-in-a-string/"></a>[387] 字符串中的第一个唯一字符 <a href="https://leetcode-cn.com/problems/first-unique-character-in-a-string/">https://leetcode-cn.com/problems/first-unique-character-in-a-string/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 不要使用 map, 直接使用 数组 作为 哈希表即可</span><span class="hljs-function"><span class="hljs-keyword">char</span> <span class="hljs-title">firstUniqChar</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">dic</span><span class="hljs-params">(<span class="hljs-number">26</span>, <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:s)   dic[ c - <span class="hljs-string">&#x27;a&#x27;</span>] += <span class="hljs-number">1</span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:s)   <span class="hljs-keyword">if</span>(dic[c - <span class="hljs-string">&#x27;a&#x27;</span>] == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> c;    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27; &#x27;</span>; <span class="hljs-comment">// 可以直接 return  &#x27; &#x27; 的</span>&#125;</code></pre><h6 id="lcof-57-和为s的两个数字-https-leetcode-cn-com-problems-he-wei-sde-liang-ge-shu-zi-lcof"><a href="#lcof-57-和为s的两个数字-https-leetcode-cn-com-problems-he-wei-sde-liang-ge-shu-zi-lcof" class="headerlink" title="[lcof 57] 和为s的两个数字 https://leetcode-cn.com/problems/he-wei-sde-liang-ge-shu-zi-lcof/"></a>[lcof 57] 和为s的两个数字 <a href="https://leetcode-cn.com/problems/he-wei-sde-liang-ge-shu-zi-lcof/">https://leetcode-cn.com/problems/he-wei-sde-liang-ge-shu-zi-lcof/</a></h6><pre><code class="hljs cpp"><span class="hljs-comment">// 要求返回下标时 -&gt; 使用哈希表解决</span><span class="hljs-comment">//    返回数值时 -&gt; 使用排序 + 双指针</span><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">twoSum</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums, <span class="hljs-keyword">int</span> target)</span> </span>&#123;    <span class="hljs-built_in">set</span>&lt;<span class="hljs-keyword">int</span>&gt; m_set;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> n : nums)&#123;        <span class="hljs-keyword">if</span>(m_set.find(target - n) == m_set.end())&#123;            m_set.insert(n);        &#125;<span class="hljs-keyword">else</span>&#123;            res.push_back(n);            res.push_back(target - n);            <span class="hljs-keyword">break</span>;        &#125;    &#125;    <span class="hljs-keyword">return</span> res; &#125;</code></pre><h6 id="242-有效的字母异位词-https-leetcode-cn-com-problems-valid-anagram"><a href="#242-有效的字母异位词-https-leetcode-cn-com-problems-valid-anagram" class="headerlink" title="[242]. 有效的字母异位词 https://leetcode-cn.com/problems/valid-anagram/"></a>[242]. 有效的字母异位词 <a href="https://leetcode-cn.com/problems/valid-anagram/">https://leetcode-cn.com/problems/valid-anagram/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">isAnagram</span><span class="hljs-params">(<span class="hljs-built_in">string</span> s, <span class="hljs-built_in">string</span> t)</span> </span>&#123;    <span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">char</span>&gt; <span class="hljs-title">m_vec</span><span class="hljs-params">(<span class="hljs-number">26</span>, <span class="hljs-number">0</span>)</span></span>;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:s) m_vec[c-<span class="hljs-string">&#x27;a&#x27;</span>]++;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> c:t) m_vec[c-<span class="hljs-string">&#x27;a&#x27;</span>]--;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>; i &lt; m_vec.size(); i++)        <span class="hljs-keyword">if</span>(m_vec[i] != <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;&#125;</code></pre><h6 id="49-字母异位词分组-https-leetcode-cn-com-problems-group-anagrams"><a href="#49-字母异位词分组-https-leetcode-cn-com-problems-group-anagrams" class="headerlink" title="[49] 字母异位词分组 https://leetcode-cn.com/problems/group-anagrams/"></a>[49] 字母异位词分组 <a href="https://leetcode-cn.com/problems/group-anagrams/">https://leetcode-cn.com/problems/group-anagrams/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&gt; <span class="hljs-title">groupAnagrams</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt;&amp; strs)</span> </span>&#123;        <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; &gt; res;        <span class="hljs-built_in">map</span>&lt;<span class="hljs-built_in">string</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-built_in">string</span>&gt; &gt;  m_map;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> str: strs)&#123;            <span class="hljs-built_in">string</span> ori_str = str;            sort(str.begin(), str.end());            m_map[str].push_back(ori_str);        &#125;        <span class="hljs-keyword">for</span>(<span class="hljs-keyword">auto</span> it:m_map) res.push_back(it.second);        <span class="hljs-keyword">return</span> res;&#125;</code></pre><h6 id="448-找到所有数组中消失的数字-https-leetcode-cn-com-problems-find-all-numbers-disappeared-in-an-array"><a href="#448-找到所有数组中消失的数字-https-leetcode-cn-com-problems-find-all-numbers-disappeared-in-an-array" class="headerlink" title="[448] 找到所有数组中消失的数字 https://leetcode-cn.com/problems/find-all-numbers-disappeared-in-an-array/"></a>[448] 找到所有数组中消失的数字 <a href="https://leetcode-cn.com/problems/find-all-numbers-disappeared-in-an-array/">https://leetcode-cn.com/problems/find-all-numbers-disappeared-in-an-array/</a></h6><pre><code class="hljs cpp"><span class="hljs-function"><span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; <span class="hljs-title">findDisappearedNumbers</span><span class="hljs-params">(<span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt;&amp; nums)</span> </span>&#123;    <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">int</span>&gt; res;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">int</span> index = <span class="hljs-built_in">abs</span>(nums[i]) - <span class="hljs-number">1</span>;        <span class="hljs-keyword">if</span>(nums[index] &gt; <span class="hljs-number">0</span>)             nums[index] = <span class="hljs-number">-1</span> * nums[index];    &#125;    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;  i &lt; nums.size(); i++)&#123;        <span class="hljs-keyword">if</span>(nums[i] &gt; <span class="hljs-number">0</span>) res.push_back(i+<span class="hljs-number">1</span>);    &#125;    <span class="hljs-keyword">return</span> res;&#125;</code></pre><h3 id="7-特殊结构"><a href="#7-特殊结构" class="headerlink" title="7. 特殊结构"></a>7. 特殊结构</h3>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>camera-calibration</title>
    <link href="/2019/06/09/camera-calibration/"/>
    <url>/2019/06/09/camera-calibration/</url>
    
    <content type="html"><![CDATA[<p>相机标定相关总结</p><a id="more"></a><h4 id="1-为什么需要相机标定？"><a href="#1-为什么需要相机标定？" class="headerlink" title="1. 为什么需要相机标定？"></a>1. 为什么需要相机标定？</h4><p>相机机标定的目的：建立相机成像几何模型并矫正透镜畸变。</p><p><strong>建立相机成像集合模型</strong>：计算机视觉的首要任务就是要通过拍摄到的图像信息获取到物体在真实三维世界里相对应的信息，于是，建立物体从三维世界映射到相机成像平面这一过程中的几何模型就显得尤为重要，而这一过程最关键的部分就是要得到相机的<strong>内参和外参</strong>。</p><p><strong>矫正透镜畸变</strong>：我们最开始接触到的成像方面的知识应该是有关小孔成像的，但是由于这种成像方式只有小孔部分能透过光线就会导致物体的成像亮度很低，于是聪明的人类发明了透镜。虽然亮度问题解决了，但是新的问题又来了：由于透镜的制造工艺，会使成像产生多种形式的畸变，于是为了去除畸变（使成像后的图像与真实世界的景象保持一致），人们计算并利用<strong>畸变系数</strong>来矫正这种像差。虽然理论上可以设计出不产生畸变的透镜，但其制造工艺相对于球面透镜会复杂很多，所以相对于复杂且高成本的制造工艺，人们更喜欢用数学来解决问题。</p><p>常见术语：</p><ul><li>内参矩阵: Intrinsic Matrix </li><li>焦距: Focal Length </li><li>主点: Principal Point </li><li>径向畸变: Radial Distortion </li><li>切向畸变: Tangential Distortion </li><li>旋转矩阵: Rotation Matrices </li><li>平移向量: Translation Vectors </li><li>平均重投影误差: Mean Reprojection Error </li><li>重投影误差: Reprojection Errors </li><li>重投影点: Reprojected Points</li></ul><h4 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a>2. 基础知识</h4><p>相机标定的目的之一是为了建立物体从三维世界到成像平面上各坐标点的对应关系，所以首先我们需要定义这样几个坐标系来为整个过程做好铺垫：</p><p><strong>世界坐标系(world coordinate system)</strong>：用户定义的三维世界的坐标系，为了描述目标物在真实世界里的位置而被引入，单位为m。</p><p><strong>相机坐标系(camera coordinate system)</strong>：在相机上建立的坐标系，为了从相机的角度描述物体位置而定义，作为沟通世界坐标系和图像/像素坐标系的中间一环。单位为m。</p><p><strong>图像坐标系(image coordinate system)</strong>：为了描述成像过程中物体从相机坐标系到图像坐标系的投影透射关系而引入，方便进一步得到像素坐标系下的坐标。 单位为m。</p><p><strong>像素坐标系(pixel coordinate system)</strong>：为了描述物体成像后的像点在数字图像上（相片）的坐标而引入，是我们真正从相机内读取到的信息所在的坐标系。单位为个（像素数目）。</p><p>下图可以更清晰地表达这四个坐标系之间的关系：</p><p><img src="/2019/06/09/camera-calibration/1.jpg" alt="img"></p><p>世界坐标系：$X_w$ 、$Y_w$、$Z_w$</p><p>相机坐标系： $X_c$、$Y_c$、$Z_c$</p><p>图像坐标系：$x$、$y$</p><p>像素坐标系：$u$、$v$。</p><p>相机坐标系的 $Z$ 轴与光轴重合，且垂直于图像坐标系平面并通过图像坐标系的原点，相机坐标系与图像坐标系之间的距离为焦距$f$（也即图像坐标系原点与焦点重合）。像素坐标系平面$u-v$和图像坐标系平面$x-y$重合，但像素坐标系原点位于图中左上角（之所以这么定义，目的是从存储信息的首地址开始读写）。</p><p><strong>棋盘</strong>是一块由黑白方块间隔组成的标定板，我们用它来作为相机标定的<strong>标定物</strong>（从真实世界映射到数字图像内的对象）。之所以我们用棋盘作为标定物是因为平面棋盘模式更容易处理（相对于复杂的三维物体），但与此同时，二维物体相对于三维物体会缺少一部分信息，于是<strong>我们会多次改变棋盘的方位来捕捉图像，以求获得更丰富的坐标信息</strong>。如下图所示，是相机在不同方向下拍摄的同一个棋盘图像。</p><p><img src="/2019/06/09/camera-calibration/2.png" alt></p><p>下面将依次对刚体进行一系列变换，使之<strong>从世界坐标系进行仿射变换、投影透射，最终得到像素坐标系下的离散图像点，过程中会逐步引入各参数矩阵</strong>。</p><h5 id="1-从世界坐标系到相机坐标系"><a href="#1-从世界坐标系到相机坐标系" class="headerlink" title="(1) 从世界坐标系到相机坐标系"></a>(1) 从世界坐标系到相机坐标系</h5><p>刚体从世界坐标系转换到相机坐标系的过程，可以通过旋转和平移来得到，我们将其变换矩阵由一个旋转矩阵和平移向量组合成的齐次坐标矩阵来表示：</p><p><img src="/2019/06/09/camera-calibration/4.png" alt></p><p>其中，$R$为旋转矩阵，$t$为平移向量。其中变换矩阵</p><p><img src="/2019/06/09/camera-calibration/7.png" alt></p><p>即为前文提到的外参矩阵，之所称之为外参矩阵可以理解为只与相机外部参数有关，且外参矩阵随刚体位置的变化而变化。下图表示了用R，t将上述世界坐标系转换到相机坐标系的过程。</p><p><img src="/2019/06/09/camera-calibration/8.png" alt></p><h5 id="2-从相机坐标系到理想图像坐标系"><a href="#2-从相机坐标系到理想图像坐标系" class="headerlink" title="(2) 从相机坐标系到理想图像坐标系"></a>(2) 从相机坐标系到理想图像坐标系</h5><p>这一过程进行了从三维坐标到二维坐标的转换，也即投影透视过程（用中心投影法将物体投射到投影面上，从而获得的一种较为接近视觉效果的单面投影图，也就是使我们人眼看到景物近大远小的一种成像方式）。我们还是拿针孔成像来说明（除了成像亮度低外，成像效果和透镜成像是一样的，但是光路更简单）。成像过程如图二所示：针孔面（相机坐标系）在图像平面（图像坐标系）和物点平面（棋盘平面）之间，所成图像为倒立实像。</p><p><img src="/2019/06/09/camera-calibration/9.png" alt></p><p>但是为了在数学上更方便描述，我们将相机坐标系和图像坐标系位置对调，变成图三所示的布置方式（没有实际的物理意义，只是方便计算）：</p><p><img src="/2019/06/09/camera-calibration/10.png" alt></p><p>此时，假设相机坐标系中有一点M，则在理想图像坐标系下（无畸变）的成像点P的坐标为（可由相似三角形原则得出）：</p><p><img src="/2019/06/09/camera-calibration/11.png" alt="img"></p><p>将上式化为齐次坐标表示形式为：</p><p><img src="/2019/06/09/camera-calibration/12.png" alt="img"></p><h5 id="3-从理想图像坐标系到实际图像坐标系（考虑畸变）"><a href="#3-从理想图像坐标系到实际图像坐标系（考虑畸变）" class="headerlink" title="(3) 从理想图像坐标系到实际图像坐标系（考虑畸变）"></a>(3) 从理想图像坐标系到实际图像坐标系（考虑畸变）</h5><p>​        透镜的畸变主要分为径向畸变和切向畸变，还有薄透镜畸变等等，但都没有径向和切向畸变影响显著，所以我们在这里只考虑径向和切向畸变。</p><ul><li><strong>径向畸变</strong>是由于透镜形状的制造工艺导致。且越向透镜边缘移动径向畸变越严重。下图所示是径向畸变的两种类型：桶形畸变和枕形畸变。</li></ul><p><img src="/2019/06/09/camera-calibration/13.png" alt="img"></p><p>实际情况中我们常用r=0处的泰勒级数展开的前几项来近似描述径向畸变。矫正径向畸变前后的坐标关系为：</p><p><img src="/2019/06/09/camera-calibration/14.png" alt="img"></p><p>由此可知对于径向畸变，我们有3个畸变参数需要求解。</p><ul><li><strong>切向畸变</strong>是由于透镜和CMOS或者CCD的安装位置误差导致。因此，如果存在切向畸变，一个矩形被投影到成像平面上时，很可能会变成一个梯形。切向畸变需要两个额外的畸变参数来描述，矫正前后的坐标关系为：</li></ul><p><img src="/2019/06/09/camera-calibration/15.png" alt="img"></p><p>由此可知对于切向畸变，我们有2个畸变参数需要求解。</p><p>综上，我们一共需要5个畸变参数（k1、k2、k3、p1和p2 ）来描述透镜畸变。</p><h5 id="4-从实际图像坐标系到像素坐标系"><a href="#4-从实际图像坐标系到像素坐标系" class="headerlink" title="(4) 从实际图像坐标系到像素坐标系"></a>(4) 从实际图像坐标系到像素坐标系</h5><p>由于定义的像素坐标系原点与图像坐标系原点不重合，假设图像坐标系原点在像素坐标系下的坐标为（u0，v0），每个像素点在图像坐标系x轴、y轴方向的尺寸为：dx、dy，且像点在实际图像坐标系下的坐标为（xc，yc），于是可得到像点在像素坐标系下的坐标为：</p><p><img src="/2019/06/09/camera-calibration/16.png" alt="img"></p><p>化为齐次坐标表示形式可得：</p><p><img src="/2019/06/09/camera-calibration/17.png" alt="img"></p><p>公式2中(xp, yp)与公式5中(xc, yc)相同，都是图像坐标系下的坐标。</p><p>若暂不考虑透镜畸变，则将式2与式5的转换矩阵相乘即为内参矩阵M：</p><p><img src="/2019/06/09/camera-calibration/17.png" alt="img"></p><p>之所以称之为内参矩阵可以理解为矩阵内各值只与相机内部参数有关，且不随物体位置变化而变化。</p><p>最后用一幅图来总结从世界坐标系到像素坐标系（不考虑畸变）的转换关系：</p><p><img src="/2019/06/09/camera-calibration/3.png" alt></p><h4 id="3-标定方法"><a href="#3-标定方法" class="headerlink" title="3. 标定方法"></a>3. 标定方法</h4><h5 id="1-、传统相机标定"><a href="#1-、传统相机标定" class="headerlink" title="(1)、传统相机标定"></a>(1)、传统相机标定</h5><p>最简单的相机标定为线性标定，即不考虑相机的畸变而只考虑空间坐标转换。<br>每个坐标点有X,Y两个变量，可列两个方程，相机内参有5个未知数，外参平移和旋转各3个，共有11个变量，因此至少需要6个特征点来求解。</p><h5 id="2-、非线性标定"><a href="#2-、非线性标定" class="headerlink" title="(2)、非线性标定"></a>(2)、非线性标定</h5><p>当镜头畸变明显时必须考虑畸变，一般较为便宜的网络摄像头畸变特别大，而价格较贵的工业摄像头则畸变很小，因为其中已经嵌入了许多消除畸变的程序。这时线性模型转化为非线性模型，需要通过非线性标定方法求解。有最速下降法，遗传算法，高斯牛顿法和神经网络算法等。</p><h5 id="3-、张正友标定"><a href="#3-、张正友标定" class="headerlink" title="(3)、张正友标定"></a>(3)、张正友标定</h5><h4 id="4-相机标定步骤："><a href="#4-相机标定步骤：" class="headerlink" title="4.  相机标定步骤："></a>4.  相机标定步骤：</h4><blockquote><p>(1)、打印一张棋盘格，把它贴在一个平面上，作为标定物。<br>(2)、通过调整标定物或摄像机的方向，为标定物拍摄一些不同方向的照片。<br>(3)、从照片中提取棋盘格角点。<br>(4)、估算理想无畸变的情况下，五个内参和六个外参。<br>(5)、应用最小二乘法估算实际存在径向畸变下的畸变系数。<br>(6)、极大似然法，优化估计，提升估计精度。</p></blockquote><h4 id="5-参考资料："><a href="#5-参考资料：" class="headerlink" title="5. 参考资料："></a>5. 参考资料：</h4><ul><li>从零开始学习张氏相机标定发： <a href="https://zhuanlan.zhihu.com/p/35223115">https://zhuanlan.zhihu.com/p/35223115</a></li><li>相机标定（Camera calibration）原理、步骤<a href="https://blog.csdn.net/qq_37791134/article/details/80942171">https://blog.csdn.net/qq_37791134/article/details/80942171</a></li><li>谭平：从相机标定到SLAM，极简三维视觉六小时课程视频 <a href="http://www.sohu.com/a/317611305_100007727">http://www.sohu.com/a/317611305_100007727</a></li><li>SLAM book： <a href="https://github.com/gaoxiang12/slambook">https://github.com/gaoxiang12/slambook</a></li><li>双目视觉之相机标定：<a href="https://www.cnblogs.com/zyly/p/9366080.html">https://www.cnblogs.com/zyly/p/9366080.html</a></li><li>最详细、最完整的相机标定讲解<a href="https://blog.csdn.net/lxy_2011/article/details/80675803">https://blog.csdn.net/lxy_2011/article/details/80675803</a></li><li>OPENCV 相机参数标定 <a href="https://www.jianshu.com/p/967a35dbb56a">https://www.jianshu.com/p/967a35dbb56a</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>探索</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch深入理解</title>
    <link href="/2019/05/17/pytorch%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/"/>
    <url>/2019/05/17/pytorch%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>挖个坑：主要想学习一下 Pytorch 的内部实现机制</p><a id="more"></a><p>参考资料</p><p><a href="https://minitorch.github.io/index.html">https://minitorch.github.io/index.html</a></p>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch分布式训练</title>
    <link href="/2019/05/17/pytorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/"/>
    <url>/2019/05/17/pytorch%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/</url>
    
    <content type="html"><![CDATA[<p>pytorch 分布式解决方案尝试: </p><ul><li>nn.Dataparallel 简单解决方案：适合于单节点多 GPU 并行</li><li>nn.parallel.DistributedDataParallel 并行 +  torch.utils.data.distributed.DistributedSampler 数据 + torch.distributed 配置</li><li>horovod： Uber 开源外部解决方案</li></ul><a id="more"></a><p>典型的两种方式： Map-reduce 和 Ring all reduce</p><p>几种通信方式：</p><h4 id="方式一-nn-DataParallel"><a href="#方式一-nn-DataParallel" class="headerlink" title="方式一: nn.DataParallel"></a>方式一: nn.DataParallel</h4><p>​    nn.DataParallel 为单进程，多线程。使用起来比较简单，相应的效率也较低， 适用于<strong>单节点多 GPU</strong> 的情况。nn.DataParallel 会将模型复制到不同的 GPU 上。 对于每个训练批次 batch， 会将其切分到不同的 GPU 上进行正向传播并将梯度汇总（默认是第一个 GPU）。其函数原型为：</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">torch</span>.<span class="hljs-title">nn</span>.<span class="hljs-title">DataParallel</span>(<span class="hljs-params">module, device_ids=None, output_device=None, dim=<span class="hljs-number">0</span></span>)</span><span class="hljs-class"># <span class="hljs-title">device_ids</span>:</span> 指定参与训练的 GPU<span class="hljs-comment">#  output_device: 用于梯度汇总的 GPU</span></code></pre><p>注意点：</p><p>（1）效率低下的原因：在每个训练批次（batch）中，会将梯度汇总然后分发到每个 GPU 上，所以网络通信就成为了一个瓶颈，并且会带来显存利用不平衡的问题。</p><p>（2）使用 nn.DataParallel 会在原有的模型外边包装一个 module， 加载模型的时候需要进行适当的拆包。</p><p>（2） 当没有指定 device_ids 的时候，程序会自动找到这个机器上面可以用的所有的显卡, 然后用于训练。可以通过：</p><p><code>os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;]</code> 事先指定可用 GPU， 防止 GPU 冲突。</p><h4 id="方式二：torch-nn-parallel-DistributedDataParallel"><a href="#方式二：torch-nn-parallel-DistributedDataParallel" class="headerlink" title="方式二：torch.nn.parallel.DistributedDataParallel"></a>方式二：torch.nn.parallel.DistributedDataParallel</h4><p>torch.nn.parallel.DistributedDataParallel 是 pytorch 推荐的并行方案。它支持多机多卡训练，显存分配更加均衡，且效率较高。</p><h5 id="Step1：-环境配置"><a href="#Step1：-环境配置" class="headerlink" title="Step1： 环境配置"></a>Step1： 环境配置</h5><p>确定网络的接口， 通常会自己寻找网络接口，当没有自己寻找到的时候，需要手动进行配置: </p><pre><code class="hljs python"><span class="hljs-keyword">import</span> osos.environ[<span class="hljs-string">&#x27;NCCL_SOCKET_IFNAME&#x27;</span>] = <span class="hljs-string">&#x27;enp2s0&#x27;</span>   <span class="hljs-comment"># for NCCL</span>os.environ[<span class="hljs-string">&#x27;GLOO_SOCKET_IFNAME&#x27;</span>] = <span class="hljs-string">&#x27;enp2s0&#x27;</span>   <span class="hljs-comment"># for GLOO</span></code></pre><h5 id="step2-确定相关配置"><a href="#step2-确定相关配置" class="headerlink" title="step2: 确定相关配置"></a>step2: 确定相关配置</h5><ul><li><p><strong>后端</strong>：  后端支持 gloo、nccl 和 mpi 三种方式。在使用 CPU 进行分布式训练的时候，优先选择 gloo， 在使用 GPU 进行分布式训练的时候， 优先选择 nccl。</p><p>   <strong>NCCL</strong>：NCCL 的全称为  NVIDIA Collective Communications Library ，是一个可以实现多个 GPU 、多个结点间聚合通信的库，在  PCIe、Nvlink、InfiniBand 上可以实现较高的通信速度。NCCL 对 GPU 均有较好支持，且  torch.distributed 对其也提供了原生支持。</p><p>MPI</p><p>​    <strong>MPI</strong>：即消息传递接口 (Message Passing Interface)，是一个来自于高性能计算领域的标准的工具。它支持点对点通信以及集体通信，并且是 torch.distributed 的 API 的灵感来源。MPI 后端的优势在于，在大型计算机集群上，MPI 应用广泛，且高度优化。 但是，torch.distributed 对 MPI 并不提供原生支持。因此，要使用 MPI，必须从源码编译 Pytorch。是否支持 GPU，视安装的 MPI 版本而定。</p><p>​    <strong>Gloo</strong>：Gloo后端支持 CPU 和 GPU，其支持集体通信（collective Communication），并对其进行了优化。torch.distributed 对 gloo 提供原生支持，无需进行额外操作。</p></li><li><p><strong>init_method: </strong> 初始化 <code>init_method</code> 的方法有两种，一种是使用 TCP 进行初始化，另外一种是使用 共享文件系统 进行初始化。并不推荐使用共享文件系统进行初始化。 TCP 初始化的格式为：<code>tcp://ip:端口号</code></p></li><li><p><strong>rank</strong> 和  <strong>world_size</strong></p><p>你需要确保, 不同机器的 <code>rank</code> 值不同， 并且需要注意： 主机的<code>rank</code>必须为0，而且使用 <code>init_method</code>的 ip 一定是 <code>rank</code>为 0 的主机，<code>world_size</code> 是你的主机数量,  不能随便设置这个数值, 当参与训练的主机数量达到 <code>world_size</code> 的设置值时, 代码才会执行的.</p></li></ul><pre><code class="hljs python">parser = argparse.ArgumentParser()parser.add_argument(<span class="hljs-string">&#x27;-bk&#x27;</span>,                    <span class="hljs-string">&#x27;--backend&#x27;</span>, type=str, default=<span class="hljs-string">&#x27;nccl&#x27;</span>, help=<span class="hljs-string">&#x27;Name of the backend to use.&#x27;</span>)parser.add_argument(<span class="hljs-string">&#x27;-im&#x27;</span>,                    <span class="hljs-string">&#x27;--init-method&#x27;</span>,                    type=str,                    default=<span class="hljs-string">&#x27;env://&#x27;</span>,                    help=<span class="hljs-string">&#x27;URL specifying how to initialize the package.&#x27;</span>)parser.add_argument(<span class="hljs-string">&#x27;-ws&#x27;</span>, <span class="hljs-string">&#x27;--world-size&#x27;</span>, type=int, default=<span class="hljs-number">1</span>, help=<span class="hljs-string">&#x27;Number of processes participating in the job.&#x27;</span>)parser.add_argument(<span class="hljs-string">&#x27;-r&#x27;</span>, <span class="hljs-string">&#x27;--rank&#x27;</span>, type=int, default=<span class="hljs-number">0</span>, help=<span class="hljs-string">&#x27;Rank of the current process.&#x27;</span>)args = parser.parse_args()distributed.init_process_group(    backend=args.backend,    init_method=args.init_method,    world_size=args.world_size,    rank=args.rank,)</code></pre><h5 id="step-3-加载数据，进行训练"><a href="#step-3-加载数据，进行训练" class="headerlink" title="step 3: 加载数据，进行训练"></a>step 3: 加载数据，进行训练</h5><pre><code class="hljs python">train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)model = nn.parallel.DistributedDataParallel(model)<span class="hljs-comment"># ...</span></code></pre><h5 id="step4-在命令行执行如下命令"><a href="#step4-在命令行执行如下命令" class="headerlink" title="step4: 在命令行执行如下命令:"></a>step4: 在命令行执行如下命令:</h5><p>机器1：</p><pre><code class="hljs shell">python3 -m torch.distributed.launch torch_ddp.py  -bk nccl -im tcp://10.10.10.1:12345 -rn 0 -ws 2</code></pre><p>机器2：</p><pre><code class="hljs shell">python3 -m torch.distributed.launch torch_ddp.py  -bk nccl -im tcp://10.10.10.1:12345 -rn 1 -ws 2</code></pre><h4 id="方式三-Horovod"><a href="#方式三-Horovod" class="headerlink" title="方式三: Horovod"></a>方式三: Horovod</h4><p>Horovod 是 Uber 开源的跨平台的分布式训练工具，名字来自于俄国传统民间舞蹈，舞者手牵手围成一个圈跳舞，与 Horovod 设备之间的通信模式很像，有以下几个特点：</p><ol><li>兼容 TensorFlow、Keras 和 PyTorch 机器学习框架。</li><li>使用 Ring-AllReduce 算法，对比 Parameter Server 算法，有着无需等待，负载均衡的优点。</li><li>实现简单，容易上手。（划重点）</li></ol><h5 id="step1-简单设置"><a href="#step1-简单设置" class="headerlink" title="step1:  简单设置"></a>step1:  简单设置</h5><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<span class="hljs-keyword">import</span> horovod.torch <span class="hljs-keyword">as</span> hvd<span class="hljs-comment"># init horovod</span>hvd.init()<span class="hljs-comment"># 给当前进程分配对应的 gpu，local_rank() 返回的是当前是第几个进程</span>torch.cuda.set_device(hvd.local_rank())</code></pre><h5 id="step2-datasets、model、optimizer"><a href="#step2-datasets、model、optimizer" class="headerlink" title="step2: datasets、model、optimizer"></a>step2: datasets、model、optimizer</h5><pre><code class="hljs python"><span class="hljs-comment"># dataset ...</span>train_dataset = ...train_sampler = torch.utils.data.distributed.DistributedSampler(    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)<span class="hljs-comment"># model ...</span>model = ...model.cuda()<span class="hljs-comment"># optimizer ...</span>optimizer = optim.SGD(model.parameters())optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())</code></pre><h5 id="step3-训练"><a href="#step3-训练" class="headerlink" title="step3: 训练"></a>step3: 训练</h5><pre><code class="hljs python"><span class="hljs-comment"># 初始化的时候广播参数，这个是为了在一开始的时候同步各个 gpu 之间的参数</span>hvd.broadcast_parameters(model.state_dict(), root_rank=<span class="hljs-number">0</span>)<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):   <span class="hljs-keyword">for</span> batch_idx, (data, target) <span class="hljs-keyword">in</span> enumerate(train_loader):       optimizer.zero_grad()       output = model(data)       loss = F.nll_loss(output, target)       loss.backward()       optimizer.step()       <span class="hljs-keyword">if</span> batch_idx % args.log_interval == <span class="hljs-number">0</span>:           print(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125;]\tLoss: &#123;&#125;&#x27;</span>.format(               epoch, batch_idx * len(data), len(train_sampler), loss.item()))</code></pre><h4 id="方式四：-混合精度-apex-搭配分布式"><a href="#方式四：-混合精度-apex-搭配分布式" class="headerlink" title="方式四： 混合精度 apex 搭配分布式"></a>方式四： 混合精度 apex 搭配分布式</h4><p>这样可以取得比较低的显存占比，同时训练时间也大幅缩减。</p>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch加速</title>
    <link href="/2019/05/17/pytorch%E5%8A%A0%E9%80%9F/"/>
    <url>/2019/05/17/pytorch%E5%8A%A0%E9%80%9F/</url>
    
    <content type="html"><![CDATA[<p>Pytorch 加速方案</p><a id="more"></a><h3 id="1-数据"><a href="#1-数据" class="headerlink" title="1. 数据"></a>1. 数据</h3><h5 id="0-dataloader"><a href="#0-dataloader" class="headerlink" title="(0) dataloader"></a>(0) dataloader</h5><ul><li>num_workers与batch_size调到合适值，并非越大越快（注意后者也影响模型性能）(需要在实验中找到最快的取值)</li><li>eval/test时shuffle=False</li><li>内存够大的情况下，dataloader的<strong>pin_memory</strong>设为True。对特别小的数据集如 MNIST 设置 <code>pin_memory=False</code>  反而更快一些。</li></ul><h5 id="1-预处理提速"><a href="#1-预处理提速" class="headerlink" title="(1) 预处理提速"></a>(1) 预处理提速</h5><ul><li>尽量减少每次读取数据时的预处理操作，可以考虑把一些固定的操作，例如 resize ，事先处理好保存下来，训练的时候直接拿来用</li><li><p>Linux上将预处理搬到GPU上加速：</p></li><li><ul><li><strong>NVIDIA/DALI</strong> ：<a href="https://github.com/NVIDIA/DALI">https://github.com/NVIDIA/DALI</a></li><li><a href="https://github.com/tanglang96/DataLoaders_DALI">https://github.com/tanglang96/DataLoaders_DALI</a></li></ul></li><li><p>数据预取：prefetch_generator（<a href="https://zhuanlan.zhihu.com/p/80695364">方法</a>）让读数据的worker能在运算时预读数据，而默认是数据清空时才读</p></li></ul><h5 id="2-IO-提速"><a href="#2-IO-提速" class="headerlink" title="(2) IO 提速"></a>(2) IO 提速</h5><ul><li><p>使用更快的图片处理：</p></li><li><ul><li><strong>opencv 一般要比 PIL 要快</strong></li><li>对于jpeg读取，可以尝试 <strong>jpeg4py</strong></li><li>存 <strong>bmp</strong> 图（降低解码时间）</li></ul></li><li><p><strong>小图拼起来存放（降低读取次数）：对于大规模的小文件读取，建议转成单独的文件，可以选择的格式可以考虑</strong>：TFRecord（Tensorflow）、recordIO(recordIO)、hdf5、 pth、n5、lmdb 等等（<a href="https://github.com/Lyken17/Efficient-PyTorch#data-loader）">https://github.com/Lyken17/Efficient-PyTorch#data-loader）</a></p></li><li><ul><li><strong>TFRecord</strong>：<a href="https://github.com/vahidk/tfrecord">https://github.com/vahidk/tfrecord</a></li><li>借助 <strong>lmdb 数据库格式</strong>：</li></ul></li><li><ul><li><ul><li><a href="https://github.com/Fangyh09/Image2LMDB">https://github.com/Fangyh09/Image2LMDB</a></li><li><a href="https://blog.csdn.net/P_LarT/article/details/103208405">https://blog.csdn.net/P_LarT/article/details/103208405</a></li><li><a href="https://github.com/lartpang/PySODToolBox/blob/master/ForBigDataset/ImageFolder2LMDB.py">https://github.com/lartpang/PySODToolBox/blob/master/ForBigDataset/ImageFolder2LMDB.py</a></li><li><a href="https://github.com/Lyken17/Efficient-PyTorch">https://github.com/Lyken17/Efficient-PyTorch</a></li></ul></li></ul></li></ul><h5 id="3-借助硬件"><a href="#3-借助硬件" class="headerlink" title="(3)　借助硬件"></a>(3)　借助硬件</h5><ul><li>借助内存：<strong>直接载到内存里面，或者把把内存映射成磁盘好了</strong></li><li>借助固态：把读取速度慢的机械硬盘换成 <strong>NVME 固态</strong>吧～</li></ul><h5 id="4-训练策略"><a href="#4-训练策略" class="headerlink" title="(4) 训练策略"></a>(4) 训练策略</h5><ul><li><p>在训练中使用<strong>低精度（FP16 甚至 INT8 、二值网络、三值网络）表示取代原有精度（FP32）表示</strong></p></li><li><ul><li>NVIDIA/Apex：</li></ul></li><li><ul><li><ul><li><a href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/100135729">https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/100135729</a></li><li><a href="https://github.com/nvidia/apex">https://github.com/nvidia/apex</a></li></ul></li></ul></li><li><p>使用分布式训练　DDP 或者 horovod</p></li></ul><h5 id="5-代码层面"><a href="#5-代码层面" class="headerlink" title="(5) 代码层面"></a>(5) 代码层面</h5><ul><li><code>torch.backends.cudnn.benchmark = True</code></li><li>Do numpy-like operations on the GPU wherever you can</li><li>Free up memory using<code>del</code>     用<code>del</code>及时删除不用的中间变量，节约GPU存储。</li><li>Avoid unnecessary transfer of data from the GPU</li><li>Use pinned memory, and use non_blocking=False to parallelize data transfer and GPU number crunching</li></ul><h3 id="2-model"><a href="#2-model" class="headerlink" title="2. model"></a>2. model</h3><ol><li><p>用<strong>float16</strong>代替默认的float32运算（<a href="https://link.zhihu.com/?target=https%3A//github.com/huggingface/transformers/blob/dad3c7a485b7ffc6fd2766f349e6ee845ecc2eee/examples/run_classifier.py">方法参考</a>，搜索”fp16”可以看到需要修改之处，包括model、optimizer、backward、learning rate）</p></li><li><p><strong>优化器</strong>以及对应参数的选择，如learning rate，不过它对性能的影响似乎更重要【占坑】</p></li><li><p>少用循环，多用<strong>向量化</strong>操作</p></li><li><p>经典操作尽量用别人优化好的<strong>库</strong>，别自己写</p></li><li><p>数据很多时少用append，虽然使用很方便，不过它每次都会重新分配空间？所以数据很大的话，光一次append就要几秒（测过），可以先分配好整个容器大小，每次用索引去修改内容，这样一步只要0.0x秒</p></li><li><p>固定对模型影响不大的部分参数，还能节约显存，可以用 detach() 切断反向传播，注意若仅仅给变量设置 required_grad=False 还是会计算梯度的</p></li><li><p>eval/test 的时候，加上 model.eval() 和 torch.no_grad()，前者固定 batch-normalization 和 dropout 但是会影响性能，后者关闭 autograd</p></li><li><p>提高程序<strong>并行度</strong>，例如 我想 train 时对每个 epoch 都能 test 一下以追踪模型性能变化，但是 test 时间成本太高要一个小时，所以写了个 socket，设一个127.0.0.1 的端口，每次 train 完一个 epoch 就发个UDP过去，那个进程就可以自己 test，同时原进程可以继续 train 下一个 epoch（对 这是自己想的诡异方法hhh）</p></li><li><p>torch.backends.cudnn.benchmark设为True，可以让cudnn根据当前训练各项config寻找优化算法，但这本身需要时间，所以input size在训练时会频繁变化的话，建议设为False</p></li><li><p>使用<code>inplace</code>操作可节约 GPU 存储，如</p><pre><code class="hljs ini"><span class="hljs-attr">x</span> = torch.nn.functional.relu(x, inplace=<span class="hljs-literal">True</span>)</code></pre></li><li><p>减少CPU和GPU之间的数据传输。例如， 如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</p></li><li><p>使用半精度浮点数<code>half()</code>会有一定的速度提升，具体效率依赖于GPU型号。需要小心数值精度过低带来的稳定性问题。时常使用 <code>assert tensor.size() == (N, D, H, W)</code>作为调试手段，确保张量维度和你设想中一致。</p></li><li><p>除了标记 y 外，尽量少使用一维张量，使用n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。</p></li><li><p>统计代码各部分耗时</p></li></ol><pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.autograd.profiler.profile(enabled=<span class="hljs-literal">True</span>, use_cuda=<span class="hljs-literal">False</span>) <span class="hljs-keyword">as</span> profile:    ...    print(profile)</code></pre><p>或者在命令行运行：</p><pre><code class="hljs css"><span class="hljs-selector-tag">python</span> <span class="hljs-selector-tag">-m</span> <span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.utils</span><span class="hljs-selector-class">.bottleneck</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch项目搭建</title>
    <link href="/2019/05/17/pytorch%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/"/>
    <url>/2019/05/17/pytorch%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<p>pytorch 搭建项目的基本流程</p><a id="more"></a><h3 id="基本工作流程"><a href="#基本工作流程" class="headerlink" title="基本工作流程"></a>基本工作流程</h3><ol><li><p>相关工作调研:  <strong>评价指标、数据集、经典解决方案、待解决问题和已有方案的不同、精度和速度预估、相关难点 ! </strong></p></li><li><p>数据探索和方案确定</p></li><li>依次编写模型 models.py、数据集读取接口 datasets.py 、损失函数 losses.py 、评价指标 criterion.py</li><li>编写训练脚本(train.py)和测试脚本(test.py)</li><li>训练、调试和测评</li><li>模型的部署</li></ol><p>注意，不要将所有层和模型放在同一个文件中。最佳做法是将最终网络分离为单独的文件（networks.py），并将layers 、loss 和 ops 保存在各自的文件（layers.py、losses.py、ops.py）中。完成的模型（由一个或多个网络组成）应在一个文件中引用，文件名为 yolov3.py、dcgan.py 这样。</p><h5 id="1-构建神经网络"><a href="#1-构建神经网络" class="headerlink" title="(1) 构建神经网络"></a>(1) 构建神经网络</h5><p>​    自定义的网络继承自一般继承自　<code>nn.Module</code> 类，　必须有一个 <code>forward</code> 方法来实现各个层或操作的 forward 传递，　</p><p>对于具有<strong>单个输入</strong>和<strong>单个输出</strong>的简单网络，请使用以下模式：</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConvBlock</span>(<span class="hljs-params">nn.Module</span>):</span>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span>    super(ConvBlock, self).__init__()    self.block = nn.Squential(       nn.Conv2d(...),       nn.ReLU(),       nn.BatchNorm2d(...)    )     <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>    <span class="hljs-keyword">return</span> self.block(x)<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SimpleNetwork</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, num_of_layers = <span class="hljs-number">15</span></span>):</span>        super(SimpleNetwork, self).__init__()        layers = list()        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(num_of_layers):            layers.append(..)        self.conv0 = nn.Sequential(*layers)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        out = self.conv0(x)        <span class="hljs-keyword">return</span> out</code></pre><p>我们建议将网络拆分为更小的<strong>可重用部分</strong>。网络由操作或其它网络模块组成。损失函数也是神经网络的模块，因此可以直接集成到网络中。</p><h5 id="2-自定义数据集"><a href="#2-自定义数据集" class="headerlink" title="(2) 自定义数据集"></a>(2) 自定义数据集</h5><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomDataset</span>(<span class="hljs-params">Dataset</span>):</span>    <span class="hljs-string">&quot;&quot;&quot; CustomDataset. &quot;&quot;&quot;</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, root_dir=<span class="hljs-string">&#x27;./data&#x27;</span>, transform=None</span>):</span>        <span class="hljs-string">&quot;&quot;&quot;</span><span class="hljs-string">        &quot;&quot;&quot;</span>        self.root_dir = root_dir        self.transform = transform        self.train_data = ...        self.train_target = ...    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span>        <span class="hljs-keyword">return</span> len(self.train_data)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, idx</span>):</span>        <span class="hljs-keyword">if</span> torch.is_tensor(idx):            idx = idx.tolist()        data = Image.open(self.train_data[idx])        target = Image.open(self.train_target[idx])        <span class="hljs-keyword">if</span> self.transform:            data, target = self.transform(data, target)        sample = &#123;<span class="hljs-string">&#x27;data&#x27;</span>: data, <span class="hljs-string">&#x27;high_img&#x27;</span>: target&#125;        <span class="hljs-keyword">return</span> sample</code></pre><h5 id="3-自定义损失"><a href="#3-自定义损失" class="headerlink" title="(3) 自定义损失"></a>(3) 自定义损失</h5><p>​        虽然 PyTorch 已经有很多标准的损失函数，但有时也可能需要创建自己的损失函数。为此，请创建单独的文件 <code>losses.py</code> 并扩展 <code>nn.module</code> 类以创建自定义的损失函数：</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomLoss</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span>        <span class="hljs-string">&quot;&quot;&quot; CustomLoss&quot;&quot;&quot;</span>        super(CustomLoss, self).__init__()    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x, y</span>):</span>        <span class="hljs-keyword">return</span> torch.mean(torch.square(x  - y))</code></pre><h5 id="4-推荐可以参考的用于训练模型的代码结构"><a href="#4-推荐可以参考的用于训练模型的代码结构" class="headerlink" title="(4) 推荐可以参考的用于训练模型的代码结构"></a>(4) 推荐可以参考的用于训练模型的代码结构</h5><pre><code class="hljs python"><span class="hljs-comment"># import statements</span><span class="hljs-keyword">import</span> torch<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data...<span class="hljs-comment"># set flags / seeds</span>torch.backends.cudnn.benchmark = <span class="hljs-literal">True</span>np.random.seed(<span class="hljs-number">1</span>)torch.manual_seed(<span class="hljs-number">1</span>)torch.cuda.manual_seed(<span class="hljs-number">1</span>)...  <span class="hljs-comment"># dataset</span>transform_train = ...trainform_text = ...train_dataset = CustomDataset(args.train_dataset, is_trainval = <span class="hljs-literal">True</span>, transform = transform_train) train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size,                                           shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, drop_last=<span class="hljs-literal">False</span>) valid_dataset = CustomDataset(args.valid_dataset, is_trainval = <span class="hljs-literal">True</span>, transform = transform_test)  valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.val_batch_size,                                            shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>) <span class="hljs-comment"># model &amp; loss</span>net = CustomNet().to(device) criterion = ...  <span class="hljs-comment"># lr &amp; optimizer</span>optim = optim.SGD(model.parameters(), lr=args.init_lr, momentum=args.momentum, weight_decay=args.weight_decay)scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="hljs-number">50</span>, <span class="hljs-number">70</span>], gamma=<span class="hljs-number">0.1</span>)<span class="hljs-comment"># load resume</span><span class="hljs-keyword">if</span> args.resume:    <span class="hljs-keyword">if</span> os.path.isfile(args.resume):        print(<span class="hljs-string">&quot;=&gt; loading checkpoint &#x27;&#123;&#125;&#x27;&quot;</span>.format(args.resume))        checkpoint = torch.load(args.resume)        args.start_epoch = checkpoint[<span class="hljs-string">&#x27;epoch&#x27;</span>]        best_prec = checkpoint[<span class="hljs-string">&#x27;best_prec&#x27;</span>]        model.load_state_dict(checkpoint[<span class="hljs-string">&#x27;state_dict&#x27;</span>])        optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;optimizer&#x27;</span>])        print(<span class="hljs-string">&quot;=&gt; loaded checkpoint &#x27;&#123;&#125;&#x27; (epoch &#123;&#125;) Prec: &#123;:f&#125;&quot;</span>              .format(args.resume, checkpoint[<span class="hljs-string">&#x27;epoch&#x27;</span>], best_prec1))    <span class="hljs-keyword">else</span>:        print(<span class="hljs-string">&quot;=&gt; no checkpoint found at &#x27;&#123;&#125;&#x27;&quot;</span>.format(args.resume))<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span>(<span class="hljs-params">epoch</span>):</span>    model.train()　<span class="hljs-comment"># 在　model(x)　前需要添加　model.eval()　或者　model.eval()</span>    avg_loss = <span class="hljs-number">0.0</span>    train_acc = <span class="hljs-number">0.0</span>    <span class="hljs-keyword">for</span> batch_idx, batchdata <span class="hljs-keyword">in</span> enumerate(train_loader):        data, target = batchdata[<span class="hljs-string">&quot;data&quot;</span>], batchdata[<span class="hljs-string">&quot;target&quot;</span>] <span class="hljs-comment">#</span>        data, target = data.to(device), target.to(device)  <span class="hljs-comment">#</span>        <span class="hljs-comment"># 在 loss.backward()　前用　optimizer.zero_grad()　清除累积梯度</span>        optimizer.zero_grad() <span class="hljs-comment"># optimizer.zero_grad　与　model.zero_grad效果一样</span>        predict = model(data) <span class="hljs-comment"># </span>        loss = criterion(predict, target) <span class="hljs-comment">#</span>        avg_loss += loss.item() <span class="hljs-comment">#</span>        loss.backward()        optimizer.step()        print(<span class="hljs-string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.1f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.format(                epoch, batch_idx * len(data), len(train_loader.dataset),                <span class="hljs-number">100.</span> * batch_idx / len(train_loader), loss.item()))    <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) %  args.save_interval == <span class="hljs-number">0</span>:        state = &#123; <span class="hljs-string">&#x27;epoch&#x27;</span>: epoch + <span class="hljs-number">1</span>,                   <span class="hljs-string">&#x27;state_dict&#x27;</span>: model.state_dict(),                   <span class="hljs-string">&#x27;best_prec&#x27;</span>: <span class="hljs-number">0.0</span>,                   <span class="hljs-string">&#x27;optimizer&#x27;</span>: optimizer.state_dict()&#125;        model_path = os.path.join(args.checkpoint_dir, <span class="hljs-string">&#x27;model_&#x27;</span> + str(epoch) + <span class="hljs-string">&#x27;.pth&#x27;</span>)        torch.save(state, model_path)<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test</span>():</span>    model.eval()    test_loss = <span class="hljs-number">0</span>    <span class="hljs-keyword">for</span> batch_idx, batchdata <span class="hljs-keyword">in</span> enumerate(valid_loader):        data, target = batchdata[<span class="hljs-string">&quot;data&quot;</span>], batchdata[<span class="hljs-string">&quot;target&quot;</span>] <span class="hljs-comment">#</span>        data, target = data.to(device), target.to(device) <span class="hljs-comment">#</span>        predict = model(data) <span class="hljs-comment"># </span>        test_loss += criterion(predict, target) <span class="hljs-comment">#</span>        psnr = criterion(predict * <span class="hljs-number">255</span>, target * <span class="hljs-number">255</span>) <span class="hljs-comment">#</span>    test_loss /= len(valid_loader.dataset)    print(<span class="hljs-string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, loss:&#123;&#125;, PSNR: (&#123;:.1f&#125;)\n&#x27;</span>.format(        test_loss, test_loss / len(valid_loader.dataset), psnr / len(valid_loader.dataset)))    <span class="hljs-keyword">return</span> psnr / float(len(valid_loader.dataset))best_prec = <span class="hljs-number">0.0</span><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(args.start_epoch, args.epochs):    train(epoch)    scheduler.step()    print(print(optimizer.state_dict()[<span class="hljs-string">&#x27;param_groups&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;lr&#x27;</span>]))    current_prec = test()     is_best = current_prec &gt; best_prec <span class="hljs-comment">#　更改大小写 !</span>    best_prec = max(best_prec, best_prec) <span class="hljs-comment">#  max or min</span>    save_checkpoint(&#123;        <span class="hljs-string">&#x27;epoch&#x27;</span>: epoch + <span class="hljs-number">1</span>,        <span class="hljs-string">&#x27;state_dict&#x27;</span>: model.state_dict(),        <span class="hljs-string">&#x27;best_prec&#x27;</span>: best_prec,        <span class="hljs-string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),    &#125;, is_best, args.checkpoint_dir)</code></pre>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>面试相关整理</title>
    <link href="/2019/04/29/Interview-2019/"/>
    <url>/2019/04/29/Interview-2019/</url>
    
    <content type="html"><![CDATA[<p>面试一些相关的感受经历整理</p><a id="more"></a><p>​    投了大概有十家公司的样子，回复并过去面试的公司有五家。应该会在这几家中决定吧。面试挺耗费时间的，心也累，得准备好多东西。这五家公司做的东西都不大相同。两家做AI+教育，一家AI+安防，一家遥感图像处理，还有一家不明确主要业务。主要面试的岗位为<strong>计算机视觉/图像处理岗位</strong>。除了一家没有给出意向，其他公司面的都还算可以。其实并不喜欢AI、人工智能这些 Title， 感觉有点虚无缥缈，不着边际(可能融资比较容易吧)，感觉计算机视觉/机器视觉/图像处理更加贴地气，也知道方向和目标。</p><p>​    每个公司的主要流程不尽相同，面试的内容也不尽相同。（其实感觉应届生和有工作经验的人的面试内容还挺不一样的。前者基础比较重要，后者更看重项目经历）。</p><p>​    先说一下大体的面试流程：<strong>投简历</strong> -&gt; <strong>HR 发送相应的面试通知</strong>  -&gt; <strong>找到相应的面试地点</strong> -&gt; <strong>填写面试应聘表</strong>  —&gt; <strong>技术面试(一面/二面)</strong> -&gt; <strong>HR 面试</strong> -&gt; <strong>后续沟通以及offer事宜</strong></p><h4 id="1-一些基本的礼仪和细节问题："><a href="#1-一些基本的礼仪和细节问题：" class="headerlink" title="1. 一些基本的礼仪和细节问题："></a>1. 一些基本的礼仪和细节问题：</h4><p>（1）着装：技术性面试，也没必要正装，平常着装就可以。然后干净，利落就行。面试前可以洗个头吧，一是看着舒爽，另外醒醒盹🤣</p><p>（2）我面试的时候携带的东西：背包 + mac + 一只中性笔 + 几张A4白纸 + 简历（一些证书可带可不带）</p><p>（3）关于到达的时间：我一般提前30分钟到达面试地点，提前20分钟上楼。一是 预留 buffer 给堵车/找路等事情。二是填个表什么的。(这个看个人习惯，也不晓得对不对。)</p><p>（4）诚实， 不会的就说不会。都是搞技术的，也不会为难大家。另外像我有段考研的经历，我也都直接说出来了。不管他们怎么想。</p><h4 id="2-面试的体验："><a href="#2-面试的体验：" class="headerlink" title="2. 面试的体验："></a>2. 面试的体验：</h4><p>A 岗位：给了一道实际工作中应用场景写代码。然后问项目、问的挺细致的。【写出代码很重要， 这不仅决定你能不能接下来二面，甚至影响二面的印象】</p><p>B 岗位：问项目，挺细致的。 还问了一些基础的CPP和linux的内容。（该岗位面试体验很差，一方面有点为难人，我都说不会了，还一直问。另外一方面问了好多和岗位无关的知识）</p><p>C 岗位：做题，可能题目[linux基础+深度学习+Python/CPP]做的比较好。然后项目问了十分钟就差不多过了。【做出题目很关键】</p><p>D 岗位：问项目，之后过了三天打电话技术面（感觉问的挺粗,可能面试官不是做这个的，对我的项目也不是很清楚）。</p><p>E 岗位：直接问项目 + 上机写代码。【上机写代码很关键】</p><h4 id="3-面试的收获以及需要努力的地方："><a href="#3-面试的收获以及需要努力的地方：" class="headerlink" title="3. 面试的收获以及需要努力的地方："></a>3. 面试的收获以及需要努力的地方：</h4><p>（0）简历/自我介绍还是要准备好的， 感觉挺重要的。其实我的介绍的并不大好。</p><p>（1）写代码很关键。Python和C++都要熟悉，C++用的少了有点生疏了。导致E岗位的翻转列表都忘了怎么写了。(⊙﹏⊙)b 准备时间比较短，也没有去刷题，直接硬着头皮就上了。。</p><p>（2）项目要记得非常仔细，每一个细节，甚至之前的代码都要记住</p><p>（3）常见的面试范围：</p><ul><li>项目</li><li>(刷题)剑指 offer + leetcode + codewars(E面试官用的，哈哈，偷偷学来的)</li><li>机器学习 + 深度学习 基础</li><li>图像处理基础知识</li></ul><p>（4）有两三家公司对 高性能计算很感兴趣。我猜测是应为部署的时候DL太慢导致的。需要进行优化。其中有一家还问了caffe 中卷积的实现方案：im2col + 矩阵乘法。还好当年看看百度的MDL 时候去看了这个源码。</p><p>​     其实这方面也是我挺感兴趣的一个方面：常见并行方案有 MPI、OPENMP、SIMD、neon、CUDA —&gt; 需要好好学学 ncnn， 看看人家怎么写的DL interface。</p><p>（5）blog 和 github 还是要好好整整的，树立个人品牌很关键(Kaggle比赛、blog、github)，有几篇blog是想着好好学习一下的(心有余而力不足呀)：</p><ul><li><p>openmp</p></li><li><p>最近的anchor free的目标检测算法(膜一下 densebox)</p></li><li><p>ncnn 的优化方案</p></li></ul><p>（6） 有些面试官感觉的出来也不大懂你做的，因此项目中的共同的东西就要非常熟悉，比如：</p><p>​      网络中的backbone、一些衡量指标、loss设计、参数调整的过程、一些检测的方案（SSD/YOLO/R-CNN、anchor free or anchor based）要熟记。</p><p>（7）有些公司还是挺看重实践能力的，比如问了 CMakeLists 怎么写？ ncnn中怎么定义层？ 怎么优化代码？最后怎么提交成绩的(在共有数据集上，比如lfw上)？</p><h4 id="4-写一下其他的吧-吐槽-："><a href="#4-写一下其他的吧-吐槽-：" class="headerlink" title="4. 写一下其他的吧(吐槽)："></a>4. 写一下其他的吧(吐槽)：</h4><p>（1）有些面试通知中都没有写明地点? 那栋楼? 怎么走? —&gt; [某公司去到没找到(ABCDE栋/楼层都没写)，打了三遍电话才接通]</p><p>（2）有一家公司说了两个多小时，一口水都没给喝(我那个渴呀，以后可以自己带一瓶水吧)</p><p>（3）有家公司扔了一张试卷就走了，我半个小时就做完了，一个半小时之后他才回来(其实也不是他，另一个面试官面的)，期间出去找面试官两次没找到，不是发现该公司同事在玩手机，就是在走廊聊天， 甚者还在我做题的那个屋里办理银行卡，我真是见识了。对该公司印象极其差。</p><p>​    【有一家创业公司给我印象挺好，早上还给我发了面试提醒，HR还下楼去接的我，虽然没碰到】</p><p>（4）面试时不要害怕(面多了就好了，现在面试心情很轻松的)，进公司之后就是同事或者leader，面试官也一般不会为难面试者的。有一家公司面试官在我做题期间很细心的指导别人，给我留下很深刻的印象。</p><p>（5）面试也是一个双选的过程，感觉不好的公司尽量也不要去，免得最后不欢而散、</p><p>（6）也不要害怕谈薪资，按自己能力要即可。好吧，这方面我一直不在行。</p>]]></content>
    
    
    <categories>
      
      <category>其他</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>YOLO</title>
    <link href="/2019/04/23/YOLO/"/>
    <url>/2019/04/23/YOLO/</url>
    
    <content type="html"><![CDATA[<p>YOLO series: YOLO v1. YOLO v2 and. YOLO v3</p><a id="more"></a><h3 id="1-YOLO-v1"><a href="#1-YOLO-v1" class="headerlink" title="1. YOLO v1"></a>1. YOLO v1</h3><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>直接在输出层回归 bounding box 的位置和 bounding box所属的类别(整张图作为网络的输入，把 Object Detection 的问题转化成一个 Regression 问题)</p><h4 id="YOLO-v1-流程"><a href="#YOLO-v1-流程" class="headerlink" title="YOLO v1 流程"></a>YOLO v1 流程</h4><p><img src="/2019/04/23/YOLO/2.png" alt></p><ol><li><p>将图片Resize成448x448，分成7x7个网格(grid cell)，某个物体的中心落在这个网格中此网格就负责预测这个物体。</p></li><li><p>提取特征和预测，卷积部分负责提取特征。全连接部分负责预测：</p><ul><li>两个 【bounding box(bbox) + conﬁdence】 (2x5)</li><li>20个物体的概率（20）</li></ul><p>总的输出为 (7X7)X30 的维度。</p></li><li><p>过滤bbox（通过nms）</p></li></ol><h3 id="2-YOLO-v2"><a href="#2-YOLO-v2" class="headerlink" title="2. YOLO v2"></a>2. YOLO v2</h3><ol><li><p>class-specific confidence score：</p><p>class-specific confidence score 是三项的成绩。第一项是 bbox每个网格预测的类别信息即20个物体的概率， 第二项是每个 bbox 的置信度， 第三项是 ground truth 和 预测框的 IOU。得到每个bbox的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果</p></li><li><p>损失函数的设计：<br><img src="/2019/04/23/YOLO/1.png" alt></p></li></ol><h3 id="3-YOLOv3"><a href="#3-YOLOv3" class="headerlink" title="3. YOLOv3"></a>3. YOLOv3</h3><p>论文改进点</p><ul><li><p>BN + leaky ReLU + res connection[ 加入了BN层, 激活函数使用了Leaky ReLU, 并且引入了残差连接 ]</p></li><li><p>backbone(FPN multi scales)[ 仿照FPN网络结构的多尺度检测 ]</p></li><li><p>loss function [ 除了w、h仍然使用平方均差， 其他均使用交叉熵。然后按权重相加 ]</p></li><li><p>bbox anchor priors -&gt; softmax [ 聚类获得先验框大小 ]</p></li></ul><h5 id="1-YOLOv3-结构"><a href="#1-YOLOv3-结构" class="headerlink" title="(1) YOLOv3 结构"></a>(1) YOLOv3 结构</h5><p><img src="/2019/04/23/YOLO/3_1.png" alt></p><p>​    先使用 DBL (conv+bn+leaky_relu) 进行一个简单的滤波处理， 然后接res1, res2, res8 提取特征1, 再接 res8 提取特征2, 再接 res4 提取特征 3, 最后融合三个特征。</p><ul><li>相比于 YOLO V2 的 darknet19 采用 maxpool 进行下采样， YOLO V3 提出的 Darknet53 则使用 stride 为 2 的卷积核来实现下采样。在 YOLO v3 中， 要经历五次下采样， 特征图尺寸缩小为原来的 1/32， 即输入为 416 x 416, 输出为 13x13。</li></ul><p><img src="/2019/04/23/YOLO/3_2.png" alt="x" style="zoom:50%;"></p><ul><li><p>具体的细节实现上， <strong>darknet 19 的 conv + bn + relu 被替换为 conv + bn + leaky_relu</strong>。并在此基础上添加了残差结构。</p></li><li><p>三个输出分别是 13x13x255、26x26x255、52x52x255。yolo v3 输出了3个不同尺度的 feature map，YOLO v3 借鉴了 FPN(feature pyramid networks)，采用多尺度来对不同 size 的目标进行检测，越精细的 grid cell 就可以检测出越精细的物体。</p><p>255的来源 ? COCO 的类别数为 80， 加上位置信息 x, y, w, h 和 confidence 为 85。每个网格单元预测 3 个 box。 总共为 3 *( 80 + 5) = 255。</p></li></ul><h5 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="(2) 损失函数"></a>(2) 损失函数</h5><p>​     在 YOLO v3除了w、h 仍然使用平方均差， 其他 (x, y)、 class, confidence 均使用交叉熵，然后按权重相加，损失函数应该由各自特点确定。最后加到一起就可以组成最终的 loss_function 了，也就是一个loss_function搞定端到端的训练。</p><pre><code class="hljs cpp">xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[..., <span class="hljs-number">0</span>:<span class="hljs-number">2</span>], from_logits=True)wh_loss = object_mask * box_loss_scale * <span class="hljs-number">0.5</span> * K.square(raw_true_wh - raw_pred[..., <span class="hljs-number">2</span>:<span class="hljs-number">4</span>])confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., <span class="hljs-number">4</span>:<span class="hljs-number">5</span>], from_logits=True) + \                          (<span class="hljs-number">1</span> - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., <span class="hljs-number">4</span>:<span class="hljs-number">5</span>],                                                                    from_logits=True) * ignore_maskclass_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., <span class="hljs-number">5</span>:], from_logits=True)xy_loss = K.sum(xy_loss) / mfwh_loss = K.sum(wh_loss) / mfconfidence_loss = K.sum(confidence_loss) / mfclass_loss = K.sum(class_loss) / mfloss += xy_loss + wh_loss + confidence_loss + class_loss</code></pre><p>以上是一段 keras 框架描述的 yolo v3 的 loss_function 代码。忽略恒定系数不看，可以从上述代码看出：除了 w, h 的损失函数依然采用均方误差之外，其他部分的损失函数用的是交叉熵。最后加到一起。</p><h5 id="3-Bounding-Box-Prediction"><a href="#3-Bounding-Box-Prediction" class="headerlink" title="(3) Bounding Box Prediction"></a>(3) Bounding Box Prediction</h5><p>​    对于YOLO v3 而言，在 prior 这里的处理有明确解释：选用的 bbox priors 的 k=9，对于 tiny-yolo 的话，k = 6。priors 都是在数据集上聚类得来的，有确定的数值，如下:</p><pre><code class="hljs cpp"><span class="hljs-number">10</span>,<span class="hljs-number">13</span>,  <span class="hljs-number">16</span>,<span class="hljs-number">30</span>,  <span class="hljs-number">33</span>,<span class="hljs-number">23</span>,  <span class="hljs-number">30</span>,<span class="hljs-number">61</span>,  <span class="hljs-number">62</span>,<span class="hljs-number">45</span>,  <span class="hljs-number">59</span>,<span class="hljs-number">119</span>,  <span class="hljs-number">116</span>,<span class="hljs-number">90</span>,  <span class="hljs-number">156</span>,<span class="hljs-number">198</span>,  <span class="hljs-number">373</span>,<span class="hljs-number">326</span></code></pre><p>​    每个 anchor prior 就是两个数字组成的，一个代表高度另一个代表宽度。 v3对b-box进行预测的时候，采用了logistic regression。输出和v2一样都是 (t_x, t_y, t_w, t_h, t_o)，然后通过公式1计算出绝对的 (x, y, w, h, c) 。</p><p><img src="/2019/04/23/YOLO/3_7.png" alt="c" style="zoom:50%;"></p><p>​    logistic回归用于对anchor包围的部分进行一个目标性评分(objectness score)，即这块位置是目标的可能性有多大。这一步是在predict之前进行的，可以去掉不必要anchor，可以减少计算量。</p><h3 id="4-YOLOv4"><a href="#4-YOLOv4" class="headerlink" title="4. YOLOv4"></a>4. YOLOv4</h3><h3 id="5-YOLOv5"><a href="#5-YOLOv5" class="headerlink" title="5. YOLOv5"></a>5. YOLOv5</h3><h3 id="6-PP-YOLO"><a href="#6-PP-YOLO" class="headerlink" title="6. PP-YOLO"></a>6. PP-YOLO</h3><h3 id="7-Bag-of-Freebies"><a href="#7-Bag-of-Freebies" class="headerlink" title="7. Bag of Freebies"></a>7. Bag of Freebies</h3><p>论文《Bag of Freebies for Training Object Detection Neural Networks》提炼了目标检测算法通用训练 tricks，论文说是 Bag of Freebies，并且更倾向于对 One-stage 系列优化，one-stage 计算量更小，在落地上更为普遍。</p><h3 id="二、目标检测训练Tricks"><a href="#二、目标检测训练Tricks" class="headerlink" title="二、目标检测训练Tricks"></a><strong>二、目标检测训练Tricks</strong></h3><p>  论文[1]总共提到了六种通用的训练Tricks，其中有几种在yolov3原始算法中都有用到，所以说不得不承认yolo系列是非常优秀的目标检测算法。具体为</p><p>1、Visually Coherent Image Mixup for Object Detection (mixup数剧增强,借鉴文[2])</p><p> 与[2]原始的mixup不同点有两点：</p><p>1）文[2]提出的mixup数据增强是一种有特色方法，但是实验对象是分类与对抗生成网络，成对图像的mixup是以resize到相同大小的图像为前提完成的。</p><p>​            <img src="https://img-blog.csdnimg.cn/20190320130541830.png" alt="img"></p><p>  目标检测问题中如果resize图像到相同大小则会造成图像畸变，检测任务对于这种变化较为敏感，因此作者采用保图像几何形状的方式对图像进行mixup,我的理解是图像直接mixup成对图像，取最大宽高并填充（constant合成的空白区域），最后计算损失时按照mixup的beta分布产生的权重，对损失进行加权求和，再反向传播loss更新模型权重。</p><p><img src="https://img-blog.csdnimg.cn/20190320130542430.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L291eWFuZ2Z1c2h1,size_16,color_FFFFFF,t_70" alt="img"></p><p>2）文[2]的mixup方法中成对图像求加权和的权重是由Beta分布随机生成（Beta分布如图），Beta的两个参数默认取值1.0（源码），原始mixup论文[2]试验则是从0.2到1.0的几组试验值，论文[1]采用的Beta分布两个参数则是取值大于等于1，在实验中Beta分布的参数值取1.5时效果更好，涨点明显：</p><p>​                    <img src="https://img-blog.csdnimg.cn/20190320130541559.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L291eWFuZ2Z1c2h1,size_16,color_FFFFFF,t_70" alt="img">。</p><p>​                     <img src="https://img-blog.csdnimg.cn/20190320130541720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L291eWFuZ2Z1c2h1,size_16,color_FFFFFF,t_70" alt="img"></p><h5 id="4-标签平滑-label-smoothing"><a href="#4-标签平滑-label-smoothing" class="headerlink" title="4. 标签平滑 label smoothing"></a>4. 标签平滑 label smoothing</h5><p>label  smoothing 个人感觉则是对标签放松处理（改变类别的分布），使得目标函数不至于太严格，降低不同类别的置信度，一定程度上使得模型更易于收敛且能避免模型过拟合（over fitting）。对目标类别的 Ground Truth 做如下处理，对原始标签乘上一个小于 1 且接近于 1 的数，再加上一个类似正则项的东东，其实也就是一种对目标函数做的正则化处理。</p><p>​                         <img src="https://img-blog.csdnimg.cn/20190320130540863.png" alt="img"></p><p>  其中，K 为类别数目，分子为小正数， 一般取 0.1 。具体的描述可以参看论文[3]。</p><pre><code class="hljs python"><span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> train_loader:    ...    N = labels.size(<span class="hljs-number">0</span>)    <span class="hljs-comment"># C is the number of classes.</span>    smoothed_labels = torch.full(size=(N, C), fill_value = <span class="hljs-number">0.1</span> / (C - <span class="hljs-number">1</span>)).cuda()    smoothed_labels.scatter_(dim=<span class="hljs-number">1</span>, index=torch.unsqueeze(labels, dim=<span class="hljs-number">1</span>), value=<span class="hljs-number">0.9</span>)        ...</code></pre><h5 id="5-数据预处理-Data-Preprocessing"><a href="#5-数据预处理-Data-Preprocessing" class="headerlink" title="5. 数据预处理  Data Preprocessing"></a>5. 数据预处理  Data Preprocessing</h5><p>文章着重评估了常见的图像增强方法:</p><ul><li>几何变换：随机裁剪、随机扩张、随机水平翻转、随机 resize</li><li>颜色抖动：亮度、色调、曝光度、对比度调整</li></ul><h5 id="6-Training-Scheduler-Revamping（训练策略改进）"><a href="#6-Training-Scheduler-Revamping（训练策略改进）" class="headerlink" title="6. Training Scheduler Revamping（训练策略改进）"></a>6. Training Scheduler Revamping（训练策略改进）</h5><p>这里主要采用的方案是： warmup + cosine schedule</p><h5 id="7-Synchronized-Batch-Normalization"><a href="#7-Synchronized-Batch-Normalization" class="headerlink" title="7. Synchronized Batch Normalization"></a>7. Synchronized Batch Normalization</h5><p>  这个策略是针对土豪提的，对于大规模数据集的多卡训练，Batch会被分割成很多小部分（小 Batch）在不同的显卡，这样实际上虽然加速了训练，但是Batch却变小了，可能会限制Batch Normalization的作用，与大Batch训练的初衷向左。对于分类问题可能影响不到，但是对于对Batch敏感的目标检测任务则影响很大。基于此采用Synchronized Batch Normalization。</p><h5 id="8、Random-shapes-training-for-single-stage-object-detection-networks-多尺度训练"><a href="#8、Random-shapes-training-for-single-stage-object-detection-networks-多尺度训练" class="headerlink" title="8、Random shapes training for single-stage object detection networks  多尺度训练"></a>8、Random shapes training for single-stage object detection networks  多尺度训练</h5><p>在训练的过程中， 每隔一定的 iterations 就改变训练图片的尺度，这样做可以实现跨尺度特征融合，也能使得模型在多种输入大小下训练以适应不同的图像大小输入。这样做也可以使得模型不容易过拟合以增强泛化性能。</p><h3 id="8-YOLO-的轻量级改进型"><a href="#8-YOLO-的轻量级改进型" class="headerlink" title="8. YOLO 的轻量级改进型"></a>8. YOLO 的轻量级改进型</h3>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>recent convolutions</title>
    <link href="/2019/04/21/recent-convolutions/"/>
    <url>/2019/04/21/recent-convolutions/</url>
    
    <content type="html"><![CDATA[<p>octave conv(octconv)、hetconv、res2net</p><a id="more"></a><h3 id="1-octave-conv"><a href="#1-octave-conv" class="headerlink" title="1. octave conv"></a>1. octave conv</h3><h5 id="Paper"><a href="#Paper" class="headerlink" title="Paper:"></a>Paper:</h5><p>Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution</p><h5 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation:"></a>Motivation:</h5><p>如下图所示：（a）自然图像可以被分解为高频部分和低频部分。高频分量表达细节，低频分量表达整体。很显然，低频分量是存在冗余的，在编码过程中可以节省。(b) 卷积层的输出通道也是如此，可以被分解为低频分量和高频分量并进行重组。（c）作者将低频分量的通道大小设置为高频分量通道大小的一半，用来减少冗余。(d) 低频部分和高频部分可以各自更新，并进行通道之间的交流。</p><p><img src="/2019/04/21/recent-convolutions/1.png" alt></p><h5 id="mothods"><a href="#mothods" class="headerlink" title="mothods"></a>mothods</h5><p>作者提出了 conv 的改进版 OctConv 用来降低低频部分的冗余度。 Octconv 的结构如下所示：</p><p><img src="/2019/04/21/recent-convolutions/2.png" alt></p><p>当在第一个 OctConv 是 $\alpha_{in} = 0$，此时执行 ①② 两个操作。</p><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.type == <span class="hljs-string">&#x27;first&#x27;</span>:    <span class="hljs-keyword">return</span> self.H2H(x), self.H2L(self.avg_pool(x))<span class="hljs-comment"># H2H、L2H 均为传统卷积</span></code></pre><p>当在最后一个 OctConv 中 $\alpha_{out} = 0$， 此时执行 ①③ 两个操作。</p><pre><code class="hljs python"><span class="hljs-keyword">if</span> self.type == <span class="hljs-string">&#x27;last&#x27;</span>:    hf, lf = x    <span class="hljs-keyword">return</span> self.H2H(hf) + self.L2H(self.upsample(lf))<span class="hljs-comment"># H2H、L2H 均为传统卷积</span></code></pre><p>当其他情况时，执行 ①②③④四个操作</p><pre><code class="hljs python"><span class="hljs-keyword">else</span>：    hf, lf = x    <span class="hljs-keyword">return</span> self.H2H(hf) + self.upsample(self.L2H(lf)),            self.L2L(lf) + self.H2L(self.avg_pool(hf))<span class="hljs-comment"># L2H、L2L、H2H、H2L 均为传统卷积</span></code></pre><p>octconv 整体的实现代码如下所示：</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">OctConv</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, </span></span><span class="hljs-function"><span class="hljs-params">             alpha_in=<span class="hljs-number">0.25</span>, alpha_out=<span class="hljs-number">0.25</span>, type=<span class="hljs-string">&#x27;normal&#x27;</span></span>):</span>        super(OctConv, self).__init__()        self.kernel_size = kernel_size        self.stride = stride        self.type = type        hf_in = int(in_channels * (<span class="hljs-number">1</span> - alpha_in))        hf_out = int(out_channels * (<span class="hljs-number">1</span> - alpha_out))        lf_in = in_channels - hf_in        lf_out = out_channels - hf_out        <span class="hljs-keyword">if</span> stride == <span class="hljs-number">2</span>:            self.downsample = nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=stride)        <span class="hljs-keyword">if</span> type == <span class="hljs-string">&#x27;first&#x27;</span>:            self.H2H = nn.Conv2d(in_channels, hf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.H2L = nn.Conv2d(in_channels, lf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.avg_pool = nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)        <span class="hljs-keyword">elif</span> type == <span class="hljs-string">&#x27;last&#x27;</span>:            self.H2H = nn.Conv2d(hf_in, out_channels, kernel_size=kernel_size, padding=padding)            self.L2H = nn.Conv2d(lf_in, out_channels, kernel_size=kernel_size, padding=padding)            self.upsample = partial(F.interpolate, scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&quot;nearest&quot;</span>)        <span class="hljs-keyword">else</span>:            self.L2L = nn.Conv2d(lf_in, lf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.L2H = nn.Conv2d(lf_in, hf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.H2L = nn.Conv2d(hf_in, lf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.H2H = nn.Conv2d(hf_in, hf_out, kernel_size=kernel_size, stride=<span class="hljs-number">1</span>, padding=padding)            self.upsample = partial(F.interpolate, scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&quot;nearest&quot;</span>)            self.avg_pool = partial(F.avg_pool2d, kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        <span class="hljs-keyword">if</span> self.type == <span class="hljs-string">&#x27;first&#x27;</span>:            <span class="hljs-keyword">if</span> self.stride == <span class="hljs-number">2</span>:                x = self.downsample(x)            <span class="hljs-keyword">return</span> self.H2H(x), self.H2L(self.avg_pool(x))        <span class="hljs-keyword">elif</span> self.type == <span class="hljs-string">&#x27;last&#x27;</span>:            hf, lf = x            <span class="hljs-keyword">if</span> self.stride == <span class="hljs-number">2</span>:                hf = self.downsample(hf)                <span class="hljs-keyword">return</span> self.H2H(hf) + self.L2H(lf)            <span class="hljs-keyword">else</span>:                <span class="hljs-keyword">return</span> self.H2H(hf) + self.L2H(self.upsample(lf))        <span class="hljs-keyword">else</span>:            hf, lf = x            <span class="hljs-keyword">if</span> self.stride == <span class="hljs-number">2</span>:                hf = self.downsample(hf)                <span class="hljs-keyword">return</span> self.H2H(hf) + self.L2H(lf), self.L2L(self.avg_pool(lf)) + self.H2L(self.avg_pool(hf))            <span class="hljs-keyword">else</span>:                <span class="hljs-keyword">return</span> self.H2H(hf) + self.upsample(self.L2H(lf)), self.L2L(lf) + self.H2L(self.avg_pool(hf))</code></pre><h3 id="2-res2net"><a href="#2-res2net" class="headerlink" title="2. res2net"></a>2. res2net</h3><h5 id="Paper-1"><a href="#Paper-1" class="headerlink" title="Paper:"></a>Paper:</h5><p>Res2Net: A New Multi-scale Backbone Architecture</p><h5 id="Methods"><a href="#Methods" class="headerlink" title="Methods:"></a>Methods:</h5><p>作者提出了一种在更加细粒度(卷积层)的层面提升多尺度表达能力。其基本结构如下图(b) 所示：</p><p><img src="/2019/04/21/recent-convolutions/3.png" alt></p><p>传统的resnet结构如上图所示，作者在其基础上进行改进，在不增加计算量的同时，使其具备更强的多尺度提取能力。如上图（b）所示，作者采用了更小的卷积组来替代 bottleneck block 里面的 3x3 卷积。具体操作为：</p><ul><li>首先将 1x1 卷积后的特征图均分为 s 个特征图子集。每个特征图子集的大小相同，但是通道数是输入特征图的 1/s。</li><li>对每一个特征图子集 $X<em>i$，有一个对应的 3x3 卷积 $K_i$ , 假设 $K_i$的输出是 $y_i$。接下来每个特征图子集 $X_i $会加上 $K</em>{i-1}$ 的输出，然后一起输入进 $K_i$。为了在增大 s 的值时减少参数量，作者省去了 $X_1$ 的 3x3 网络。因此，输出 $y_i$ 可以用如下公式表示：</li></ul><script type="math/tex; mode=display">y_i = \begin{equation}\begin{cases}x_i && i=1;\\K_i(x_i+y_{i-1}) && 1 < i \leq s.\end{cases}\end{equation}</script><p>根据图(b)，可以发现每一个 $X_j (j&lt;=i)$ 下的 3x3 卷积可以利用之前所有的特性信息，它的输出会有比 $X_j$ 更大的感受野。因此这样的组合可以使 Res2Net 的输出有更多样的感受野信息。为了更好的融合不同尺度的信息，作者将它们的输出拼接起来，然后再送入 1x1 卷积，如上图（b）所示。</p><p>res2Net module 的实现代码如下所示：</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Res2NetBottleneck</span>(<span class="hljs-params">nn.Module</span>):</span>   expansion = <span class="hljs-number">4</span>   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, downsample=None, stride=<span class="hljs-number">1</span>, scales=<span class="hljs-number">4</span>, groups=<span class="hljs-number">1</span>, se=False, norm_layer=None</span>):</span>       super(Res2NetBottleneck, self).__init__()       <span class="hljs-keyword">if</span> out_channels % scales != <span class="hljs-number">0</span>:           <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Planes must be divisible by scales&#x27;</span>)       <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:           norm_layer = nn.BatchNorm2d                  <span class="hljs-comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span>       self.conv1 = conv1x1(in_channels, out_channels, stride)       self.bn1 = norm_layer(out_channels)       self.conv2 = nn.ModuleList([conv3x3(out_channels // scales, out_channels // scales, groups=groups) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(scales<span class="hljs-number">-1</span>)])       self.bn2 = nn.ModuleList([norm_layer(out_channels // scales) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(scales<span class="hljs-number">-1</span>)])       self.conv3 = conv1x1(out_channels, out_channels * self.expansion)       self.bn3 = norm_layer(out_channels * self.expansion)       self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)       self.downsample = downsample       self.stride = stride       self.scales = scales   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>       identity = x              out = self.relu(self.bn1(self.conv1(x)))       xs = torch.chunk(out, self.scales, <span class="hljs-number">1</span>)       ys = []       <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> range(self.scales):           <span class="hljs-keyword">if</span> s == <span class="hljs-number">0</span>:               ys.append(xs[s])           <span class="hljs-keyword">elif</span> s == <span class="hljs-number">1</span>:               ys.append(self.relu(self.bn2[s<span class="hljs-number">-1</span>](self.conv2[s<span class="hljs-number">-1</span>](xs[s]))))           <span class="hljs-keyword">else</span>:               ys.append(self.relu(self.bn2[s<span class="hljs-number">-1</span>](self.conv2[s<span class="hljs-number">-1</span>](xs[s] + ys[<span class="hljs-number">-1</span>]))))       out = torch.cat(ys, <span class="hljs-number">1</span>)       out = self.bn3(self.conv3(out))              <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:           identity = self.downsample(identity)       <span class="hljs-keyword">return</span> self.relu(out + identity)</code></pre><h3 id="3-Hetconv"><a href="#3-Hetconv" class="headerlink" title="3. Hetconv"></a>3. Hetconv</h3><h5 id="Paper："><a href="#Paper：" class="headerlink" title="Paper："></a>Paper：</h5><p>HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs</p><h5 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods:"></a>Methods:</h5><p>本文提出了一种高效的异构卷积过滤器(一些核的大小是 3x3， 其余的是1x1)，相较于 mobilenet的原始的 depthwise conv，能在不牺牲准确度的同时提升这些架构的效率。实现的方案很简单， 将传统卷积进行改进，对于某一个卷积，只有1/p个通道 使用 3x3 的卷积，其余均使用 1x1卷积，然后将所有通道相加，作为一个输出通道。</p><p>Hexconv module 的实现代码如下所示</p><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">HetConv</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, p=<span class="hljs-number">2</span></span>):</span>        super(HetConv, self).__init__()        <span class="hljs-keyword">if</span> in_channels % groups != <span class="hljs-number">0</span>:            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;in_channels must be divisible by groups&#x27;</span>)        self.in_channels = in_channels        self.out_channels = out_channels        self.blocks = nn.ModuleList()        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(out_channels):            self.blocks.append(self._make_hetconv_layer(i, p))    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">_make_hetconv_layer</span>(<span class="hljs-params">self, n, p</span>):</span>        layers = nn.ModuleList()        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(self.in_channels):            <span class="hljs-keyword">if</span> ((i - n) % (p)) == <span class="hljs-number">0</span>:                layers.append(nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))            <span class="hljs-keyword">else</span>:                layers.append(nn.Conv2d(in_channels=<span class="hljs-number">1</span>, out_channels=<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>))        <span class="hljs-keyword">return</span> layers    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        out = []        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, self.out_channels):            out_ = self.blocks[i][<span class="hljs-number">0</span>](x[:, <span class="hljs-number">0</span>: <span class="hljs-number">1</span>, :, :])            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, self.in_channels):               out_ += self.blocks[i][j](x[:, j:j + <span class="hljs-number">1</span>, :, :])            out.append(out_)        <span class="hljs-keyword">return</span> torch.cat(out, <span class="hljs-number">1</span>)</code></pre><h3 id="三种卷积的构造方式总结："><a href="#三种卷积的构造方式总结：" class="headerlink" title="三种卷积的构造方式总结："></a>三种卷积的构造方式总结：</h3><p><img src="/2019/04/21/recent-convolutions/4.png" alt></p><ol><li>三种卷积均在输入通道进行改进，前两种方案(res2net、octconv)都进行了特征通道的融合。但是第一种方案对硬件并不友好(没有进行试验的验证)。第三种方案可以看做是传统卷积的改善，将其中的某些通道设置为3x3，其他通道设置为1x1卷积。</li><li>常见的多尺度的获取方式：<ul><li>细粒度卷积(res2net方式)</li><li>NIN(例如 Inception 样式的卷积也可以)</li><li>多尺度图像输出(图像金字塔)</li><li>特征多尺度(融合多个尺度的特征图：FPN网络)</li><li>空间金字塔池化(Spatial Pyramid Pooling)</li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>receptive_size_and_anchor_design</title>
    <link href="/2019/04/21/receptive-size-and-anchor-design/"/>
    <url>/2019/04/21/receptive-size-and-anchor-design/</url>
    
    <content type="html"><![CDATA[<p>octave conv(octconv)、hetconv、res2net</p><a id="more"></a><h3 id="1-感受野的计算："><a href="#1-感受野的计算：" class="headerlink" title="1. 感受野的计算："></a>1. 感受野的计算：</h3><pre><code class="hljs python"><span class="hljs-comment"># [kernel_size, stride, padding]</span>convnet =   [[<span class="hljs-number">11</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">5</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>], [<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]]layer_names = [<span class="hljs-string">&#x27;conv1&#x27;</span>,<span class="hljs-string">&#x27;pool1&#x27;</span>,<span class="hljs-string">&#x27;conv2&#x27;</span>,<span class="hljs-string">&#x27;pool2&#x27;</span>,<span class="hljs-string">&#x27;conv3&#x27;</span>,<span class="hljs-string">&#x27;conv4&#x27;</span>,<span class="hljs-string">&#x27;conv5&#x27;</span>,<span class="hljs-string">&#x27;pool5&#x27;</span>]input image: receptive size: <span class="hljs-number">1</span> conv1: receptive size: <span class="hljs-number">11</span>  pool1: receptive size: <span class="hljs-number">19</span>  conv2: receptive size: <span class="hljs-number">51</span>pool2: receptive size: <span class="hljs-number">67</span>conv3: receptive size: <span class="hljs-number">99</span>conv4: receptive size: <span class="hljs-number">131</span>conv5: receptive size: <span class="hljs-number">163</span>pool5: receptive size: <span class="hljs-number">195</span></code></pre><h5 id="1-反向推导："><a href="#1-反向推导：" class="headerlink" title="(1) 反向推导："></a>(1) <strong>反向推导</strong>：</h5><ul><li>初始(最后) $feature map$ 层的感受野是1。</li><li>每经过一层 kernel<em>size为 k, 步长为 s的卷积/池化层，感受野 $r</em>{l} = r \times s + (k-s) = (r_{l+1} -1) \times s + k$ 。</li><li>经过多分支的路径，按照感受野最大支路计算。</li><li>不会改变感受野的情况: conv1x1 s1、ReLU、BN、dropout、shotcut等元素级操作。</li><li>经过FC层和Gobal Ave Pooling 层，感受野就是整个输入图像。</li></ul><pre><code class="hljs angelscript">以 pool5 为例：Pool5: (<span class="hljs-number">1</span><span class="hljs-number">-1</span>)*<span class="hljs-number">2</span> + <span class="hljs-number">3</span> = <span class="hljs-number">3</span>Conv5: (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">1</span> + <span class="hljs-number">3</span> = <span class="hljs-number">5</span>Conv4: (<span class="hljs-number">5</span><span class="hljs-number">-1</span>)*<span class="hljs-number">1</span> + <span class="hljs-number">3</span> =  <span class="hljs-number">7</span>Conv3:(<span class="hljs-number">7</span><span class="hljs-number">-1</span>)*<span class="hljs-number">1</span> + <span class="hljs-number">3</span> = <span class="hljs-number">9</span>pool2: (<span class="hljs-number">9</span><span class="hljs-number">-1</span>)*<span class="hljs-number">2</span> + <span class="hljs-number">3</span> = <span class="hljs-number">19</span>Conv2: (<span class="hljs-number">19</span><span class="hljs-number">-1</span>)*<span class="hljs-number">1</span> + <span class="hljs-number">5</span>  = <span class="hljs-number">23</span>Pool1： (<span class="hljs-number">23</span><span class="hljs-number">-1</span>)*<span class="hljs-number">2</span> + <span class="hljs-number">3</span> = <span class="hljs-number">47</span>Conv1: (<span class="hljs-number">47</span><span class="hljs-number">-1</span>)*<span class="hljs-number">4</span> + <span class="hljs-number">11</span> = <span class="hljs-number">195</span></code></pre><h5 id="2-正向推导"><a href="#2-正向推导" class="headerlink" title="(2) 正向推导"></a>(2) 正向推导</h5><p>和反向推导相似， $s_0 = 1$,  $feature_map$ 的感受野为1。</p><script type="math/tex; mode=display">\begin{eqnarray}&& r_{l+1} = r_l + (k-1) * s_l \\&& s_{l+1} = s_{l} * s \\\end{eqnarray}</script><pre><code class="hljs python">以 pool5 为例：Conv1: <span class="hljs-number">1</span> + (<span class="hljs-number">11</span><span class="hljs-number">-1</span>)*<span class="hljs-number">1</span> =  <span class="hljs-number">11</span>, s1=<span class="hljs-number">1</span>*<span class="hljs-number">4</span>=<span class="hljs-number">4</span>   <span class="hljs-comment"># [11,4,0]</span>Pool1: <span class="hljs-number">11</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">4</span> = <span class="hljs-number">19</span>, s2=<span class="hljs-number">4</span>*<span class="hljs-number">2</span>=<span class="hljs-number">8</span>   <span class="hljs-comment"># [3,2,0]</span>Conv2: <span class="hljs-number">19</span> + (<span class="hljs-number">5</span><span class="hljs-number">-1</span>)*<span class="hljs-number">8</span> = <span class="hljs-number">51</span>, s3=<span class="hljs-number">8</span>*<span class="hljs-number">1</span>=<span class="hljs-number">8</span>  <span class="hljs-comment"># [5,1,2]</span>pool2: <span class="hljs-number">51</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">8</span> = <span class="hljs-number">67</span>, s4=<span class="hljs-number">8</span>*<span class="hljs-number">2</span>=<span class="hljs-number">16</span> <span class="hljs-comment"># [3,2,0]</span>Conv3: <span class="hljs-number">67</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">16</span> = <span class="hljs-number">99</span>, s5=<span class="hljs-number">16</span>*<span class="hljs-number">1</span>=<span class="hljs-number">16</span>  <span class="hljs-comment"># [3，1，1]</span>Conv4: <span class="hljs-number">99</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">16</span> = <span class="hljs-number">131</span>， s6=<span class="hljs-number">16</span>*<span class="hljs-number">1</span>=<span class="hljs-number">16</span> <span class="hljs-comment"># [3，1，1]</span>Conv5: <span class="hljs-number">131</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">16</span> = <span class="hljs-number">163</span>, s7=<span class="hljs-number">16</span>*<span class="hljs-number">1</span>=<span class="hljs-number">16</span> <span class="hljs-comment"># [3, 1, 1]</span>Pool5: <span class="hljs-number">163</span> + (<span class="hljs-number">3</span><span class="hljs-number">-1</span>)*<span class="hljs-number">16</span> = <span class="hljs-number">195</span>, s8=<span class="hljs-number">16</span>*<span class="hljs-number">2</span>=<span class="hljs-number">32</span> <span class="hljs-comment"># [3, 2, 0]</span></code></pre><p>[<a href="https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807">https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807</a>]</p><p>[<a href="https://fomoro.com/projects/project/receptive-field-calculator">https://fomoro.com/projects/project/receptive-field-calculator</a>]</p><h3 id="2-卷积的有效感受野"><a href="#2-卷积的有效感受野" class="headerlink" title="2. 卷积的有效感受野"></a>2. 卷积的有效感受野</h3><p>上文所述的是理论感受野，而特征的有效感受野（实际起作用的感受野）实际上是远小于理论感受野的，如下图所示。具体数学分析比较复杂，不再赘述，感兴趣的话可以参考论文 [Understanding the Effective Receptive Field in Deep Convolutional Neural Networks]。</p><p><img src="/2019/04/21/receptive-size-and-anchor-design/effective_receptive.jpg" alt="有效感受野示例"></p><p>​    下面我从直观上解释一下有效感受野背后的原因。以一个两层 <img src="https://www.zhihu.com/equation?tex=kernel%5C_size%3D3" alt="kernel\_size=3">， <img src="https://www.zhihu.com/equation?tex=stride%3D1" alt="stride=1">的网络为例，该网络的理论感受野为5，计算流程可以参加下图。其中 <img src="https://www.zhihu.com/equation?tex=x" alt="x"> 为输入， <img src="https://www.zhihu.com/equation?tex=w" alt="w"> 为卷积权重， <img src="https://www.zhihu.com/equation?tex=o" alt="o"> 为经过卷积后的输出特征。</p><p>​    很容易可以发现， <img src="https://www.zhihu.com/equation?tex=x_%7B1%2C1%7D" alt="x_{1,1}"> 只影响第一层feature map中的 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E1" alt="o_{1,1}^1"> ；而 <img src="https://www.zhihu.com/equation?tex=x_%7B3%2C3%7D" alt="x_{3,3}"> 会影响第一层feature map中的所有特征，即 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E1%2Co_%7B1%2C2%7D%5E1%2Co_%7B1%2C3%7D%5E1%2Co_%7B2%2C1%7D%5E1%2Co_%7B2%2C2%7D%5E1%2Co_%7B2%2C3%7D%5E1%2Co_%7B3%2C1%7D%5E1%2Co_%7B3%2C2%7D%5E1%2Co_%7B3%2C3%7D%5E1" alt="o_{1,1}^1,o_{1,2}^1,o_{1,3}^1,o_{2,1}^1,o_{2,2}^1,o_{2,3}^1,o_{3,1}^1,o_{3,2}^1,o_{3,3}^1"> 。第一层的输出全部会影响第二层的 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E2" alt="o_{1,1}^2"> 。于是 <img src="https://www.zhihu.com/equation?tex=x_%7B1%2C1%7D" alt="x_{1,1}"> 只能通过 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E1" alt="o_{1,1}^1"> 来影响 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E2" alt="o_{1,1}^2"> ；而 <img src="https://www.zhihu.com/equation?tex=x_%7B3%2C3%7D" alt="x_{3,3}"> 能通过 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E1%2Co_%7B1%2C2%7D%5E1%2Co_%7B1%2C3%7D%5E1%2Co_%7B2%2C1%7D%5E1%2Co_%7B2%2C2%7D%5E1%2Co_%7B2%2C3%7D%5E1%2Co_%7B3%2C1%7D%5E1%2Co_%7B3%2C2%7D%5E1%2Co_%7B3%2C3%7D%5E1" alt="o_{1,1}^1,o_{1,2}^1,o_{1,3}^1,o_{2,1}^1,o_{2,2}^1,o_{2,3}^1,o_{3,1}^1,o_{3,2}^1,o_{3,3}^1"> 来影响 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E2" alt="o_{1,1}^2"> 。显而易见，虽然 <img src="https://www.zhihu.com/equation?tex=x_%7B1%2C1%7D" alt="x_{1,1}"> 和 <img src="https://www.zhihu.com/equation?tex=x_%7B3%2C3%7D" alt="x_{3,3}"> 都位于第二层特征感受野内，但是二者对最后的特征 <img src="https://www.zhihu.com/equation?tex=o_%7B1%2C1%7D%5E2" alt="o_{1,1}^2"> 的影响却大不相同，输入中越靠感受野中间的元素对特征的贡献越大。</p><p><img src="/2019/04/21/receptive-size-and-anchor-design/123.png" alt></p><h3 id="3-anchor-设计原则："><a href="#3-anchor-设计原则：" class="headerlink" title="3. anchor 设计原则："></a>3. anchor 设计原则：</h3><p>anchor的本质是特征层的map，这和传统cv中的滑动窗口并无二致。我们的目标是生成更好的窗口去匹配bbox。faster rcnn 是通过CNN 来自动生成 anchor，利用了 CNN 自动提取特征的能力。</p><p>anchor 设计原则：</p><p>(1) anchor 的尺寸、长宽比、位置都应该 match 源数据中的bbox。一种方法是针对特定数据集设计anchor，如YOLOv2中的聚类，和近期有论文CNN训练anchor的设置，这些方法或许更适合某一数据集，但也可能影响模型的泛化能力，换一个库是否依然够用。</p><p>(2) anchor 的 size 必须小于感受野</p><p>(3) 不同size的anchor应当具有相同的空间密度分布。密度一致的话，要求 anchor/stride 为一个定值。</p><p>下面以人脸检测为例，来分析 anchor 的设计：</p><p>（1）MSFD 中通过分析 WIDER Face 中人脸的范围，进而将 anchor 的尺寸设定为 </p><p>16/32/64/128/256/512 这些范围，从而覆盖不同尺寸的人脸。anchors’ aspect ratio 则设定为1: 1.5 。这是考虑到人脸的形状宽高比为 1.5 这一事实。</p><p>(2) S3FD 中提出的两条设计原则。我们看到 anchor 小于感受野，大约为感受野的 1/4， stride 则均为 anchor 的 1/4。这保证了anchor 的密度一致。</p><p><img src="/2019/04/21/receptive-size-and-anchor-design/rf.png" alt></p><p>我们来看Faceboxes中的anchor 设计：</p><p><img src="/2019/04/21/receptive-size-and-anchor-design/anchor.png" alt></p><p>这里 32 和 64 的anchor 密度为1和2，小于其他的密度4，所以通过对 32 复制4次，对64 复制两次来使anchor 密度一致。</p><p>[1]SSD:Single Shot MultiBox Detector</p><p>[2] YOLOv3: An Incremental Improvement</p><p>[3]FPN: feature pyramid networks for object detection </p><p>[4] A practical theory for designing very deep convolutional neural networks</p><p>[5] S3FD: Single Shot Scale-invariant Face Detector</p><p>[6] FaceBoxes: A CPU Real-time Face Detector with High Accuracy</p><p>[7] <a href="https://medium.com/@andersasac/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9">https://medium.com/@andersasac/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9</a></p><p>[8] <a href="https://www.reddit.com/r/MachineLearning/comments/7giwk1/d_is_anchor_necessary_for_object_detection/">https://www.reddit.com/r/MachineLearning/comments/7giwk1/d_is_anchor_necessary_for_object_detection/</a></p><p>[9] <a href="https://zhuanlan.zhihu.com/p/55824651">https://zhuanlan.zhihu.com/p/55824651</a></p>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GCN</title>
    <link href="/2019/04/20/GCN/"/>
    <url>/2019/04/20/GCN/</url>
    
    <content type="html"><![CDATA[<p>GCN tutorial</p><a id="more"></a><h4 id="1-基本的传播规则"><a href="#1-基本的传播规则" class="headerlink" title="1. 基本的传播规则"></a>1. 基本的传播规则</h4><p><img src="/2019/04/20/GCN/1.png" alt></p><p>在开始前先说明几个符号的含义：</p><ol><li>$N = 1,2,3,…,n$ 代表所有节点。</li><li>$X$ 代表所有节点的特征， 其中  $X_i$ 代表节点 $i$ 的特征。</li><li>$A$  代表邻接矩阵，其中 $A_{ij}$ 代表节点 $i$ 和 节点 $j$ 之间的边的权， 如果无权图则为 0 或者 1。</li></ol><h5 id="1-简单传播（平均）："><a href="#1-简单传播（平均）：" class="headerlink" title="1. 简单传播（平均）："></a>1. 简单传播（平均）：</h5><script type="math/tex; mode=display">f(X，A) = AX</script><p>简单传播的问题：</p><ul><li>节点的聚合表征不包含它自己的特征！</li><li>度大的节点在其特征表征中将具有较大的值，度小的节点将具有较小的值。</li></ul><h5 id="2-增加自环"><a href="#2-增加自环" class="headerlink" title="2. 增加自环"></a>2. 增加自环</h5><script type="math/tex; mode=display">f(X，A) = (A+I)X</script><h5 id="3-特征归一化处理"><a href="#3-特征归一化处理" class="headerlink" title="3. 特征归一化处理"></a>3. 特征归一化处理</h5><script type="math/tex; mode=display">f(X，A) =  D^{-1}(A+I)X</script><h5 id="4-对称归一化处理"><a href="#4-对称归一化处理" class="headerlink" title="4. 对称归一化处理"></a>4. 对称归一化处理</h5><script type="math/tex; mode=display">f(X，A) = D^{-0.5}(A+I)D^{-0.5}X</script><h5 id="5-增加权重"><a href="#5-增加权重" class="headerlink" title="5. 增加权重"></a>5. 增加权重</h5><script type="math/tex; mode=display">f(X，A) = D^{-0.5}(A+I)D^{-0.5}X W</script><h5 id="6-添加-激活函数"><a href="#6-添加-激活函数" class="headerlink" title="6. 添加 激活函数"></a>6. 添加 激活函数</h5><script type="math/tex; mode=display">f(X，A) = \sigma (D^{-0.5}(A+I)D^{-0.5}XW)</script><h4 id="2-GCN-可以做什么？"><a href="#2-GCN-可以做什么？" class="headerlink" title="2. GCN 可以做什么？"></a>2. GCN 可以做什么？</h4><h5 id="（1）-结点分类（Node-classification）"><a href="#（1）-结点分类（Node-classification）" class="headerlink" title="（1） 结点分类（Node classification）"></a>（1） 结点分类（Node classification）</h5><h5 id="（2）-图分类（Graph-classification）"><a href="#（2）-图分类（Graph-classification）" class="headerlink" title="（2） 图分类（Graph classification）"></a>（2） 图分类（Graph classification）</h5><h5 id="（3）连接预测（Link-prediction-）"><a href="#（3）连接预测（Link-prediction-）" class="headerlink" title="（3）连接预测（Link prediction ）"></a>（3）连接预测（Link prediction ）</h5><p><img src="/2019/04/20/GCN/2.png" alt></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol><li><a href="https://tkipf.github.io/graph-convolutional-networks">https://tkipf.github.io/graph-convolutional-networks</a></li><li></li></ol>]]></content>
    
    
    <categories>
      
      <category>探索</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>awesome-face</title>
    <link href="/2019/04/18/awesome-face/"/>
    <url>/2019/04/18/awesome-face/</url>
    
    <content type="html"><![CDATA[<p>my GitHub project awesome-face: face algorithm、source code、datasets、conf/workshop/trans</p><a id="more"></a><h1 id="awesome-face"><a href="#awesome-face" class="headerlink" title="awesome-face"></a>awesome-face</h1><p>🔥  face releated algorithm, datasets and papers  🤔</p><h2 id="📝-Paper-Algorithm"><a href="#📝-Paper-Algorithm" class="headerlink" title="📝 Paper / Algorithm"></a>📝 Paper / Algorithm</h2><h4 id="2D-Face-Recognition"><a href="#2D-Face-Recognition" class="headerlink" title="2D- Face Recognition"></a>2D- Face Recognition</h4><p><img src="/2019/04/18/awesome-face/face_reg.png" alt="2d_face_reg"></p><p><strong>[1] DeepID1</strong>  <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf"><strong>[paper]</strong></a> </p><p>Deep Learning Face Representation from Predicting 10,000 Classes</p><p><strong>[2] DeepID2</strong>  <a href="https://arxiv.org/abs/1406.4773"><strong>[paper]</strong></a> </p><p>Deep Learning Face Representation by Joint Identification-Verification</p><p><strong>[3] DeepID2+</strong>  <a href="https://arxiv.org/abs/1412.1265"><strong>[paper]</strong></a></p><p>Deeply learned face representations are sparse, selective, and robust</p><p><strong>[4] DeepIDv3</strong>  <a href="https://arxiv.org/abs/1502.00873"><strong>[paper]</strong></a> </p><p>DeepID3: Face Recognition with Very Deep Neural Networks</p><p><strong>[5] Deep Face</strong> <a href="https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf"><strong>[paper]</strong></a> </p><p>Deep Face Recognition</p><p><strong>[6] Center Loss</strong> <a href="http://ydwen.github.io/papers/WenECCV16.pdf"><strong>[paper]</strong></a>    <a href="https://github.com/ydwen/caffe-face"><strong>[code]</strong></a></p><p>A Discriminative Feature Learning Approach for Deep Face Recognition</p><p><strong>[7]Marginal loss</strong> <a href="https://www.computer.org/csdl/proceedings-article/cvprw/2017/0733c006/12OmNzayNCT"><strong>[paper]</strong></a></p><p>Marginal loss for deep face recognition</p><p><strong>[8] Range Loss</strong><a href="https://arxiv.org/abs/1611.08976"><strong>[paper]</strong></a> </p><p>Range Loss for Deep Face Recognition with Long-tail</p><p><strong>[9]Contrastive Loss</strong> <a href="https://arxiv.org/abs/1406.4773"><strong>[paper]</strong></a></p><p>Deep learning face representation by joint identification-verification</p><p><strong>[10] FaceNet</strong>   <a href="https://arxiv.org/abs/1503.03832"><strong>[paper]</strong></a>   <a href="https://github.com/davidsandberg/facenet">[<strong>third-party implemention</strong>]</a></p><p>FaceNet: A Unified Embedding for Face Recognition and Clustering</p><p><strong>[11] NormFace</strong>  <a href="https://arxiv.org/pdf/1704.06369.pdf"><strong>[paper]</strong></a>    <a href="https://github.com/happynear/NormFace"><strong>[code]</strong></a></p><p>NormFace: L2 Hypersphere Embedding for Face Verification</p><p><strong>[12] COCO Loss:</strong>    <a href="https://arxiv.org/pdf/1710.00870.pdf"><strong>[paper]</strong></a>   <a href="https://github.com/sciencefans/coco_loss">[<strong>code</strong>]</a></p><p>Rethinking Feature Discrimination and Polymerization for Large-scale Recognition</p><p><strong>[13] Large-Margin Softmax Loss</strong>  <a href="https://arxiv.org/pdf/1612.02295.pdf"><strong>[paper]</strong></a>  <a href="https://github.com/wy1iu/LargeMargin_Softmax_Loss">[<strong>code</strong>]</a></p><p>Large-Margin Softmax Loss for Convolutional Neural Networks(L-Softmax loss)</p><p><strong>[14]SphereFace：</strong>  <strong>A-Softmax</strong>   <a href="https://arxiv.org/abs/1704.08063"><strong>[paper]</strong></a>  <a href="https://github.com/wy1iu/sphereface">[<strong>code</strong>]</a></p><p>SphereFace: Deep Hypersphere Embedding for Face Recognition</p><p><strong>[15]AM-Softmax/cosFace</strong>     <a href="https://arxiv.org/pdf/1801.05599.pdf"><strong>[paper AM-Softmax]</strong></a>       <a href="https://arxiv.org/pdf/1801.09414.pdf"><strong>[paper cosFace]</strong></a>        <a href="https://github.com/happynear/AMSoftmax">[<strong>AM-softmax code</strong>]</a></p><p>AM : Additive Margin Softmax for Face Verification</p><p>CosFace: Large Margin Cosine Loss for Deep Face Recognition(Tencent AI Lab)</p><p><strong>[16] ArcFace:</strong>  <a href="https://arxiv.org/pdf/1801.07698.pdf"><strong>[paper]</strong></a>  <a href="https://github.com/deepinsight/insightface"><strong>[code]</strong></a></p><p>ArcFace: Additive Angular Margin Loss for Deep Face Recognition</p><p><img src="/2019/04/18/awesome-face/cos_loss.png" alt="cos_loss"></p><h4 id="Face-Detection"><a href="#Face-Detection" class="headerlink" title="Face Detection"></a>Face Detection</h4><p><img src="/2019/04/18/awesome-face/face_detection.png" alt></p><p><strong>[1] Cascade CNN</strong>  <a href="https://ieeexplore.ieee.org/document/7299170/"><strong>[paper]</strong></a>   <a href="https://github.com/anson0910/CNN_face_detection"><strong>[code]</strong></a>    </p><p>A Convolutional Neural Network Cascade for Face Detection</p><p><strong>[2] MTCNN</strong>   <a href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/"><strong>[Paper]</strong></a>    <a href="https://github.com/kpzhang93/MTCNN_face_detection_alignment"><strong>[code]</strong></a>  </p><p>Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</p><p><strong>[3] ICC - CNN</strong>  <a href="https://ieeexplore.ieee.org/document/8237606"><strong>[paper]</strong></a></p><p>Detecting Faces Using Inside Cascaded Contextual CNN</p><p><strong>[4] Face R-CNN</strong>  <a href="https://arxiv.org/pdf/1706.01061.pdf"><strong>[Paper]</strong></a></p><p>Face R-CNN</p><p><strong>[5] Deep-IR</strong><a href="https://arxiv.org/abs/1701.08289"><strong>[Paper]</strong></a></p><p>Face Detection using Deep Learning: An Improved Faster RCNN Approach</p><p><strong>[6] SSH</strong>     <a href="https://arxiv.org/pdf/1708.03979.pdf"><strong>[paper]</strong></a>    <a href="https://github.com/mahyarnajibi/SSH"><strong>[code]</strong></a></p><p>SSH: Single Stage Headless Face Detector</p><p><strong>[7] S3FD</strong>   <a href="https://arxiv.org/abs/1708.05237"><strong>[paper]</strong></a></p><p>Single Shot Scale-invariant Face Detector</p><p><strong>[8] FaceBoxes</strong> <a href="https://arxiv.org/pdf/1708.05234.pdf"><strong>[paper]</strong></a>     <a href="https://github.com/sfzhang15/FaceBoxes"><strong>[code]</strong></a></p><p>Faceboxes: A CPU Real-time Face Detector with High Accuracy</p><p><strong>[9] Scaleface</strong>     <a href="http://cn.arxiv.org/abs/1706.02863"><strong>[paper]</strong></a></p><p>Face Detection through Scale-Friendly Deep Convolutional Networks</p><p><strong>[10] HR</strong>  <a href="https://arxiv.org/abs/1612.04402"><strong>[paper]</strong></a>  <a href="https://github.com/peiyunh/tiny"><strong>[code]</strong></a></p><p>Finding Tiny Faces</p><p><strong>[11] FAN</strong>   <a href="https://arxiv.org/abs/1712.00721"><strong>[paper]</strong></a></p><p>Feature Agglomeration Networks for Single Stage Face Detection.</p><p><strong>[12] PyramidBox</strong>    <a href="https://arxiv.org/abs/1803.07737?context=cs"><strong>[paper]</strong></a> <a href="https://github.com/PaddlePaddle/models/blob/develop/fluid/PaddleCV/face_detection/README_cn.md"><strong>[code]</strong></a></p><p>PyramidBox: A Context-assisted Single Shot Face Detector</p><p><strong>[13] SRN</strong>     <a href="https://arxiv.org/abs/1809.02693"><strong>[paper]</strong></a> </p><p>Selective Refinement Network for High Performance Face Detection.</p><p><strong>[14] DSFD</strong>  <a href="https://arxiv.org/abs/1810.10220"><strong>[paper]</strong></a></p><p>DSFD: Dual Shot Face Detector</p><p><strong>[15] VIM FD</strong> <a href="https://arxiv.org/abs/1901.02350"><strong>[paper]</strong></a></p><p>Robust and High Performance Face Detector</p><p><strong>[16] ISRN</strong>  <a href="https://arxiv.org/abs/1901.06651"><strong>[paper]</strong></a></p><p>Improved Selective Refinement Network for Face Detection</p><h4 id="Face-Alignment"><a href="#Face-Alignment" class="headerlink" title="Face Alignment"></a>Face Alignment</h4><ul><li><a href="https://arxiv.org/abs/1805.10483">Look at Boundary: A Boundary-Aware Face Alignment Algorithm</a>[Wayne Wu al., 2018]</li><li><a href="https://arxiv.org/pdf/1902.10859.pdf">PFLD: A Practical Facial Landmark Detector</a>[Xiaojie Guo al., 2019]</li></ul><h2 id="⚙-Open-source-lib"><a href="#⚙-Open-source-lib" class="headerlink" title="⚙ Open source lib"></a>⚙ Open source lib</h2><h4 id="face-recognition"><a href="#face-recognition" class="headerlink" title="face recognition"></a>face recognition</h4><ul><li><p><a href="https://github.com/ZhaoJ9014/face.evoLVe.PyTorch">face.evoLVe.</a></p></li><li><p><a href="https://github.com/grib0ed0v/face_recognition.pytorch">face_recognition.pytorch</a></p></li><li><a href="https://github.com/deepinsight/insightface">insightface</a></li></ul><h4 id="face-detection"><a href="#face-detection" class="headerlink" title="face detection"></a>face detection</h4><ul><li><a href="https://github.com/ShiqiYu/libfacedetection">libfaccedetection</a></li></ul><h2 id="📦-Datasets"><a href="#📦-Datasets" class="headerlink" title="📦 Datasets"></a>📦 Datasets</h2><h4 id="2D-Face-Recognition-1"><a href="#2D-Face-Recognition-1" class="headerlink" title="2D Face Recognition"></a>2D Face Recognition</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>CASIA-WebFace</strong></td><td><strong>10,575</strong> subjects and <strong>494,414</strong> images</td><td><a href="http://www.cbsr.ia.ac.cn/english/CASIA-WebFace-Database.html">Download</a></td><td>2014</td></tr><tr><td><strong>MegaFace</strong>🏅</td><td><strong>1 million</strong> faces, <strong>690K</strong> identities</td><td><a href="http://megaface.cs.washington.edu/">Download</a></td><td>2016</td></tr><tr><td><strong>MS-Celeb-1M</strong>🏅</td><td>about <strong>10M</strong> images for <strong>100K</strong> celebrities   Concrete measurement to evaluate the performance of recognizing one million celebrities</td><td><a href="http://www.msceleb.org">Download</a></td><td>2016</td></tr><tr><td><strong>LFW</strong>🏅</td><td><strong>13,000</strong> images of faces collected from the web. Each face has been labeled with the name of the person pictured.  <strong>1680</strong> of the people pictured have two or more distinct photos in the data set.</td><td><a href="http://vis-www.cs.umass.edu/lfw/">Download</a></td><td>2007</td></tr><tr><td><strong>VGG Face2</strong>🏅</td><td>The dataset contains <strong>3.31 million</strong> images of <strong>9131</strong> subjects (identities), with an average of 362.6 images for each subject.</td><td><a href="http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/">Download</a></td><td>2017</td></tr><tr><td><strong>UMDFaces Dataset-image</strong></td><td><strong>367,888 face annotations</strong> for <strong>8,277 subjects.</strong></td><td><a href="http://www.umdfaces.io">Download</a></td><td>2016</td></tr><tr><td><strong>Trillion Pairs</strong>🏅</td><td>Train: <strong>MS-Celeb-1M-v1c</strong> &amp;  <strong>Asian-Celeb</strong> Test: <strong>ELFW&amp;DELFW</strong></td><td><a href="http://trillionpairs.deepglint.com/overview">Download</a></td><td>2018</td></tr><tr><td><strong>FaceScrub</strong></td><td>It comprises a total of <strong>106,863</strong> face images of male and female <strong>530</strong> celebrities, with about <strong>200 images per person</strong>.</td><td><a href="http://vintage.winklerbros.net/facescrub.html">Download</a></td><td>2014</td></tr><tr><td><strong>Mut1ny</strong>🏅</td><td>head/face segmentation dataset contains over 17.3k labeled images</td><td><a href="http://www.mut1ny.com/face-headsegmentation-dataset">Download</a></td><td>2018</td></tr><tr><td><strong>IMDB-Face</strong></td><td>The dataset contains about 1.7 million faces, 59k identities, which is manually cleaned from 2.0 million raw images.</td><td><a href="https://github.com/fwang91/IMDb-Face">Download</a></td><td>2018</td></tr></tbody></table></div><h4 id="video-face-recognition"><a href="#video-face-recognition" class="headerlink" title="video face recognition"></a>video face recognition</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>YouTube Face</strong>🏅</td><td>The data set contains <strong>3,425</strong> videos of <strong>1,595</strong> different people.</td><td><a href="http://www.cs.tau.ac.il/%7Ewolf/ytfaces/">Download</a></td><td>2011</td></tr><tr><td><strong>UMDFaces Dataset-video</strong>🏅</td><td>Over <strong>3.7 million</strong> annotated video frames from over <strong>22,000</strong> videos of <strong>3100 subjects.</strong></td><td><a href="http://www.umdfaces.io">Download</a></td><td>2017</td></tr><tr><td><strong>PaSC</strong></td><td>The challenge includes 9,376 still images and 2,802 videos of 293 people.</td><td><a href="https://www.nist.gov/programs-projects/point-and-shoot-face-recognition-challenge-pasc">Download</a></td><td>2013</td></tr><tr><td><strong>YTC</strong></td><td>The data consists of two parts: video clips (1910 sequences of 47 subjects) and initialization data(initial frame face bounding boxes, manually marked).</td><td><a href="http://seqamlab.com/youtube-celebrities-face-tracking-and-recognition-dataset/">Download</a></td><td>2008</td></tr><tr><td><strong>iQIYI-VID</strong>🏅</td><td>The iQIYI-VID dataset <strong>contains 500,000 videos clips of 5,000 celebrities, adding up to 1000 hours</strong>. This dataset supplies multi-modal cues, including face, cloth, voice, gait, and subtitles, for character identification.</td><td><a href="http://challenge.ai.iqiyi.com/detail?raceId=5b1129e42a360316a898ff4f">Download</a></td><td>2018</td></tr></tbody></table></div><h4 id="3D-face-recognition"><a href="#3D-face-recognition" class="headerlink" title="3D face recognition"></a>3D face recognition</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>Bosphorus</strong>🏅</td><td>105 subjects and 4666 faces 2D &amp; 3D face data</td><td><a href="http://bosphorus.ee.boun.edu.tr/default.aspx">Download</a></td><td>2008</td></tr><tr><td><strong>BD-3DFE</strong></td><td>Analyzing <strong>Facial Expressions</strong> in <strong>3D</strong> Space</td><td><a href="http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html">Download</a></td><td>2006</td></tr><tr><td><strong>ND-2006</strong></td><td>422 subjects and 9443 faces 3D Face Recognition</td><td><a href="https://sites.google.com/a/nd.edu/public-cvrl/data-sets">Download</a></td><td>2006</td></tr><tr><td><strong>FRGC V2.0</strong></td><td>466 subjects and 4007 of 3D Face, Visible Face Images</td><td><a href="https://sites.google.com/a/nd.edu/public-cvrl/data-sets">Download</a></td><td>2005</td></tr><tr><td><strong>B3D(AC)^2</strong></td><td><strong>1000</strong> high quality, dynamic <strong>3D scans</strong> of faces, recorded while pronouncing a set of English sentences.</td><td><a href="http://www.vision.ee.ethz.ch/datasets/b3dac2.en.html">Download</a></td><td>2010</td></tr></tbody></table></div><h4 id="Anti-spoofing"><a href="#Anti-spoofing" class="headerlink" title="Anti-spoofing"></a>Anti-spoofing</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th style="text-align:center"># of subj. / # of sess.</th><th>Links</th><th>Year</th><th>Spoof attacks attacks</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>NUAA</strong></td><td style="text-align:center">15/3</td><td><a href="http://parnec.nuaa.edu.cn/xtan/data/nuaaimposterdb.html">Download</a></td><td>2010</td><td><strong>Print</strong></td><td>2010</td></tr><tr><td><strong>CASIA-MFSD</strong></td><td style="text-align:center">50/3</td><td>Download(link failed)</td><td>2012</td><td><strong>Print, Replay</strong></td><td>2012</td></tr><tr><td><strong>Replay-Attack</strong></td><td style="text-align:center">50/1</td><td><a href="https://www.idiap.ch/dataset/replayattack">Download</a></td><td>2012</td><td><strong>Print, 2 Replay</strong></td><td>2012</td></tr><tr><td><strong>MSU-MFSD</strong></td><td style="text-align:center">35/1</td><td><a href="https://www.cse.msu.edu/rgroups/biometrics/Publications/Databases/MSUMobileFaceSpoofing/index.htm">Download</a></td><td>2015</td><td><strong>Print, 2 Replay</strong></td><td>2015</td></tr><tr><td><strong>MSU-USSA</strong></td><td style="text-align:center">1140/1</td><td><a href="http://biometrics.cse.msu.edu/Publications/Databases/MSU_USSA/">Download</a></td><td>2016</td><td><strong>2 Print, 6 Replay</strong></td><td>2016</td></tr><tr><td><strong>Oulu-NPU</strong></td><td style="text-align:center">55/3</td><td><a href="https://sites.google.com/site/oulunpudatabase/">Download</a></td><td>2017</td><td><strong>2 Print, 6 Replay</strong></td><td>2017</td></tr><tr><td><strong>Siw</strong></td><td style="text-align:center">165/4</td><td><a href="http://cvlab.cse.msu.edu/spoof-in-the-wild-siw-face-anti-spoofing-database.html">Download</a></td><td>2018</td><td><strong>2 Print, 4 Replay</strong></td><td>2018</td></tr></tbody></table></div><h4 id="cross-age-and-cross-pose"><a href="#cross-age-and-cross-pose" class="headerlink" title="cross age and cross pose"></a>cross age and cross pose</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th style="text-align:left">Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>CACD2000</strong></td><td style="text-align:left">The dataset contains more than 160,000 images of 2,000 celebrities with <strong>age ranging from 16 to 62</strong>.</td><td><a href="http://bcsiriuschen.github.io/CARC/">Download</a></td><td>2014</td></tr><tr><td><strong>FGNet</strong></td><td style="text-align:left">The dataset contains more than 1002 images of 82 people with <strong>age ranging from 0 to 69</strong>.</td><td><a href="http://www-prima.inrialpes.fr/FGnet/html/benchmarks.html">Download</a></td><td>2000</td></tr><tr><td><strong>MPRPH</strong></td><td style="text-align:left">The MORPH database contains <strong>55,000</strong> images of more than <strong>13,000</strong> people within the age ranges of <strong>16</strong> to <strong>77</strong></td><td><a href="http://www.faceaginggroup.com/morph/">Download</a></td><td>2016</td></tr><tr><td><strong>CPLFW</strong></td><td style="text-align:left">we construct a Cross-Pose LFW (CPLFW) which deliberately searches and selects <strong>3,000 positive face pairs</strong> with <strong>pose difference</strong> to add pose variation to intra-class variance.</td><td><a href="http://www.whdeng.cn/cplfw/index.html">Download</a></td><td>2017</td></tr><tr><td><strong>CALFW</strong></td><td style="text-align:left">Thereby we construct a Cross-Age LFW (CALFW) which deliberately searches and selects <strong>3,000 positive face pairs</strong> with <strong>age gaps</strong> to add aging process intra-class variance.</td><td><a href="http://www.whdeng.cn/calfw/index.html">Download</a></td><td>2017</td></tr></tbody></table></div><h4 id="Face-Detection-1"><a href="#Face-Detection-1" class="headerlink" title="Face Detection"></a>Face Detection</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>FDDB</strong>🏅</td><td><strong>5171</strong> faces in a set of <strong>2845</strong> images</td><td><a href="http://vis-www.cs.umass.edu/fddb/index.html">Download</a></td><td>2010</td></tr><tr><td><strong>Wider-face</strong> 🏅</td><td><strong>32,203</strong> images and label <strong>393,703</strong> faces with a high degree of variability in scale, pose and occlusion, organized based on <strong>61</strong> event classes</td><td><a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/">Download</a></td><td>2015</td></tr><tr><td><strong>AFW</strong></td><td>AFW dataset is built using Flickr images. It has <strong>205</strong> images with <strong>473</strong> labeled faces. For each face, annotations include a rectangular <strong>bounding box</strong>, <strong>6 landmarks</strong> and the <strong>pose angles</strong>.</td><td><a href="http://www.ics.uci.edu/~xzhu/face/">Download</a></td><td>2013</td></tr><tr><td><strong>MALF</strong></td><td>MALF is the first face detection dataset that supports fine-gained evaluation. MALF consists of <strong>5,250</strong> images and <strong>11,931</strong> faces.</td><td><a href="http://www.cbsr.ia.ac.cn/faceevaluation/">Download</a></td><td>2015</td></tr></tbody></table></div><h4 id="Face-Attributes"><a href="#Face-Attributes" class="headerlink" title="Face Attributes"></a>Face Attributes</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Key features</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>CelebA</strong></td><td><strong>10,177</strong> number of <strong>identities</strong>,  <strong>202,599</strong> number of <strong>face images</strong>, and  <strong>5 landmark locations</strong>, <strong>40 binary attributes</strong> annotations per image.</td><td><a href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Download</a></td><td><strong>attribute &amp; landmark</strong></td><td>2015</td></tr><tr><td><strong>IMDB-WIKI</strong></td><td>500k+ face images with <strong>age</strong> and <strong>gender</strong> labels</td><td><a href="https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/">Download</a></td><td><strong>age &amp; gender</strong></td><td>2015</td></tr><tr><td><strong>Adience</strong></td><td>Unfiltered faces for <strong>gender</strong> and <strong>age</strong> classification</td><td><a href="http://www.openu.ac.il/home/hassner/Adience/data.html">Download</a></td><td><strong>age &amp; gender</strong></td><td>2014</td></tr><tr><td><strong>WFLW</strong>🏅</td><td>WFLW contains <strong>10000 faces</strong> (7500 for training and 2500 for testing) with <strong>98 fully manual annotated landmarks</strong>.</td><td><a href="https://wywu.github.io/projects/LAB/WFLW.html">Download</a></td><td><strong>landmarks</strong></td><td>2018</td></tr><tr><td><strong>Caltech10k Web Faces</strong></td><td>The dataset has 10,524 human faces of various resolutions and in <strong>different settings</strong></td><td><a href="http://www.vision.caltech.edu/Image_Datasets/Caltech_10K_WebFaces/#Description">Download</a></td><td><strong>landmarks</strong></td><td>2005</td></tr><tr><td><strong>EmotioNet</strong></td><td>The EmotioNet database includes<strong>950,000 images</strong> with <strong>annotated AUs</strong>.  A <strong>subset</strong> of the images in the EmotioNet database correspond to <strong>basic and compound emotions.</strong></td><td><a href="http://cbcsl.ece.ohio-state.edu/EmotionNetChallenge/index.html#overview">Download</a></td><td><strong>AU and Emotion</strong></td><td>2017</td></tr><tr><td><strong>RAF( Real-world Affective Faces)</strong></td><td><strong>29672</strong> number of <strong>real-world images</strong>,  including <strong>7</strong> classes of basic emotions and <strong>12</strong> classes of compound emotions,  <strong>5 accurate landmark locations</strong>,  <strong>37 automatic landmark locations</strong>, <strong>race, age range</strong> and  <strong>gender</strong> <strong>attributes</strong> annotations per image</td><td><a href="http://www.whdeng.cn/RAF/model1.html">Download</a></td><td><strong>Emotions、landmark、race、age and gender</strong></td><td>2017</td></tr></tbody></table></div><h4 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h4><div class="table-container"><table><thead><tr><th>Datasets</th><th>Description</th><th>Links</th><th>Publish Time</th></tr></thead><tbody><tr><td><strong>IJB C/B/A</strong>🏅</td><td>IJB C/B/A is currently running <strong>three challenges</strong> related to  <strong>face detection, verification, identification, and identity clustering.</strong></td><td><a href="https://www.nist.gov/programs-projects/face-challenges">Download</a></td><td>2015</td></tr><tr><td><strong>MOBIO</strong></td><td><strong>bi-modal</strong> (<strong>audio</strong> and <strong>video</strong>) data taken from 152 people.</td><td><a href="https://www.idiap.ch/dataset/mobio">Download</a></td><td>2012</td></tr><tr><td><strong>BANCA</strong></td><td>The BANCA database was captured in four European languages in <strong>two modalities</strong> (<strong>face</strong> and <strong>voice</strong>).</td><td><a href="http://www.ee.surrey.ac.uk/CVSSP/banca/">Download</a></td><td>2014</td></tr><tr><td><strong>3D Mask Attack</strong></td><td><strong>76500</strong> frames of <strong>17</strong> persons using Kinect RGBD with eye positions (Sebastien Marcel).</td><td><a href="https://www.idiap.ch/dataset/3dmad">Download</a></td><td>2013</td></tr><tr><td><strong>WebCaricature</strong></td><td><strong>6042</strong> <strong>caricatures</strong> and <strong>5974 photographs</strong> from <strong>252 persons</strong> collected from the web</td><td><a href="https://cs.nju.edu.cn/rl/WebCaricature.htm">Download</a></td><td>2018</td></tr></tbody></table></div><h2 id="🏠-Research-home-conf-amp-workshop-amp-trans"><a href="#🏠-Research-home-conf-amp-workshop-amp-trans" class="headerlink" title="🏠 Research home(conf &amp; workshop &amp; trans)"></a>🏠 Research home(conf &amp; workshop &amp; trans)</h2><p><img src="/2019/04/18/awesome-face/research_home.png" alt></p><p><strong>ICCV</strong>: <a href="http://iccv2019.thecvf.com">IEEE International Conference on Computer Vision</a></p><p><strong>CVPR</strong>: <a href="http://cvpr2018.thecvf.com/">IEEE Conference on Computer Vision and Pattern Recognition</a></p><p><strong>ECCV</strong>: <a href="https://eccv2018.org">European Conference on Computer Vision</a></p><p><strong>FG</strong>: <a href="http://dblp.uni-trier.de/db/conf/fgr/">IEEE International Conference on Automatic Face and Gesture Recognition</a></p><p><strong>BMVC:</strong> <a href="http://www.bmva.org/bmvc/?id=bmvc">The British Machine Vision Conference</a></p><p><strong>IJCB[ICB+BTAS]</strong>:International Joint Conference on Biometrics</p><ul><li><p><strong>ICB</strong>: <a href="http://icb2018.org">International Conference on Biometrics</a></p></li><li><p><strong>BTAS</strong>: <a href="https://www.isi.edu/events/btas2018/home">IEEE International Conference on Biometrics: Theory, Applications and Systems</a></p></li></ul><p><strong>AMFG</strong>: IEEE workshop on Analysis and Modeling of Faces and Gestures</p><p><strong>CVPR Workshop on Biometrics</strong></p><p><strong>TPAMI:</strong> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></p><p><strong>IJCV:</strong> <a href="https://link.springer.com/journal/11263">International Journal of Computer Vision</a> </p><p><strong>TIP:</strong> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing</a></p><p><strong>TIFS:</strong> <a href="IEEE Transactions on Information Forensics and Security">IEEE Transactions on Information Forensics and Security</a></p><p><strong>PR:</strong> <a href="https://www.journals.elsevier.com/pattern-recognition/">Pattern Recognition</a></p><h2 id="🏷-References"><a href="#🏷-References" class="headerlink" title="🏷 References:"></a>🏷 References:</h2><p>[1] <a href="https://github.com/RiweiChen/DeepFace/tree/master/FaceDataset">https://github.com/RiweiChen/DeepFace/tree/master/FaceDataset</a></p><p>[2] <a href="https://www.zhihu.com/question/33505655?sort=created">https://www.zhihu.com/question/33505655?sort=created</a></p><p>[3] <a href="https://github.com/betars/Face-Resources">https://github.com/betars/Face-Resources</a></p><p>[4] <a href="https://zhuanlan.zhihu.com/p/33288325">https://zhuanlan.zhihu.com/p/33288325</a></p><p>[5] <a href="https://github.com/L706077/DNN-Face-Recognition-Papers">https://github.com/L706077/DNN-Face-Recognition-Papers</a></p><p>[6] <a href="https://www.zhihu.com/question/67919300">https://www.zhihu.com/question/67919300</a></p><p>[7] <a href="https://jackietseng.github.io/conference_call_for_paper/2018-2019-conferences.html">https://jackietseng.github.io/conference_call_for_paper/2018-2019-conferences.html</a></p><p>[8]<a href="http://history.ccf.org.cn/sites/ccf/biaodan.jsp?contentId=2903940690839">http://history.ccf.org.cn/sites/ccf/biaodan.jsp?contentId=2903940690839</a></p><p>[9]<a href="http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/WiderFace_Results.html">http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/WiderFace_Results.html</a></p>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch常见工具箱</title>
    <link href="/2019/04/17/pytorch%E5%B8%B8%E8%A7%81%E5%B7%A5%E5%85%B7%E7%AE%B1/"/>
    <url>/2019/04/17/pytorch%E5%B8%B8%E8%A7%81%E5%B7%A5%E5%85%B7%E7%AE%B1/</url>
    
    <content type="html"><![CDATA[<p>收集整理了一些常见的可以用到的深度学习网址、工具</p><a id="more"></a><h3 id="1-预训练模型"><a href="#1-预训练模型" class="headerlink" title="1. 预训练模型"></a>1. 预训练模型</h3><p><a href="https://github.com/Cadene/pretrained-models.pytorch">https://github.com/Cadene/pretrained-models.pytorch</a></p><p><a href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a></p><p><a href="https://github.com/welkin-feng/ComputerVision">https://github.com/welkin-feng/ComputerVision</a></p><h3 id="2-数据增强"><a href="#2-数据增强" class="headerlink" title="2. 数据增强"></a>2. 数据增强</h3><p><a href="https://github.com/albumentations-team/albumentations">https://github.com/albumentations-team/albumentations</a></p><h3 id="3-标记工具"><a href="#3-标记工具" class="headerlink" title="3. 标记工具"></a>3. 标记工具</h3><p><a href="https://github.com/wkentaro/labelme"><strong>Labelme:</strong></a> Image Polygonal Annotation with Python</p><p><a href="https://github.com/tzutalin/labelImg"><strong>LabelImg</strong></a>：LabelImg is a graphical image annotation tool and label object bounding boxes in images</p><h3 id="4-数据集查找"><a href="#4-数据集查找" class="headerlink" title="4. 数据集查找"></a>4. 数据集查找</h3><p><strong>! ! !  You can find datasets in Paper Beachmark</strong></p><p><a href="https://www.kaggle.com/"><strong>Kaggle</strong></a></p><p><a href="https://toolbox.google.com/datasetsearch"><strong>Google Datasets Search Engine</strong></a></p><p><a href="https://msropendata.com/"><strong>Microsoft Datasets</strong></a></p><p><a href="https://www.visualdata.io/"><strong>Computer Vision Datasets</strong></a></p><p><a href="https://github.com/awesomedata/awesome-public-datasets"><strong>Github awesomedata</strong></a></p><p><a href="https://archive.ics.uci.edu/ml/datasets.html"><strong>UCI Machine Learning Repository.</strong></a></p><p><a href="https://registry.opendata.aws/"><strong>Amazon Datasets</strong></a></p><p><strong>Government Datasets:</strong> <a href="https://data.europa.eu/euodp/data/dataset"><strong>EU</strong></a> <a href="https://www.data.gov/"><strong>US</strong></a> <a href="https://catalogue.data.govt.nz/dataset"><strong>NZL</strong></a> <a href="https://data.gov.in/"><strong>IND</strong></a></p><h3 id="5-模型分析工具"><a href="#5-模型分析工具" class="headerlink" title="5. 模型分析工具"></a>5. 模型分析工具</h3><h5 id="1-卷积层输出大小计算"><a href="#1-卷积层输出大小计算" class="headerlink" title="(1) 卷积层输出大小计算"></a>(1) 卷积层输出大小计算</h5><h5 id="https-ezyang-github-io-convolution-visualizer-index-html"><a href="#https-ezyang-github-io-convolution-visualizer-index-html" class="headerlink" title="https://ezyang.github.io/convolution-visualizer/index.html"></a><a href="https://ezyang.github.io/convolution-visualizer/index.html">https://ezyang.github.io/convolution-visualizer/index.html</a></h5><h5 id="2-计算模型参数量"><a href="#2-计算模型参数量" class="headerlink" title="(2) 计算模型参数量"></a>(2) 计算模型参数量</h5><p><a href="https://github.com/sksq96/pytorch-summary">https://github.com/sksq96/pytorch-summary</a></p><h5 id="3-模型可视化工具"><a href="#3-模型可视化工具" class="headerlink" title="(3) 模型可视化工具"></a>(3) 模型可视化工具</h5><p><a href="https://github.com/lutzroeder/Netron"><strong>Netron:</strong></a> now supports <strong>ONNX</strong>, <strong>Keras</strong>, <strong>CoreML</strong>, <strong>Caffe2</strong>, <strong>Mxnet</strong>, <strong>Pytorch</strong> and <strong>Tensorflow</strong>.</p><p><a href="https://github.com/szagoruyko/pytorchviz"><strong>Graphviz:</strong></a> <strong>Pytorch</strong></p><h3 id="6-可视化工具"><a href="#6-可视化工具" class="headerlink" title="6. 可视化工具"></a>6. 可视化工具</h3><p><a href="https://github.com/facebookresearch/visdom">visdom</a></p><pre><code class="hljs python"><span class="hljs-comment"># Example using Visdom.</span>vis = visdom.Visdom(env=<span class="hljs-string">&#x27;Learning curve&#x27;</span>, use_incoming_socket=<span class="hljs-literal">False</span>)<span class="hljs-keyword">assert</span> self._visdom.check_connection()self._visdom.close()options = collections.namedtuple(<span class="hljs-string">&#x27;Options&#x27;</span>, [<span class="hljs-string">&#x27;loss&#x27;</span>, <span class="hljs-string">&#x27;acc&#x27;</span>, <span class="hljs-string">&#x27;lr&#x27;</span>])(    loss=&#123;<span class="hljs-string">&#x27;xlabel&#x27;</span>: <span class="hljs-string">&#x27;Epoch&#x27;</span>, <span class="hljs-string">&#x27;ylabel&#x27;</span>: <span class="hljs-string">&#x27;Loss&#x27;</span>, <span class="hljs-string">&#x27;showlegend&#x27;</span>: <span class="hljs-literal">True</span>&#125;,    acc=&#123;<span class="hljs-string">&#x27;xlabel&#x27;</span>: <span class="hljs-string">&#x27;Epoch&#x27;</span>, <span class="hljs-string">&#x27;ylabel&#x27;</span>: <span class="hljs-string">&#x27;Accuracy&#x27;</span>, <span class="hljs-string">&#x27;showlegend&#x27;</span>: <span class="hljs-literal">True</span>&#125;,    lr=&#123;<span class="hljs-string">&#x27;xlabel&#x27;</span>: <span class="hljs-string">&#x27;Epoch&#x27;</span>, <span class="hljs-string">&#x27;ylabel&#x27;</span>: <span class="hljs-string">&#x27;Learning rate&#x27;</span>, <span class="hljs-string">&#x27;showlegend&#x27;</span>: <span class="hljs-literal">True</span>&#125;)<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> epoch(<span class="hljs-number">80</span>):    tran(...)    val(...)    vis.line(X=torch.Tensor([t + <span class="hljs-number">1</span>]), Y=torch.Tensor([train_loss]),             name=<span class="hljs-string">&#x27;train&#x27;</span>, win=<span class="hljs-string">&#x27;Loss&#x27;</span>, update=<span class="hljs-string">&#x27;append&#x27;</span>, opts=options.loss)    vis.line(X=torch.Tensor([t + <span class="hljs-number">1</span>]), Y=torch.Tensor([val_loss]),             name=<span class="hljs-string">&#x27;val&#x27;</span>, win=<span class="hljs-string">&#x27;Loss&#x27;</span>, update=<span class="hljs-string">&#x27;append&#x27;</span>, opts=options.loss)    vis.line(X=torch.Tensor([t + <span class="hljs-number">1</span>]), Y=torch.Tensor([train_acc]),             name=<span class="hljs-string">&#x27;train&#x27;</span>, win=<span class="hljs-string">&#x27;Accuracy&#x27;</span>, update=<span class="hljs-string">&#x27;append&#x27;</span>, opts=options.acc)    vis.line(X=torch.Tensor([t + <span class="hljs-number">1</span>]), Y=torch.Tensor([val_acc]),             name=<span class="hljs-string">&#x27;val&#x27;</span>, win=<span class="hljs-string">&#x27;Accuracy&#x27;</span>, update=<span class="hljs-string">&#x27;append&#x27;</span>, opts=options.acc)    vis.line(X=torch.Tensor([t + <span class="hljs-number">1</span>]), Y=torch.Tensor([lr]),             win=<span class="hljs-string">&#x27;Learning rate&#x27;</span>, update=<span class="hljs-string">&#x27;append&#x27;</span>, opts=options.lr)</code></pre><p><a href="https://pytorch.org/docs/stable/tensorboard.html">Tensorboard</a></p><ul><li><strong>acc / loss</strong></li></ul><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorboard <span class="hljs-keyword">import</span> SummaryWriterwriter = SummaryWriter()<span class="hljs-keyword">for</span> n_iter <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):    dummy_s1 = torch.rand(<span class="hljs-number">1</span>)    writer.add_scalar(<span class="hljs-string">&#x27;data/scalar1&#x27;</span>, dummy_s1[<span class="hljs-number">0</span>], n_iter)writer.close()</code></pre><ul><li><strong>img</strong></li></ul><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorboard <span class="hljs-keyword">import</span> SummaryWriter<span class="hljs-keyword">import</span> torchvision.utils <span class="hljs-keyword">as</span> vutilswriter = SummaryWriter()<span class="hljs-keyword">if</span> n_iter % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:    x = vutils.make_grid(dummy_img, normalize=<span class="hljs-literal">True</span>, scale_each=<span class="hljs-literal">True</span>)    writer.add_image(<span class="hljs-string">&#x27;Image&#x27;</span>, x, n_iter)writer.close()</code></pre><ul><li>在一张图中加入两条曲线</li></ul><pre><code class="hljs python"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">100</span>):    writer.add_scalars(<span class="hljs-string">&#x27;run_14h&#x27;</span>, &#123;<span class="hljs-string">&#x27;xsinx&#x27;</span>:i*np.sin(i/r),                                    <span class="hljs-string">&#x27;xcosx&#x27;</span>:i*np.cos(i/r),                                    <span class="hljs-string">&#x27;tanx&#x27;</span>: np.tan(i/r)&#125;, i)</code></pre><h3 id="7-Pytorch-加速"><a href="#7-Pytorch-加速" class="headerlink" title="7. Pytorch 加速"></a>7. Pytorch 加速</h3><p><strong>NVIDIA/DLAI:</strong> <a href="https://github.com/NVIDIA/DALI">https://github.com/NVIDIA/DALI</a></p><p><strong>Efficient-Pytorch:</strong> <a href="https://github.com/Lyken17/Efficient-PyTorch">https://github.com/Lyken17/Efficient-PyTorch</a></p><p><strong>NVIDIA/APEX:</strong> <a href="https://github.com/nvidia/apex">https://github.com/nvidia/apex</a></p><h3 id="8-性能分析工具"><a href="#8-性能分析工具" class="headerlink" title="8. 性能分析工具"></a>8. 性能分析工具</h3><ul><li>nvidia-smi</li><li>htop</li><li>iotop</li><li>nvtop</li><li>py-spy</li><li>strace</li></ul><h3 id="9-深度学习绘图"><a href="#9-深度学习绘图" class="headerlink" title="9. 深度学习绘图"></a>9. 深度学习绘图</h3><ul><li><a href="https://github.com/dair-ai/ml-visuals"><strong>ML Visuals</strong></a></li><li><a href="https://github.com/HarisIqbal88/PlotNeuralNet"><strong>PlotNeuralNet</strong></a></li></ul><h3 id="10-其他辅助工具"><a href="#10-其他辅助工具" class="headerlink" title="10. 其他辅助工具"></a>10. 其他辅助工具</h3><ul><li><strong>byobu</strong></li><li><strong>screen</strong></li></ul>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>人脸识别损失函数</title>
    <link href="/2019/04/15/Face-recog-loss-fun/"/>
    <url>/2019/04/15/Face-recog-loss-fun/</url>
    
    <content type="html"><![CDATA[<p>常见的损失函数一览:从softmax loss 到 triplet loss 再到各种 softmax 改型。</p><a id="more"></a><h4 id="softmax-loss"><a href="#softmax-loss" class="headerlink" title="softmax loss"></a>softmax loss</h4><p>softmax是最常见的人脸识别函数。softmax 函数将人脸识别问题看做一个经典的分类问题。</p><script type="math/tex; mode=display">L_{softmax} = -\frac{1}{N}\sum_{i=1}^{N} log \frac{e^{W^T_{y_i}x_i+b_{y_i}}}{\sum_{j=1}^{k}e^{W^T_jx_i+b_j}}</script><p>公式中 N 是 batch size 的大小，k是类别数目。</p><h4 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h4><p>​        Triplet loss 采用三元组进行训练，所谓的三元组就是三个样例，如(anchor, pos, neg)，其中，x和p是同一类，x和n是不同类。那么学习的过程就是学到一种表示，对于尽可能多的三元组，使得anchor和pos的距离，小于anchor和neg的距离。</p><p><img src="/2019/04/15/Face-recog-loss-fun/triplet.png" alt></p><script type="math/tex; mode=display">||x_i^a - x_i^p||^2_2 +m < ||x_i^a-x_i^n||_2^2</script><h4 id="center-loss"><a href="#center-loss" class="headerlink" title="center loss"></a>center loss</h4><p>​       center loss的核心是：为每一个类别提供一个类别中心，最小化每个样本与该中心的距离，从而减小类内差距。center loss 由两项构成，第一项是传统的 softmax loss， 第二项是样本到类中心的距离。</p><script type="math/tex; mode=display">L_{center} = -\frac{1}{N}\sum_{i=1}^{N} log \frac{e^{W^T_{y_i}x_i+b_{y_i}}}{\sum_{j=1}^{k}e^{W^T_jx_i+b_j}} + \frac{\lambda}{2}\sum_{i=1}^N||x_i-c_{y_i}||^2_2</script><p><img src="/2019/04/15/Face-recog-loss-fun/center loss.png" alt></p><h4 id="L-softmax"><a href="#L-softmax" class="headerlink" title="L-softmax"></a>L-softmax</h4><p>考虑一个两分类问题。原始的Softmax的目的是使得  $W_1^Tx &gt; W_2^Tx$， 即 $||W_1||||x||cos(\theta_1) &gt; ||W_1||||x||cos(\theta_2)$，在这个基础上，L-softmax(Large-margin softmax) 希望可以通过增加一个正整数变量m，使得产生的决策边界可以更加严格地约束上述不等式，让类内的间距更加的紧凑，类间的间距更加具有区分性。</p><script type="math/tex; mode=display">L_{l-softmax} = -\frac{1}{N}\sum_{i=1}^N log(\frac{e^{||W_{yi}||||x_i||\psi{(\theta_{y_i})}}}{e^{||W_{yi}||||x_i||\psi{(\theta_{y_i})}} + \sum_{j=1, j\neq y_i}^k{e^{||W_j||||x_i||cos(\theta_j)}}})</script><p>其中,</p><script type="math/tex; mode=display">\psi(\theta) = \begin{equation}  \left\{      \begin{array}{**lr**}     cos(m\theta), 0 \leq \theta \leq \frac{\pi}{m}\\     D(\theta) ,  \frac{\pi}{m}\leq \theta \leq \pi \\        \end{array}  \right. \end{equation}</script><p>cos函数在(0,π)内是单调递减的，乘上正整数m后内积会减小，这样可以加大类间的差别。通过控制m的大小，调整类间距离。m越大，类间距离就越大，类内更加紧凑。</p><p><img src="/2019/04/15/Face-recog-loss-fun/lms.png" alt></p><h4 id="sphereface-A-softmax"><a href="#sphereface-A-softmax" class="headerlink" title="sphereface(A-softmax)"></a>sphereface(A-softmax)</h4><p>SphereFace是在 softmax 的基础上将权重归一化，即式 $||W||=1, b=0$  。它与前面提到的L-sofrmax最大的区别在于SphereFace将W权重归一化了。L-Softmax会同时从角度和权重长度上区分不同类别，而SphereFace只从角度上去区分不同类别。</p><script type="math/tex; mode=display">L_{A-softmax} = -\frac{1}{N}\sum_{i=1}^{N}log(\frac{e^{||x_i||\psi(\theta_{y_i})}}{e^{||x_i||\psi(\theta_{y_i})} + \sum_{j=1, j \neq y_i}^k{e^{||x_i||cos\theta_j}}})</script><h4 id="cosface"><a href="#cosface" class="headerlink" title="cosface"></a>cosface</h4><p>cosFace的思想和sphereFace( A-softmax)的思想接近，其中主要做了以下三点的改进：</p><ul><li>loss的形式做了稍微的改变，将超参数m由乘法运算变成了减法运算</li><li>不仅对权重进行了正则化，还对特征进行了正则化</li><li>再乘上一个 s 参数，当超球面过小时，分类映射到超球面上不好分类，这个 s 参数可以扩大超球面体积，帮助分类</li></ul><script type="math/tex; mode=display">L_{cos} = -\frac{1}{N} \sum_{i=1}^{N} log(\frac{e^{s(cos(\theta_{yi})-m)}}{e^{s(cos(\theta_{yi})-m)}+\sum_{j=1, j\neq y_i}^k e^{scos \theta_j}})</script><h4 id="arcface"><a href="#arcface" class="headerlink" title="arcface"></a>arcface</h4><p>arcface的思想和cosface类似，主要区别是将m放入了cos中，角度距离比余弦距离对角度的影响更加直接:</p><script type="math/tex; mode=display">L_{arc} = -\frac{1}{N} \sum_{i=1}^{N} log(\frac{e^{s(cos(\theta_{yi}+m))}}{e^{s(cos(\theta_{yi}+m))}+\sum_{j=1,j\neq y_i}^k e^{scos\theta_j}})</script><p>arcface 人脸识别流程图：</p><p><img src="/2019/04/15/Face-recog-loss-fun/flowchart.png" alt></p><p>不同损失函数的分类边界如下图所示：</p><p><img src="/2019/04/15/Face-recog-loss-fun/cos_loss.png" alt></p>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Face-Detection-Solution</title>
    <link href="/2019/04/13/Face-Detection-Solution/"/>
    <url>/2019/04/13/Face-Detection-Solution/</url>
    
    <content type="html"><![CDATA[<p>Face Detection 人脸检测设计方案</p><a id="more"></a><h4 id="1-整体网络架构设计"><a href="#1-整体网络架构设计" class="headerlink" title="1. 整体网络架构设计"></a>1. 整体网络架构设计</h4><p><strong>DSFD</strong>：ResNet101, DPN−98, SE-ResNeXt101 32×4d、<strong>ResNet152</strong>、SE-ResNet101（SSD 架构、未进行上下层的融合）</p><p><strong>Faceboxes</strong>：(conv+CReLU+pool)<em>2 + inception </em> 3 + conv * 4（SSD 架构、未进行上下层的融合）</p><p><strong>PymaridBox</strong>：VGG16（LFPN架构）</p><p><strong>VIM-FD</strong> ： densenet121 （SSD+attention：STR+STC）</p><p><strong>S3FD</strong>：VGG16 （SSD + norm）</p><p><strong>SSH</strong>: vgg16</p><p><strong>Scale Face</strong>：Resnet 50</p><p><strong>smallhardface</strong>：VGG16 （one shot、直通式架构：能实现这个性能简直有点不可思议！ 值得研究的架构）</p><p><strong>SRN</strong>：combining DRN with Root-ResNet-18 to have a training speed/accuracy trade-off backbone for SRN</p><p>(比较新的架构、值得研究一下：STR+STC)</p><p><strong>MSFD</strong>：VGG 16（上中下三层融合机制）</p><p><strong>对于主干架构，通常选择 vgg16 或者 resnet50/101, 如果追求轻量级可以使用 mobilenetv2 or shufflenet v2。</strong></p><h4 id="2-如何设计多尺度特征"><a href="#2-如何设计多尺度特征" class="headerlink" title="2. 如何设计多尺度特征"></a>2. 如何设计多尺度特征</h4><p>常见的多尺度的设计方案：</p><p>（a）图像金字塔，即将图像做成不同的scale，然后不同scale的图像生成对应的不同scale的特征。这种方法的缺点在于增加了时间成本。有些算法会在测试时候采用图像金字塔。 </p><p>（b）像SPP net，Fast RCNN，Faster RCNN是采用这种方式，即仅采用网络最后一层的特征。 </p><p>（c）像SSD（Single Shot Detector）采用这种多尺度特征融合的方式，没有上采样过程，即从网络不同层抽取不同尺度的特征做预测，这种方式不会增加额外的计算量。作者认为SSD算法中没有用到足够低层的特征（在SSD中，最低层的特征是VGG网络的conv4_3），而在作者看来足够低层的特征对于检测小物体是很有帮助的。 </p><p>（d）本文作者是采用这种方式，顶层特征通过上采样和低层特征做融合，而且每层都是独立预测的。</p><p><img src="/2019/04/13/Face-Detection-Solution/2.png" alt></p><p><strong>进入 2018年以来，大部分网络均采用 FPN 网络结构的形式，融合多个特征层进行检测。有时候会搭配一个独特设计的网络，比如SRN 的 STR_STC 结构、MSFD 的三层融合机制、DSFD 的 Two-shot 结构。都进行了不同程度的创新。</strong></p><h4 id="3-Loss-设计"><a href="#3-Loss-设计" class="headerlink" title="3. Loss 设计"></a>3. Loss 设计</h4><h5 id="（1）smooth-l1-loss"><a href="#（1）smooth-l1-loss" class="headerlink" title="（1）smooth l1  loss"></a>（1）smooth l1  loss</h5><p>Smooth l1 loss 的定义如下所示：</p><script type="math/tex; mode=display">smooth_{L_1}(x) = \begin{equation}  \left\{      \begin{array}{**lr**}      0.5 x^2,  if |x| < 1  \\      |x|-0.5,  otherwise \\        \end{array}  \right.  \end{equation}</script><h5 id="（2）focal-loss"><a href="#（2）focal-loss" class="headerlink" title="（2）focal loss"></a>（2）focal loss</h5><script type="math/tex; mode=display">L_{focol\ loss} = \begin{equation}  \left\{      \begin{array}{**lr**}      -(1-y')^\gamma logy',  y=1 \\      -y'^\gamma log(1-y'),  y=0 \\        \end{array}  \right.  \end{equation}</script><h4 id="4-anchor-设计"><a href="#4-anchor-设计" class="headerlink" title="4. anchor 设计"></a>4. anchor 设计</h4><p><strong>anchor 设计的三个原则：</strong><br><strong>(1) anchor 的尺寸、长宽比、位置都应该 match 源数据中的bbox。一种方法是针对特定数据集设计anchor，如YOLOv2中的聚类，和近期有论文CNN训练anchor的设置，这些方法或许更适合某一数据集，但也可能影响模型的泛化能力，换一个库是否依然够用。</strong><br><strong>(2) anchor的size 必须小于感受野</strong><br><strong>(3) 不同size的anchor应当具有相同的空间密度分布。密度一致的话，要求 anchor/stride 为一个定值。</strong></p><h4 id="5-数据增强策略"><a href="#5-数据增强策略" class="headerlink" title="5. 数据增强策略:"></a>5. 数据增强策略:</h4><p><strong>S3FD</strong>：Color distort、Random crop、Horizontal flip</p><p><strong>Faceboxes</strong>：Color distort、Random crop、Horizontal flip、Scale transformation、Face-box filter</p><p><strong>SRN</strong>：photometric distortions<strong>, </strong>randomly expanding by zero-padding operation<strong>, </strong>randomly cropping patches<strong>、 </strong>data-anchor-sampling in PyramidBox</p><p><strong>Pyramid box</strong>： color distort, random crop and horizontal flip.data-anchor-sampling</p><p><strong>VIMFD</strong>: data-anchor-sampling method in PyramidBox</p><p><strong>Small hard face</strong>: random cropping,photometric distortion</p><p><strong>Tiny face</strong>: resize</p><p><strong>最常见的几种方案是：Color distort、Random crop(resize)、Horizontal flip、data-anchor-sampling method in PyramidBox </strong></p><p>其他值得借鉴的数据增强策略:</p><p>[1] SSD &amp; YOLO v3 相关数据增强</p><p>[2] <a href="https://github.com/maozezhong/CV_ToolBox/blob/master/DataAugForObjectDetection/DataAugmentForObejctDetection.py">https://github.com/maozezhong/CV_ToolBox/blob/master/DataAugForObjectDetection/DataAugmentForObejctDetection.py</a></p><p>[3] torchvision</p><p>[4] <a href="https://github.com/dmlc/gluon-cv?files=1">mxnet：Bag of Freebies for Training Object Detection Neural Networks</a></p><h4 id="6-深度学习人脸检测方案的发展"><a href="#6-深度学习人脸检测方案的发展" class="headerlink" title="6. 深度学习人脸检测方案的发展"></a>6. 深度学习人脸检测方案的发展</h4><p><img src="/2019/04/13/Face-Detection-Solution/face_detection.png" alt="Face Detection"></p><h4 id="7-常见数据集"><a href="#7-常见数据集" class="headerlink" title="7. 常见数据集"></a>7. 常见数据集</h4><ul><li><p>FDDB</p></li><li><p>Wider-Face</p></li><li><p>PASCAL</p></li><li><p>AFW</p></li></ul><p><strong>相比而言：WIDER-FACE 更加权威、FDDB 次之，PASCAL和AFW 都是比较小的数据集，基本可以忽略。</strong></p>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>FaceBoxes</title>
    <link href="/2019/04/13/FaceBoxes/"/>
    <url>/2019/04/13/FaceBoxes/</url>
    
    <content type="html"><![CDATA[<p>FaceBoxes: A CPU Real-time Face Detector with High Accuracy</p><a id="more"></a><h3 id="FaceBoxes-A-CPU-Real-time-Face-Detector-with-High-Accuracy"><a href="#FaceBoxes-A-CPU-Real-time-Face-Detector-with-High-Accuracy" class="headerlink" title="FaceBoxes: A CPU Real-time Face Detector with High Accuracy"></a>FaceBoxes: A CPU Real-time Face Detector with High Accuracy</h3><p>论文阅读：FaceBoxes: A CPU Real-time Face Detector with High Accuracy</p><p>文章： <a href="http://cn.arxiv.org/abs/1708.05234">http://cn.arxiv.org/abs/1708.05234</a></p><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>2个挑战：</p><p>1) 在杂乱背景下人脸视角大的变化需要人脸检测器精准的解决复杂人脸和非人脸的分类问题。</p><p>2) 较大的搜索空间和人脸尺寸进一步增加了时间效率的需要。</p><p>​        传统方法效率高但在人脸大的视角变化下精度不够，基于CNN的方法精度高但速度很慢。受到Faster R-CNN的RPN以及SSD中多尺度机制的启发，便有了这篇可以在CPU上实时跑的FaceBoxes。</p><h4 id="FaceBoxes"><a href="#FaceBoxes" class="headerlink" title="FaceBoxes"></a>FaceBoxes</h4><p><strong>（1）RDCL：Rapidly Digested Convolutional Layers, 加速计算</strong></p><p>​    缩小输入的空间大小：为了快速减小输入的空间尺度大小，在卷积核池化上使用了一系列的大的stride,在Conv1,Pool1,Conv2,Pool2上stride分别是4,2,2,2,RDCL的stride一共是32，意味着输入的尺度大小被快速减小了32倍。这里是区别于YOLO v3 的关键， YOLO v3 整体下降了32倍，这里仅仅在 RDCL 部分就下降了32倍，参数量是少了很多，可以加快速度，这个点还是值得借鉴的</p><ul><li><p>选择合适的kernel size：一个网络开始的一些层的kernel size应该比较小以用来加速，同时也应该足够大用以减轻空间大小减小带来的信息损失。Conv1,Conv2和所有的Pool分别选取7x7, 5x5, 3x3的kernel size。</p></li><li><p>减少输出通道数：使用C.ReLU来增加输出通道数，比使用卷积增加通道数需要的参数量更少。</p></li></ul><p><strong>（2）MSCL：Multiple Scale Convolutional Layers,丰富感受野，使不同层的anchor离散化以处理多尺度人脸</strong></p><p>　　将RPN作为一个人脸检测器，不能获取很好的性能有以下两个原因：(1) RPN中的anchor只和最后一个卷积层相关，其中的特征和分辨率在处理人脸变化上太弱。(2) anchor相应的层使用一系列不同的尺度来检测人脸，但只有单一的感受野，不能匹配不同尺度的人脸。</p><p>　　为解决这个问题，对MSCL从以下两个角度去设计：</p><p>　　Multi-scale design along the dimension of network depth.如下图，anchor在多尺度的feature map上面取，类似SSD。</p><p><img src="/2019/04/13/FaceBoxes/1.png" alt="img"></p><p>Multi-scale design along the dimension of network width.使用inception模块，内部使用不同大小的卷积核，可以捕获到更多的尺度信息。</p><p><strong>（3）Anchor densification strategy：</strong></p><p> Inception的anchor尺度为32<em>32,64</em>64,128<em>128,Conv3_2、Conv4_2的尺度分别为256</em>256和512<em>512。比如Conv3_2的stride是64、anchor大小为256</em>256，表示对应输入图片每64像素大小有一个256*256的anchor。</p><p><img src="/2019/04/13/FaceBoxes/2.png" alt="img"></p><p>​    我们定义 anchor密度为：Adensity = Ascale/Ainterval。Ascale表示anchor的尺度，Ainterval表示anchor间隔。</p><p>​    显然在不同尺度上anchor的密度不均衡。相比大的anchor（128-256-512），小的anchor（32和64）过于稀疏，将会导致在小脸检测中低的召回率。</p><p>为解决不均衡问题，此处提出新的anchor策略。为了加大一种anchor的密度，在一个感受野的中心均匀的堆叠n^2 个anchor（本来是1个）用来预测。文章里对32<em>32的anchor做了4倍，对64</em>64的anchor做了2倍，这样就可以保证不同尺度的anchor有相同的密度。</p><p><img src="/2019/04/13/FaceBoxes/3.png" alt="img"></p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><h5 id="1-Training-dataset"><a href="#1-Training-dataset" class="headerlink" title="1. Training dataset:"></a>1. Training dataset:</h5><p>​    WIDER FACE的子集，12880个图片。</p><p><strong>（1）Data augmentation:</strong></p><ul><li><p>Color distorition:根据<a href="https://arxiv.org/ftp/arxiv/papers/1312/1312.5402.pdf">《Some Improvements on Deep Convolutional Neural Network Based Image Classification》</a></p></li><li><p>Random cropping: 从原图中随机裁剪5个方块patch:一个最大方块，其他的分别在范围[0.3, 1]之于原图尺寸。</p></li><li><p>Scale transformation:将随机裁剪后的方块patch给resize到1024*1024.</p></li><li><p>Horizontal flipping: 0.5的概率翻转。</p></li><li><p>Face-box filter: 如果face box的中心在处理后的图片上，则保持其重叠，然后将高或宽小于20像素的face box过滤出来。</p></li></ul><p><strong>（2）Matching strategy:</strong></p><p>​    在训练时需要判断哪个anchor是和哪个face bounding box相关的。首先使用jaccard overlap将每个脸和anchor对应起来，然后对anchor和任意脸jaccard overlap高于阈值（0.35）的匹配起来。</p><p><strong>（3）Loss function:</strong></p><p>​    和Faster R-CNN中的RPN用同样的loss,一个2分类的softmax loss用来做分类，smooth L1用来做回归。</p><p><strong>（4）Hard negative mining:</strong></p><p>在anchor匹配后，大多数anchor都是负样本，导致正样本和负样本严重不均衡。为了更快更稳定的训练，将他们按照loss值排序并选取最高的几个，保证正样本和负样本的比例最高不超过3:1.</p><p><strong>（5）Other implementation details:</strong></p><p>​    Xavier随机初始化、优化器SGD、momentum:0.9、weight decay:5e-4，batch size:32，迭代最大次数:120k，初始80k迭代learning rate:1e-3，80-100k迭代用1e-4，,100-120k迭代用1e-5，使用caffe实现。</p><h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p><img src="/2019/04/13/FaceBoxes/4.png" alt="img"></p><p><strong>(2) Model analysis</strong></p><p>​    FDDB相比 AFW 和 PASCAL face 较为困难，因此这里在FDDB上作分析。</p><p><strong>(2) Ablative Setting:</strong></p><p>1) 去掉 anchor densification strategy. =&gt; Anchor densification strategy is crucial.  这种 anchor 策略也提升了大约1个百分点</p><p>2)把 MSCL 替换为三层卷积，其大小都为3*3，输出数都和MSCL中前三个Inception的保持一致. 同时，把anchor只和最后一层卷积关联。 =&gt; MSCL is better.  稍微慢了 1点，但是精度提高了一个点（！FPN 已经成为现有网络都借鉴的一点）</p><p>3)把RDCL中的C.ReLU替换为ReLU。=&gt; RDCL is efficient and accuracy-preserving. 不改变精确度的情况下， 提升了大约 1/3 的速度</p><p><img src="/2019/04/13/FaceBoxes/5.png" alt="img"></p><p><strong>(3) 实验结果:</strong></p><p>AFW:</p><p><img src="/2019/04/13/FaceBoxes/6.png" alt="img"></p><p>PASCAL face:</p><p><img src="/2019/04/13/FaceBoxes/7.png" alt="img"></p><p>FDDB:</p><p><img src="/2019/04/13/FaceBoxes/8.png" alt="img"></p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><ul><li>大卷积快速降低运算量 + CReLU</li><li>anchor 采样机制</li><li>多尺度特征融合</li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MTCNN</title>
    <link href="/2019/04/13/MTCNN/"/>
    <url>/2019/04/13/MTCNN/</url>
    
    <content type="html"><![CDATA[<p>论文阅读: MTCNN  Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks</p><a id="more"></a><h4 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h4><p>​    相比于R-CNN系列通用检测方法，本文更加针对人脸检测这一专门的任务，速度和精度都有足够的提升。R-CNN，Fast R-CNN，FasterR-CNN这一系列的方法不是一篇博客能讲清楚的，有兴趣可以找相关论文阅读。类似于TCDCN，<strong>本文提出了一种 Multi-task的人脸检测框架，将人脸检测和人脸特征点检测同时进行。论文使用3个CNN级联的方式，和Viola-Jones类似，实现了coarse-to-fine的算法结构</strong>。</p><h4 id="2-框架"><a href="#2-框架" class="headerlink" title="2. 框架"></a>2. 框架</h4><p><strong>（1）.算法流程</strong></p><p><img src="/2019/04/13/MTCNN/1.jpg" alt="algorithm flow"></p><p><strong>当给定一张照片的时候，将其缩放到不同尺度形成图像金字塔，以达到尺度不变。</strong></p><p><strong>Stage 1：使用P-Net是一个全卷积网络，用来生成候选窗和边框回归向量(bounding box regression vectors)。使用Bounding box regression的方法来校正这些候选窗，使用非极大值抑制（NMS）合并重叠的候选框。全卷积网络和Faster R-CNN中的RPN一脉相承。</strong></p><p><strong>Stage 2：使用N-Net改善候选窗。将通过P-Net的候选窗输入R-Net中，拒绝掉大部分false的窗口，继续使用Bounding box regression和NMS合并。</strong></p><p><strong>Stage 3：最后使用O-Net输出最终的人脸框和特征点位置。和第二步类似，但是不同的是生成5个特征点位置。</strong></p><p><strong>（2）CNN结构</strong></p><p>本文使用三个CNN，结构如图：</p><p><img src="/2019/04/13/MTCNN/2.png" alt="MTCNN"></p><p><strong>（3）.训练</strong></p><p>这个算法需要实现三个任务的学习：人脸非人脸的分类，bounding box regression和人脸特征点定位。</p><p>(1)人脸检测</p><p>这就是一个分类任务，使用交叉熵损失函数即可：</p><script type="math/tex; mode=display">L_i^{det} = -(y_i^{det}log(p_i)+(1-y_i^{det})(1-log(p_i)))</script><p>(2)Bounding box regression</p><p>这是一个回归问题，使用平方和损失函数：</p><script type="math/tex; mode=display">L_i^{box} = || y_i^{box} - y_i^{box} ||_2^2</script><p>(3)人脸特征点定位</p><p>这也是一个回归问题，目标是5个特征点与标定好的数据的平方和损失：</p><script type="math/tex; mode=display">L_i^{Landmark} = ||y_i^{landmark} - y_i^{landmark}||</script><p><strong>(4)多任务训练</strong></p><p>不是每个sample都要使用这三种损失函数的，比如对于背景只需要计算$L^{det}_i$，不需要计算别的损失，这样就需要引入一个指示值指示样本是否需要计算某一项损失。最终的训练目标函数是：</p><script type="math/tex; mode=display">min\sum_{i=1}^{N} \sum_{j \in \{det,box,landmark\}} \alpha_j\beta_i^jL_i^j</script><p>N是训练样本的数量，$\alpha<em>j$表示任务的重要性。在 P-Net 和 R-Net 中，$\alpha</em>{det}=1, \alpha<em>{box}=0.5, \alpha</em>{landmark}=0.5$，在O-Net中，$\alpha<em>{det}=1, \alpha</em>{box}=0.5, \alpha_{landmark}=1$</p><p><strong>(5)online hard sample mining</strong></p><p>传统的难例处理方法是检测过一次以后，手动检测哪些困难的样本无法被分类，本文采用online hard sample mining的方法。具体就是在每个mini-batch中，取loss最大的70%进行反向传播，忽略那些简单的样本。</p><h4 id="3-实验"><a href="#3-实验" class="headerlink" title="3. 实验"></a>3. 实验</h4><p>本文主要使用三个数据集进行训练：FDDB，Wider Face，AFLW。</p><p>A、训练数据</p><p>本文将数据分成4种：</p><p>Negative：非人脸 </p><p>Positive：人脸 </p><p>Part faces：部分人脸 </p><p>Landmark face：标记好特征点的人脸</p><p>分别用于训练三种不同的任务。Negative和Positive用于人脸分类，positive和part faces用于bounding box regression，landmark face用于特征点定位。</p><p>B、效果</p><p>本文的人脸检测和人脸特征点定位的效果都非常好。关键是这个算法速度很快，在2.6GHZ的CPU上达到16fps，在Nvidia Titan达到99fps。</p><h4 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h4><p>本文使用一种级联的结构进行人脸检测和特征点检测，该方法速度快效果好，可以考虑在移动设备上使用。这种方法也是一种由粗到细的方法，和Viola-Jones的级联AdaBoost思路相似。</p><p>类似于Viola-Jones：1、如何选择待检测区域：图像金字塔+P-Net；2、如何提取目标特征：CNN；3、如何判断是不是指定目标：级联判断。</p><h4 id="5-训练流程"><a href="#5-训练流程" class="headerlink" title="5. 训练流程"></a>5. 训练流程</h4><p>第一阶段：首先对原图片构建一个金字塔，对不同尺寸的图片调整到12x12输入到PNet(Propossal)中，PNet会返回诸多的Bbox，利用nms选取合适的Bbox。</p><p>第二阶段，由PNet得出的候选框输送给RNet(Refine)， RNet会对相应的Bbox进行精细回归，并返回置信度。利用nms对精细回归后的Bbox进行nms选取， 并舍弃相应的置信度较低的人脸。</p><p>第三阶段和第二阶段相似，只不过最后会返回相应的Landmark坐标。</p><p>具体的训练过程如下所示：</p><p><img src="/2019/04/13/MTCNN/train_step.png" alt></p><p><strong>具体的技术细节：</strong></p><p><strong>(1) 如何构造金字塔：</strong></p><p>如果输入图像为100×120, 假设输入图像中存在一个人脸，则其中人脸最小为20×20，最大为100×100——对应图像较短边长, 为了将人脸放缩到12×12，同时保证相邻层间缩放比率factor=0.709，则金子塔中图像尺寸依次为 60×72、52×61、36×43、26×31、18×22、13×16，其中60×72对应把20×20的人脸缩放到12×12，13×16对应把100×100的人脸缩放到12×12</p><pre><code class="hljs python"><span class="hljs-comment"># scales for scaling the image</span>scales = [] m = min_detection_size/min_face_sizemin_length *= m factor_count = <span class="hljs-number">0</span><span class="hljs-keyword">while</span> min_length &gt; min_detection_size:      scales.append(m*factor**factor_count)    min_length *= factor      factor_count += <span class="hljs-number">1</span></code></pre><p><strong>(2) 如何生成训练数据?</strong></p><p>PNet 网络：pos、part、neg 是随机裁剪得到的图像，landmark截取的是带有关键点的图像。将这些图像都resize成12x12 作为PNet的输入。</p><p>RNet网络：图片(金字塔之后)经过PNet 产生产生的大量人脸框，然后将其resize为 24x24大小作为Rnet 输入。</p><p>ONet网络： 图片(金字塔之后)经过PNet 和 RNet 产生的过滤后的人脸框，然后将其 resize 为 48x48大小作为ONet 的输入。</p><p>注意：</p><ul><li>pos[IoU&gt;0.65]、part[0.4&lt;=IoU&lt;0.65]、neg[IoU&lt;0.3] </li><li>BBox 和 Landmark 都是需要进行归一化的</li></ul><p><strong>(2)NMS的基本原理：</strong> </p><p>非极大值抑制（NMS）顾名思义就是抑制不是极大值的元素，搜索局部的极大值。</p><ul><li>将所有框的得分降序排列，选中最高分及其对应的框。</li><li>遍历其余的框，如果和当前最高分框的重叠面积(IOU)大于一定阈值，我们就将框删除。</li><li>从未处理的框中继续选一个得分最高的，重复上述过程。</li></ul><pre><code class="hljs python"><span class="hljs-comment"># nms python cpu 实现</span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">py_cpu_nms</span>(<span class="hljs-params">dets, thresh</span>):</span>    <span class="hljs-string">&quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot;</span>    x1 = dets[:, <span class="hljs-number">0</span>]    y1 = dets[:, <span class="hljs-number">1</span>]    x2 = dets[:, <span class="hljs-number">2</span>]    y2 = dets[:, <span class="hljs-number">3</span>]    scores = dets[:, <span class="hljs-number">4</span>]    areas = (x2 - x1 + <span class="hljs-number">1</span>) * (y2 - y1 + <span class="hljs-number">1</span>)    order = scores.argsort()[::<span class="hljs-number">-1</span>]    keep = []    <span class="hljs-keyword">while</span> order.size &gt; <span class="hljs-number">0</span>:        i = order[<span class="hljs-number">0</span>]        keep.append(i)        xx1 = np.maximum(x1[i], x1[order[<span class="hljs-number">1</span>:]])        yy1 = np.maximum(y1[i], y1[order[<span class="hljs-number">1</span>:]])        xx2 = np.minimum(x2[i], x2[order[<span class="hljs-number">1</span>:]])        yy2 = np.minimum(y2[i], y2[order[<span class="hljs-number">1</span>:]])        w = np.maximum(<span class="hljs-number">0.0</span>, xx2 - xx1 + <span class="hljs-number">1</span>)        h = np.maximum(<span class="hljs-number">0.0</span>, yy2 - yy1 + <span class="hljs-number">1</span>)        inter = w * h        ovr = inter / (areas[i] + areas[order[<span class="hljs-number">1</span>:]] - inter)        inds = np.where(ovr &lt;= thresh)[<span class="hljs-number">0</span>]        order = order[inds + <span class="hljs-number">1</span>]    <span class="hljs-keyword">return</span> keep</code></pre><p><strong>（3）三个任务的损失是什么？函数如何平衡？</strong></p><p>第一个任务是分类任务：其损失函数为交叉熵损失函数。第二个任务和第三个任务均是回归任务，其损失是平方均差损失函数。通过加权 $\alpha$ 来平衡三个任务的权重：在 P-Net 和 R-Net 中，$\alpha<em>{det}=1$, $\alpha</em>{box}=0.5$, $\alpha<em>{landmark}=0.5$，在O-Net中，$\alpha</em>{det}=1$, $\alpha<em>{box}=0.5$, $\alpha</em>{landmark}=1$</p><p><strong>（4）论文的主要创新点？ 尽量简单概括</strong></p><p>​    通过级联三个卷积神经网络来实现人脸的检测和Landmark定位。另外本文也提出了一种online hard sample mining方法，具体就是在每个mini-batch中，取loss最大的70%进行反向传播，忽略那些简单的样本。</p><p><strong>（5）有什么改进措施？</strong></p><ul><li>融入 anchor机制， 同时可以修改损失函数为 focal loss</li><li>加大数据增强方法</li><li>bn层、leakey relu/prelu</li><li>模仿shufflenet、mobilenet进行改进提高速度</li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
    <tags>
      
      <tag>face、MTCNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Classification_neural_network</title>
    <link href="/2019/04/13/Classification-neural-network/"/>
    <url>/2019/04/13/Classification-neural-network/</url>
    
    <content type="html"><![CDATA[<p>本文主要梳理了四种主要常见的分类网络 alexnet、vgg、inception、resnet。</p><a id="more"></a><h3 id="一-较为基础的分类网络"><a href="#一-较为基础的分类网络" class="headerlink" title="一. 较为基础的分类网络"></a>一. 较为基础的分类网络</h3><h4 id="1-Alexnet"><a href="#1-Alexnet" class="headerlink" title="1. Alexnet"></a>1. Alexnet</h4><p>Alexnet 将 LeNet 的思想发扬光大，把CNN 的基本原理应用到了很深很宽的网络中。</p><p>AlexNet 主要用到的新技术点如下：</p><p>（1） 成功<strong>使用ReLU作为CNN 的激活函数</strong>，并验证其效果在较深的网络超过 Sigmoid， 成功解决了Sigmoid在网络较深时的梯度弥散问题。</p><p>（2） 训练时<strong>使用Dropout随机忽略一部分神经元，以避免过拟合</strong>。</p><p>（3）在CNN中<strong>使用重叠的最大池化</strong>。此前CNN 中普遍采用平均池化,AlexNet 全部使用最大池化，避免平均池化的模糊化效果。并且 AlexNet 中提出让步长比池化核的尺寸小，这样池化层的输出之间有重叠和覆盖，提高了特征的丰富性。</p><p>（4）提出<strong>LRN层，对局部神经元的活动创建竞争机制</strong>，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强模型的泛化能力。</p><p>（5） <strong>使用CUDA加速深度卷积网络的训练</strong>，利用GPU强大的并行能力，处理神经网络训练时大量的矩阵运算。</p><p>（6）<strong>数据增强</strong>，随机地从 256 x 256 的原始图像中截取 224 x 224 大小的区域（以及水平翻转的镜像）相当于增加了(256-224)^2 * 2 = 2048 倍的数据量。大大减轻了模型过拟合，提升泛化能力。同时 AlexNet 论文中提到了会对图像的RGB 数据进行PCA 处理，并对主成分做一个标准差为0.1的高斯扰动， 增加一些噪声。</p><p><img src="/2019/04/13/Classification-neural-network/Alexnet.png" style="zoom:35%;"></p><h4 id="2-VGGNet"><a href="#2-VGGNet" class="headerlink" title="2. VGGNet"></a>2. VGGNet</h4><p><strong>VGGNet探索了卷积神经网络的深度与其性能之间的关系，通过反复堆叠3x3的小型卷积核和2x2 的最大池化层， VGGnet成功构筑了16~19层深的卷积神经网络</strong>。</p><p>（1）<strong>通过将多个卷积层堆叠在一起，可以减少参数数目的同时增加卷积层的非线性变换，使得CNN 对特征的学习能力更强</strong>。</p><p>（2）VGGNet 在训练时有个小技巧，先训练级别A 的简单网络，再复用A网络的权重来初始化后面几个复杂模型，这样训练收敛的速度更快。</p><p>（3）在测试，VGG 采用了 Multi-Scale 的方法，将 图像scale到一个尺寸Q， 并将图片输入卷积网络运算。再将不同尺寸Q的结果平均得到最后结果，这样提高图片数据的利用率并提升准确率。同时在训练中还是用了Multi-Scale 的方法做数据增强。</p><p><img src="/2019/04/13/Classification-neural-network/vgg.jpg" style="zoom:50%;"></p><h4 id="3-Google-Inception-Net"><a href="#3-Google-Inception-Net" class="headerlink" title="3. Google Inception Net"></a>3. Google Inception Net</h4><p>（1）<strong>精心设计了 Inception Module提高参数的利用效率，其结构如下所示，Inception Module中包含3种不同尺寸的卷积核1个最大池化，增加了网络对不同尺度的适应性</strong>。</p><p>第一个分支对输入进行 1x1卷积，<strong>1x1卷积可以跨通道组织信息，提高网络的表达能力，同时可以对输出通道升维和降维</strong>。</p><p>第二个分支先使用了 1x1 卷积，然后连接 3x3 卷积，相当于进行两次特征变换。</p><p>第三个分支和第二个分支类似，先是使用了1x1 的卷积，然后连接 5x5 的卷积。</p><p>最后一个分支则是3x3 最大池化后直接使用1x1卷积。</p><p>Inception Module 的4个分支在最后通过一个聚合操作合并（再输出通道这个维度上聚合）</p><p><img src="/2019/04/13/Classification-neural-network/inception.png" alt="img" style="zoom:50%;"></p><p>（2） <strong>去除了最后的全连接层，用全局平均池化层来取代它</strong>。</p><h4 id="4-ResNet"><a href="#4-ResNet" class="headerlink" title="4. ResNet"></a>4. ResNet</h4><p>​    <strong>ResNet 通过调整网络结构来解决梯度消失问题</strong>（反向传播时，梯度将涉及多层参数的交叉相乘，可能会在离输入近的网络层中产生梯度消失的现象）。首先考虑两层神经网络的简单叠加，这时  x 经过两个网络层的变换得到H(x),  激活函数采用 ReLU， 如下图所示。既然离输入近的神经网络层较难训练，那么我们可以将它短接到更靠近输出的层，如下图所示。输入  经过两个神经网络变换得到F(x) , 同时也短接到两层之后，最后这个包含两层的神经网络模块输出H(x) = F(x) + x 。这样一来，F(x) 被设计为只需要拟合输入x与目标输入H(x)的残差H(x)-x ， 残差网络的名称也因此而来。如果某一层的输出已经较好的拟合了期望结果，那么多加入一层也不会使得模型变得更差，因为该层的输出将直接短接到两层之后，相当于直接学习了一个恒等映射，而跳过的两层只需要拟合上层输出和目标之间的残差即可。</p><p><img src="/2019/04/13/Classification-neural-network/resnet.png" alt="img" style="zoom:70%;"></p><pre><code class="hljs python"><span class="hljs-comment"># resnet basicblock</span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BasicBlock</span>(<span class="hljs-params">nn.Module</span>):</span>    expansion = <span class="hljs-number">1</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, inplanes, planes, stride=<span class="hljs-number">1</span>, downsample=None, groups=<span class="hljs-number">1</span>,</span></span><span class="hljs-function"><span class="hljs-params">                 base_width=<span class="hljs-number">64</span>, norm_layer=None</span>):</span>        super(BasicBlock, self).__init__()        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:            norm_layer = nn.BatchNorm2d        <span class="hljs-keyword">if</span> groups != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> base_width != <span class="hljs-number">64</span>:            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;BasicBlock only supports groups=1 and base_width=64&#x27;</span>)        <span class="hljs-comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span>        self.conv1 = conv3x3(inplanes, planes, stride)        self.bn1 = norm_layer(planes)        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)        self.conv2 = conv3x3(planes, planes)        self.bn2 = norm_layer(planes)        self.downsample = downsample        self.stride = stride    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        identity = x        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)        out = self.conv2(out)        out = self.bn2(out)        <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            identity = self.downsample(x)        out += identity        out = self.relu(out)        <span class="hljs-keyword">return</span> out</code></pre><h4 id="二、简述-Inception-V1-V4-网络-🌟"><a href="#二、简述-Inception-V1-V4-网络-🌟" class="headerlink" title="二、简述 Inception V1 - V4 网络? 🌟"></a>二、简述 Inception V1 - V4 网络? <strong>🌟</strong></h4><p><strong>Inception V1(GoogLeNet)</strong> <strong>精心设计了 Inception Module 来提高参数的利用效率</strong>，该模块包含3种不同尺寸的卷积核1个最大池化，增加了网络对不同尺度的适应性。(<strong>1x1conv、1x1conv+3x3conv、1x1conv+5x5conv、3x3pool+1x1conv</strong>)</p><p><strong>Inception V2</strong> 提出来 <strong>Batch Normalization</strong>,  用来加速网络收敛。</p><p><strong>Inception v3</strong> 改进了 Inception Module， <strong>将大卷积分解为对称的堆叠小卷积(VGG)</strong>, <strong>把n*n的卷积核替换成1*n和n*1的堆叠卷积核</strong>，在降低运算量的同时增加网络的非线性，减少过拟合。</p><p><strong>Inception v4</strong> 实际上是 <strong>inception + resnet</strong>。</p><pre><code class="hljs python"><span class="hljs-comment"># Inception </span><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Inception</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):</span>        super(Inception, self).__init__()        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="hljs-number">1</span>)        self.branch2 = nn.Sequential(            BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="hljs-number">1</span>),            BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)        )        self.branch3 = nn.Sequential(            BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="hljs-number">1</span>),            BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)        )        self.branch4 = nn.Sequential(            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">True</span>),            BasicConv2d(in_channels, pool_proj, kernel_size=<span class="hljs-number">1</span>)        )    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>        branch1 = self.branch1(x)        branch2 = self.branch2(x)        branch3 = self.branch3(x)        branch4 = self.branch4(x)        outputs = [branch1, branch2, branch3, branch4]        <span class="hljs-keyword">return</span> torch.cat(outputs, <span class="hljs-number">1</span>)</code></pre><h3 id="三-具体阐述一下你知道的resnet的相关变种"><a href="#三-具体阐述一下你知道的resnet的相关变种" class="headerlink" title="三. 具体阐述一下你知道的resnet的相关变种 ?"></a>三. 具体阐述一下你知道的resnet的相关变种 ?</h3><h5 id="1-resnetv2"><a href="#1-resnetv2" class="headerlink" title="1. resnetv2"></a>1. resnetv2</h5><ul><li><p>将激活函数放置在旁路中, short-cut 构建 clean information path</p></li><li><p>旁路中的结构从 <strong>conv-bn-relu</strong> 转换为 <strong>bn-relu-conv</strong></p></li></ul><p><img src="/2019/04/13/Classification-neural-network/18.png" style="zoom:30%;"></p><h5 id="2-resnext"><a href="#2-resnext" class="headerlink" title="2. resnext"></a>2. resnext</h5><p>​        借鉴了 Inception split-transform-merge 的模式， 将单路卷积变成多个支路的多路卷积，不过分组结构一致，进行分组卷积。</p><p><img src="/2019/04/13/Classification-neural-network/20.png" style="zoom:30%;"></p><h5 id="3-SENet"><a href="#3-SENet" class="headerlink" title="3. SENet"></a>3. SENet</h5><p>​        采用了一种全新的<strong>「特征重标定」</strong>的策略。具体来说，<strong>就是通过学习的方式来自动获取到每个特征通道的重要程度，然后依照这个重要程度去提升有用的特征并抑制对当前任务用处不大的特征。</strong></p><p><img src="/2019/04/13/Classification-neural-network/6.png" style="zoom:70%;"></p><h5 id="4-Densenet"><a href="#4-Densenet" class="headerlink" title="4. Densenet"></a>4. Densenet</h5><p>​    DenseNet 的目标是提升网络层级间信息流与梯度流的效率，并提高参数效率。它也如同 ResNet那样连接前层特征图与后层特征图，但 DenseNet 并不会像 ResNet 那样对两个特征图求和，而是直接将特征图按深度相互拼接在一起。DenseNet最大的特点即<strong>每一层的输出都会作为后面所有层的输入，这样最后一层将拼接前面所有层级的输出特征图。这种结构确保了每一层能从损失函数直接访问到梯度，因此可以训练非常深的网络</strong>。</p><h5 id="5-res2net"><a href="#5-res2net" class="headerlink" title="5. res2net"></a>5. res2net</h5><h5 id="Paper-Res2Net-A-New-Multi-scale-Backbone-Architecture"><a href="#Paper-Res2Net-A-New-Multi-scale-Backbone-Architecture" class="headerlink" title="Paper:  Res2Net: A New Multi-scale Backbone Architecture"></a>Paper:  Res2Net: A New Multi-scale Backbone Architecture</h5><h5 id="Methods"><a href="#Methods" class="headerlink" title="Methods:"></a>Methods:</h5><p>作者提出了一种在更加细粒度 (卷积层) 的层面提升多尺度表达能力。其基本结构如下图(b) 所示：</p><p><img src="/Users/zhichaozhao/Documents/hexo-blog/source/_posts/recent-convolutions/3.png" alt></p><p>传统的resnet结构如上图所示，作者在其基础上进行改进，在不增加计算量的同时，使其具备更强的多尺度提取能力。如上图（b）所示，作者采用了更小的卷积组来替代 bottleneck block 里面的 3x3 卷积。具体操作为：</p><ul><li>首先将 1x1 卷积后的特征图均分为 s 个特征图子集。每个特征图子集的大小相同，但是通道数是输入特征图的 1/s。</li><li>对每一个特征图子集 $X<em>i$，有一个对应的 3x3 卷积 $K_i$ , 假设 $K_i$的输出是 $y_i$。接下来每个特征图子集 $X_i $会加上 $K</em>{i-1}$ 的输出，然后一起输入进 $K_i$。为了在增大 s 的值时减少参数量，作者省去了 $X_1$ 的 3x3 网络。因此，输出 $y_i$ 可以用如下公式表示：</li></ul><script type="math/tex; mode=display">y_i = \begin{equation}\begin{cases}x_i && i=1;\\K_i(x_i+y_{i-1}) && 1 < i \leq s.\end{cases}\end{equation}</script><p>根据图(b)，可以发现每一个 $X_j (j&lt;=i)$ 下的 3x3 卷积可以利用之前所有的特性信息，它的输出会有比 $X_j$ 更大的感受野。因此这样的组合可以使 Res2Net 的输出有更多样的感受野信息。为了更好的融合不同尺度的信息，作者将它们的输出拼接起来，然后再送入 1x1 卷积，如上图（b）所示。</p><h3 id="四-一些问题"><a href="#四-一些问题" class="headerlink" title="四. 一些问题"></a>四. 一些问题</h3><ul><li>关于通道的求和与拼接 ?</li></ul><p>​    (1) 常见的 add 操作见于 resnet 和 FPN、CPN。 而 concat 操作见于 Unet 和 Dense net。</p><p>​    (2) add等价于concat之后对应通道共享同一个卷积核。当两路输入可以具有“对应通道的特征图语义类似” 的性质的时候，可以用add来替代concat，这样更节省参数和计算量（concat是add的2倍）。</p>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
    <tags>
      
      <tag>classification</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>create user and setup security</title>
    <link href="/2019/04/12/create-user-and-setup-security/"/>
    <url>/2019/04/12/create-user-and-setup-security/</url>
    
    <content type="html"><![CDATA[<p>Let’s create a new user and then setup some security.</p><h3 id="1-New-User"><a href="#1-New-User" class="headerlink" title="1. New User"></a>1. New User</h3><p>login first</p><pre><code class="hljs shell">mkdfideloper<span class="hljs-meta">#</span><span class="bash"> Create password, skip extra field and Set Y to save the new user</span></code></pre><p>Become new user fideloper</p><pre><code class="hljs ebnf"><span class="hljs-attribute">sudo su fideloper</span></code></pre><p>Head to home directory</p><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ~/</code></pre><p>See the file path</p><pre><code class="hljs bash"><span class="hljs-built_in">pwd</span> <span class="hljs-comment"># /home/ubuntu</span></code></pre><h3 id="2-Setup-SSH-Key-Authentication"><a href="#2-Setup-SSH-Key-Authentication" class="headerlink" title="2 . Setup SSH Key Authentication"></a>2 . Setup SSH Key Authentication</h3><p>We can re-use the SSH key we created to allow us to log in as user root. On our Mac, we can get the public key into our clipboard again:</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> On our host (Macintosh):</span>cat ~/.ssh/id_sfh_start.pub | pbcopy</code></pre><p>Then over in the server, add that public key to user fideloper’s authorized_keys file:</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> Logged <span class="hljs-keyword">in</span> as user fideloper</span>cd ~mkdir .sshvim .ssh/authorized_keys <span class="hljs-meta">#</span><span class="bash"> Paste <span class="hljs-keyword">in</span> the public key </span></code></pre><h3 id="3-Disallow-Root-Login"><a href="#3-Disallow-Root-Login" class="headerlink" title="3. Disallow Root Login"></a>3. Disallow Root Login</h3><p>First, we want user fideloper to be able to use sudo commands, so we don’t need the root user to perform administrative tasks.</p><pre><code class="hljs dockerfile">sudo <span class="hljs-keyword">user</span></code></pre><p>We can do this easily in Ubuntu by adding the user fideloper to the group sudo or admin (More explanation on that within the video).</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> Append (-a) secondary group (-G) <span class="hljs-string">&quot;admin&quot;</span> to user <span class="hljs-string">&quot;fideloper&quot;</span></span>usermod -aG admin fideloper</code></pre><p>Then log out, and log back in as user fideloper and you’ll be able to use sudocommands. Next, let’s secure our server further and disallow root. </p><h4 id="Configure-SSH"><a href="#Configure-SSH" class="headerlink" title="Configure SSH"></a>Configure SSH</h4><p>Now that user fideloper can do administrative tasks (thingsrequiring super user access), let’s edit the SSH daemonconfiguration to change this.</p><p>We’ll do two things:</p><ul><li><p>Disallow password based authentication</p></li><li><p>Disallow root user login</p></li></ul><p>Do to that, we update the file <code>/etc/ssh/sshd_config</code> and change the following: </p><pre><code class="hljs yaml"><span class="hljs-comment"># Disallow root login over ssh</span><span class="hljs-string">PermitRootLogin</span> <span class="hljs-literal">no</span> <span class="hljs-comment"># Disallow password authentication</span><span class="hljs-string">PasswordAuthentication</span> <span class="hljs-literal">no</span></code></pre><p> Then restart the SSH daemon: </p><pre><code class="hljs routeros">sudo<span class="hljs-built_in"> service </span>ssh restart</code></pre><p>And you’re all set!</p><p><strong>reference</strong>:<a href="https://serversforhackers.com/c/creating-users-">https://serversforhackers.com/c/creating-users-</a> and-ssh-security</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>常用开发工具</title>
    <link href="/2019/04/10/Dev-tools/"/>
    <url>/2019/04/10/Dev-tools/</url>
    
    <content type="html"><![CDATA[<h4 id="1-Mac-必备软件"><a href="#1-Mac-必备软件" class="headerlink" title="1. Mac 必备软件"></a>1. Mac 必备软件</h4><p>快捷键查询：cheat sheet</p><p>软件安装与下载：brew</p><p>Github：Github Desktop</p><p>图片标记： 圈点</p><p>远程会议： TeamViewer</p><p>待办事项：Things3</p><p>防止待机软件： caffeine</p><p>文档/API查询: Dash</p><p>护眼：Flux</p><p>影音播放：IINA</p><p>下载 Motrix</p><h4 id="2-Python"><a href="#2-Python" class="headerlink" title="2. Python"></a>2. Python</h4><p>2/3版本管理: anaconda </p><p>Python 代码可视化工具 yapf</p><h4 id="3-笔记类软件"><a href="#3-笔记类软件" class="headerlink" title="3. 笔记类软件"></a>3. 笔记类软件</h4><p>Markdown：Typora</p><p>笔记软件：evernote、有道云笔记</p><p>pdf 阅读：PDF Expert、margin note3、adobe reader、预览</p><p>编辑器： Sublime Text3、Visual Studio Code</p><p>论文编辑：Latex</p><h4 id="4-思维导图："><a href="#4-思维导图：" class="headerlink" title="4. 思维导图："></a>4. 思维导图：</h4><p>Xmind ZEN</p><p>MindNode</p><h4 id="5-chrome-插件"><a href="#5-chrome-插件" class="headerlink" title="5. chrome 插件"></a>5. chrome 插件</h4><p>Firshot:    网页截图</p><p>oneTab:    固定网页</p><p>grammarly:      语法检测</p><p>pocket：   网页收藏</p><p>Twitter Web：  推特web</p><p>adblock Plus:   广告拦截 </p><p>chaZD：   查字典</p><p>google Translate: google   翻译</p><p>Tampermonkey    油猴， 插件管理</p><p>User-Agent Switcher for Chrome 1.1.0     User-Agent 切换， 用于百度不限速下载</p><p>SourceGraph ：  github 助手</p><h4 id="6-开发工具"><a href="#6-开发工具" class="headerlink" title="6. 开发工具"></a>6. 开发工具</h4><p>代码比对： Beyond compare</p><p>代码阅读：Sourcetrail</p><p>反编译：hopper disassembler</p><h4 id="7-其他"><a href="#7-其他" class="headerlink" title="7. 其他"></a>7. 其他</h4><p><strong>jupyter_contrib_nbextension</strong>: jupyter notebook 插件</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>FDDB测评</title>
    <link href="/2019/04/06/FDDB-benchmark/"/>
    <url>/2019/04/06/FDDB-benchmark/</url>
    
    <content type="html"><![CDATA[<h4 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h4><h5 id="（1）下载-FDDB-相关文件"><a href="#（1）下载-FDDB-相关文件" class="headerlink" title="（1）下载 FDDB 相关文件"></a>（1）下载 FDDB 相关文件</h5><ul><li>从 <a href="http://vis-www.cs.umass.edu/fddb/index.html">官网</a>下载 FDDB 数据集，解压得到 <strong>originalPics</strong> 文件夹，<strong>FDDB-folds</strong> 文件夹和 <strong>README.txt</strong> </li><li>到 <a href="http://vis-www.cs.umass.edu/fddb/results.html">results 页面</a> 下载评估程序，解压得到 evaluation 文件夹。</li></ul><h5 id="（2）准备-txt-文件"><a href="#（2）准备-txt-文件" class="headerlink" title="（2）准备 .txt 文件"></a>（2）准备 .txt 文件</h5><p>用你的模型按照 FDDB-folds/FDDB-fold-i.txt 的顺序检测图片，生成与之对应的 10 个 fold-i-out.txt，存放在 out-folds 文件夹中，并合并或复制粘贴成 results.txt。结果文件的格式需要为 </p><pre><code class="hljs tex">... image name i number of faces in this image =im face i1 face i2 ... face im ...</code></pre><h5 id="（3）安装-OPENCV（v3-2）"><a href="#（3）安装-OPENCV（v3-2）" class="headerlink" title="（3）安装 OPENCV（v3.2）"></a>（3）安装 OPENCV（v3.2）</h5><h5 id="（4）安装-gnuplot"><a href="#（4）安装-gnuplot" class="headerlink" title="（4）安装 gnuplot"></a>（4）安装 gnuplot</h5><p>Ubuntu 上执行如下命令：</p><pre><code class="hljs shell">sudo apt-get install gnuplot</code></pre><h4 id="2-编译-evalution"><a href="#2-编译-evalution" class="headerlink" title="2. 编译 evalution"></a>2. 编译 evalution</h4><h5 id="（1）修改Makefile-文件："><a href="#（1）修改Makefile-文件：" class="headerlink" title="（1）修改Makefile 文件："></a>（1）修改Makefile 文件：</h5><p>打开evalution 文件夹下的MakeFile， 添加如下相应的行</p><pre><code class="hljs makefile">INCS = -I/usr/local/<span class="hljs-keyword">include</span>/opencvLIBS = -L/usr/local/lib -lopencv_core -lopencv_imgproc -lopencv_highgui       -lopencv_ml -lopencv_video -lopencv_features2d -lopencv_calib3d       -lopencv_objdetect -lopencv_contrib -lopencv_legacy<span class="hljs-comment"># 对于 opencv 3.2 去掉 -lopencv_contrib and -lopencv_legacy  加上 -lopencv_imgcodecs</span></code></pre><p>修改如下行：</p><pre><code class="hljs gams"># evaluate: <span class="hljs-symbol">$</span>(OBJS)#        <span class="hljs-symbol">$</span>(CC) <span class="hljs-symbol">$</span>(LIBS) <span class="hljs-symbol">$</span>(OBJS) -o <span class="hljs-symbol">$</span>@evaluate: <span class="hljs-symbol">$</span>(OBJS)    <span class="hljs-symbol">$</span>(CC) <span class="hljs-symbol">$</span>(OBJS) -o <span class="hljs-symbol">$</span>@ <span class="hljs-symbol">$</span>(LIBS)</code></pre><h5 id="（2）修改-common-hpp"><a href="#（2）修改-common-hpp" class="headerlink" title="（2）修改 common.hpp"></a>（2）修改 common.hpp</h5><p>打开 evaluation 文件夹下的 common.hpp，将</p><pre><code class="hljs cpp"><span class="hljs-comment">// #define __IMAGE_FORMAT__ &quot;.jpg&quot;</span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __IMAGE_FORMAT__ <span class="hljs-meta-string">&quot;.ppm&quot;</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __CVLOADIMAGE_WORKING__</span></code></pre><p>修改为：</p><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __IMAGE_FORMAT__ <span class="hljs-meta-string">&quot;.jpg&quot;</span></span><span class="hljs-comment">// #define __IMAGE_FORMAT__ &quot;.ppm&quot;</span><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> __CVLOADIMAGE_WORKING__</span></code></pre><h5 id="（3）编译"><a href="#（3）编译" class="headerlink" title="（3）编译"></a>（3）编译</h5><pre><code class="hljs ebnf"><span class="hljs-attribute">make</span></code></pre><p>如果出现错误： <strong>fatal error</strong>: ‘cv.h’ file not found [Mac platform]</p><p><strong>solution</strong>: 找到对应文件：将其修改为</p><pre><code class="hljs cpp"><span class="hljs-comment">// #include &quot;opencv/cv.h&quot;</span><span class="hljs-comment">// #include &quot;opencv/highgui.h&quot;</span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;opencv/cv.h&quot;</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;opencv/highgui.h&quot;</span></span></code></pre><h4 id="3-输出文件并绘图"><a href="#3-输出文件并绘图" class="headerlink" title="3. 输出文件并绘图"></a>3. 输出文件并绘图</h4><h5 id="（1）修改-runEvaluate-pl"><a href="#（1）修改-runEvaluate-pl" class="headerlink" title="（1）修改 runEvaluate.pl"></a>（1）修改 runEvaluate.pl</h5><p>打开 evaluation 文件夹下的 runEvaluate.pl，填写路径如下：</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">where</span> gnuplot is</span>my $GNUPLOT = &quot;/usr/local/bin/gnuplot&quot;;<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">where</span> the binary is</span>my $evaluateBin = &quot;./evaluate&quot;;<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">where</span> the images are</span>my $imDir = &quot;../originalPics/&quot;;<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">where</span> the folds are</span>my $fddbDir = &quot;../FDDB-folds&quot;;<span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">where</span> the detections are</span>my $detDir = &quot;../results&quot;;</code></pre><p>注意若文件名称和路径与笔者 (见第 2 步中的截图) 不同，需要相应修改。</p><h5 id="（2）执行-runEvaluate-pl"><a href="#（2）执行-runEvaluate-pl" class="headerlink" title="（2）执行 runEvaluate.pl"></a>（2）执行 runEvaluate.pl</h5><pre><code class="hljs reasonml">perl runEvaluate.pl 完成后在 results 文件夹下生成了 <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">ContROC</span>.</span></span>txt, <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">DiscROC</span>.</span></span>txt, <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">ContROC</span>.</span></span>png 和 <span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">DiscROC</span>.</span></span>png 四个文件。</code></pre>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch Cookbook</title>
    <link href="/2019/03/19/Pytorch-Cookbook/"/>
    <url>/2019/03/19/Pytorch-Cookbook/</url>
    
    <content type="html"><![CDATA[<p>🔥 一些 pytorch 编程的小技巧、trick 和 示例代码</p><a id="more"></a><p>本文代码基于PyTorch 1.0版本，需要用到以下包</p><pre><code class="hljs elm"><span class="hljs-keyword">import</span> collections<span class="hljs-keyword">import</span> os<span class="hljs-keyword">import</span> shutil<span class="hljs-keyword">import</span> tqdm<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-keyword">import</span> PIL.Image<span class="hljs-keyword">import</span> torch<span class="hljs-keyword">import</span> torchvision</code></pre><h3 id="1-基础配置"><a href="#1-基础配置" class="headerlink" title="1. 基础配置"></a>1. 基础配置</h3><h5 id="1-check-pytorch-version"><a href="#1-check-pytorch-version" class="headerlink" title="(1) check pytorch version"></a>(1) check pytorch version</h5><pre><code class="hljs python">torch.__version__               <span class="hljs-comment"># PyTorch version</span>torch.version.cuda              <span class="hljs-comment"># Corresponding CUDA version</span>torch.backends.cudnn.version()  <span class="hljs-comment"># Corresponding cuDNN version</span>torch.cuda.get_device_name(<span class="hljs-number">0</span>)   <span class="hljs-comment"># GPU type</span></code></pre><h5 id="2-update-pytorch"><a href="#2-update-pytorch" class="headerlink" title="(2) update pytorch"></a>(2) update pytorch</h5><pre><code class="hljs ebnf"><span class="hljs-attribute">conda update pytorch torchvision -c pytorch</span></code></pre><h5 id="3-random-seed-setting"><a href="#3-random-seed-setting" class="headerlink" title="(3) random seed setting"></a>(3) random seed setting</h5><pre><code class="hljs css"><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.manual_seed</span>(0) # <span class="hljs-selector-tag">CPU</span><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.manual_seed_all</span>(0) # <span class="hljs-selector-tag">GPU</span></code></pre><h5 id="4-指定程序运行在特定显卡上："><a href="#4-指定程序运行在特定显卡上：" class="headerlink" title="(4) 指定程序运行在特定显卡上："></a>(4) 指定程序运行在特定显卡上：</h5><p>在命令行指定环境变量</p><pre><code class="hljs angelscript">CUDA_VISIBLE_DEVICES=<span class="hljs-number">0</span>,<span class="hljs-number">1</span> python train.py</code></pre><p>在代码中指定</p><pre><code class="hljs lua"><span class="hljs-built_in">os</span>.environ[<span class="hljs-string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="hljs-string">&#x27;0,1&#x27;</span></code></pre><h5 id="5-判断是否有CUDA支持"><a href="#5-判断是否有CUDA支持" class="headerlink" title="(5) 判断是否有CUDA支持"></a>(5) 判断是否有CUDA支持</h5><pre><code class="hljs ceylon">torch.cuda.<span class="hljs-keyword">is</span><span class="hljs-number">_</span>available()torch.set<span class="hljs-number">_</span><span class="hljs-keyword">default</span><span class="hljs-number">_</span>tensor<span class="hljs-number">_</span>type(<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span>)   os.environ[<span class="hljs-string">&#x27;CUDA_LAUNCH_BLOCKING&#x27;</span>] = <span class="hljs-string">&#x27;1&#x27;</span></code></pre><h5 id="6-设置为cuDNN-benchmark模式"><a href="#6-设置为cuDNN-benchmark模式" class="headerlink" title="(6) 设置为cuDNN benchmark模式"></a>(6) 设置为cuDNN benchmark模式</h5><p>Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。</p><pre><code class="hljs ini"><span class="hljs-attr">toch.backends.cudnn.benchmark</span> = <span class="hljs-literal">True</span></code></pre><p>如果想要避免这种结果波动，设置</p><pre><code class="hljs ini"><span class="hljs-attr">torch.backends.cudnn.deterministic</span> = <span class="hljs-literal">True</span></code></pre><h5 id="7-手动清除GPU存储"><a href="#7-手动清除GPU存储" class="headerlink" title="(7) 手动清除GPU存储"></a>(7) 手动清除GPU存储</h5><p>有时Control-C中止运行后GPU存储没有及时释放，需要手动清空。在PyTorch内部可以</p><pre><code class="hljs css"><span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.empty_cache</span>()</code></pre><p>或在命令行可以先使用ps找到程序的PID，再使用kill结束该进程</p><pre><code class="hljs vim"><span class="hljs-keyword">ps</span> aux | <span class="hljs-keyword">grep</span> <span class="hljs-keyword">python</span>    kill -<span class="hljs-number">9</span> [pid]</code></pre><p>或者直接重置没有被清空的GPU</p><pre><code class="hljs ada">nvidia-smi <span class="hljs-comment">--gpu-reset -i [gpu_id]</span></code></pre><h3 id="2-模型"><a href="#2-模型" class="headerlink" title="2. 模型"></a>2. 模型</h3><h5 id="1-提取ImageNet预训练模型某层的卷积特征"><a href="#1-提取ImageNet预训练模型某层的卷积特征" class="headerlink" title="(1) 提取ImageNet预训练模型某层的卷积特征"></a>(1) 提取ImageNet预训练模型某层的卷积特征</h5><pre><code class="hljs gams"># VGG<span class="hljs-number">-16</span> relu5<span class="hljs-number">-3</span> feature.<span class="hljs-keyword">model</span> = torchvision.<span class="hljs-keyword">models</span>.vgg16(pretrained=True).features# VGG<span class="hljs-number">-16</span> pool5 feature.<span class="hljs-keyword">model</span> = torchvision.<span class="hljs-keyword">models</span>.vgg16(pretrained=True)<span class="hljs-keyword">model</span> = torch.nn.Sequential(<span class="hljs-keyword">model</span>.features, <span class="hljs-keyword">model</span>.avgpool)# VGG<span class="hljs-number">-16</span> fc7 feature.<span class="hljs-keyword">model</span> = torchvision.<span class="hljs-keyword">models</span>.vgg16(pretrained=True)<span class="hljs-keyword">model</span>.classifier = torch.nn.Sequential(*list(<span class="hljs-keyword">model</span>.classifier.children())[:<span class="hljs-number">-3</span>])# ResNet GAP feature.<span class="hljs-keyword">model</span> = torchvision.<span class="hljs-keyword">models</span>.resnet18(pretrained=True)<span class="hljs-keyword">model</span> = torch.nn.Sequential(collections.OrderedDict(    list(<span class="hljs-keyword">model</span>.named_children())[:<span class="hljs-number">-1</span>]))with torch.no_grad():    <span class="hljs-keyword">model</span>.eval()    conv_representation = <span class="hljs-keyword">model</span>(image)</code></pre><h5 id="2-提取ImageNet预训练模型多层的卷积特征"><a href="#2-提取ImageNet预训练模型多层的卷积特征" class="headerlink" title="(2) 提取ImageNet预训练模型多层的卷积特征"></a>(2) 提取ImageNet预训练模型多层的卷积特征</h5><pre><code class="hljs vim">class FeatureExtractor(torch.<span class="hljs-keyword">nn</span>.Module):    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;Helper class to extract several convolution features from the given</span>    <span class="hljs-keyword">pre</span>-trained model.    Attribute<span class="hljs-variable">s:</span>        _model, torch.<span class="hljs-keyword">nn</span>.Module.        _layers_to_extract, <span class="hljs-keyword">list</span><span class="hljs-symbol">&lt;str&gt;</span> <span class="hljs-built_in">or</span> <span class="hljs-keyword">set</span><span class="hljs-symbol">&lt;str&gt;</span>    Example:        &gt;&gt;&gt; model = torchvision.models.resnet152(pretrained=True)        &gt;&gt;&gt; model = torch.<span class="hljs-keyword">nn</span>.Sequential(collections.OrderedDict(                <span class="hljs-keyword">list</span>(model.named_children())[:-<span class="hljs-number">1</span>]))        &gt;&gt;&gt; conv_representation = FeatureExtractor(                pretrained_model=model,                layers_to_extract=&#123;<span class="hljs-string">&#x27;layer1&#x27;</span>, <span class="hljs-string">&#x27;layer2&#x27;</span>, <span class="hljs-string">&#x27;layer3&#x27;</span>, <span class="hljs-string">&#x27;layer4&#x27;</span>&#125;)(image)    <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment">&quot;</span>    def __init__(self, pretrained_model, layers_to_extract):        torch.<span class="hljs-keyword">nn</span>.Module.__init__(self)        self._model = pretrained_model        self._model.<span class="hljs-built_in">eval</span>()        self._layers_to_extract = <span class="hljs-keyword">set</span>(layers_to_extract)        def forward(self, <span class="hljs-keyword">x</span>):        with torch.no_grad():            conv_representation = []            <span class="hljs-keyword">for</span> name, layer in self._model.named_children():                <span class="hljs-keyword">x</span> = layer(<span class="hljs-keyword">x</span>)                <span class="hljs-keyword">if</span> name in self._layers_to_extrac<span class="hljs-variable">t:</span>                    conv_representation.<span class="hljs-keyword">append</span>(<span class="hljs-keyword">x</span>)            <span class="hljs-keyword">return</span> conv_representation</code></pre><h5 id="３-部分层使用预训练模型"><a href="#３-部分层使用预训练模型" class="headerlink" title="(３)  部分层使用预训练模型"></a>(３)  部分层使用预训练模型</h5><p>注意如果保存的模型是<code>torch.nn.DataParallel</code>，则当前的模型也需要是<code>torch.nn.DataParallel</code>。<code>torch.nn.DataParallel(model).module == model</code>。</p><pre><code class="hljs reasonml">model.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(&#x27;<span class="hljs-params">model</span>,<span class="hljs-params">pth</span>&#x27;)</span>, strict=False)</code></pre><p>将在GPU保存的模型加载到CPU:</p><pre><code class="hljs reasonml">model.load<span class="hljs-constructor">_state_dict(<span class="hljs-params">torch</span>.<span class="hljs-params">load</span>(&#x27;<span class="hljs-params">model</span>,<span class="hljs-params">pth</span>&#x27;, <span class="hljs-params">map_location</span>=&#x27;<span class="hljs-params">cpu</span>&#x27;)</span>)</code></pre><h5 id="（４）fine-tune-微调全连接层"><a href="#（４）fine-tune-微调全连接层" class="headerlink" title="（４）fine-tune 微调全连接层"></a>（４）fine-tune 微调全连接层</h5><h5 id="4-微调全连接层"><a href="#4-微调全连接层" class="headerlink" title="(4) 微调全连接层"></a>(4) 微调全连接层</h5><pre><code class="hljs nix"><span class="hljs-attr">model</span> = torchvision.models.resnet18(<span class="hljs-attr">pretrained=True)</span>for param <span class="hljs-keyword">in</span> model.parameters():    param.<span class="hljs-attr">requires_grad</span> = Falsemodel.<span class="hljs-attr">fc</span> = nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">100</span>)  <span class="hljs-comment"># Replace the last fc layer</span><span class="hljs-attr">optimizer</span> = torch.optim.SGD(model.fc.parameters(), <span class="hljs-attr">lr=1e-2,</span> <span class="hljs-attr">momentum=0.9,</span> <span class="hljs-attr">weight_decay=1e-4)</span></code></pre><p>以较大学习率微调全连接层，较小学习率微调卷积层</p><pre><code class="hljs ini"><span class="hljs-attr">model</span> = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<span class="hljs-attr">finetuned_parameters</span> = list(map(id, model.fc.parameters()))<span class="hljs-attr">conv_parameters</span> = (p for p in model.parameters() if id(p) not in finetuned_parameters)<span class="hljs-attr">parameters</span> = [&#123;<span class="hljs-string">&#x27;parameters&#x27;</span>: conv_parameters, <span class="hljs-string">&#x27;lr&#x27;</span>: <span class="hljs-number">1</span>e-<span class="hljs-number">3</span>&#125;,               &#123;<span class="hljs-string">&#x27;parameters&#x27;</span>: model.fc.parameters()&#125;]<span class="hljs-attr">optimizer</span> = torch.optim.SGD(parameters, lr=<span class="hljs-number">1</span>e-<span class="hljs-number">2</span>, momentum=<span class="hljs-number">0.9</span>, weight_decay=<span class="hljs-number">1</span>e-<span class="hljs-number">4</span>)</code></pre><h5 id="（５）保存与加载断点"><a href="#（５）保存与加载断点" class="headerlink" title="（５）保存与加载断点"></a>（５）保存与加载断点</h5><p>注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。</p><pre><code class="hljs lua"># Save checkpoint.is_best = current_acc &gt; best_accbest_acc = <span class="hljs-built_in">max</span>(best_acc, current_acc)checkpoint = &#123;    <span class="hljs-string">&#x27;best_acc&#x27;</span>: best_acc,        <span class="hljs-string">&#x27;epoch&#x27;</span>: t + <span class="hljs-number">1</span>,    <span class="hljs-string">&#x27;model&#x27;</span>: model.state_dict(),    <span class="hljs-string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),&#125;model_path = <span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-string">&#x27;model&#x27;</span>, <span class="hljs-string">&#x27;checkpoint.pth.tar&#x27;</span>)torch.save(checkpoint, model_path)<span class="hljs-keyword">if</span> is_best:    shutil.copy(<span class="hljs-string">&#x27;checkpoint.pth.tar&#x27;</span>, model_path)# Load checkpoint.<span class="hljs-keyword">if</span> <span class="hljs-built_in">resume</span>:    model_path = <span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.join(<span class="hljs-string">&#x27;model&#x27;</span>, <span class="hljs-string">&#x27;checkpoint.pth.tar&#x27;</span>)    <span class="hljs-built_in">assert</span> <span class="hljs-built_in">os</span>.<span class="hljs-built_in">path</span>.isfile(model_path)    checkpoint = torch.<span class="hljs-built_in">load</span>(model_path)    best_acc = checkpoint[<span class="hljs-string">&#x27;best_acc&#x27;</span>]    start_epoch = checkpoint[<span class="hljs-string">&#x27;epoch&#x27;</span>]    model.load_state_dict(checkpoint[<span class="hljs-string">&#x27;model&#x27;</span>])    optimizer.load_state_dict(checkpoint[<span class="hljs-string">&#x27;optimizer&#x27;</span>])    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Load checkpoint at epoch %d.&#x27;</span> % start_epoch)</code></pre><h5 id="６-计算模型参数量-D"><a href="#６-计算模型参数量-D" class="headerlink" title="(６) 计算模型参数量[D]"></a>(６) 计算模型参数量[D]</h5><pre><code class="hljs lisp"># Total parameters                    num_params = sum(<span class="hljs-name">p</span>.numel() for p in model.parameters()) # Trainable parametersnum_trainable_params = sum(<span class="hljs-name">p</span>.numel() for p in model.parameters() if p.requires_grad)</code></pre><h5 id="７-模型权值初始化-D"><a href="#７-模型权值初始化-D" class="headerlink" title="(７) 模型权值初始化[D]"></a>(７) 模型权值初始化[D]</h5><p>注意<code>model.modules()</code>和<code>model.children()</code>的区别：<code>model.modules()</code>会迭代地遍历模型的所有子层，而<code>model.children()</code>只会遍历模型下的一层。</p><pre><code class="hljs python"><span class="hljs-comment"># Common practise for initialization.</span><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> model.modules():    <span class="hljs-keyword">if</span> isinstance(m, torch.nn.Conv2d):        torch.nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>,                                      nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)        <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            torch.nn.init.constant_(m.bias, val=<span class="hljs-number">0.0</span>)        <span class="hljs-keyword">elif</span> isinstance(m, torch.nn.BatchNorm2d):        torch.nn.init.constant_(m.weight, <span class="hljs-number">1.0</span>)        torch.nn.init.constant_(m.bias, <span class="hljs-number">0.0</span>)      <span class="hljs-keyword">elif</span> isinstance(m, torch.nn.Linear):        torch.nn.init.xavier_normal_(m.weight)        <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:            torch.nn.init.constant_(m.bias, <span class="hljs-number">0.0</span>)<span class="hljs-comment"># Initialization with given tensor.</span>m.weight = torch.nn.Parameter(tensor)</code></pre><h5 id="8-冻结参数"><a href="#8-冻结参数" class="headerlink" title="(8) 冻结参数"></a>(8) 冻结参数</h5><pre><code class="hljs sqf"><span class="hljs-keyword">if</span> <span class="hljs-built_in">not</span> requires_grad:    <span class="hljs-keyword">for</span> <span class="hljs-built_in">param</span> <span class="hljs-built_in">in</span> self.parameters():        <span class="hljs-built_in">param</span>.requires_grad = <span class="hljs-literal">False</span></code></pre><h3 id="3-数据"><a href="#3-数据" class="headerlink" title="3. 数据"></a>3. 数据</h3><h5 id="1-常见训练和验证数据预处理"><a href="#1-常见训练和验证数据预处理" class="headerlink" title="(1) 常见训练和验证数据预处理"></a>(1) 常见训练和验证数据预处理</h5><p>ToTensor操作会将PIL.Image或形状为H×W×D，数值范围为[0, 255]的np.ndarray转换为形状为D×H×W，数值范围为[0.0, 1.0]的torch.Tensor。</p><pre><code class="hljs angelscript">train_transform = torchvision.transforms.Compose([    torchvision.transforms.RandomResizedCrop(size=<span class="hljs-number">224</span>,                                             scale=(<span class="hljs-number">0.08</span>, <span class="hljs-number">1.0</span>)),    torchvision.transforms.RandomHorizontalFlip(),    torchvision.transforms.ToTensor(),    torchvision.transforms.Normalize(mean=(<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>),                                     std=(<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>)), ]) val_transform = torchvision.transforms.Compose([    torchvision.transforms.Resize(<span class="hljs-number">224</span>),    torchvision.transforms.CenterCrop(<span class="hljs-number">224</span>),    torchvision.transforms.ToTensor(),    torchvision.transforms.Normalize(mean=(<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>),                                     std=(<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>)),])</code></pre><h3 id="4-训练"><a href="#4-训练" class="headerlink" title="4. 训练"></a>4. 训练</h3><h5 id="1-将整数标记转换成独热（one-hot）编码"><a href="#1-将整数标记转换成独热（one-hot）编码" class="headerlink" title="(1) 将整数标记转换成独热（one-hot）编码"></a>(1) 将整数标记转换成独热（one-hot）编码</h5><p> (PyTorch中的标记默认从0开始)</p><pre><code class="hljs routeros">N = tensor.size(0)one_hot = torch.zeros(N, num_classes).long()one_hot.scatter_(<span class="hljs-attribute">dim</span>=1, <span class="hljs-attribute">index</span>=torch.unsqueeze(tensor, <span class="hljs-attribute">dim</span>=1), <span class="hljs-attribute">src</span>=torch.ones(N, num_classes).long())</code></pre><h5 id="2-计算两组数据之间的两两欧式距离"><a href="#2-计算两组数据之间的两两欧式距离" class="headerlink" title="(2) 计算两组数据之间的两两欧式距离"></a>(2) 计算两组数据之间的两两欧式距离</h5><pre><code class="hljs markdown"><span class="hljs-section"># X1 is of shape m<span class="hljs-emphasis">*d.</span></span><span class="hljs-section"><span class="hljs-emphasis">X1 = torch.unsqueeze(X1, dim=1).expand(m, n, d)</span></span><span class="hljs-section"><span class="hljs-emphasis"># X2 is of shape n*</span>d.</span>X2 = torch.unsqueeze(X2, dim=0).expand(m, n, d)<span class="hljs-section"># dist is of shape m<span class="hljs-emphasis">*n, where dist[<span class="hljs-string">i</span>][<span class="hljs-symbol">j</span>] = sqrt(|X1[i, :] - X[j, :]|^2)</span></span><span class="hljs-section"><span class="hljs-emphasis">dist = torch.sqrt(torch.sum((X1 - X2) <span class="hljs-strong">** 2, dim=2))</span></span></span></code></pre><h5 id="3-双线性汇合（bilinear-pooling）"><a href="#3-双线性汇合（bilinear-pooling）" class="headerlink" title="(3) 双线性汇合（bilinear pooling）"></a>(3) 双线性汇合（bilinear pooling）</h5><pre><code class="hljs tp"><span class="hljs-keyword">X</span> = torch.reshape(N, D, H * <span class="hljs-keyword">W</span>)                        # Assume <span class="hljs-keyword">X</span> has shape N*D*H*<span class="hljs-keyword">W</span><span class="hljs-keyword">X</span> = torch.bmm(<span class="hljs-keyword">X</span>, torch.transpose(<span class="hljs-keyword">X</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)) / (H * <span class="hljs-keyword">W</span>)  # Bilinear poolingassert <span class="hljs-keyword">X</span>.size() == (N, D, D)<span class="hljs-keyword">X</span> = torch.reshape(<span class="hljs-keyword">X</span>, (N, D * D))<span class="hljs-keyword">X</span> = torch.sign(<span class="hljs-keyword">X</span>) * torch.sqrt(torch.abs(<span class="hljs-keyword">X</span>) + <span class="hljs-number">1e-5</span>)   # Signed-sqrt normalization<span class="hljs-keyword">X</span> = torch.nn.functional.normalize(<span class="hljs-keyword">X</span>)                  # L<span class="hljs-number">2</span> normalization</code></pre><h5 id="4-L1-正则化"><a href="#4-L1-正则化" class="headerlink" title="(4) L1 正则化"></a>(4) L1 正则化</h5><pre><code class="hljs gams">l1_regularization = torch.nn.L1Loss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)loss = ...  # Standard cross-<span class="hljs-built_in">entropy</span> loss<span class="hljs-keyword">for</span> param in <span class="hljs-keyword">model</span>.parameters():    loss += torch.<span class="hljs-keyword">sum</span>(torch.<span class="hljs-built_in">abs</span>(param))loss.backward()reg = <span class="hljs-number">1e-6</span>l2_loss = <span class="hljs-keyword">Variable</span>(torch.FloatTensor(1), requires_grad=True)for <span class="hljs-comment">name, param in model.named_parameters():</span>    if <span class="hljs-comment">&#x27;bias&#x27;</span><span class="hljs-comment"> not in name:</span>        l2_loss <span class="hljs-comment">= l2_loss + (0.5 * reg * torch.sum(torch.pow(W, 2)))</span></code></pre><h5 id="5-不对偏置项进行L2正则化-权值衰减（weight-decay）"><a href="#5-不对偏置项进行L2正则化-权值衰减（weight-decay）" class="headerlink" title="(5) 不对偏置项进行L2正则化/权值衰减（weight decay）"></a>(5) 不对偏置项进行L2正则化/权值衰减（weight decay）</h5><pre><code class="hljs ini"><span class="hljs-attr">bias_list</span> = (param for name, param in model.named_parameters() if name[-<span class="hljs-number">4</span>:] == <span class="hljs-string">&#x27;bias&#x27;</span>)<span class="hljs-attr">others_list</span> = (param for name, param in model.named_parameters() if name[-<span class="hljs-number">4</span>:] != <span class="hljs-string">&#x27;bias&#x27;</span>)<span class="hljs-attr">parameters</span> = [&#123;<span class="hljs-string">&#x27;parameters&#x27;</span>: bias_list, <span class="hljs-string">&#x27;weight_decay&#x27;</span>: <span class="hljs-number">0</span>&#125;,                              &#123;<span class="hljs-string">&#x27;parameters&#x27;</span>: others_list&#125;]<span class="hljs-attr">optimizer</span> = torch.optim.SGD(parameters, lr=<span class="hljs-number">1</span>e-<span class="hljs-number">2</span>, momentum=<span class="hljs-number">0.9</span>, weight_decay=<span class="hljs-number">1</span>e-<span class="hljs-number">4</span>)</code></pre><h5 id="6-梯度裁剪（gradient-clipping）"><a href="#6-梯度裁剪（gradient-clipping）" class="headerlink" title="(6) 梯度裁剪（gradient clipping）"></a>(6) 梯度裁剪（gradient clipping）</h5> <pre><code class="hljs reasonml">torch.nn.utils.clip<span class="hljs-constructor">_grad_norm_(<span class="hljs-params">model</span>.<span class="hljs-params">parameters</span>()</span>, max_norm=<span class="hljs-number">20</span>)</code></pre><h5 id="7-计算Softmax-输出的正确率"><a href="#7-计算Softmax-输出的正确率" class="headerlink" title="(7) 计算Softmax 输出的正确率"></a>(7) 计算Softmax 输出的正确率</h5><pre><code class="hljs ini"><span class="hljs-attr">score</span> = model(images)<span class="hljs-attr">prediction</span> = torch.argmax(score, dim=<span class="hljs-number">1</span>)<span class="hljs-attr">num_correct</span> = torch.sum(prediction == labels).item()<span class="hljs-attr">accuruacy</span> = num_correct / labels.size(<span class="hljs-number">0</span>)</code></pre><h5 id="8-获取当前学习率"><a href="#8-获取当前学习率" class="headerlink" title="(8) 获取当前学习率"></a>(8) 获取当前学习率</h5><pre><code class="hljs vim"># If there <span class="hljs-keyword">is</span> one <span class="hljs-keyword">global</span> learning rate (which <span class="hljs-keyword">is</span> the common case).<span class="hljs-keyword">lr</span> = <span class="hljs-keyword">next</span>(iter(optimizer.param_groups))[<span class="hljs-string">&#x27;lr&#x27;</span>]# If there are multiple learning rates <span class="hljs-keyword">for</span> different layers.all_lr = []<span class="hljs-keyword">for</span> param_group in optimizer.param_group<span class="hljs-variable">s:</span>    all_lr.<span class="hljs-keyword">append</span>(param_group[<span class="hljs-string">&#x27;lr&#x27;</span>])</code></pre><h3 id="5-Trick"><a href="#5-Trick" class="headerlink" title="5. Trick"></a>5. Trick</h3><h5 id="1-label-smothing"><a href="#1-label-smothing" class="headerlink" title="(1)  label smothing"></a>(1)  label smothing</h5><pre><code class="hljs nix">for images, labels <span class="hljs-keyword">in</span> train_loader:    images, <span class="hljs-attr">labels</span> = images.cuda(), labels.cuda()    <span class="hljs-attr">N</span> = labels.size(<span class="hljs-number">0</span>)    <span class="hljs-comment"># C is the number of classes.</span>    <span class="hljs-attr">smoothed_labels</span> = torch.full(<span class="hljs-attr">size=(N,</span> C), <span class="hljs-attr">fill_value=0.1</span> / (C - <span class="hljs-number">1</span>)).cuda()    smoothed_labels.scatter_(<span class="hljs-attr">dim=1,</span> <span class="hljs-attr">index=torch.unsqueeze(labels,</span> <span class="hljs-attr">dim=1),</span> <span class="hljs-attr">value=0.9)</span>    <span class="hljs-attr">score</span> = model(images)    <span class="hljs-attr">log_prob</span> = torch.nn.functional.log_softmax(score, <span class="hljs-attr">dim=1)</span>    <span class="hljs-attr">loss</span> = -torch.sum(log_prob * smoothed_labels) / N    optimizer.zero_grad()    loss.backward()    optimizer.step()</code></pre><h5 id="2-Mixup"><a href="#2-Mixup" class="headerlink" title="(2) Mixup"></a>(2) Mixup</h5><pre><code class="hljs reasonml">beta_distribution = torch.distributions.beta.<span class="hljs-constructor">Beta(<span class="hljs-params">alpha</span>, <span class="hljs-params">alpha</span>)</span><span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> train_loader:    images, labels = images.cuda<span class="hljs-literal">()</span>, labels.cuda<span class="hljs-literal">()</span>    # Mixup images.    lambda_ = beta_distribution.sample(<span class="hljs-literal">[]</span>).item<span class="hljs-literal">()</span>    index = torch.randperm(images.size(<span class="hljs-number">0</span>)).cuda<span class="hljs-literal">()</span>    mixed_images = lambda_<span class="hljs-operator"> * </span>images + (<span class="hljs-number">1</span> - lambda_)<span class="hljs-operator"> * </span>images<span class="hljs-literal">[<span class="hljs-identifier">index</span>, :]</span>    # Mixup loss.        scores = model(mixed_images)    loss = (lambda_<span class="hljs-operator"> * </span>loss<span class="hljs-constructor">_function(<span class="hljs-params">scores</span>, <span class="hljs-params">labels</span>)</span>             + (<span class="hljs-number">1</span> - lambda_)<span class="hljs-operator"> * </span>loss<span class="hljs-constructor">_function(<span class="hljs-params">scores</span>, <span class="hljs-params">labels</span>[<span class="hljs-params">index</span>])</span>)    optimizer.zero<span class="hljs-constructor">_grad()</span>    loss.backward<span class="hljs-literal">()</span>    optimizer.step<span class="hljs-literal">()</span></code></pre><h5 id="3-多卡同步BN（Batch-normalization）"><a href="#3-多卡同步BN（Batch-normalization）" class="headerlink" title="(3) 多卡同步BN（Batch normalization）"></a>(3) 多卡同步BN（Batch normalization）</h5><p>当使用torch.nn.DataParallel将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。</p><p>参见： <a href="vacancy/Synchronized-BatchNorm-PyTorchgithub.com">Synchronized-BatchNorm-PyTorchgithub</a></p><p>Reference:</p><ol><li><a href>Tensorflow cookbook</a></li><li><a href>Pytorch cookbook</a></li><li><a href="https://github.com/kevinzakka/pytorch-goodies">Pytorch-goodies</a></li><li><a href="https://github.com/chenyuntc/pytorch-book">Pytorch book</a></li><li>Pytorch 官方文档 和 Tutorial</li></ol>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch基本概念</title>
    <link href="/2019/03/17/pytorch%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <url>/2019/03/17/pytorch%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<p>Pytorch几个基本概念的区分</p><a id="more"></a><h3 id="1-numpy-array-和-Tensor-CPU-amp-GPU"><a href="#1-numpy-array-和-Tensor-CPU-amp-GPU" class="headerlink" title="1. numpy array 和 Tensor (CPU &amp; GPU)"></a>1. numpy array 和 Tensor (CPU &amp; GPU)</h3><pre><code class="hljs shell"><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; import torch</span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; import numpy as np</span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; a = np.ones(5)</span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; a</span>array([1., 1., 1., 1., 1.])<span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; b = torch.from_numpy(a)     <span class="hljs-comment"># numpy array-&gt; CPU Tensor</span></span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; b </span>tensor([1., 1., 1., 1., 1.], dtype=torch.float64)<span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y = y.cuda()     <span class="hljs-comment"># CPU Tensor -&gt; GPU Tensor</span></span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y</span>tensor([1., 1., 1., 1., 1.], device=&#x27;cuda:0&#x27;, dtype=torch.float64)<span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y = y.cpu()  <span class="hljs-comment"># GPU Tensor-&gt; CPU Tensor</span></span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y</span>tensor([1., 1., 1., 1., 1.], dtype=torch.float64)<span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y = y.numpy()  <span class="hljs-comment"># CPU Tensor -&gt; numpy array</span></span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y</span>array([1., 1., 1., 1., 1.])device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)<span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y = torch.from_numpy(y)</span><span class="hljs-meta">&gt;</span><span class="bash">&gt;&gt; y.to(device)   <span class="hljs-comment"># 这里 x.to(device) 等价于 x.cuda()</span></span>tensor([1., 1., 1., 1., 1.], device=&#x27;cuda:0&#x27;, dtype=torch.float64)</code></pre><p>索引、 view 是不会开辟新内存的，而像 y = x + y 这样的运算是会新开内存的，然后将 y 指向新内存。</p><h3 id="2-Variable-和-Tensor-require-grad-True"><a href="#2-Variable-和-Tensor-require-grad-True" class="headerlink" title="2. Variable 和 Tensor (require_grad=True)"></a>2. Variable 和 Tensor (require_grad=True)</h3><p>​    Pytorch 0.4 之前的模式为:　<strong>Tensor 没有梯度计算，加上梯度更新等操作后可以变为Variable</strong>.  Pytorch0.4 将 Tensor 和Variable 合并。默认 Tensor 的 require_grad 为 false，可以通过修改 requires_grad 来为其添加梯度更新操作。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>ytensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>], dtype=torch.float64)  <span class="hljs-meta">&gt;&gt;&gt; </span>y.requires_grad<span class="hljs-literal">False</span><span class="hljs-meta">&gt;&gt;&gt; </span>y.requires_grad = <span class="hljs-literal">True</span><span class="hljs-meta">&gt;&gt;&gt; </span>ytensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>], dtype=torch.float64, requires_grad=<span class="hljs-literal">True</span>)</code></pre><h3 id="3-detach-和-with-torch-no-grad"><a href="#3-detach-和-with-torch-no-grad" class="headerlink" title="3. detach 和　with torch.no_grad()"></a>3. detach 和　with torch.no_grad()</h3><p>一个比较好的 detach和 torch.no_grad区别的解释:</p><blockquote><p><strong><code>detach()</code> detaches the output from the computationnal graph. So no gradient will be backproped along this variable.</strong></p><p><strong><code>torch.no_grad</code> says that no operation should build the graph.</strong></p><p><strong>The difference is that one refers to only a given variable on which it’s called. The other affects all operations taking place within the with statement.</strong></p></blockquote><p><code>detach()</code> 将一个变量从计算图中分离出来，也没有了相关的梯度更新。<code>torch.no_grad()</code>只是说明该操作没必要建图。不同之处在于，前者只能指定一个给定的变量，后者 则会影响影响在 with 语句中发生的所有操作。</p><h3 id="4-model-eval-和-torch-no-grad"><a href="#4-model-eval-和-torch-no-grad" class="headerlink" title="4. model.eval()　和 torch.no_grad()"></a>4. model.eval()　和 torch.no_grad()</h3><blockquote><p><strong>These two have different goals:</strong></p><ul><li><p><code>model.eval()</code> will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.</p></li><li><p><code>torch.no_grad()</code> impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).</p></li></ul></blockquote><p><code>model.eval()</code>和<code>torch.no_grad()</code>的区别在于，<code>model.eval()</code>是将网络切换为测试状态，例如 BN 和随机失活（dropout）在训练和测试阶段使用不同的计算方法。<code>torch.no_grad()</code>是关闭PyTorch张量的自动求导机制，以减少存储使用和加速计算，得到的结果无法进行<code>loss.backward()</code></p><h3 id="5-model-train-和-model-eval-的不同"><a href="#5-model-train-和-model-eval-的不同" class="headerlink" title="5. model.train() 和 model.eval() 的不同"></a>5. model.train() 和 model.eval() 的不同</h3><ul><li><code>model.train()</code>  ——  训练时候启用， 会计算对应 Tensor 的梯度<br>启用 BatchNormalization 和 Dropout，将 BatchNormalization 和 Dropout 置为 True</li><li><code>model.eval()</code>  ——  验证和测试时候启用， 不会计算对应 Tensor 的梯度<br>不启用 BatchNormalization 和 Dropout，将 BatchNormalization 和 Dropout 置为 False</li></ul><h3 id="6-xx-data-和-xx-detach"><a href="#6-xx-data-和-xx-detach" class="headerlink" title="6. xx.data 和 xx.detach()"></a>6. xx.data 和 xx.detach()</h3><p>​      在 0.4.0 版本之前,  .data 的语义是 获取 Variable 的 内部 Tensor, 在 0.4.0 版本将 Variable 和 Tensor merge 之后,  <code>.data</code> 和之前有类似的语义， 也是内部的 Tensor 的概念。<code>x.data</code> 与 <code>x.detach()</code> 返回的 tensor 有相同的地方, 也有不同的地方:</p><p><strong>相同:</strong></p><ul><li>都和 x 共享同一块数据</li><li>都和 x 的 计算历史无关</li><li>requires_grad = False</li></ul><p><strong>不同:</strong></p><ul><li>y= x.data 在某些情况下不安全, 某些情况, 指的就是上述 inplace operation 的第二种情况, 所以, release note 中指出, 如果想要 detach 的效果的话, 还是 detach() 安全一些.</li></ul><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch<span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.FloatTensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>w1 = torch.FloatTensor([[<span class="hljs-number">2.</span>], [<span class="hljs-number">1.</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>w2 = torch.FloatTensor([<span class="hljs-number">3.</span>])<span class="hljs-meta">&gt;&gt;&gt; </span>w1.requires_grad = <span class="hljs-literal">True</span><span class="hljs-meta">&gt;&gt;&gt; </span>w2.requires_grad = <span class="hljs-literal">True</span><span class="hljs-meta">&gt;&gt;&gt; </span>d = torch.matmul(x, w1)<span class="hljs-meta">&gt;&gt;&gt; </span>d_ = d.data<span class="hljs-meta">&gt;&gt;&gt; </span>f = torch.matmul(d, w2)<span class="hljs-meta">&gt;&gt;&gt; </span>d_[:] = <span class="hljs-number">1</span><span class="hljs-meta">&gt;&gt;&gt; </span>f.backward()</code></pre><p><strong>如果需要获取其值，可以使用  xx.cpu().numpy() 或者 xx.cpu().detach().numpy() 然后进行操作，不建议再使用 volatile和  xx.data操作。</strong></p><h3 id="7-ToTensor-amp-ToPILImage-各自都做了什么"><a href="#7-ToTensor-amp-ToPILImage-各自都做了什么" class="headerlink" title="7. ToTensor &amp; ToPILImage 各自都做了什么?"></a>7. ToTensor &amp; ToPILImage 各自都做了什么?</h3><p><strong>ToTensor:</strong></p><ul><li>取值范围：   [0, 255]  —&gt;  [0, 1.0]</li><li>NHWC  —&gt; NCHW</li><li>PILImage  —&gt; FloatTensor</li></ul><pre><code class="hljs python"><span class="hljs-comment"># PIL.Image -&gt; torch.Tensor.</span>tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))    ).permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).float() / <span class="hljs-number">255</span><span class="hljs-comment">#　等价于</span>tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))</code></pre><p><strong>ToPILImage:</strong></p><ul><li>取值范围:  [0, 1.0] —&gt;  [0, 255]</li><li>NCHW —&gt; NHWC</li><li>类型: FloatTensor -&gt; numpy Uint8 -&gt; PILImage</li></ul><pre><code class="hljs python"><span class="hljs-comment"># torch.Tensor -&gt; PIL.Image.</span>image = PIL.Image.fromarray(torch.clamp(tensor * <span class="hljs-number">255</span>, min=<span class="hljs-number">0</span>, max=<span class="hljs-number">255</span>    ).byte().permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).cpu().numpy())<span class="hljs-comment">#　等价于</span>image = torchvision.transforms.functional.to_pil_image(tensor)</code></pre><h3 id="8-torch-nn-xxx-与-torch-nn-functional-xxx"><a href="#8-torch-nn-xxx-与-torch-nn-functional-xxx" class="headerlink" title="8. torch.nn.xxx 与 torch.nn.functional.xxx"></a>8. torch.nn.xxx 与 torch.nn.functional.xxx</h3><p>建议统一使用　<code>torch.nn.xxx</code>　模块，<code>torch.functional.xxx</code> 可能会在下一个版本中去掉。</p><p><code>torch.nn</code>　模块和　<code>torch.nn.functional</code>　的区别在于，<code>torch.nn</code>　模块在计算时底层调用了<code>torch.nn.functional</code>，但　<code>torch.nn</code>　模块包括该层参数，还可以应对训练和测试两种网络状态。使用　<code>torch.nn.functional</code>　时要注意网络状态，如:</p><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>    ...    x = torch.nn.functional.dropout(x, p=<span class="hljs-number">0.5</span>, training=self.training)</code></pre><h3 id="9-pytorch-中-torch-Tensor-和-torch-tensor-有什么相同点和区别"><a href="#9-pytorch-中-torch-Tensor-和-torch-tensor-有什么相同点和区别" class="headerlink" title="9. pytorch 中 torch.Tensor() 和 torch.tensor() 有什么相同点和区别?"></a>9. pytorch 中 torch.Tensor() 和 torch.tensor() 有什么相同点和区别?</h3><ul><li><p>相同点 </p><p>都能用于生成新的张量</p></li><li><p>不同点：</p></li></ul><p>torch.Tensor()是 python类，更明确地说，是默认张量类型torch.FloatTensor() 的别名，torch.Tensor([1,2])会调用Tensor类的构造函数 _<em>init_</em>，生成单精度浮点类型的张量。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a=torch.Tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.FloatTensor&#x27;</span><span class="hljs-number">123</span></code></pre><p>而 torch.tensor()  是 python 函数：<a href="https://pytorch.org/docs/stable/torch.html#torch.tensor">https://pytorch.org/docs/stable/torch.html#torch.tensor</a> ，函数原型是：</p><pre><code class="hljs python">torch.tensor(data, dtype=<span class="hljs-literal">None</span>, device=<span class="hljs-literal">None</span>, requires_grad=<span class="hljs-literal">False</span>)</code></pre><p>其中 data 可以是：list, tuple, NumPy ndarray, scalar 和其他类型。<br>torch.tensor 会从 data 中的数据部分做拷贝，根据原始数据类型生成相应的torch.LongTensor、torch.FloatTensor 和torch.DoubleTensor。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a=torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>])<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.LongTensor&#x27;</span><span class="hljs-meta">&gt;&gt;&gt; </span>a=torch.tensor([<span class="hljs-number">1.</span>,<span class="hljs-number">2.</span>])<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.FloatTensor&#x27;</span><span class="hljs-meta">&gt;&gt;&gt; </span>a=np.zeros(<span class="hljs-number">2</span>,dtype=np.float64)<span class="hljs-meta">&gt;&gt;&gt; </span>a=torch.tensor(a)<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.DoubleTensor&#x27;</span></code></pre><h3 id="10-tensorflow-和-pytorch-构建网络的差异"><a href="#10-tensorflow-和-pytorch-构建网络的差异" class="headerlink" title="10. tensorflow 和 pytorch 构建网络的差异"></a>10. tensorflow 和 pytorch 构建网络的差异</h3><p>[如果是比较 Tensorflow 和 Pytorch 的差异， 可以从: 上手难易程度、静态图vs动态图、调试、可视化、部署等方面进行分析]</p><p> <strong>图的动态定义 vs 静态定义</strong></p><p>​      两个框架都是在张量上进行运算，并将任意一个模型看成是有向非循环图（DAG），但是它们在其定义方面有很大的区别。</p><p>​      Tensorflow 基于静态图。 TensorFlow遵循“数据即代码，代码即数据”的理念。在TensorFlow中，你可以<strong>在模型能够运行之前静态地定义图， 然后在运行时将 数据 feed 到计算图中。</strong>与外部世界的<strong>所有通信都通过tf.Session对象和tf.Placeholder来执行</strong>，这两个张量在运行时会被外部数据替代。<strong>静态计算允许编译器进行更大程度的优化，但是其调试相对比较困难。</strong></p><p>​      Pytorch 基于动态图， 在PyTorch中，图的定义则更为重要和动态化：<strong>你可以随时定义、随时更改、随时执行节点，并且没有特殊的会话接口或占位符</strong>。总体而言，该框架与Python语言集成地更为紧密，并且在大多数时候用起来感觉<strong>更加本地化，更加容易将大脑中的想法转化为程序.</strong></p><p>​     近年来的发展， tf 引入了 eager 模式实现动态图··， pytorch 也可以借助于 onnx、caffe2和 torchscript 来实现静态图， tensorflow 和 pytorch 的之间静态图和动态图的界限也逐渐变的模糊。</p>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>neural-network-part1</title>
    <link href="/2019/03/11/neural-network-part1/"/>
    <url>/2019/03/11/neural-network-part1/</url>
    
    <content type="html"><![CDATA[<h3 id="一-数据预处理"><a href="#一-数据预处理" class="headerlink" title="一. 数据预处理"></a>一. 数据预处理</h3><h4 id="1-中心化"><a href="#1-中心化" class="headerlink" title="1. 中心化"></a>1. 中心化</h4><p>中心化是预处理最常用的形式。它对数据中每个独立<em>特征</em>减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码<code>X -= np.mean(X, axis=0)</code>实现。而对于图像，更常用的是对所有像素都减去一个值，可以用<code>X -= np.mean(X)</code>实现，也可以在3个颜色通道上分别操作。</p><h4 id="2-归一化"><a href="#2-归一化" class="headerlink" title="2. 归一化"></a>2. 归一化</h4><p>归一化是指将数据的所有维度都归一化，使其数值范围都近似相等。有两种常用方法可以实现归一化。</p><p>第一种是先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为<code>X /= np.std(X, axis=0)</code>。</p><p>第二种方法是对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。</p><p>这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。</p><h3 id="二-激活函数"><a href="#二-激活函数" class="headerlink" title="二. 激活函数"></a>二. 激活函数</h3><h4 id="1-常见的激活函数及其导数"><a href="#1-常见的激活函数及其导数" class="headerlink" title="1. 常见的激活函数及其导数"></a>1. 常见的激活函数及其导数</h4><p>Sigmoid 激活函数的形式为   <script type="math/tex">f(z) = \frac{1}{1+e^{-z}}</script>,  对应的导函数为    $f’(z) = f(z)(1-f(z))$</p><p>Tanh激活函数的形式为   $f(z) = \frac{e^{z} - e^{-z}}{e^{z}+e^{-z}}$,    对应的导函数为$f’(z) = 1 - (f(z))^2$ </p><p>ReLU 激活函数的形式为  $f(z) = max(0, z)$,    对应的导函数为   <script type="math/tex">f'(z)=\left\{\begin{aligned}1, z > 0 \\0, z \leq 0 \\\end{aligned}\right.</script></p><h4 id="2-为什么-sigmoid-和-tanh-激活函数会导致梯度消失的现象？"><a href="#2-为什么-sigmoid-和-tanh-激活函数会导致梯度消失的现象？" class="headerlink" title="2. 为什么 sigmoid 和 tanh 激活函数会导致梯度消失的现象？"></a>2. 为什么 sigmoid 和 tanh 激活函数会导致梯度消失的现象？</h4><p>sigmoid 激活函数的曲线如下左图所示。它将输入z 映射到（0, 1），当z很大时， f(z) 趋近于1；当z很小时， f(z) 趋近于0， 而其导函数 $f’(z) = f(z)(1-f(z)) $ 在 z 很大或者很小时都会趋近于0，造成梯度消失的现象。</p><p>tanh 激活函数的图像如下右图所示。当z很大时，f(z) 趋近于1， 当z 很小时， z 趋近于-1。 其导数 $f’(z) = 1 - (f(z))^2$  在 z 很大或很小时都会趋近于0，同样会出现梯度消失。</p><p>实际上，Tanh 相当于 Sigmoid的平移：  <script type="math/tex">tanh(z) = 2sigmoid(2x)-1</script>。</p><p><img src="/2019/03/11/neural-network-part1/sigmoid_and_tanh.png" alt="sigmoid and tanh"></p><h4 id="3-ReLU-系列的激活函数相对于-sigmoid-和-tanh-的优点是什么？它们有什么局限性以及如何改进？"><a href="#3-ReLU-系列的激活函数相对于-sigmoid-和-tanh-的优点是什么？它们有什么局限性以及如何改进？" class="headerlink" title="3. ReLU 系列的激活函数相对于 sigmoid 和 tanh 的优点是什么？它们有什么局限性以及如何改进？"></a>3. ReLU 系列的激活函数相对于 sigmoid 和 tanh 的优点是什么？它们有什么局限性以及如何改进？</h4><p>优点：</p><p>（1）从计算角度上， Sigmoid 和 tanh 激活函数均需要计算指数，复杂度高，而ReLU只需要一个阈值即可得到激活值。</p><p>（2）ReLU 的非线性包含线性可以有效地解决梯度消失问题，提供相对较宽的激活边界。</p><p>（3）ReLU的单侧抑制提供了网络的稀疏表达能力。  </p><p>局限性：在训练过程中会会导致神经元死亡的问题。这是由于 $f(z) = max(0, z)$  导致负梯度在经过该ReLU 单元时被置为0， 且在之后也不被任何数据激活，即流经该神经元的梯度永远为0， 不对任何数据产生响应。在实际训练中，如果学习率设置较大，会导致超过一定比例的神经元不可逆死亡，进而参数梯度无法更新，整个训练过程失败。</p><p>一些ReLU 的改进措施：</p><p>（1）Leaky ReLU（LReLU）</p><p>Leaky ReLU 的表示形式为：<script type="math/tex">f(z)=\left\{\begin{aligned}z, z > 0 \\\alpha z, z \leq 0 \\\end{aligned}\right.</script> ， Leaky ReLU 与 ReLU 的区别在于当 $z\le 0$ 时， 其值不为零，一般来说a 为一个很小的常数(0.01或者0.001数量级的较小整数)，这样既实现了单侧抑制，又保留了部分负梯度信息以致不完全丢失。但另一方面，$ \alpha$  为超参数，较难设置为合适的值，且较为敏感，因此Leaky ReLU 函数在实际使用中的性能部分十分稳定。</p><p>（2）参数化 ReLU（Parametric  ReLU，PReLU）：PReLU将负轴部分斜率$ \alpha$ 作为网络中的一个可学习的参数融入模型的整体训练过程。有几点有趣的现象需要注意：</p><ul><li><p>自由度较大的各通道独享参数的参数化ReLU性能相比较各通道共享参数更优。</p></li><li><p>在独享参数设定下学到的$ \alpha$取值呈现出由浅层到深层依次递减的趋势，这说明实际上网络所需要的非线性随着网络层数的增加而递减。 </p><p>在分类精度上， 使用PReLU 作为激活函数的网络要优于原始ReLU的网络。但是PReLU在带来更大自由度的同时，也增加了网络模型过拟合的奉献，在实际使用中需要格外注意。</p></li></ul><p>（3）随机化ReLU(Random ReLU, RReLU）：增加了“随机化机制， 其取值在训练阶段服从均匀分布，在测试阶段则将其指定为该均匀分布对应的数学期望 $ \frac{l+u}{2}\ $。</p><p><img src="/2019/03/11/neural-network-part1/relu_adv.png" alt="sigmoid and tanh"></p><p>（4）指数化线性单元（Exponential Linear Unit， ELU）：2016年 Clevert 等人提出了指数化线性单元 ELU，其公式为： <script type="math/tex">ELU(x)=\left\{\begin{aligned}x, x \ge 0 \\\lambda \cdot (e^x - 1), z \lt 0 \\\end{aligned}\right.</script>。ReLU 具备了 ReLU 函数的优点，同时也解决了ReLU 函数自身的“死区”问题。不过ELU 函数中的指数操作稍稍增大了计算量。在实际应用中，ELU 中的超参数 $\lambda$ 一般被设置为1。</p><h3 id="三-网络参数初始化"><a href="#三-网络参数初始化" class="headerlink" title="三. 网络参数初始化"></a>三. 网络参数初始化</h3><p>网络参数初始化方式主要分为四种：</p><p>（1）全零初始化：全零初始化会导致网络不通神经元的输出相同，相同的输出导致梯度更新完全一样，这样便会令更新后的参数仍然保持一样的状态，从而无法对模型进行训练。</p><p>（2）随机初始化：将参数值随机设定为接近0的一个很小的随机数（有正有负）。</p><p>高斯分布：</p><pre><code class="hljs python"><span class="hljs-comment"># origin method</span>w = <span class="hljs-number">0.001</span> * randn(n_in, n_out)<span class="hljs-comment"># Xavier method </span>w = (<span class="hljs-number">0.001</span> * randn(n_in, n_out)) / sqrt(n)<span class="hljs-comment"># He method</span>w = (<span class="hljs-number">0.001</span> * randn(n_in, n_out)) / sqrt(n/<span class="hljs-number">2</span>)<span class="hljs-comment"># 其中n=n_in或n=(n_in+n_out)/2</span></code></pre><p>均匀分布：</p><pre><code class="hljs python"><span class="hljs-comment">#  Xavier method</span>low = -sqrt(<span class="hljs-number">3</span>/n)high = sqrt(<span class="hljs-number">3</span>/n)rand_param = low + (high - low) * rand(n_in, n_out)w = <span class="hljs-number">0.001</span> * rand_param <span class="hljs-comment"># He mothod</span>low = -sqrt(<span class="hljs-number">6</span>/n)high = sqrt(<span class="hljs-number">6</span>/n)rand_param = low + (high - low) * rand(n_in, n_out)w = <span class="hljs-number">0.001</span> * rand_param</code></pre><p>（3）预训练模型初始化</p><p>（4） 数据敏感的参数初始化方式   <a href="https://github.com/philkr/magic_init">github address</a></p><p>总结： </p><ul><li>网络参数初始化的优劣在极大程度上决定了网络的最终性能。</li><li>比较推荐的网络初始化方式为He方式，将参数初始化为服从高斯部分或者均匀分布的较小随机数，同时对参数方差需要加以规范化。</li><li>另外借助预训练模型中的参数作为新任务的参数初始化方式一种简便异性且十分有效的模型参数初始化方法。</li></ul><p>xavier 参数初始化方式的由来：</p><p>假设s为未经非线性变化的该层网络输出结果，w为该层参数，x为该层的输入数据，则：</p><script type="math/tex; mode=display">Var(s) = Var(\sum_i^nw_ix_i)   \\       = \sum_i^nVar(w_ix_i)   \\       = \sum_i^n[E(w_i)]^2Var(x_i) +[E(x_i)]^2Var(w_i) + Var(x_i)Var(x_i)     \\       = \sum_i^nVar(x_i)Var(w_i) \\       = (nVar(w))Var(x) \\</script><p>为了保证输出数据 Var(s) 和输入数据Var(x)的方差一致，需令 nVar（w） = 1，即 $n \cdot Var(a\omega)=n\cdot a^2 \cdot Var(\omega’) = 1$， 则 $a=\sqrt{(1/n)}$， 其中$\omega’$为方差规范化后的参数。</p><h3 id="四-目标函数"><a href="#四-目标函数" class="headerlink" title="四. 目标函数"></a>四. 目标函数</h3><h4 id="1-分类任务的目标函数"><a href="#1-分类任务的目标函数" class="headerlink" title="1. 分类任务的目标函数"></a>1. 分类任务的目标函数</h4><h5 id="1-交叉熵损失函数-Softmax-损失函数"><a href="#1-交叉熵损失函数-Softmax-损失函数" class="headerlink" title="(1) 交叉熵损失函数/Softmax 损失函数"></a>(1) 交叉熵损失函数/Softmax 损失函数</h5><p>交叉熵(cross entropy)损失函数又称Softmax 损失函数，是目前卷积神经网络最常用的分类目标函数。其形式为：</p><p>$L<em>{cross\ entropy\ loss} = L</em>{softmax\ loss} = -\frac{1}{N}\sum<em>{i=1}^{N}log(\frac{e^{h</em>{y<em>i}}}{\sum</em>{j=1}^{C}e^{h_j}})$</p><p>即通过指数化变换使网络输出 $h$ 转换为概率形式。</p><h5 id="2-合页损失函数"><a href="#2-合页损失函数" class="headerlink" title="(2) 合页损失函数"></a>(2) 合页损失函数</h5><p>在支持向量机中被广泛使用的合页损失函数（hinge loss）有时也作为目标函数在神经网络模型中使用：</p><p>$L<em>{hinge\ loss} = \frac{1}{N}\sum</em>{i=1}^{N}max{(0, 1-h_{yi})}$</p><p>合页损失函数的设计理念是：对错误越大的样本施加越严重的惩罚。可是这一损失函数对噪声的抵抗能力较差。另外，一般的分类任务中的交叉熵损失函数的分类效果略优于合页损失函数的分类效果。</p><h5 id="3-坡道损失函数"><a href="#3-坡道损失函数" class="headerlink" title="(3) 坡道损失函数"></a>(3) 坡道损失函数</h5><p>坡道损失函数的定义为：</p><script type="math/tex; mode=display">L_{ramp\ loss} = L_{hinge\ loss} - \frac{1}{N}\sum_{i=1}^{M}max{(0, s-h{yi})}  \\= \frac{1}{N}\sum_{i=1}^{M}(max{(0, 1-h_{yi})} - max{(0, s-h_{yi})})  \\</script><p>其中 , $s$ 制定了“截断点”的文职。由于坡道损失函数实际在 $s$ 处“截断” 合页损失函数，因此坡道损失函数也被称为“截断合页损失函数”(truncated hinge loss function)</p><h5 id="4-大间隔交叉熵损失函数"><a href="#4-大间隔交叉熵损失函数" class="headerlink" title="(4) 大间隔交叉熵损失函数"></a>(4) 大间隔交叉熵损失函数</h5><p>上面提到的网络输出结果 $h$ 实际上市全连接层参数 $W$ 与该层特征向量 $x_i$的内积， 即 $h=W^Tx_i$。因此传统的交叉熵损失还可以表示为：</p><script type="math/tex; mode=display">L_{softmax\ loss} = -\frac{1}{N}\sum_{i=1}^{N}log(\frac{e^{h_{y_i}}}{\sum_{j=1}^{C}e^{h_j}}) \\= -\frac{1}{N}\sum_{i=1}^{N}log(\frac{e^{W^T_{yi}x_i}}{\sum_{j=1}^{C}e^{W^T_jx_i}}) \\</script><p>其中， $W_i^T$ 为$W$ 第i列参数值。根据内积的定义，上式可以变换为</p><script type="math/tex; mode=display">L_{softmax\ loss} = -\frac{1}{N}\sum_{i=1}^{N}log(\frac{e^{||W_{yi}||||x_i||cos(\theta_{yi})}}{\sum_{j=1}^{C}e^{||W_{j}||||x_i||cos(\theta_j)}})</script><p>式中的 $\theta_j(0\leq\theta_j \leq \pi)$ 为向量 $W_i^T$ 和 $x_i$的夹角。以二分类为例，对隶属于第一个类别的某样本 $x_i$而言， 为分类正确，传统的交叉熵损失函数需迫使学到的参数满足 $W_1^Tx_i &gt; W_2^Tx_i$, 亦即$||W_1||||x_i|| cos(\theta) &gt; ||W2||||x_i||cos(\theta)$。大间隔交叉熵损失函数为了使特征更加具有分辨能力，则再次基础上要求二者差异更大，即引入 $m$ “拉大”两者差距，这便是“大间隔”名称的由来。$||W_1||||x_i||cos(m\theta_1) \geq ||W2||||x_i||cos(\theta_2) , (0\leq\theta_1\leq\frac{\pi}{m})$。式中 $m$ 为正整数，起到控制间隔大小的作用，$m$ 越大。类间间隔越大，反之亦然。特别地， 当 $m=1$ 时， 大间隔交叉熵损失函数即退化为传统交叉熵损失函数。</p><p>综上可得：</p><script type="math/tex; mode=display">||W_1||||x_i||cos(\theta_1) \geq ||W_1||||x_i||cos(m\theta_1) \geq ||W2||||x_i||cos(\theta_2) , (0\leq\theta_1\leq\frac{\pi}{m})</script><p>可以发现，上式不仅满足传统交叉熵损失函数的约束，在确保分类正确的同时增大了不同类别间分类的置信度，这有助于进一步提升特征分辨能力。</p><p>大间隔交叉熵损失函数的定义为：</p><script type="math/tex; mode=display">L_{large-margin\ softmax\ loss} = -\frac{1}{N}\sum^{1}_{i=1}log(\frac{e^{||W_i||||x_i||\phi(\theta_{y_i})}}{e^{||W_i||||x_i||\phi(\theta_{yi})}+\sum_{j\neq y_i}e^{||W_j||||x_i||\phi(\theta_{j})}})</script><p>可以发现，上式与$Softmax$ 损失函数的区别仅仅在于第 $i$ 类分类间隔 “拉大”了：由  $cos(\theta<em>{y_i})$ 变为 $\phi(\theta</em>{y_i})$, 其中：</p><script type="math/tex; mode=display">\phi(\theta) = \begin{equation}  \left\{               \begin{array}{**lr**}               cos(m\theta), 0 \leq \theta \leq \frac{\pi}{m}&  \\               \mathcal{D}(\theta) , \frac{\pi}{m} < \theta \leq \pi &\\                  \end{array}  \right.  \end{equation}</script><p>式中，$\mathcal{D}(\theta)$ 只需要满足“单调递减”条件， 且 $D(\frac{\pi}{m})=cos\frac{\pi}{m})$。</p><h5 id="5-中心损失函数"><a href="#5-中心损失函数" class="headerlink" title="(5) 中心损失函数"></a>(5) 中心损失函数</h5><p>大交叉熵损失函数主要考虑增大类间距离，而中心损失函数则在考虑类间距离的同时还将一些注意力放在减小类间差异上。中心损失函数的定义为：</p><script type="math/tex; mode=display">L_{center\ loss} = \frac{1}{2}\sum_{i=1}^{N}||x_i - c_{y_i}||_2^2</script><p>其中， $c_{y_i}$ 为 第 $y_i$ 类所有深度特征均值的中心，故名“中心损失函数”。</p><p>在实际使用中，由于中心损失函数本身考虑类内差异，因此应该讲中心损失函数与其他主要考虑类间距离的损失函数配合使用，如交叉熵损失函数，这样网络最终目标形式可表示为：</p><script type="math/tex; mode=display">L_{final} = L_{cross\ entropy\ loss} + \lambda L_{center\ loss}(h, y_i)  \\= -\frac{1}{N}\sum_{i=1}^{N}log(\frac{e_{h_{y_i}}}{\sum_{j=1}^{C}e^{h_j}})+\frac{\lambda}{2}\sum_{i=1}^{N}||x_i - c_{y_i}||_2^2</script><h4 id="2-回归任务的目标函数"><a href="#2-回归任务的目标函数" class="headerlink" title="2. 回归任务的目标函数"></a>2. 回归任务的目标函数</h4><h5 id="1-mathcal-L1-损失函数"><a href="#1-mathcal-L1-损失函数" class="headerlink" title="(1) $\mathcal{L1}$ 损失函数"></a>(1) $\mathcal{L1}$ 损失函数</h5><script type="math/tex; mode=display">L_{\mathcal{l1}} = \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{M}||y_t^i-\hat{y}t^i||</script><h5 id="2-mathcal-L2-损失函数"><a href="#2-mathcal-L2-损失函数" class="headerlink" title="(2) $\mathcal{L2}$ 损失函数"></a>(2) $\mathcal{L2}$ 损失函数</h5><script type="math/tex; mode=display">L_{\mathcal{l2}} = \frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{M}(||y_t^i-\hat{y}t^i||)^2</script><p>在实际使用中， $\mathcal{l_1}$ 与 $\mathcal{l_2}$ 损失函数在回归精度上几乎相差无几。不过在一些情况先 $\mathcal{l_2}$ 损失函数会略优于 $\mathcal{l_1}$ ，同时收敛速度方面 $l_2$ 损失函数也略快于 $\mathcal{l_1}$ 损失函数。</p><h5 id="3-Tukey’s-biweight-损失函数"><a href="#3-Tukey’s-biweight-损失函数" class="headerlink" title="(3) Tukey’s biweight 损失函数"></a>(3) Tukey’s biweight 损失函数</h5><p>Tukey’s biweight 损失函数是一类非凸函数，其可克服在回归任务中的利群店或者样本噪声对整体回归模型的干扰和影响，是回归任务中一种健壮的损失函数，其定义如下：</p><script type="math/tex; mode=display">\mathcal{L_{Tukey's\ biweight\ loss}} =\begin{equation}  \left\{               \begin{array}{**lr**}               \frac{c^2}{6N}\sum_{i=1}^{N}\sum_{t=1}^{M}[1-(1-(\frac{l_t^i}{c})^2)], |l_t^i| \leq c  \\               \frac{c^2{M}}{6}, 其他 &\\                  \end{array}  \right.  \end{equation}</script><p>式中， 常数  $c$ 指定了函数拐点的位置。需要说明的是，该超参数并不需要认为指定。一般情况下， 当 $c=4.6851$ 时， $Tukey’s\ biweight $损失函数可取得与 $\mathcal{l_2}$ 损失函数在最小化符合标准正态分布时的残差类似的(95%渐进)回归效果。</p><h4 id="3-其他任务的损失函数"><a href="#3-其他任务的损失函数" class="headerlink" title="3. 其他任务的损失函数"></a>3. 其他任务的损失函数</h4><p>在一些如人脸年龄估计、头部角度识别等任务样本标记具有不确定性的特殊场景下，基于标记分布(label distribution)的损失函数不失为一种优质的选择。具体而言，假设 $h=(h_1, h_2, …, h_C)^T$ 为模型对于输入样本 $x_i$ 的最终输出结果，那么在利用标记分布技术解决问题之前，首先需要将 $h$ 转化为一个合法分布。以softmax 为例可以将 $h$ 转化为:</p><script type="math/tex; mode=display">\hat{y}_k = \frac{e^{h_k}}{\sum_{j=1}^{C}{e^{h_j}}}</script><p>其中，$k \in {1,2,3,…,C}$ 代表标记向量的第 $k$ 维。</p><p>可以用Kullback-Leibler散度(KL divergence)来度量 $\hat{y}$与真实标记 $y$ 之间的误差：$\mathcal{L}_{KL\ loss}=\sum_k{y_klog\frac{y_k}{\hat{y}_k}}$。</p><p>由于 $y<em>k$ 为常量，上式等价于：$\mathcal{L}</em>{KL\ loss} = -\sum_{k}{y_k}{log{\hat{y}_k}}$。通过该式可以衡量样本标记分布与真实部分之间的差异，并利用该差异指导模型训练。</p>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>model_evaluation</title>
    <link href="/2019/03/10/model-evaluation/"/>
    <url>/2019/03/10/model-evaluation/</url>
    
    <content type="html"><![CDATA[<h3 id="Chapter-2-模型评估"><a href="#Chapter-2-模型评估" class="headerlink" title="Chapter 2 模型评估"></a>Chapter 2 模型评估</h3><h4 id="1-准确率和平方根误差的缺陷"><a href="#1-准确率和平方根误差的缺陷" class="headerlink" title="1. 准确率和平方根误差的缺陷"></a>1. 准确率和平方根误差的缺陷</h4><h5 id="准确率"><a href="#准确率" class="headerlink" title="准确率"></a>准确率</h5><p>​     <strong>准确率是指分类正确的样本占样本个数的比例</strong>，即 <strong>$Accuracy  = \frac{n<em>{correct}}{n</em>{total}}$</strong> ,其中 $n<em>{correct}$ 为被正确分类的样本个数， $n</em>{total}$ 为总样本的个数。</p><p>​     准确率是分类问题中最简单也是最直观的评价指标， 但存在明显缺陷。当<strong>不同类别的样本比例非常不均衡</strong>时，占比较大的类别往往会成为影响准确率最主要的因素。比如，当负样本占99%时，分类器把所有样本预测为负样本也可以获得99% 的准确率。 </p><p>​      为了解决这个问题，可以使用更为有效的<strong>平均准确率</strong>(每个类别下的样本准确率的算术平均)作为评估的指标。</p><h5 id="平方根误差-RMSE"><a href="#平方根误差-RMSE" class="headerlink" title="平方根误差 RMSE"></a>平方根误差 RMSE</h5><p>​      RMSE 平方根误差经常被用来衡量回归模型的好坏，其计算公式为 $RMSE = \sqrt{\frac{1}{n}\sum^{n}<em>{i-1}{(y</em>{i}-\hat{y_{i}})^2}}$, 其中 $y_i$  是第i个样本点的真实值吗，$\hat{y_i}$  是 第i个样本的预测值，n 是样本点的个数。</p><p>​     一般情况下，RMSE 能够更好的反映回归模型预测值与真实值的偏离程度。但在实际问题中，如果存在个别偏离程度非常大的<strong>离群点</strong>(Outlier),   即使离群点数量非常少，也会让RSME 指标变得非常差。</p><p>​     针对这种情况从三个角度进行解决。（1） 如何认定这些离群点是“噪声点”的话，就需要在数据预处理的阶段把这些噪声<strong>过滤</strong>掉。（2）如果不认为这些离群点是“噪声点”的话，需要进一步<strong>提高模型的预测能力</strong>，将离群点产生的机制建模进去。（3）找一个更合适的指标来评估模型。比如平均绝对百分比误差<strong>MAPE</strong>， 它定义为  $MAPE  = \sum_{i=1}^{n}\lvert \frac{y_i - \hat{y_i}}{y_i}\rvert \times\frac{100}{n}$,  相比于 RSME， MAPE 相当于把这个点的误差进行了归一化，降低了个别离群点带来的误差影响。</p><h4 id="2-混淆矩阵、P-R曲线、ROC-曲线"><a href="#2-混淆矩阵、P-R曲线、ROC-曲线" class="headerlink" title="2. 混淆矩阵、P-R曲线、ROC 曲线"></a>2. 混淆矩阵、P-R曲线、ROC 曲线</h4><p><img src="/2019/03/10/model-evaluation/matrix.png" alt="混淆矩阵"></p><p>​        <strong>精确率：</strong> 分类正确的正样本个数占分类器判定为正样本的样本个数的比例。即: $Precision = \frac{TP}{TP+FP}$。</p><p>​        <strong>召回率：</strong> 分类正确的正样本个数占真正正样本个数的比例。即：$Recall = \frac{TP}{TP+FN}$。</p><p>​        Precision 值和 Recall 值是既矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在”更有把握“时才把样本预测为正样本，但此时由于过于保守而漏掉很多”没有把握“的正样本，导致Recall值降低。</p><p>​        P-R 曲线能够综合评估一个排序模型的好坏。P-R 曲线的横轴是召回率，纵轴是精确率。对于一个排序模型来说， 某P-R曲线上的一个点代表着，在某一阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回的结果对应的召回率和精确率。整条P-R曲线是通过将阈值从高到底移动而生成的。</p><p>​        <strong>假阳性率</strong>：分类错误的正样本(预测为正样本，实际是正样本)占真正负样本的比例。即 $FPR = \frac{FP}{FP+TN}$。</p><p>​        <strong>真阳性率</strong>：分类正确的正样本占真正正样本个数的比例。$TPR = \frac{TP}{TP+FN}$。</p><p>​        ROC 曲线是通过不断移动分类器区分正负预测结果的阈值来生成曲线上的一组关键点的。从最高的得分开始（实际上是从正无穷开始，对应ROC 曲线的零点）， 逐渐调整到最低得分，每一个阈值都会对应一个FPR和TPR，在ROC图上绘制出每个阈值对应的位置，再连接所有点酒得到最终的ROC 曲线。另外所谓的AUC 是指ROC 曲线下的面积大小，该值能够量化地反应基于ROC 曲线衡量出的模型性能。计算AUC 的值只需要沿着ROC横轴积分即可。由于ROC 曲线一般都处于y=x 这条直线的上方，所以AUC 的取值一般在0.5-1 之间。AUC 越大，说明分类器越可能把真正的正样本排在前面，分类性能越好。</p><p>​    相比于 P-R 曲线，ROC 曲线有一个特点，当政府样本的分布发生变化时， ROC 曲线的形状能够基本保持不变，而P-R 曲线的形状一般会发生比较剧烈的变化。所以 ROC 曲线的使用场景更多，被广泛用于排序、推荐、广告等领域。</p><p>​        <strong>F1-Score</strong> 也能综合反映一个排序模型的性能。它是精准率和召回率的调和平均值。它的定义为：</p><script type="math/tex; mode=display">F1 = \frac{2*precision*recall}{precision+recall}</script><h4 id="3-余弦距离的应用"><a href="#3-余弦距离的应用" class="headerlink" title="3. 余弦距离的应用"></a>3. 余弦距离的应用</h4><p>​        对于两个向量 A和 B ，其余弦相似度的定义为 $cos(A,B) = \frac{A\cdot B}{\Vert A \Vert_2 \Vert B \Vert_2}$。 即两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心它们的绝对大小，其取值范围是[-1, 1]。 相比较而言，欧式距离的数值受维度的影响，范围不固定，并且含义也比较模糊。总体来说，欧式距离体现在数值上的绝对差异，而余弦距离则体现方向上的相对差异。比如统计两部剧的用户观看行为，用户A 的观看向量是（0，1）， 而用户B 的观看向量为（1，0）；此时两者的余弦距离很大，而欧式距离很小；我们分析两个用户不同视频的偏好，更关注相对差异，显然应当使用余弦距离。而当我们分析用户活跃度时，以登录次数和平均观看市场作为调整，余弦距离会认为（1，10）（10，100） 两个用户距离很近；但是显然两个用户活跃度有着极大差异的，此时我们要关注数值的绝对差异，应当使用欧式距离。</p><p>​        考查一个距离是否是严格定义的距离。要从距离的定义出发：在一个集合中，如果每一对元素均可唯一决定一个实数，使得三条距离公理（正定性、对称性、三角不等式）成立，则该实数可称为这对元素之间的距离。以余弦距离为例：</p><ul><li><p>正定型：$dist(A, B) = 1-  cos\theta \ge 0 $ 恒成立， 特别地，有  $dist(A, B) = 0 \Leftrightarrow \Vert A \Vert_2 \Vert B \Vert_2 = AB \Leftrightarrow A=B$</p><p>因此余弦距离满足正定性。</p></li><li><p>对称性： </p></li><li><script type="math/tex; mode=display">dist(A, B) = 1- cos(A,B) = \frac{\Vert A \Vert_2 \Vert B \Vert_2 - A\cdot B}{\Vert A \Vert_2 \Vert B \Vert_2} = \frac{\Vert B \Vert_2 \Vert A \Vert_2 - A\cdot B}{\Vert A \Vert_2 \Vert B \Vert_2} = dist(B, A)</script><p>因此，余弦距离满足对称性。</p></li><li><p>三角不等式：该性质并不成立，下面给出一个反例。给定 A = (1, 0)， B = (1, 1)，C=（0，1），则有</p><script type="math/tex; mode=display">dist(A, B) = 1 - \frac{\sqrt{2}}{2}</script><script type="math/tex; mode=display">dist(B, C) = 1 - \frac{\sqrt{2}}{2}</script><script type="math/tex; mode=display">dist(A,C) = 1</script><p>因此有 $dist(A, B)+dist(B,C) = 2-\sqrt{2} &lt; 1 = dist(A, C)$</p></li></ul><p>在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离，还有KL距离，也叫相对熵， 它常用于计算两个分布之间的差异，但不满足对称性和三角不等式。</p><h4 id="4-为什么对模型进行过充分的离线评估之后，还要进行在线A-B-测试？如何进行A-B-测试？"><a href="#4-为什么对模型进行过充分的离线评估之后，还要进行在线A-B-测试？如何进行A-B-测试？" class="headerlink" title="4. 为什么对模型进行过充分的离线评估之后，还要进行在线A/B 测试？如何进行A/B 测试？"></a>4. 为什么对模型进行过充分的离线评估之后，还要进行在线A/B 测试？如何进行A/B 测试？</h4><p>需要进行在线 A/B 测试的<strong>原因</strong>如下：</p><p>（1）离线评估<strong>无法完全消除模型过拟合的影响</strong>，因此，得出的离线评估结果无法完全替代线上评估结果。</p><p>（2）离线评估<strong>无法完全还原线上工程环境</strong>。一般来讲，离线评估往往不会考虑线上环境的延迟、数据丢失、标签数据缺失等情况。因此，离线评估的结果是理想工程环境下的结果。</p><p>（3）线上系统的<strong>某些商业指标</strong>在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标，往往无法直接获得。</p><p>进行A/B 测试的主要手段是将用户划分为实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以就模型。在划分用户的过程过程中，要注意样本的独立性（同一用户每次只能划分到一个分组中）和采样方式的无偏性（划分过程中选取的usr_id 是一个随机数）。    </p><h4 id="5-模型评估中的验证方法"><a href="#5-模型评估中的验证方法" class="headerlink" title="　5. 模型评估中的验证方法"></a>　5. 模型评估中的验证方法</h4><p><strong>Holdout检验：</strong>　将原始的样本集合随机划分为训练集和验证集两部分。训练集用于模型训练，　验证集用于模型验证。　<strong>缺点</strong>：在验证集上计算出来的最后评估指标与原始分组有很大关系。</p><p><strong>交叉验证：</strong>　最常见的是ｋ-fold　交叉验证。首先将全部样本划分成ｋ个大小相等的样本子集；依次遍历这ｋ个子集，每次把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估；最后把ｋ次评估指标的平均值作为最终的评估指标。在实际实验中，ｋ经常取10。</p><p><strong>自助法(Bootstrap) : </strong> 对于总数为ｎ　的样本集合，进行ｎ次有放回的随机采样，得到大小为ｎ的训练集合。ｎ次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集，进行模型验证。</p><p>　　在自助采样过程中。对于样本进行ｎ次自助抽样，当ｎ趋于无穷大时，最终有多少数据从未被选择过？</p><p>一个样本在一次抽样过程中未被抽中的概率为　$1 - \frac{1}{n} $，　ｎ次抽样均未被抽中的概率为 $（１-\frac{1}{n})^n$。 当ｎ趋于无穷大时，概率为　</p><script type="math/tex; mode=display">{\lim_{n\to+\infty}}(1-\frac{1}{n})^n 　 = \lim_{n\to\infty}\frac{1}{(1+\frac{1}{n-1})^n}　 = \frac{1}{\lim_{n\to\infty}(1+\frac{1}{n-1})^{n-1}} ×\frac{1}{\lim_{n\to\infty}(1+\frac{1}{n-1})}   = \frac{1}{e}    \approx 0.368</script><h4 id="6-超参数调优"><a href="#6-超参数调优" class="headerlink" title="　6. 超参数调优"></a>　6. 超参数调优</h4><p><strong>网格搜索：</strong>　网格搜索可能是最简单，应用最广泛的超参数搜索算法，它通过查找搜索范围内的所有的点来确定最优值。在实际应用中，我们一般会先使用较广的搜索范围和较大的步长，来寻找全局最优值可能的位置；然后会逐渐缩小搜索范围和步长，来寻找更精确的最优值。</p><p><strong>随机搜索：</strong>　在搜索范围内随机选取样本点而不是测试上界和下界之间之间的所有值。它的理论依据是如果样本点足够大，那么通过随机采样也能大概率找到全局最优值或者近似值、。</p><p><strong>贝叶斯优化算法：</strong>贝叶斯优化算法通过对目标函数的形状进行学习，找到使目标函数向全局最优值提升的参数。具体来说，它的学习目标函数形状的方法是，首先根据先验分布，假设一个搜集函数；然后每一次使用新的采样点来测试目标函数时，利用这个信息来更新目标函数的先验分布；最后，算法测试由后验分布给出的全局最优最可能出现的位置的点。对于贝叶斯算法，有一个需要注意的地方，一旦找到一个局部最优值，它就会在该区域不断采样，所以很容易陷入局部最优值。为了弥补这个缺陷，贝叶斯优化算法会在探索和利用直接找到一个平衡点，“探索”就是在还未取样的区域获取采样点；而“利用”则是根据后验分布在最可能出现的全局区域最值进行采样。</p><h4 id="7-在模型评估过程中，过拟合现象和欠拟合现象具体是指什么"><a href="#7-在模型评估过程中，过拟合现象和欠拟合现象具体是指什么" class="headerlink" title="　7. 在模型评估过程中，过拟合现象和欠拟合现象具体是指什么?"></a>　7. 在模型评估过程中，过拟合现象和欠拟合现象具体是指什么?</h4><p><strong>过拟合</strong>是指模型对于训练数据拟合过当的情况，反应到评估指标上，就是模型在训练集上表现很好，但是在测试集和新数据上表现较差。 <strong>欠拟合</strong>是指模型在训练和预测时表现都不好的情况。</p><p><img src="/2019/03/10/model-evaluation/underfitting.png" alt="IMG"></p><h4 id="8-常见的降低过拟合和欠拟合风险的方法"><a href="#8-常见的降低过拟合和欠拟合风险的方法" class="headerlink" title="8. 常见的降低过拟合和欠拟合风险的方法"></a>8. 常见的降低过拟合和欠拟合风险的方法</h4><h5 id="降低过拟合风险的方法"><a href="#降低过拟合风险的方法" class="headerlink" title="　降低过拟合风险的方法"></a>　降低过拟合风险的方法</h5><p>（１）　获取更多的数据集，或者通过一定的规则来扩充训练数据，　如在图像分类问题上，可以通过平移、旋转、缩放等方法来扩充数据；更进一步地，可以通过对抗生成网络来合成大量的新训练数据。</p><p>（２）降低模型的复杂度。当数据较少，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。例如，在神经网络中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。</p><p>（３）正则化方法。　给模型的参数加上一定的正则约束，比如，将权值的大小加入到损失函数中。以L2正则化为例：$C = C<em>0 + \frac{\lambda}{2n}\dot\sum</em>{i}{w_i}^2$。 这样在优化原来目标函数$C_0$　的同时，也能避免权值过大带来的过拟合风险。</p><p>（４）集成学习方法。集成学习是把多个模型集成在一起，来降低模型的过拟合风险。</p><h5 id="降低欠拟合风险的方法"><a href="#降低欠拟合风险的方法" class="headerlink" title="　降低欠拟合风险的方法"></a>　降低欠拟合风险的方法</h5><p>（１）添加新特征。　当特征不足或者现有特征与样本标签的相关性不强时，　模型容易出现欠拟合。</p><p>（２）增加模型复杂度。简单模型的学习能力较差，通过增加模型的复杂度可以使模型拥有较强的拟合能力。例如，在线性模型中添加高次项，在神经网络中添加网络层数或神经元个数等。</p><p>（３）减小正则化洗漱。正则化是用来防止过拟合的，但当模型中出现欠拟合现象时，则需要有针对性地减少正则化系数。</p><p><em>补充：添加特征时，通过挖掘“上下文特征”、“ID 类特征”、“组合特征”等新的特征，往往能取得更好的效果，在深度学习中，有很多模型可以帮助完成特征工程，如因子分解机、梯度提升策略树、Deep-crossing等都可以成为丰富特征的方法</em></p>]]></content>
    
    
    <categories>
      
      <category>基础</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch API</title>
    <link href="/2019/03/08/Pytorch-API/"/>
    <url>/2019/03/08/Pytorch-API/</url>
    
    <content type="html"><![CDATA[<p>Pytorch API 汇总整理</p><a id="more"></a><h3 id="1-import-torch"><a href="#1-import-torch" class="headerlink" title="1. import torch"></a>1. import torch</h3><p>import &amp; vision</p><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch print(torch.__version__)</code></pre><h3 id="2-Tensor-type-🌟"><a href="#2-Tensor-type-🌟" class="headerlink" title="2. Tensor type 🌟"></a>2. Tensor type 🌟</h3><p>Pytorch 给出了 9 种 CPU Tensor 类型和 9 种 GPU Tensor 类型。Pytorch 中默认的数据类型是 torch.FloatTensor, 即 torch.Tensor 等同于 torch.FloatTensor。</p><div class="table-container"><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td>torch.float32 or torch.float</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>64-bit floating point</td><td>torch.float64 or torch.double</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr><tr><td>16-bit floating point</td><td>torch.float16 or torch.half</td><td>torch.HalfTensor</td><td>torch.cuda.HalfTensor</td></tr><tr><td>8-bit integer (unsigned)</td><td>torch.uint8</td><td>torch.ByteTensor</td><td>torch.cuda.ByteTensor</td></tr><tr><td>8-bit integer (signed)</td><td>torch.int8</td><td>torch.CharTensor</td><td>torch.cuda.CharTensor</td></tr><tr><td>16-bit integer (signed)</td><td>torch.int16 or torch.short</td><td>torch.ShortTensor</td><td>torch.cuda.ShortTensor</td></tr><tr><td>32-bit integer (signed)</td><td>torch.int32 or torch.int</td><td>torch.IntTensor</td><td>torch.cuda.IntTensor</td></tr><tr><td>64-bit integer (signed)</td><td>torch.int64 or torch.long</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>Boolean</td><td>torch.bool</td><td>torch.BoolTensor</td><td>torch.cuda.BoolTensor</td></tr></tbody></table></div><h5 id="设置默认Tensor-类型"><a href="#设置默认Tensor-类型" class="headerlink" title="设置默认Tensor 类型"></a>设置默认Tensor 类型</h5><p>Pytorch 可以通过 <code>set_default_tensor_type</code> 函数<strong>设置默认使用的Tensor类型</strong>， 在局部使用完后如果需要其他类型，则还需要重新设置会所需的类型 </p><pre><code class="hljs elm"><span class="hljs-title">torch</span>.set_default_tensor_<span class="hljs-keyword">type</span>(&#x27;torch.<span class="hljs-type">DoubleTensor</span>&#x27;)</code></pre><h5 id="CPU-GPU-互转"><a href="#CPU-GPU-互转" class="headerlink" title="CPU/GPU 互转"></a>CPU/GPU 互转</h5><p>CPU Tensor 和 GPU Tensor 的区别在于， 前者存储在内存中，而后者存储在显存中。两者之间的转换可以通过 <code>.cpu()</code>、<code>.cuda()</code>和 <code>.to(device)</code> 来完成  </p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.cuda() <span class="hljs-comment"># CPU -&gt; GPU</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span><span class="hljs-meta">&gt;&gt;&gt; </span>a = a.cpu() <span class="hljs-comment"># GPU -&gt; CPU</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.FloatTensor&#x27;</span><span class="hljs-meta">&gt;&gt;&gt; </span>a = a.to(device) <span class="hljs-comment"># to device</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span></code></pre><h5 id="判定-Tensor-类型的几种方式"><a href="#判定-Tensor-类型的几种方式" class="headerlink" title="判定 Tensor 类型的几种方式:"></a>判定 Tensor 类型的几种方式:</h5><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>a.is_cuda  <span class="hljs-comment"># 可以显示是否在显存中</span><span class="hljs-literal">True</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.dtype   <span class="hljs-comment"># Tensor 内部data的类型</span>torch.float32<span class="hljs-meta">&gt;&gt;&gt; </span>a.type()<span class="hljs-string">&#x27;torch.cuda.FloatTensor&#x27;</span>  <span class="hljs-comment"># 可以直接显示 Tensor 类型 = is_cuda + dtype</span></code></pre><h5 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h5><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>a.type(torch.DoubleTensor)   <span class="hljs-comment"># 使用 type() 函数进行转换</span>tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], dtype=torch.float64)<span class="hljs-meta">&gt;&gt;&gt; </span>a = a.double()  <span class="hljs-comment"># 直接使用 int()、long() 、float() 、和 double() 等直接进行数据类型转换进行</span>tensor([[<span class="hljs-number">0.6065</span>, <span class="hljs-number">0.0122</span>, <span class="hljs-number">0.4473</span>],        [<span class="hljs-number">0.5937</span>, <span class="hljs-number">0.5530</span>, <span class="hljs-number">0.4663</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, dtype=torch.float64)<span class="hljs-meta">&gt;&gt;&gt; </span>b = torch.randn(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>b.type_as(a)  <span class="hljs-comment"># 使用 type_as 函数, 并不需要明确具体是哪种类型</span>tensor([[ <span class="hljs-number">0.2129</span>,  <span class="hljs-number">0.1877</span>, <span class="hljs-number">-0.0626</span>,  <span class="hljs-number">0.4607</span>, <span class="hljs-number">-1.0375</span>],        [ <span class="hljs-number">0.7222</span>, <span class="hljs-number">-0.3502</span>,  <span class="hljs-number">0.1288</span>,  <span class="hljs-number">0.6786</span>,  <span class="hljs-number">0.5062</span>],        [<span class="hljs-number">-0.4956</span>, <span class="hljs-number">-0.0793</span>,  <span class="hljs-number">0.7590</span>, <span class="hljs-number">-1.0932</span>, <span class="hljs-number">-0.1084</span>],        [<span class="hljs-number">-2.2198</span>,  <span class="hljs-number">0.3827</span>,  <span class="hljs-number">0.2735</span>,  <span class="hljs-number">0.5642</span>,  <span class="hljs-number">0.6771</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>,       dtype=torch.float64)</code></pre><h5 id="numpy-array-与-torch-Tensor-互转"><a href="#numpy-array-与-torch-Tensor-互转" class="headerlink" title="numpy array 与　torch Tensor　互转"></a>numpy array 与　torch Tensor　互转</h5><pre><code class="hljs python">torch.Tensor 与 np.ndarray 转换<span class="hljs-comment"># torch.Tensor -&gt; np.ndarray.</span>ndarray = tensor.cpu().numpy()<span class="hljs-comment"># np.ndarray -&gt; torch.Tensor.</span>tensor = torch.from_numpy(ndarray).float()tensor = torch.from_numpy(ndarray.copy()).float()  <span class="hljs-comment"># If ndarray has negative stride</span></code></pre><h5 id="Tensor-相关信息获取"><a href="#Tensor-相关信息获取" class="headerlink" title="Tensor 相关信息获取"></a>Tensor 相关信息获取</h5><pre><code class="hljs python">t.size()/t、.shape   <span class="hljs-comment"># 两者等价， 返回 t 的形状, 可以使用 t.size()[1] 或 t.size(1) 查看列数</span>t.numel() / t.nelement()  <span class="hljs-comment"># 两者等价, 返回 tensor 中元素总个数</span>t.item()  <span class="hljs-comment"># 取出单个 tensor 的值</span>t.dim()  <span class="hljs-comment"># 维度</span></code></pre><h3 id="3-Tensor-Create"><a href="#3-Tensor-Create" class="headerlink" title="3. Tensor Create"></a>3. Tensor Create</h3><h5 id="最基本的Tensor创建方式"><a href="#最基本的Tensor创建方式" class="headerlink" title="最基本的Tensor创建方式"></a>最基本的Tensor创建方式</h5><pre><code class="hljs python">troch.Tensor(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># 会使用默认的类型创建 Tensor, </span>                   <span class="hljs-comment"># 可以通过 torch.set_default_tensor_type(&#x27;torch.DoubleTensor&#x27;) 进行修改</span>torch.DoubleTensor(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># 指定类型创建 Tensor</span>torch.Tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]])  <span class="hljs-comment"># 通过 list 创建 Tensor</span>                                <span class="hljs-comment"># 将 Tensor转换为list可以使用: t.tolist()</span>torch.from_numpy(np.array([<span class="hljs-number">2</span>, <span class="hljs-number">3.3</span>]) ) <span class="hljs-comment"># 通过 numpy array 创建 tensor</span></code></pre><h5 id="确定初始值的方式创建"><a href="#确定初始值的方式创建" class="headerlink" title="确定初始值的方式创建"></a>确定初始值的方式创建</h5><pre><code class="hljs python">torch.ones(sizes)  <span class="hljs-comment"># 全 1 Tensor     </span>torch.zeros(sizes)  <span class="hljs-comment"># 全 0 Tensor</span>torch.eye(sizes)  <span class="hljs-comment"># 对角线为1，不要求行列一致</span>torch.full(sizes, value) <span class="hljs-comment"># 指定 value</span></code></pre><h5 id="分布"><a href="#分布" class="headerlink" title="分布"></a>分布</h5><pre><code class="hljs python">torch.rand(sizes)  <span class="hljs-comment"># 均匀分布   </span>torch.randn(sizes)   <span class="hljs-comment"># 标准分布</span><span class="hljs-comment"># 正态分布: 返回一个张量，包含从给定参数 means, std 的离散正态分布中抽取随机数。 </span><span class="hljs-comment"># 均值 means 是一个张量，包含每个输出元素相关的正态分布的均值 -&gt; 以此张量的均值作为均值</span><span class="hljs-comment"># 标准差 std 是一个张量，包含每个输出元素相关的正态分布的标准差 -&gt; 以此张量的标准差作为标准差。 </span><span class="hljs-comment"># 均值和标准差的形状不须匹配，但每个张量的元素个数须相同</span>torch.normal(mean=torch.arange(<span class="hljs-number">1.</span>, <span class="hljs-number">11.</span>), std=torch.arange(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">-0.1</span>))tensor([<span class="hljs-number">-0.1987</span>,  <span class="hljs-number">3.1957</span>,  <span class="hljs-number">3.5459</span>,  <span class="hljs-number">2.8150</span>,  <span class="hljs-number">5.5398</span>,  <span class="hljs-number">5.6116</span>,  <span class="hljs-number">7.5512</span>,  <span class="hljs-number">7.8650</span>,         <span class="hljs-number">9.3151</span>, <span class="hljs-number">10.1827</span>])torch.uniform(<span class="hljs-keyword">from</span>,to) <span class="hljs-comment"># 均匀分布 </span>torch.arange(s, e, steps)  <span class="hljs-comment"># 从 s 到 e，步长为 step</span>torch.linspace(s, e, num)   <span class="hljs-comment"># 从 s 到 e, 均匀切分为 num 份</span><span class="hljs-comment"># ! 注意linespace和arange的区别，前者的最后一个参数是生成的Tensor中元素的数量，而后者的最后一个参数是步长。</span>torch.randperm(m) <span class="hljs-comment"># 0 到 m-1 的随机序列</span><span class="hljs-comment"># ! shuffle 操作</span>tensor[torch.randperm(tensor.size(<span class="hljs-number">0</span>))]</code></pre><h5 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h5><p>Pytorch 有几种不同的复制方式，注意区分</p><div class="table-container"><table><thead><tr><th>Operation</th><th>New/Shared memory</th><th>Still in computation graph</th></tr></thead><tbody><tr><td>tensor.clone()</td><td>New</td><td>Yes</td></tr><tr><td>tensor.detach()</td><td>Shared</td><td>No</td></tr><tr><td>tensor.detach.clone()</td><td>New</td><td>No</td></tr></tbody></table></div><h3 id="4-索引、比较、排序"><a href="#4-索引、比较、排序" class="headerlink" title="4. 索引、比较、排序"></a>4. 索引、比较、排序</h3><h5 id="索引操作"><a href="#索引操作" class="headerlink" title="索引操作"></a>索引操作</h5><pre><code class="hljs python">a.item() <span class="hljs-comment">#　从只包含一个元素的张量中提取值</span>a[row, column]   <span class="hljs-comment"># row 行， cloumn 列</span>a[index]   <span class="hljs-comment"># 第index 行</span>a[:,index]   <span class="hljs-comment"># 第 index 列</span>a[<span class="hljs-number">0</span>, <span class="hljs-number">-1</span>]  <span class="hljs-comment"># 第零行， 最后一个元素</span>a[:index]  <span class="hljs-comment"># 前 index 行</span>a[:row, <span class="hljs-number">0</span>:<span class="hljs-number">1</span>]  <span class="hljs-comment"># 前 row 行， 0和1列</span>a[a&gt;<span class="hljs-number">1</span>]  <span class="hljs-comment"># 选择 a &gt; 1的元素， 等价于 a.masked_select(a&gt;1)</span>torch.nonzero(a) <span class="hljs-comment"># 选择非零元素的坐标，并返回</span>a.clamp(x, y)  <span class="hljs-comment"># 对 Tensor 元素进行限制， 小于x用x代替， 大于y用y代替</span>torch.where(condition, x, y)  <span class="hljs-comment"># 满足condition 的位置输出x， 否则输出y</span><span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[ <span class="hljs-number">6.</span>, <span class="hljs-number">-2.</span>],        [ <span class="hljs-number">8.</span>,  <span class="hljs-number">0.</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>torch.where(a &gt; <span class="hljs-number">1</span>, torch.full_like(a, <span class="hljs-number">1</span>), a)  <span class="hljs-comment"># 大于1 的部分直接用1代替， 其他保留原值</span>tensor([[ <span class="hljs-number">1.</span>, <span class="hljs-number">-2.</span>],        [ <span class="hljs-number">1.</span>,  <span class="hljs-number">0.</span>]])<span class="hljs-comment">#　得到非零元素</span>torch.nonzero(tensor)               <span class="hljs-comment"># 非零元素的索引</span>torch.nonzero(tensor == <span class="hljs-number">0</span>)          <span class="hljs-comment"># 零元素的索引</span>torch.nonzero(tensor).size(<span class="hljs-number">0</span>)       <span class="hljs-comment"># 非零元素的个数</span>torch.nonzero(tensor == <span class="hljs-number">0</span>).size(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 零元素的个数</span></code></pre><h5 id="比较操作"><a href="#比较操作" class="headerlink" title="比较操作"></a>比较操作</h5><pre><code class="hljs python">gt &gt;    lt &lt;     ge &gt;=     le &lt;=   eq ==    ne != topk(input, k) -&gt; (Tensor, LongTensor)sort(input) -&gt; (Tensor, LongTensor)max/min =&gt; max(tensor)      max(tensor, dim)    max(tensor1, tensor2)</code></pre><p>sort 函数接受两个参数, 其中 参数 0 为按照行排序、1为按照列排序: True 为降序， False 为升序， 返回值有两个， 第一个是排序结果， 第二个是排序序号</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch<span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[<span class="hljs-number">-1.8500</span>, <span class="hljs-number">-0.2005</span>,  <span class="hljs-number">1.4475</span>],        [<span class="hljs-number">-1.7795</span>, <span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.8965</span>],        [ <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>,  <span class="hljs-number">1.6395</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">0</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>] tensor([[ <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>,  <span class="hljs-number">1.6395</span>],        [<span class="hljs-number">-1.7795</span>, <span class="hljs-number">-0.2005</span>,  <span class="hljs-number">1.4475</span>],        [<span class="hljs-number">-1.8500</span>, <span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.8965</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">0</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>],        [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],        [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">1</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">1</span>]tensor([[<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],        [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>],        [<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.sort(<span class="hljs-number">1</span>, <span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]tensor([[ <span class="hljs-number">1.4475</span>, <span class="hljs-number">-0.2005</span>, <span class="hljs-number">-1.8500</span>],        [<span class="hljs-number">-0.4968</span>, <span class="hljs-number">-1.7795</span>, <span class="hljs-number">-1.8965</span>],        [ <span class="hljs-number">1.6395</span>,  <span class="hljs-number">0.5798</span>, <span class="hljs-number">-0.1554</span>]])</code></pre><h3 id="5-Element-wise-和-归并操作"><a href="#5-Element-wise-和-归并操作" class="headerlink" title="5. Element-wise 和 归并操作"></a>5. Element-wise 和 归并操作</h3><p>Element-wise：输出的 Tensor 形状与原始的形状一致</p><pre><code class="hljs python">abs / sqrt / div / exp / fmod / log / pow...cos / sin / asin / atan2 / cosh...ceil / round / floor / truncclamp(input, min, max)sigmoid / tanh...</code></pre><p>归并操作：输出的 Tensor 形状小于原始的 Tensor形状</p><pre><code class="hljs python">mean/sum/median/mode   <span class="hljs-comment"># 均值/和/ 中位数/众数</span>norm/dist  <span class="hljs-comment"># 范数/距离</span>std/var  <span class="hljs-comment"># 标准差/方差</span>cumsum/cumprd <span class="hljs-comment"># 累加/累乘</span></code></pre><h3 id="6-变形操作"><a href="#6-变形操作" class="headerlink" title="6. 变形操作"></a>6. 变形操作</h3><h5 id="view-resize-reshape-调整Tensor的形状"><a href="#view-resize-reshape-调整Tensor的形状" class="headerlink" title="view/resize/reshape  调整Tensor的形状"></a>view/resize/reshape  调整Tensor的形状</h5><ul><li>元素总数必须相同  </li><li>view 和 reshape 可以使用 -1 自动计算维度</li><li>共享内存</li></ul><p>!!!  <code>view()</code> 操作是需要 Tensor 在内存中连续的， 这种情况下需要使用 <code>contiguous()</code> 操作先将内存变为连续。 对于reshape 操作， 可以看做是 <code>Tensor.contiguous().view()</code>.   🌟</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.Tensor(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[<span class="hljs-number">6.0000e+00</span>, <span class="hljs-number">8.0000e+00</span>],        [<span class="hljs-number">1.0000e+00</span>, <span class="hljs-number">1.8367e-40</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.resize(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)tensor([[<span class="hljs-number">6.0000e+00</span>],        [<span class="hljs-number">8.0000e+00</span>],        [<span class="hljs-number">1.0000e+00</span>],        [<span class="hljs-number">1.8367e-40</span>]])</code></pre><h5 id="transpose-permute-各维度之间的变换"><a href="#transpose-permute-各维度之间的变换" class="headerlink" title="transpose / permute  各维度之间的变换"></a>transpose / permute  各维度之间的变换</h5><p>transpose 可以将指定的两个维度的元素进行转置， permute 则可以按照指定的维度进行维度变换</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>xtensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>]],        [[ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])<span class="hljs-meta">&gt;&gt;&gt; </span>x.shapetorch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>])<span class="hljs-meta">&gt;&gt;&gt; </span>x.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 2, 3])</span>tensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>],         [ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])<span class="hljs-meta">&gt;&gt;&gt; </span>x.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 2, 3])</span>tensor([[[<span class="hljs-number">-0.9699</span>, <span class="hljs-number">-0.3375</span>, <span class="hljs-number">-0.0178</span>],         [ <span class="hljs-number">1.4260</span>, <span class="hljs-number">-0.2305</span>, <span class="hljs-number">-0.2883</span>]]])<span class="hljs-meta">&gt;&gt;&gt; </span></code></pre><h5 id="squeeze-dim-unsquence-dim-🌟"><a href="#squeeze-dim-unsquence-dim-🌟" class="headerlink" title="squeeze(dim) / unsquence(dim)   🌟"></a>squeeze(dim) / unsquence(dim)   🌟</h5><p>处理 size 为 1 的维度， 前者用于去除 size 为 1 的维度， 而后者则是将指定的维度的size变为1</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>atensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]) <span class="hljs-comment"># shape =&gt; torch.Size([3])</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># shape =&gt; torch.Size([1, 3])</span><span class="hljs-meta">&gt;&gt;&gt; </span>a.unqueeze(<span class="hljs-number">0</span>).squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment"># shape =&gt; torch.Size([3])</span></code></pre><h5 id="expand-expand-as-repeat复制元素来扩展维度"><a href="#expand-expand-as-repeat复制元素来扩展维度" class="headerlink" title="expand / expand_as / repeat复制元素来扩展维度"></a>expand / expand_as / repeat复制元素来扩展维度</h5><p>有时需要采用复制的形式来扩展 Tensor 的维度， 这时可以使用 <code>expand</code>， <code>expand()</code> 函数将 size 为 1的维度复制扩展为指定大小， 也可以用 <code>expand_as()</code>函数指定为 示例 Tensor 的维度。</p><p>!! <code>expand</code> 扩大 tensor 不需要分配新内存，只是仅仅新建一个 tensor 的视图，其中通过将 stride 设为0，一维将会扩展位更高维。</p><p><code>repeat</code> 沿着指定的维度重复 tensor。 不同于 <code>expand()</code>，复制的是 tensor 中的数据。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[[<span class="hljs-number">0.3094</span>],         [<span class="hljs-number">0.4812</span>]],        [[<span class="hljs-number">0.0950</span>],         [<span class="hljs-number">0.8652</span>]]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.expand(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>) <span class="hljs-comment"># 将第2维的维度由1变为3， 则复制该维的元素，并扩展为3</span>tensor([[[<span class="hljs-number">0.3094</span>, <span class="hljs-number">0.3094</span>, <span class="hljs-number">0.3094</span>],         [<span class="hljs-number">0.4812</span>, <span class="hljs-number">0.4812</span>, <span class="hljs-number">0.4812</span>]],        [[<span class="hljs-number">0.0950</span>, <span class="hljs-number">0.0950</span>, <span class="hljs-number">0.0950</span>],         [<span class="hljs-number">0.8652</span>, <span class="hljs-number">0.8652</span>, <span class="hljs-number">0.8652</span>]]])<span class="hljs-meta">&gt;&gt;&gt; </span>a.repeat(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>) <span class="hljs-comment"># 将第二位复制一次</span>tensor([[[<span class="hljs-number">0.3094</span>],         [<span class="hljs-number">0.4812</span>],         [<span class="hljs-number">0.3094</span>],         [<span class="hljs-number">0.4812</span>]],        [[<span class="hljs-number">0.0950</span>],         [<span class="hljs-number">0.8652</span>],         [<span class="hljs-number">0.0950</span>],         [<span class="hljs-number">0.8652</span>]]])</code></pre><h5 id="使用切片操作扩展多个维度-🌟"><a href="#使用切片操作扩展多个维度-🌟" class="headerlink" title="使用切片操作扩展多个维度 🌟"></a>使用切片操作扩展多个维度 🌟</h5><pre><code class="hljs fortran">b = a[:,<span class="hljs-keyword">None</span>, <span class="hljs-keyword">None</span>,:] # <span class="hljs-keyword">None</span> 处的维度为１</code></pre><h3 id="7-组合与分块"><a href="#7-组合与分块" class="headerlink" title="7. 组合与分块"></a>7. 组合与分块</h3><p><strong>组合操作</strong> 是将不同的 Tensor 叠加起来。 主要有 <code>cat()</code> 和 <code>torch.stack()</code> 两个函数，cat 即 concatenate 的意思， 是指沿着已有的数据的某一维度进行拼接， 操作后的数据的总维数不变， 在进行拼接时， 除了拼接的维度之外， 其他维度必须相同。 而<code>torch. stack()</code> 函数会新增一个维度， 并按照指定的维度进行叠加。</p><pre><code class="hljs shell">torch.cat(list_of_tensors, dim=0)　  # k 个 (m,n) -&gt; (k*m, n)torch.stack(list_of_tensors, dim=0)   # k 个 (m,n) -&gt; (k*m*n)</code></pre><p><strong>分块操作</strong> 是指将 Tensor 分割成不同的子 Tensor，主要有 <code>torch.chunk()</code> 与 <code>torch.split()</code> 两个函数，前者需要指定分块的数量，而后者则需要指定每一块的大小，以整形或者list来表示。</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.Tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]])<span class="hljs-meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>]]), tensor([[<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]))<span class="hljs-meta">&gt;&gt;&gt; </span>torch.chunk(a, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>],        [<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>]]), tensor([[<span class="hljs-number">3.</span>],        [<span class="hljs-number">6.</span>]]))<span class="hljs-meta">&gt;&gt;&gt; </span>torch.split(a, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)(tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>],        [<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]),)<span class="hljs-meta">&gt;&gt;&gt; </span>torch.split(a, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], <span class="hljs-number">1</span>)(tensor([[<span class="hljs-number">1.</span>],        [<span class="hljs-number">4.</span>]]), tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>],        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]]))</code></pre><h3 id="8-聚合-与-分散"><a href="#8-聚合-与-分散" class="headerlink" title="8.  聚合 与 分散"></a>8.  聚合 与 分散</h3><pre><code class="hljs python">torch.gather(input, dim, index, out=<span class="hljs-literal">None</span>)  <span class="hljs-comment"># 根据 index 和 dim, 寻找 input 对应的索引位置, 得到 output</span>Tensor.scatter_(dim, index, src)   <span class="hljs-comment"># 根据 dim 和 index, 将 src 指定位置上的值， 分配给 output 对应索引位置。</span></code></pre><h3 id="9-linear-algebra"><a href="#9-linear-algebra" class="headerlink" title="9. linear algebra"></a>9. linear algebra</h3><pre><code class="hljs python">trace  <span class="hljs-comment"># 对角线元素之和(矩阵的迹)</span>diag  <span class="hljs-comment"># 对角线元素</span>triu/tril  <span class="hljs-comment"># 矩阵的上三角/下三角</span>addmm/addbmm/addmv/addr/badbmm...  <span class="hljs-comment"># 矩阵运算</span>t <span class="hljs-comment"># 转置</span>dor/cross <span class="hljs-comment"># 内积/外积</span>inverse <span class="hljs-comment"># 矩阵求逆</span>svd  <span class="hljs-comment"># 奇异值分解</span>torch.mm(tensor1, tensor2)   <span class="hljs-comment"># 矩阵乘法  (m*n) * (n*p) -&gt; (m*p)</span>torch.bmm(tensor1, tensor2) <span class="hljs-comment"># batch的矩阵乘法: (b*m*n) * (b*n*p) -&gt; (b*m*p).</span>torch.mv(tensor, vec) <span class="hljs-comment">#　矩阵向量乘法 (m*n) * (n) = (m)</span>tensor1 * tensor2 <span class="hljs-comment"># Element-wise multiplication.</span></code></pre><h3 id="10-基本机制"><a href="#10-基本机制" class="headerlink" title="10. 基本机制"></a>10. 基本机制</h3><h5 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h5><p>不同形状的 Tensor 进行计算时， 可以自动扩展到较大的相同形状再进行计算。 广播机制的前提是一个 Tensor  至少有一个维度，且从尾部遍历 Tensor 时，两者维度必须相等， 其中七个要么是1， 要么不存在</p><h5 id="向量化操作"><a href="#向量化操作" class="headerlink" title="向量化操作"></a>向量化操作</h5><p>可以在同一时间进行批量地并行计算，例如矩阵运算，以达到更高的计算效率的一种方式:</p><h5 id="共享内存机制"><a href="#共享内存机制" class="headerlink" title="共享内存机制"></a>共享内存机制</h5><p>(1) 直接通过 Tensor 来初始化另一个 Tensor， 或者通过 Tensor 的组合、分块、索引、变形来初始化另一个Tensor， 则这两个 Tensor 共享内存:</p><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>b = a<span class="hljs-meta">&gt;&gt;&gt; </span>c = a.view(<span class="hljs-number">6</span>)<span class="hljs-meta">&gt;&gt;&gt; </span>b[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = <span class="hljs-number">0</span><span class="hljs-meta">&gt;&gt;&gt; </span>c[<span class="hljs-number">3</span>] = <span class="hljs-number">4</span><span class="hljs-meta">&gt;&gt;&gt; </span>atensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.3898</span>, <span class="hljs-number">-0.7641</span>],        [ <span class="hljs-number">4.0000</span>,  <span class="hljs-number">0.6859</span>, <span class="hljs-number">-1.5179</span>]])</code></pre><p>(2) 对于一些操作通过加后缀  “_”  实现 inplace 操作， 如 <code>add_()</code> 和 <code>resize_()</code> 等， 这样操作只要被执行， 本身的 Tensor 就会被改变。</p><pre><code class="hljs angelscript">&gt;&gt;&gt; atensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.3898</span>, <span class="hljs-number">-0.7641</span>],        [ <span class="hljs-number">4.0000</span>,  <span class="hljs-number">0.6859</span>, <span class="hljs-number">-1.5179</span>]])&gt;&gt;&gt; a.add_(a)tensor([[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.7796</span>, <span class="hljs-number">-1.5283</span>],        [ <span class="hljs-number">8.0000</span>,  <span class="hljs-number">1.3719</span>, <span class="hljs-number">-3.0358</span>]])</code></pre><p>(3) Tensor与 Numpy 可以高效的完成转换， 并且转换前后的变量共享内存。在进行 Pytorch 不支持的操作的时候， 甚至可以曲线救国， 将 Tensor 转换为 Numpy 类型，操作后再转化为 Tensor</p><pre><code class="hljs clean"># tensor &lt;--&gt; numpyb = a.numpy() # tensor -&gt; numpya = torch.from_numpy(a) # numpy -&gt; tensor</code></pre><p>!!! 需要注意的是，<code>torch.tensor()</code> 总是会进行数据拷贝，新 tensor 和原来的数据不再共享内存。所以如果你想共享内存的话，建议使用 <code>torch.from_numpy()</code> 或者 <code>tensor.detach()</code> 来新建一个 tensor, 二者共享内存。</p><h3 id="11-nn"><a href="#11-nn" class="headerlink" title="11. nn"></a>11. nn</h3><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</code></pre><h5 id="pad-填充"><a href="#pad-填充" class="headerlink" title="pad 填充"></a>pad 填充</h5><pre><code class="hljs python">nn.ConstantPad2d(padding, value)</code></pre><h5 id="卷积和反卷积"><a href="#卷积和反卷积" class="headerlink" title="卷积和反卷积"></a>卷积和反卷积</h5><pre><code class="hljs python">nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, output_padding=<span class="hljs-number">0</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, dilation=<span class="hljs-number">1</span>)</code></pre><pre><code class="hljs python"><span class="hljs-comment">#　最常用的两种卷积层设计 3x3 &amp; 1x1</span>conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, bias=<span class="hljs-literal">True</span>)</code></pre><h5 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h5><pre><code class="hljs python">nn.MaxPool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, return_indices=<span class="hljs-literal">False</span>, ceil_mode=<span class="hljs-literal">False</span>)nn.AvgPool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>, ceil_mode=<span class="hljs-literal">False</span>, count_include_pad=<span class="hljs-literal">True</span>)nn.AdaptiveMaxPool2d(output_size, return_indices=<span class="hljs-literal">False</span>)nn.AdaptiveAvgPool2d(output_size)  <span class="hljs-comment"># global avg pool: output_size=1</span>nn.MaxUnpool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>)</code></pre><h5 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h5><pre><code class="hljs python">nn.Linear(in_features, out_features, bias=<span class="hljs-literal">True</span>)</code></pre><h5 id="防止过拟合相关层"><a href="#防止过拟合相关层" class="headerlink" title="防止过拟合相关层"></a>防止过拟合相关层</h5><pre><code class="hljs python">nn.Dropout2d(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)nn.AlphaDropout(p=<span class="hljs-number">0.5</span>)nn.BatchNorm2d(num_features, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)</code></pre><h5 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h5><pre><code class="hljs python">nn.Softplus(beta=<span class="hljs-number">1</span>, threshold=<span class="hljs-number">20</span>)nn.Tanh()nn.ReLU(inplace=<span class="hljs-literal">False</span>)    nn.ReLU6(inplace=<span class="hljs-literal">False</span>)nn.LeakyReLU(negative_slope=<span class="hljs-number">0.01</span>, inplace=<span class="hljs-literal">False</span>)nn.PReLU(num_parameters=<span class="hljs-number">1</span>, init=<span class="hljs-number">0.25</span>)nn.SELU(inplace=<span class="hljs-literal">False</span>)nn.ELU(alpha=<span class="hljs-number">1.0</span>, inplace=<span class="hljs-literal">False</span>)</code></pre><h5 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h5><pre><code class="hljs python">nn.RNNCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>, nonlinearity=<span class="hljs-string">&#x27;tanh&#x27;</span>)nn.RNN(*args, **kwargs)nn.LSTMCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>)nn.LSTM(*args, **kwargs)nn.GRUCell(input_size, hidden_size, bias=<span class="hljs-literal">True</span>)nn.GRU(*args, **kwargs)</code></pre><h5 id="Embedding"><a href="#Embedding" class="headerlink" title="Embedding"></a>Embedding</h5><pre><code class="hljs python">nn.Embedding(num_embeddings, embedding_dim, padding_idx=<span class="hljs-literal">None</span>, max_norm=<span class="hljs-literal">None</span>, norm_type=<span class="hljs-number">2</span>, scale_grad_by_freq=<span class="hljs-literal">False</span>, sparse=<span class="hljs-literal">False</span>, _weight=<span class="hljs-literal">None</span>)</code></pre><h5 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h5><pre><code class="hljs python">nn.Sequential(*args)</code></pre><h5 id="loss-functon"><a href="#loss-functon" class="headerlink" title="loss functon"></a>loss functon</h5><pre><code class="hljs python">nn.BCELoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.CrossEntropyLoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)<span class="hljs-comment"># CrossEntropyLoss 等价于 log_softmax + NLLLoss</span>nn.L1Loss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.KLDivLoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.MSELoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.NLLLoss(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)nn.NLLLoss2d(weight=<span class="hljs-literal">None</span>, size_average=<span class="hljs-literal">True</span>, ignore_index=<span class="hljs-number">-100</span>, reduce=<span class="hljs-literal">True</span>)nn.SmoothL1Loss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.SoftMarginLoss(size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.TripletMarginLoss(margin=<span class="hljs-number">1.0</span>, p=<span class="hljs-number">2</span>, eps=<span class="hljs-number">1e-06</span>, swap=<span class="hljs-literal">False</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)nn.CosineEmbeddingLoss(margin=<span class="hljs-number">0</span>, size_average=<span class="hljs-literal">True</span>, reduce=<span class="hljs-literal">True</span>)</code></pre><h5 id="functional-🌟"><a href="#functional-🌟" class="headerlink" title="functional    🌟"></a>functional    🌟</h5><pre><code class="hljs python">nn.functional <span class="hljs-comment"># nn中的大多数layer，在functional中都有一个与之相对应的函数。</span>              <span class="hljs-comment"># nn.functional中的函数和nn.Module的主要区别在于，</span>              <span class="hljs-comment"># 用nn.Module实现的layers是一个特殊的类，都是由 class layer(nn.Module)定义，</span>              <span class="hljs-comment"># 会自动提取可学习的参数。而nn.functional中的函数更像是纯函数，</span>              <span class="hljs-comment"># 由def function(input)定义。</span></code></pre><h5 id="init"><a href="#init" class="headerlink" title="init"></a>init</h5><pre><code class="hljs python">torch.nn.init.uniformtorch.nn.init.normaltorch.nn.init.kaiming_uniformtorch.nn.init.kaiming_normaltorch.nn.init.xavier_normaltorch.nn.init.xavier_uniformtorch.nn.init.sparse</code></pre><h5 id="net"><a href="#net" class="headerlink" title="net"></a>net</h5><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">net_name</span>(<span class="hljs-params">nn.Module</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span>        super(net_name, self).__init__()        self.layer_name = xxxx    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span>         x = self.layer_name(x)                <span class="hljs-keyword">return</span> xnet.parameters()   <span class="hljs-comment"># 获取参数 </span>net.named_parameters  <span class="hljs-comment"># 获取参数及名称</span>net.zero_grad()  <span class="hljs-comment"># 网络所有梯度清零, grad 在反向传播过程中是累加的(accumulated)，</span>                 <span class="hljs-comment"># 这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以反向传播之前需把梯度清零。</span></code></pre><h3 id="12-optim-gt-form-torch-import-optim"><a href="#12-optim-gt-form-torch-import-optim" class="headerlink" title="12. optim -&gt; form torch import optim"></a>12. optim -&gt; form torch import optim</h3><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optimoptim.SGD(params, lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0</span>, dampening=<span class="hljs-number">0</span>, weight_decay=<span class="hljs-number">0</span>, nesterov=<span class="hljs-literal">False</span>)optim.ASGD(params, lr=<span class="hljs-number">0.01</span>, lambd=<span class="hljs-number">0.0001</span>, alpha=<span class="hljs-number">0.75</span>, t0=<span class="hljs-number">1000000.0</span>, weight_decay=<span class="hljs-number">0</span>)optim.LBFGS(params, lr=<span class="hljs-number">1</span>, max_iter=<span class="hljs-number">20</span>, max_eval=<span class="hljs-literal">None</span>, tolerance_grad=<span class="hljs-number">1e-05</span>, tolerance_change=<span class="hljs-number">1e-09</span>, history_size=<span class="hljs-number">100</span>, line_search_fn=<span class="hljs-literal">None</span>)optim.RMSprop(params, lr=<span class="hljs-number">0.01</span>, alpha=<span class="hljs-number">0.99</span>, eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>, momentum=<span class="hljs-number">0</span>, centered=<span class="hljs-literal">False</span>)optim.Rprop(params, lr=<span class="hljs-number">0.01</span>, etas=(<span class="hljs-number">0.5</span>, <span class="hljs-number">1.2</span>), step_sizes=(<span class="hljs-number">1e-06</span>, <span class="hljs-number">50</span>))optim.Adadelta(params, lr=<span class="hljs-number">1.0</span>, rho=<span class="hljs-number">0.9</span>, eps=<span class="hljs-number">1e-06</span>, weight_decay=<span class="hljs-number">0</span>)optim.Adagrad(params, lr=<span class="hljs-number">0.01</span>, lr_decay=<span class="hljs-number">0</span>, weight_decay=<span class="hljs-number">0</span>, initial_accumulator_value=<span class="hljs-number">0</span>)optim.Adam(params, lr=<span class="hljs-number">0.001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>, amsgrad=<span class="hljs-literal">False</span>)optim.Adamax(params, lr=<span class="hljs-number">0.002</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>, weight_decay=<span class="hljs-number">0</span>)optim.SparseAdam(params, lr=<span class="hljs-number">0.001</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>), eps=<span class="hljs-number">1e-08</span>)optim.Optimizer(params, defaults)optimizer.zero_grad()  <span class="hljs-comment"># 等价于 net.zero_grad() </span>optimizer.step()</code></pre><h3 id="13-learning-rate"><a href="#13-learning-rate" class="headerlink" title="13.  learning rate"></a>13.  learning rate</h3><pre><code class="hljs python"><span class="hljs-comment"># Reduce learning rate when validation accuarcy plateau.</span>scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=<span class="hljs-string">&#x27;max&#x27;</span>, patience=<span class="hljs-number">5</span>, verbose=<span class="hljs-literal">True</span>)<span class="hljs-comment"># Cosine annealing learning rate.</span>scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class="hljs-number">80</span>)<span class="hljs-comment"># Reduce learning rate by 10 at given epochs.</span>scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="hljs-number">50</span>, <span class="hljs-number">70</span>], gamma=<span class="hljs-number">0.1</span>)<span class="hljs-comment"># Learning rate warmup by 10 epochs.</span>scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=<span class="hljs-keyword">lambda</span> t: t / <span class="hljs-number">10</span>)<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>):    scheduler.step()    train(...); val(...)</code></pre><h3 id="14-save-and-load-model"><a href="#14-save-and-load-model" class="headerlink" title="14. save and load model"></a>14. save and load model</h3><pre><code class="hljs python">torch.save(model.state_dict(), <span class="hljs-string">&#x27;xxxx_params.pth&#x27;</span>)model.load_state_dict(t.load(<span class="hljs-string">&#x27;xxxx_params.pth&#x27;</span>))torch.save(model, <span class="hljs-string">&#x27;xxxx.pth&#x27;</span>)model.torch.load(<span class="hljs-string">&#x27;xxxx.pth&#x27;</span>)all_data = dict(    optimizer = optimizer.state_dict(),    model = model.state_dict(),    info = <span class="hljs-string">u&#x27;model and optim parameter&#x27;</span>)t.save(all_data, <span class="hljs-string">&#x27;xxx.pth&#x27;</span>)all_data = t.load(<span class="hljs-string">&#x27;xxx.pth&#x27;</span>)all_data.keys()</code></pre><h3 id="15-torchvision"><a href="#15-torchvision" class="headerlink" title="15. torchvision"></a>15. torchvision</h3><h5 id="models"><a href="#models" class="headerlink" title="models"></a>models</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> modelsresnet34 = models.resnet34(pretrained=<span class="hljs-literal">True</span>, num_classes=<span class="hljs-number">1000</span>)</code></pre><h5 id="data-augmentation"><a href="#data-augmentation" class="headerlink" title="data augmentation"></a>data augmentation</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<span class="hljs-comment"># transforms.CenterCrop           transforms.Grayscale           transforms.ColorJitter          </span><span class="hljs-comment"># transforms.Lambda               transforms.Compose             transforms.LinearTransformation </span><span class="hljs-comment"># transforms.FiveCrop             transforms.Normalize           transforms.functional           </span><span class="hljs-comment"># transforms.Pad                  transforms.RandomAffine        transforms.RandomHorizontalFlip  </span><span class="hljs-comment"># transforms.RandomApply          transforms.RandomOrder         transforms.RandomChoice         </span><span class="hljs-comment"># transforms.RandomResizedCrop    transforms.RandomCrop          transforms.RandomRotation        </span><span class="hljs-comment"># transforms.RandomGrayscale      transforms.RandomSizedCrop     transforms.RandomVerticalFlip   </span><span class="hljs-comment"># transforms.ToTensor             transforms.Resize              transforms.transforms                                           </span><span class="hljs-comment"># transforms.TenCrop              transforms.Scale               transforms.ToPILImage</span></code></pre><h5 id="自定义-dataset"><a href="#自定义-dataset" class="headerlink" title="自定义 dataset"></a>自定义 dataset</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">my_data</span>(<span class="hljs-params">Dataset</span>):</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, image_path, annotation_path, transform=None</span>):</span>        <span class="hljs-comment"># 初始化， 读取数据集  🌟</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span>(<span class="hljs-params">self</span>):</span>          <span class="hljs-comment"># 获取数据集的总大小  🌟</span>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span>(<span class="hljs-params">self, id</span>):</span>  🌟        <span class="hljs-comment"># 对于制定的 id, 读取该数据并返回    </span></code></pre><p><strong>datasets</strong></p><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, Dataloader<span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">as</span> transformstransform = transforms.Compose([        transforms.ToTensor(), <span class="hljs-comment"># convert to Tensor</span>        transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]) <span class="hljs-comment"># normalization</span>dataset = ImageFolder(root, transform=transform, target_transform=<span class="hljs-literal">None</span>, loader=default_loader)dataloader = DataLoader(dataset, <span class="hljs-number">2</span>, collate_fn=my_collate_fn, num_workers=<span class="hljs-number">1</span>,shuffle=<span class="hljs-literal">True</span>)<span class="hljs-keyword">for</span> batch_datas, batch_labels <span class="hljs-keyword">in</span> dataloader:    ...</code></pre><h5 id="img-process"><a href="#img-process" class="headerlink" title="img process"></a>img process</h5><pre><code class="hljs python">img = make_grid(next(dataiter)[<span class="hljs-number">0</span>], <span class="hljs-number">4</span>) save_image(img, <span class="hljs-string">&#x27;a.png&#x27;</span>)</code></pre><h5 id="data-Visualization"><a href="#data-Visualization" class="headerlink" title="data Visualization"></a>data Visualization</h5><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToPILImageshow = ToPILImage()  <span class="hljs-comment"># 可以把Tensor转成Image，方便可视化</span>(data, label) = trainset[<span class="hljs-number">100</span>]show((data + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>).resize((<span class="hljs-number">100</span>, <span class="hljs-number">100</span>))  <span class="hljs-comment"># 应该会自动乘以 255 的</span></code></pre><h3 id="16-Code-Samples"><a href="#16-Code-Samples" class="headerlink" title="16. Code Samples"></a>16. Code Samples</h3><pre><code class="hljs python"><span class="hljs-comment"># torch.device object used throughout this script</span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> use_cuda <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)model = MyRNN().to(device)<span class="hljs-comment"># train</span>total_loss = <span class="hljs-number">0</span><span class="hljs-keyword">for</span> input, target <span class="hljs-keyword">in</span> train_loader:    input, target = input.to(device), target.to(device)    hidden = input.new_zeros(*h_shape)  <span class="hljs-comment"># has the same device &amp; dtype as `input`</span>    ...  <span class="hljs-comment"># get loss and optimize</span>    total_loss += loss.item()           <span class="hljs-comment"># get Python number from 1-element Tensor</span><span class="hljs-comment"># evaluate</span><span class="hljs-keyword">with</span> torch.no_grad():                   <span class="hljs-comment"># operations inside don&#x27;t track history</span>    <span class="hljs-keyword">for</span> input, target <span class="hljs-keyword">in</span> test_loader:        ...</code></pre><h3 id="17-jit-amp-torchscript"><a href="#17-jit-amp-torchscript" class="headerlink" title="17. jit &amp; torchscript"></a>17. jit &amp; torchscript</h3><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.jit <span class="hljs-keyword">import</span> script, tracetorch.jit.trace(model, torch.rand(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">224</span>,<span class="hljs-number">224</span>)) 　<span class="hljs-comment"># export model</span><span class="hljs-meta">@torch.jit.script</span></code></pre><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;torch/torch.h&gt;</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;torch/script.h&gt;</span></span><span class="hljs-meta"># img blob -&gt; img tensor</span>torch::Tensor img_tensor = torch::from_blob(image.data, &#123;<span class="hljs-number">1</span>, image.rows, image.cols, <span class="hljs-number">3</span>&#125;, torch::kByte);img_tensor = img_tensor.permute(&#123;<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;);img_tensor = img_tensor.toType(torch::kFloat);img_tensor = img_tensor.div(<span class="hljs-number">255</span>);<span class="hljs-meta"># load model</span><span class="hljs-built_in">std</span>::<span class="hljs-built_in">shared_ptr</span>&lt;torch::jit::script::Module&gt; <span class="hljs-keyword">module</span> = torch::jit::load(<span class="hljs-string">&quot;resnet.pt&quot;</span>);<span class="hljs-meta"># forward</span>torch::Tensor output = <span class="hljs-keyword">module</span>-&gt;forward(&#123;img_tensor&#125;).toTensor();</code></pre><h3 id="18-onnx"><a href="#18-onnx" class="headerlink" title="18. onnx"></a>18. onnx</h3><pre><code class="hljs python">torch.onnx.export(model, dummy data, xxxx.proto) <span class="hljs-comment"># exports an ONNX formatted</span>model = onnx.load(<span class="hljs-string">&quot;alexnet.proto&quot;</span>)               <span class="hljs-comment"># load an ONNX model</span>onnx.checker.check_model(model)                  <span class="hljs-comment"># check that the model</span>onnx.helper.printable_graph(model.graph)         <span class="hljs-comment"># print a human readable　representation of the graph</span></code></pre><h3 id="19-Distributed-Training"><a href="#19-Distributed-Training" class="headerlink" title="19. Distributed Training"></a>19. Distributed Training</h3><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.distributed <span class="hljs-keyword">as</span> dist          <span class="hljs-comment"># distributed communication</span><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process       <span class="hljs-comment"># memory sharing processes</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>语言和库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The next step of machine learning</title>
    <link href="/2019/03/08/The-next-step-of-machine-learning/"/>
    <url>/2019/03/08/The-next-step-of-machine-learning/</url>
    
    <content type="html"><![CDATA[<p>🔍 The next step of machine learning (机器学习下一步的可能的发展方向)</p><a id="more"></a><h3 id="The-next-step-of-machine-learning："><a href="#The-next-step-of-machine-learning：" class="headerlink" title="The next step of machine learning："></a>The next step of machine learning：</h3><h5 id="1-Anomaly-Detection（让机器知道我不知道）"><a href="#1-Anomaly-Detection（让机器知道我不知道）" class="headerlink" title="1.Anomaly Detection（让机器知道我不知道）"></a>1.Anomaly Detection（让机器知道我不知道）</h5><h5 id="2-Explainable-AI（可解释性AI）"><a href="#2-Explainable-AI（可解释性AI）" class="headerlink" title="2.Explainable AI（可解释性AI）"></a>2.Explainable AI（可解释性AI）</h5><h5 id="3-Adversarial-attack（对抗攻击）"><a href="#3-Adversarial-attack（对抗攻击）" class="headerlink" title="3.Adversarial attack（对抗攻击）"></a>3.Adversarial attack（对抗攻击）</h5><h5 id="4-Life-long-Learning（终身学习）"><a href="#4-Life-long-Learning（终身学习）" class="headerlink" title="4.Life-long Learning（终身学习）"></a>4.Life-long Learning（终身学习）</h5><h5 id="5-Meta-learning-Learning-to-learn（学会如何学习）"><a href="#5-Meta-learning-Learning-to-learn（学会如何学习）" class="headerlink" title="5.Meta-learning/Learning to learn（学会如何学习）"></a>5.Meta-learning/Learning to learn（学会如何学习）</h5><h5 id="6-Few-shot-learning-Zero-shot-Learning（小样本学习）"><a href="#6-Few-shot-learning-Zero-shot-Learning（小样本学习）" class="headerlink" title="6.Few-shot learning/Zero-shot Learning（小样本学习）"></a>6.Few-shot learning/Zero-shot Learning（小样本学习）</h5><h5 id="7-how-to-use-reinforcement-Learning-effectively？（有效使用增强学习）"><a href="#7-how-to-use-reinforcement-Learning-effectively？（有效使用增强学习）" class="headerlink" title="7.how to use reinforcement Learning  effectively？（有效使用增强学习）"></a>7.how to use reinforcement Learning  effectively？（有效使用增强学习）</h5><h5 id="8-Network-Compression（神经网络压缩）"><a href="#8-Network-Compression（神经网络压缩）" class="headerlink" title="8.Network Compression（神经网络压缩）"></a>8.Network Compression（神经网络压缩）</h5><h5 id="9-Unsupervised-Domain-Adaptation（领域自适应）"><a href="#9-Unsupervised-Domain-Adaptation（领域自适应）" class="headerlink" title="9.Unsupervised Domain Adaptation（领域自适应）"></a>9.Unsupervised Domain Adaptation（领域自适应）</h5><h5 id="10-Weak-Supervision-unsupervised-learning-微监督-无监督"><a href="#10-Weak-Supervision-unsupervised-learning-微监督-无监督" class="headerlink" title="10.Weak Supervision/unsupervised learning(微监督/无监督)"></a>10.Weak Supervision/unsupervised learning(微监督/无监督)</h5><h5 id="11-Video-understanding-（视频理解）"><a href="#11-Video-understanding-（视频理解）" class="headerlink" title="11.Video understanding （视频理解）"></a>11.Video understanding （视频理解）</h5><h5 id="12-Graph-network（图网络）"><a href="#12-Graph-network（图网络）" class="headerlink" title="12.Graph network（图网络）"></a>12.Graph network（图网络）</h5><h5 id="13-Transfer-learning（迁移学习）"><a href="#13-Transfer-learning（迁移学习）" class="headerlink" title="13.Transfer learning（迁移学习）"></a>13.Transfer learning（迁移学习）</h5>]]></content>
    
    
    
    <tags>
      
      <tag>探索</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Deep Learning Toolbox</title>
    <link href="/2018/09/08/Deep-Learning-Toolbox/"/>
    <url>/2018/09/08/Deep-Learning-Toolbox/</url>
    
    <content type="html"><![CDATA[<h2 id="🔧-Deep-Learning-toolbox"><a href="#🔧-Deep-Learning-toolbox" class="headerlink" title="🔧 Deep Learning toolbox"></a>🔧 Deep Learning toolbox</h2><a id="more"></a><h4 id="📚-Datasets-search"><a href="#📚-Datasets-search" class="headerlink" title="📚 Datasets search"></a>📚 Datasets search</h4><ol><li><p><a href="https://www.kaggle.com"><strong>Kaggle</strong></a> </p></li><li><p><a href="https://toolbox.google.com/datasetsearch"><strong>Google Datasets Search Engine</strong></a></p></li><li><p><a href="https://msropendata.com"><strong>Microsoft Datasets</strong></a></p></li><li><p><a href="https://www.visualdata.io"><strong>Computer Vision Datasets</strong></a></p></li><li><p><a href="https://github.com/awesomedata/awesome-public-datasets"><strong>Github awesomedata</strong></a></p></li><li><p><a href="https://archive.ics.uci.edu/ml/datasets.html"><strong>UCI Machine Learning Repository.</strong></a></p></li><li><p><a href="https://registry.opendata.aws"><strong>Amazon Datasets</strong></a></p></li><li><p><strong>Government Datasets:</strong> <a href="https://data.europa.eu/euodp/data/dataset"><strong>EU</strong></a>                 <a href="https://www.data.gov/"><strong>US</strong></a>                 <a href="https://catalogue.data.govt.nz/dataset"><strong>NZL</strong></a>                <a href="https://data.gov.in/"><strong>IND</strong></a>  </p></li></ol><h4 id="🔍-Visualizing-neural-network-architectures"><a href="#🔍-Visualizing-neural-network-architectures" class="headerlink" title="🔍 Visualizing neural network architectures"></a>🔍 Visualizing neural network architectures</h4><ol><li><a href="https://github.com/lutzroeder/Netron"><strong>Netron:</strong></a>  now supports <strong>ONNX</strong>, <strong>Keras</strong>, <strong>CoreML</strong>, <strong>Caffe2</strong>, <strong>Mxnet</strong>, <strong>Pytorch</strong> and <strong>Tensorflow</strong>.</li><li><a href="https://ethereon.github.io/netscope/#/editor"><strong>Netscope:</strong></a>  or  <strong>GraphViz</strong>:   <strong>Caffe</strong>       </li><li><a href="https://github.com/tensorflow/tensorboard"><strong>TensorBoard:</strong></a>   <strong>Tensorflow</strong>  </li><li><a href="https://github.com/szagoruyko/pytorchviz"><strong>Graphviz:</strong></a>   <strong>Pytorch</strong>   </li><li><a href="https://github.com/Murugan-natarajan/mxnet/blob/7cd06109643664442045457a6c318c26d1c728ae/docs/how_to/visualize_graph.md"><strong>mxnet.viz:</strong></a>  <strong>mxnet</strong>   </li><li><a href="https://keras.io/utils/#print_summary"><strong>model.summary():</strong></a>    <strong>keras</strong></li></ol><h4 id="🏷-Lable-Tool"><a href="#🏷-Lable-Tool" class="headerlink" title="🏷 Lable Tool"></a>🏷 Lable Tool</h4><ol><li><p><a href="https://github.com/opencv/cvat"><strong>CVAT:</strong></a>Computer Vision Annotation Tool (CVAT) is a web-based tool which helps to annotate video and images for Computer Vision algorithms</p></li><li><p><a href="https://github.com/wkentaro/labelme"><strong>Labelme:</strong></a> Image Polygonal Annotation with Python</p></li><li><a href="https://github.com/tzutalin/labelImg"><strong>LabelImg</strong></a>：LabelImg is a graphical image annotation tool and label object bounding boxes in images </li><li><a href="https://github.com/AlexeyAB/Yolo_mark"><strong>Yolo_mark:</strong></a>GUI for marking bounded boxes of objects in images for training neural network Yolo v3 and v2</li><li><a href="https://github.com/cvhciKIT/sloth"><strong>Sloth:</strong></a>Sloth is a tool for labeling image and video data for computer vision research.</li><li><a href="http://www.cs.columbia.edu/~vondrick/vatic/"><strong>Vatic:</strong></a>  vatic is a <strong>free, online, interactive video annotation tool</strong> for computer vision research that crowdsources work to Amazon’s Mechanical Turk.</li><li><a href="https://github.com/Microsoft/VoTT/"><strong>VoTT:</strong></a>Visual Object Tagging Tool: An electron app for building end to end Object Detection Models from Images and Videos.</li><li><a href="https://github.com/fidler-lab/polyrnn-pp-pytorch"><strong>Polygon-RNN++:</strong></a> Polygon-RNN++ allows you to train new Polygon-RNN++ models, and run our demo tool on local machines. </li></ol>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Toolbox</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git常见问题</title>
    <link href="/2018/08/17/git%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/2018/08/17/git%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h4 id="1-Git-基本流程"><a href="#1-Git-基本流程" class="headerlink" title="1. Git 基本流程"></a>1. Git 基本流程</h4><p><img src="/2018/08/17/git%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/gitflow.png" alt></p><h4 id="2-git-commit-规范"><a href="#2-git-commit-规范" class="headerlink" title="2. git commit 规范:"></a>2. git commit 规范:</h4><p>常用的 Git commit 规范，没有强制的规定，主要是翻阅以前的日志会更清晰。</p><p><strong>基本格式:</strong></p><pre><code class="hljs shell">git commit -m &quot;type: description&quot;</code></pre><p><strong>一个比较详细的格式:</strong></p><pre><code class="hljs shell">&lt;type&gt;: (If applied, this commit will...) &lt;subject&gt; (Max 50 char)|&lt;----  Using a Maximum Of 50 Characters  ----&gt;|Explain why this change is being made|&lt;----   Try To Limit Each Line to a Maximum Of 72 Characters   ----&gt;|Provide links or keys to any relevant tickets, articles or other resourcesExample: Github issue #23</code></pre><p><strong>type</strong> 是 commit 的类别，只允许如下几种标识：</p><ul><li><strong>fix: 修复bug</strong></li><li><strong>feat/add:</strong> 新功能 (new feature) </li><li>update: 更新</li><li>refactor : 某个已有功能重构</li><li>perf : 性能优化</li><li>style : 代码格式改变 (formatting, missing semi colons, etc; no code change)</li><li>test: 增加测试代码 (adding or refactoring tests; no production code change)</li><li>docs : 文档改变  (changes to documentation)</li><li>revert: 撤销上一次的commit</li><li>build: 构建工具或构建过程等的变动，如：关联包升级等</li><li><strong>chore</strong>    (updating grunt tasks etc; no production code change)</li></ul><p><strong>description</strong> 是对本次提交的简短描述：</p><ul><li>不超过50个字符。</li><li>推荐以动词开头，如： 设置、修改、增加、删减、撤销等</li></ul><p>参考: <a href="https://gist.github.com/adeekshith/cd4c95a064977cdc6c50">https://gist.github.com/adeekshith/cd4c95a064977cdc6c50</a></p><h4 id="3-git-提交空文件夹"><a href="#3-git-提交空文件夹" class="headerlink" title="3. git 提交空文件夹"></a>3. git 提交空文件夹</h4><p>在空文件夹下建立 .gitkeep</p><pre><code class="hljs shell">touch .gitkeep</code></pre><p>内容如下:</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> Ignore everything <span class="hljs-keyword">in</span> this directory </span>* <span class="hljs-meta">#</span><span class="bash"> Except this file !.gitkeep </span></code></pre><h4 id="4-删除-mac-下面自动生成的-DS-store"><a href="#4-删除-mac-下面自动生成的-DS-store" class="headerlink" title="4. 删除 mac 下面自动生成的 .DS_store"></a>4. 删除 mac 下面自动生成的 .DS_store</h4><p>删除所有隐藏.DS_store文件，打开命令行窗口</p><pre><code class="hljs cpp">sudo find . -name <span class="hljs-string">&quot;.DS_Store&quot;</span> -depth -exec rm &#123;&#125; \;</code></pre><p>设置不再产生选项, 执行如下命令</p><pre><code class="hljs shell">defaults write com.apple.desktopservices DSDontWriteNetworkStores true</code></pre><h4 id="5-通过修改-hosts-提高-github-访问速度"><a href="#5-通过修改-hosts-提高-github-访问速度" class="headerlink" title="5. 通过修改 hosts 提高 github 访问速度"></a>5. 通过修改 hosts 提高 github 访问速度</h4><p>先去 <strong>IPAddress.com 或者 <a href="http://tool.chinaz.com/dns">http://tool.chinaz.com/dns</a></strong> 网站，查询3个与GitHub相关网址对应的IP地址：</p><p>​    1、github.com</p><p>​    2、assets-cdn.github.com</p><p>​    3、github.global.ssl.fastly.net</p><p>页面上会查看到这3个地址对应的 IP 地址，把查询到的IP和地址加到 hosts 文件下, 比如:</p><pre><code class="hljs shell">13.250.177.223   github.com</code></pre><p>我的系统下hosts文件不能直接保存，那就 copy 到其它路径下，修改保存后再 ctrl+x，ctrl+v 回去；</p><p>再清一下系统DNS缓存，</p><p>win: cmd命令打开DOS窗口，输入</p><pre><code class="hljs shell">ipconfig/flushdns</code></pre><p>ubuntu 下:</p><p>安装并重新启动 nscd 守护程序。</p><pre><code class="hljs shell">sudo aptitude install nscdsudo /etc/init.d/nscd restart</code></pre><h4 id="6-如何设置不被追踪的文件"><a href="#6-如何设置不被追踪的文件" class="headerlink" title="6. 如何设置不被追踪的文件"></a>6. 如何设置不被追踪的文件</h4><p>​    有些文件是不想被追踪的， 可以修改  <strong>.git/info/exclude</strong> 文件， 以 # 开头，添加规则即可。</p><p>这里提供一个比较常见的 .gitignore 文件, 将其命名为 .gitignore 然后放到根目录即可。</p><h4 id="7-server-certificate-verification-failed-CAfile-etc-ssl-certs-ca-certificates-crt-CRLfile-none"><a href="#7-server-certificate-verification-failed-CAfile-etc-ssl-certs-ca-certificates-crt-CRLfile-none" class="headerlink" title="7. server certificate verification failed. CAfile:/etc/ssl/certs/ca-certificates.crt CRLfile: none"></a>7. server certificate verification failed. CAfile:/etc/ssl/certs/ca-certificates.crt CRLfile: none</h4><pre><code class="hljs routeros"><span class="hljs-builtin-name">export</span> <span class="hljs-attribute">GIT_SSL_NO_VERIFY</span>=1</code></pre>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>cmake使用</title>
    <link href="/2018/08/17/cmake%E4%BD%BF%E7%94%A8/"/>
    <url>/2018/08/17/cmake%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>cmake 基本使用</p><a id="more"></a><h3 id="一-实例项目"><a href="#一-实例项目" class="headerlink" title="一. 实例项目"></a>一. 实例项目</h3><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> project1  <span class="hljs-comment"># use project2/project3 instead of project1</span></span><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> build</span><span class="hljs-meta">$</span><span class="bash"> cmake ..</span><span class="hljs-meta">$</span><span class="bash"> make</span><span class="hljs-meta">$</span><span class="bash"> ./hello <span class="hljs-comment"># </span></span>Hello World.</code></pre><ul><li><strong>project 1:</strong>  使用cmake 编译项目</li><li><strong>project 2:</strong> 使用动态链接库</li><li><strong>project 3：</strong> 将src和include 分别放到不同的文件夹下</li><li><strong>project4:</strong> 使用第三方库</li></ul><h3 id="二-基本语法"><a href="#二-基本语法" class="headerlink" title="二. 基本语法"></a>二. 基本语法</h3><h5 id="1-CMake-基本使用"><a href="#1-CMake-基本使用" class="headerlink" title="1. CMake 基本使用"></a>1. CMake 基本使用</h5><pre><code class="hljs cmake"><span class="hljs-keyword">cmake_minimum_required</span> (VERSION <span class="hljs-number">2.8</span>)<span class="hljs-keyword">project</span> (Demo1)<span class="hljs-keyword">add_executable</span>(Demo main.cpp)</code></pre><h5 id="2-多个文件同时编译"><a href="#2-多个文件同时编译" class="headerlink" title="2. 多个文件同时编译"></a>2. 多个文件同时编译</h5><pre><code class="hljs cmake"><span class="hljs-comment"># 使用 aux_source_directory(&lt;dir&gt; &lt;variable&gt;)</span><span class="hljs-keyword">aux_source_directory</span>(src DIR_SRCS)<span class="hljs-keyword">add_library</span>(xxxxx SHARED <span class="hljs-variable">$&#123;SRC_FILES&#125;</span>)<span class="hljs-comment"># glob</span><span class="hljs-keyword">file</span>(GLOB_RECURSE SRC_FILES src/*.cpp) <span class="hljs-keyword">add_library</span>(xxxxx SHARED <span class="hljs-variable">$&#123;SRC_FILES&#125;</span>)<span class="hljs-comment"># (3)多个文件同时写</span><span class="hljs-keyword">set</span>(SRC_FILES    src/util/xxx.cpp    src/util/xxxxx_xxxxxxx.cpp    src/xxxx.cpp    )<span class="hljs-keyword">add_library</span>(xxxxx SHARED <span class="hljs-variable">$&#123;SRC_FILES&#125;</span>)</code></pre><h5 id="3-生成动态库或者共享库"><a href="#3-生成动态库或者共享库" class="headerlink" title="3. 生成动态库或者共享库"></a>3. 生成动态库或者共享库</h5><pre><code class="hljs cmake"><span class="hljs-comment"># 静态库</span><span class="hljs-keyword">add_library</span>(slzheliib STATIC libStatic.cpp)<span class="hljs-comment"># 共享库</span><span class="hljs-keyword">add_library</span>(dlib SHARED libShared.cpp)</code></pre><h5 id="4-使用第三方包-以-opencv-和-FFTW-为例"><a href="#4-使用第三方包-以-opencv-和-FFTW-为例" class="headerlink" title="4. 使用第三方包(以 opencv 和 FFTW 为例)"></a>4. 使用第三方包(以 opencv 和 FFTW 为例)</h5><pre><code class="hljs cmake"><span class="hljs-comment"># 编译: add_executable(Demo demo.cpp)</span><span class="hljs-keyword">find_package</span>( OpenCV REQUIRED)<span class="hljs-keyword">if</span> (OpenCV_FOUND)    <span class="hljs-keyword">include_directories</span>(<span class="hljs-variable">$&#123;OpenCV_INCLUDE_DIRS&#125;</span>)    <span class="hljs-keyword">target_link_libraries</span>(Demo <span class="hljs-variable">$&#123;Opencv_LIBS&#125;</span>)<span class="hljs-keyword">endif</span> (OpenCV_FOUND)</code></pre><pre><code class="hljs cmake"><span class="hljs-comment"># 另外一种方式(通过 xxx.cmake 进行)　</span><span class="hljs-comment"># cmake相当于上一种方式中的find_package和include_directories</span><span class="hljs-comment"># 这里以 FFTW 为例</span><span class="hljs-keyword">include</span>(cmake/FindFFTW.cmake)<span class="hljs-keyword">target_link_libraries</span>(udwt-gumbel <span class="hljs-variable">$&#123;OpenCV_LIBS&#125;</span> <span class="hljs-variable">$&#123;FFTW_LIBRARIES&#125;</span>)</code></pre><h5 id="5-如何优化编译选项-Debug-Release模式-："><a href="#5-如何优化编译选项-Debug-Release模式-：" class="headerlink" title="5. 如何优化编译选项(Debug/Release模式)："></a>5. 如何优化编译选项(Debug/Release模式)：</h5><p>​    Debug通常称为调试版本，它包含调试信息，并且不作任何优化，便于程序员调试程序。Release 称为发布版本，它往往是进行了各种优化，使得程序在代码大小和运行速度上都是最优的，以便用户很好地使用。</p><ul><li>在CMakeLists.txt下加入</li></ul><pre><code class="hljs cmake"><span class="hljs-comment"># cmake -DCMAKE_BUILD_TYPE=Debug/Release ..</span><span class="hljs-keyword">SET</span>(CMAKE_BUILD_TYPE <span class="hljs-string">&quot;Release&quot;</span>)<span class="hljs-keyword">if</span> (CMAKE_BUILD_TYPE <span class="hljs-keyword">STREQUAL</span> <span class="hljs-string">&quot;Debug&quot;</span>)    <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS_DEBUG <span class="hljs-string">&quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;</span>)    <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;CMAKE_BUILD_TYPE = Debug&quot;</span>)<span class="hljs-keyword">else</span>()    <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="hljs-string">&quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;</span>)    <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;CMAKE_BUILD_TYPE = Release&quot;</span>)<span class="hljs-keyword">endif</span>()</code></pre><p>​        <strong>CMake中有一个变量 CMAKE_BUILD_TYPE ,可以的取值是None、Debug、Release、RelWithDebInfo和MinSizeRel。当这个变量值为Debug的时候,CMake会使用变量 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_C_FLAGS_DEBUG 中的字符串作为编译选项生成 Makefile</strong></p><div class="table-container"><table><thead><tr><th>CMAKE_BUILD_TYPE</th><th>对应的c编译选项变量</th><th>对应的c++编译选项变量</th></tr></thead><tbody><tr><td>None</td><td>CMAKE_C_FLAGS</td><td>CMAKE_CXX_FLAGS</td></tr><tr><td>Debug</td><td>CMAKE_C_FLAGS_DEBUG</td><td>CMAKE_CXX_FLAGS_DEBUG</td></tr><tr><td>Release</td><td>CMAKE_C_FLAGS_RELEASE</td><td>CMAKE_CXX_FLAGS_RELEASE</td></tr><tr><td>RelWithDebInfo</td><td>CMAKE_C_FLAGS_RELWITHDEBINFO</td><td>CMAKE_CXX_FLAGS_RELWITHDEBINFO</td></tr><tr><td>MinSizeRel</td><td>CMAKE_C_FLAGS_MINSIZEREL</td><td>CMAKE_CXX_FLAGS_MINSIZEREL</td></tr></tbody></table></div><p>​    如果将优化程度调到最高需要设置<code>-O3</code>，最低的是<code>-O0</code>即不做优化，添加调试信息的参数是<code>-g  -ggdb</code>，如果不添加这个参数，调试信息就不会被包含在生成的二进制中。</p><p>（1）<code>-O</code>，<code>-O1</code> 这两个命令的效果是一样的，目的都是在不影响编译速度的前提下，尽量采用一些优化算法降低代码大小和可执行代码的运行速度。 </p><p>（2）<code>-O2</code> 该优化选项会牺牲部分编译速度，除了执行<code>-O1</code>所执行的所有优化之外，还会采用几乎所有的目标配置支持的优化算法，用以提高目标代码的运行速度。 </p><p>（3） <code>-O3</code> 该选项除了执行<code>-O2</code>所有的优化选项之外，一般都是采取很多向量化算法，提高代码的并行执行程度，利用现代CPU中的流水线，Cache等。这个选项会提高执行代码的大小，当然会降低目标代码的执行时间。</p><p>（4）<code>-Os</code> 这个优化标识和<code>-O3</code>有异曲同工之妙，当然两者的目标不一样，<code>-O3</code>的目标是宁愿增加目标代码的大小，也要拼命的提高运行速度，但是这个选项是在<code>-O2</code>的基础之上，尽量的降低目标代码的大小，这对于存储容量很小的设备来说非常重要。为了降低目标代码大小，会禁用下列优化选项，一般就是压缩内存中的对齐空白(alignment padding)</p><p>（5）<code>-Ofast</code> 该选项将不会严格遵循语言标准，除了启用所有的<code>-O3</code>优化选项之外，也会针对某些语言启用部分优化。如：<code>-ffast-math</code> .</p><p>（6）<code>-Og</code>: 该标识会精心挑选部分与<code>-g</code>选项不冲突的优化选项，当然就能提供合理的优化水平，同时产生较好的可调试信息和对语言标准的遵循程度。</p><h5 id="6-设定使用-C-11"><a href="#6-设定使用-C-11" class="headerlink" title="6. 设定使用 C++11"></a>6. 设定使用 C++11</h5><pre><code class="hljs cmake"><span class="hljs-comment"># Use C++11</span><span class="hljs-keyword">set</span>(CMAKE_CXX_STANDARD <span class="hljs-number">11</span>)<span class="hljs-keyword">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class="hljs-keyword">ON</span>)<span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;C++11 support has been enabled by default.&quot;</span>)</code></pre><h5 id="7-自定义编译选项-以-OpenMP-和-SSE为例"><a href="#7-自定义编译选项-以-OpenMP-和-SSE为例" class="headerlink" title="7. 自定义编译选项(以 OpenMP 和 SSE为例)"></a>7. 自定义编译选项(以 OpenMP 和 SSE为例)</h5><pre><code class="hljs cmake"><span class="hljs-comment"># Use OpenMP</span><span class="hljs-keyword">option</span>(USE_OPENMP      <span class="hljs-string">&quot;Set to ON to build use openmp&quot;</span>  <span class="hljs-keyword">ON</span>)<span class="hljs-keyword">if</span> (USE_OPENMP)    <span class="hljs-keyword">find_package</span>(OpenMP QUIET)    <span class="hljs-keyword">if</span> (OPENMP_FOUND)        <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;Use OpenMP&quot;</span>)        <span class="hljs-keyword">add_definitions</span>(-DUSE_OPENMP)        <span class="hljs-keyword">set</span>(CMAKE_C_FLAGS <span class="hljs-string">&quot;$&#123;CMAKE_C_FLAGS&#125; $&#123;OpenMP_C_FLAGS&#125;&quot;</span>)        <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; $&#123;OpenMP_CXX_FLAGS&#125;&quot;</span>)        <span class="hljs-keyword">set</span>(CMAKE_EXE_LINKER_FLAGS <span class="hljs-string">&quot;$&#123;CMAKE_EXE_LINKER_FLAGS&#125; $&#123;OpenMP_EXE_LINKER_FLAGS&#125;&quot;</span>)    <span class="hljs-keyword">endif</span>()<span class="hljs-keyword">endif</span>()<span class="hljs-comment"># Use SSE</span><span class="hljs-keyword">option</span>(USE_SSE         <span class="hljs-string">&quot;Set to ON to build use SSE&quot;</span>  <span class="hljs-keyword">ON</span>)<span class="hljs-keyword">if</span> (USE_SSE)    <span class="hljs-keyword">add_definitions</span>(-DUSE_SSE)    <span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;Use SSE&quot;</span>)    <span class="hljs-keyword">set</span>(CMAKE_CXX_FLAGS <span class="hljs-string">&quot;$&#123;CMAKE_CXX_FLAGS&#125; -msse4.1&quot;</span>)<span class="hljs-keyword">endif</span>()</code></pre><h5 id="8-添加版本号"><a href="#8-添加版本号" class="headerlink" title="8. 添加版本号"></a>8. 添加版本号</h5><pre><code class="hljs cmake"><span class="hljs-comment"># Version (DEMO is Project Name)</span><span class="hljs-keyword">set</span> (DEMO_VERSION_MAJOR <span class="hljs-number">0</span>)<span class="hljs-keyword">set</span> (DEMO_VERSION_MINOR <span class="hljs-number">1</span>)<span class="hljs-keyword">message</span>(STATUS <span class="hljs-string">&quot;PROJECT VERSION IS $&#123;DEMO_VERSION_MAJOR&#125;.$&#123;DEMO_VERSION_MINOR&#125;&quot;</span>)</code></pre><h5 id="9-设置子文件夹"><a href="#9-设置子文件夹" class="headerlink" title="9. 设置子文件夹"></a>9. 设置子文件夹</h5><p>在主项目的 <code>CMakeLists.txt</code> 中, 可以使用 <code>add_subdirectory</code> 来添加 子文件夹, 然后在子文件夹中也要有一个 <code>CMakeLists.txt</code> 文件.</p><pre><code class="hljs cmake"><span class="hljs-keyword">add_subdirectory</span>(benchmark)<span class="hljs-keyword">add_subdirectory</span>(src)<span class="hljs-keyword">add_subdirectory</span>(tools)</code></pre><p>项目的基本目录为:</p><pre><code class="hljs cmake">.├── src│   ├── CMakeLists.txt│   └── xxx.cpp├── tools│   ├── CMakeLists.txt│   └── xxx.cpp├── benchmark│   ├── CMakeLists.txt│   └── xxx.cpp├── main.cpp└── CMakeLists.txt</code></pre><h5 id="10-测试"><a href="#10-测试" class="headerlink" title="10. 测试"></a>10. 测试</h5><pre><code class="hljs cmake"><span class="hljs-keyword">enable_testing</span>()<span class="hljs-keyword">add_test</span> (test_5_2 Demo <span class="hljs-number">5</span> <span class="hljs-number">2</span>)<span class="hljs-keyword">set_tests_properties</span> (test_5_2 PROPERTIES PASS_REGULAR_EXPRESSION <span class="hljs-string">&quot;is 25&quot;</span>)<span class="hljs-keyword">add_test</span> (test_2_10 Demo <span class="hljs-number">2</span> <span class="hljs-number">10</span>)<span class="hljs-keyword">set_tests_properties</span> (test_2_10 PROPERTIES PASS_REGULAR_EXPRESSION <span class="hljs-string">&quot;is 1024&quot;</span>)</code></pre><p>set_tests_properties 中的 <code>PASS_REGULAR_EXPRESSION</code> 用来测试输出是否包含后面跟着的字符串。</p><h5 id="11-设置安装与与生成安装包"><a href="#11-设置安装与与生成安装包" class="headerlink" title="11.设置安装与与生成安装包"></a>11.设置安装与与生成安装包</h5><p>生成的 Demo 文件将会被复制到 <code>/usr/local/bin</code> 中，而 demo.h 和则会被复制到 <code>/usr/local/include</code> 中。顺带一提的是，这里的 <code>/usr/local/</code> 是默认安装到的根目录，可以通过修改 <code>CMAKE_INSTALL_PREFIX</code> 变量的值来指定这些文件应该拷贝到哪个根目录。</p><pre><code class="hljs cmake"><span class="hljs-keyword">install</span> (TARGETS Demo DESTINATION bin) <span class="hljs-keyword">install</span> (FILES demo.h DESTINATION <span class="hljs-keyword">include</span>)</code></pre><h5 id="12-指定输出目录"><a href="#12-指定输出目录" class="headerlink" title="12. 指定输出目录"></a>12. 指定输出目录</h5><pre><code class="hljs cmake"><span class="hljs-keyword">SET</span>(EXECUTABLE_OUTPUT_PATH <span class="hljs-variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/bin)       <span class="hljs-comment"># 设置可执行文件的输出目录</span><span class="hljs-keyword">SET</span>(LIBRARY_OUTPUT_PATH <span class="hljs-variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/lib)           <span class="hljs-comment"># 设置库文件的输出目录</span></code></pre><h5 id="13-使用第三方软件-但是不安装-以opencv为例"><a href="#13-使用第三方软件-但是不安装-以opencv为例" class="headerlink" title="13.  使用第三方软件,  但是不安装(以opencv为例)"></a>13.  使用第三方软件,  但是不安装(以opencv为例)</h5><p>将所需的头文件放在  <code>include</code>  文件夹中, 将需要的 共享库 <code>*.so</code> 放在 <code>lib</code> 文件夹中.</p><pre><code class="hljs cmake"><span class="hljs-keyword">include_directories</span>(<span class="hljs-keyword">include</span>)<span class="hljs-keyword">set</span>(opencv_lib   <span class="hljs-variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/lib/libopencv_highgui.so.<span class="hljs-number">3.3</span>   <span class="hljs-variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/lib/libopencv_videoio.so.<span class="hljs-number">3.3</span>   <span class="hljs-variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/lib/libopencv_imgcodecs.so.<span class="hljs-number">3.3</span>   <span class="hljs-variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/lib/libopencv_imgproc.so.<span class="hljs-number">3.3</span>   <span class="hljs-variable">$&#123;CMAKE_CURRENT_SOURCE_DIR&#125;</span>/lib/libopencv_core.so.<span class="hljs-number">3.3</span>)<span class="hljs-keyword">target_link_libraries</span>(demo <span class="hljs-variable">$&#123;opencv_lib&#125;</span>)</code></pre><h3 id="三-Cmake常见问题"><a href="#三-Cmake常见问题" class="headerlink" title="三. Cmake常见问题"></a>三. Cmake常见问题</h3><h5 id="1-Question-make-Nothing-to-be-done-for-all-Solution"><a href="#1-Question-make-Nothing-to-be-done-for-all-Solution" class="headerlink" title="1. Question : make: Nothing to be done for `all` Solution"></a>1. <strong>Question</strong> : <strong>make: Nothing to be done for `all` Solution</strong></h5><p>这句提示是说明你已经编译好了，而且没有对代码进行任何改动。若想重新编译，可以先删除以前编译产生的目标文件，然后使用 make clean，然后再使用 make。</p><h5 id="2-Question-gcc-make-cmake-的联系与区别"><a href="#2-Question-gcc-make-cmake-的联系与区别" class="headerlink" title="2. Question: gcc/make/cmake 的联系与区别"></a>2. Question: gcc/make/cmake 的联系与区别</h5><p>​      gcc是GNU Compiler Collection（就是GNU编译器套件），也可以简单认为是编译器，它可以编译很多种编程语言（括C、C++、Objective-C、Fortran、Java等等）。<strong>当你的程序只有一个源文件时，直接就可以用gcc命令编译它</strong>。但是当你的程序包含很多个源文件时，用gcc命令逐个去编译时，你就很容易混乱而且工作量大。这时可以使用make 工具，<strong>make工具可以看成是一个智能的批处理工具，它本身并没有编译和链接的功能，而是用类似于批处理的方式—— 通过调用makefile文件中用户指定的命令来进行编译和链接的</strong>。简单的说就像一首歌的乐谱，make工具就像指挥家，指挥家根据乐谱指挥整个乐团怎么样演奏，make工具就根据makefile中的命令进行编译和链接的。makefile命令中就包含了调用gcc（也可以是别的编译器）去编译某个源文件的命令。</p><p>​        makefile在一些简单的工程完全可以人工手写，但是当工程非常大的时候，手写makefile也是非常麻烦的，如果换了个平台makefile又要重新修改。这时候就出现了Cmake这个工具，<strong>cmake就可以更加简单的生成makefile文件给上面那个make用</strong>。当然cmake还有其他功能，就是<strong>可以跨平台</strong>生成对应平台能用的makefile，你不用再自己去修改了。可是cmake根据什么生成makefile呢？它又要<strong>根据一个叫CMakeLists.txt文件（学名：组态档）去生成makefile</strong>。到最后CMakeLists.txt文件谁写啊？亲，是你自己手写的。三者的关系可以如下面的简图所示：</p><p><img src="/2018/08/17/cmake%E4%BD%BF%E7%94%A8/cmake.png" alt="p4107"></p><h5 id="3-常见的路径"><a href="#3-常见的路径" class="headerlink" title="3. 常见的路径"></a>3. 常见的路径</h5><p><strong>PROJECT_SOURCE_DIR:</strong> 含有 <code>project()</code> 指令的<code>CMakeLists.txt</code> 文件夹。</p><p><strong>CMAKE_CURRENT_SOURCE_DIR:</strong> 目前正在处理的CMakeLists.txt 所在位置。</p><h5 id="4-指定输出路径"><a href="#4-指定输出路径" class="headerlink" title="4. 指定输出路径"></a>4. 指定输出路径</h5><pre><code class="hljs cmake"><span class="hljs-keyword">SET</span>(EXECUTABLE_OUTPUT_PATH <span class="hljs-variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/../bin)       <span class="hljs-comment">#设置可执行文件的输出目录</span><span class="hljs-keyword">SET</span>(LIBRARY_OUTPUT_PATH <span class="hljs-variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/../lib)           <span class="hljs-comment">#设置库文件的输出目录</span></code></pre><h3 id="四-参考链接"><a href="#四-参考链接" class="headerlink" title="四. 参考链接"></a>四. 参考链接</h3><p>[0] <a href="https://cmake.org">CMake官方网站</a></p><p>[1] <a href="https://www.hahack.com/codes/cmake/">CMake 入门实战</a></p><p>[2]  <a href="https://cmake.org/cmake-tutorial/">CMake-tutorial</a></p><p>[3] 《CMake Pratice》</p><p>[4]  <a href="https://cmake.org/mailing-lists/">cmake-maillist</a></p><p>[5]  <a href="https://github.com/onqtam/awesome-cmake">awesome-camke</a></p><p>[6] 《Mastering CMake》</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>gcc和g++使用</title>
    <link href="/2018/08/17/gcc%E5%92%8Cg++%E4%BD%BF%E7%94%A8/"/>
    <url>/2018/08/17/gcc%E5%92%8Cg++%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>gcc/g++ 和 makefile 的基本用法</p><a id="more"></a><h4 id="gcc-g-流程"><a href="#gcc-g-流程" class="headerlink" title="gcc/g++流程"></a>gcc/g++流程</h4><p><strong>预处理</strong>　－&gt;  <strong>编译</strong>　－&gt;　<strong>汇编</strong>　－&gt;  <strong>链接</strong></p><h4 id="常见选项"><a href="#常见选项" class="headerlink" title="常见选项"></a>常见选项</h4><h6 id="目录选项"><a href="#目录选项" class="headerlink" title="目录选项"></a>目录选项</h6><p><strong>-L[dir]</strong>     　指定搜索目录</p><p>默认会在<code>/lib</code>和<code>/usr/lib</code>和<code>/usr/local/lib</code>三个目录进行搜索</p><p>👉  动态添加方法　<code>pkg-config [pkg_name] —libs</code></p><p><strong>-l[libname]</strong>      指定程序要链接的库，-l参数紧接着就是库名</p><p>例如： 库名是<code>m</code>，　库文件名　<code>libm.so</code>　 链接　<code>-lm</code></p><h6 id="头文件设置"><a href="#头文件设置" class="headerlink" title="头文件设置"></a>头文件设置</h6><p><strong>-I</strong>            指定头文件目录</p><p><code>/usr/include</code>目录一般是不用指定的，gcc知道去那里找，但是如果头文件不在 <code>/usr/icnclude</code> 里我们就要用-I参数指定了，比如头文件放在 <code>/myinclude</code>目录里，那编译命令行就要加上    <code>-I /myinclude</code></p><p><strong>—include [lib]</strong>      用来包含头文件</p><p>一般情况下包含头文件都在源码里用<code>＃include xxxxxx</code>实现， <code>--include</code>  参数很少用。</p><h6 id="连接器选项"><a href="#连接器选项" class="headerlink" title="连接器选项"></a>连接器选项</h6><p><strong>-share</strong>        共享库:尽量使用动态库</p><p><strong>-static</strong> 　    静态库: 禁止使用动态库</p><h6 id="警告选项"><a href="#警告选项" class="headerlink" title="警告选项"></a>警告选项</h6><p><strong>-w</strong>            禁止所有警告信息</p><p><strong>-Wall</strong>             开启大部分警告提示</p><p><strong>-Werror</strong>        视警告为错误</p><h6 id="指定优化级别"><a href="#指定优化级别" class="headerlink" title="指定优化级别"></a>指定优化级别</h6><p>包含<code>-O1</code>/<code>-O2</code>  和<code>-O3</code>等级别，推荐使用<code>-O3</code>　进行优化</p><h6 id="生成位置无关目标码"><a href="#生成位置无关目标码" class="headerlink" title="生成位置无关目标码"></a>生成位置无关目标码</h6><p><strong>-fpic</strong>            适用于共享库</p><p><strong>-fPIC</strong>　          适用于动态链接库</p><h6 id="语言选项"><a href="#语言选项" class="headerlink" title="语言选项"></a>语言选项</h6><p><strong>-ansi</strong>         #　支持符合ＡＮＳＩ标准的Ｃ程序</p><p><strong>-std=c99</strong>      # c99标准</p><p><strong>-std=C++11</strong>    #　支持　c++11　标准  &lt;-</p><h6 id="常见环境变量"><a href="#常见环境变量" class="headerlink" title="常见环境变量"></a>常见环境变量</h6><p><strong>PKG_CONFIG_PATH</strong>：用来指定pkg-config用到的pc文件的路径，默认是/usr/lib/pkgconfig，pc文件是文本文件，扩展名是.pc，里面定义开发包的安装路径，Libs参数和Cflags参数等等。</p><p><strong>CC</strong>：用来指定c编译器。</p><p><strong>CXX</strong>：用来指定cxx编译器。</p><p><strong>LIBS</strong>：跟上面的—libs作用差不多。</p><p><strong>CFLAGS</strong>:跟上面的—cflags作用差不多。</p><p><strong>CC，CXX，LIBS，CFLAGS</strong> 手动编译时一般用不上，在做configure时有时用到，一般情况下不用管。</p><p>环境变量设定方法：<strong>export  ENV_NAME=xxx</strong></p><h4 id="makefile-基本格式"><a href="#makefile-基本格式" class="headerlink" title="makefile 基本格式"></a>makefile 基本格式</h4><pre><code class="hljs cmake"><span class="hljs-comment"># 指定编译器</span><span class="hljs-comment"># 设置编译选项</span><span class="hljs-comment"># 库 &amp; 头文件</span><span class="hljs-comment"># 变量设置</span><span class="hljs-comment"># 语句：</span><span class="hljs-comment"># 编译目标：依赖文件</span><span class="hljs-comment">#     运行脚本</span><span class="hljs-comment"># 清理脚本</span></code></pre><h4 id="makefile-模板"><a href="#makefile-模板" class="headerlink" title="makefile 模板"></a>makefile 模板</h4><pre><code class="hljs makefile">CC = g++ CFLAGS += -g -O3 -WallINC += -I. `pkg-config --cflags opencv`　LIBS += `pkg-config --libs opencv`　　TARGET = main.binOBJS += main.o \        config.o <span class="hljs-section">all:<span class="hljs-variable">$(TARGET)</span></span><span class="hljs-variable">$(TARGET)</span>:<span class="hljs-variable">$(OBJS)</span>    <span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(INC)</span> <span class="hljs-variable">$(CFLAGS)</span> <span class="hljs-variable">$(OBJS)</span> -o <span class="hljs-variable">$(TARGET)</span> <span class="hljs-variable">$(LIBS)</span><span class="hljs-variable">$(OBJS)</span>:%.o:%.cpp    <span class="hljs-variable">$(CC)</span> <span class="hljs-variable">$(INC)</span> <span class="hljs-variable">$(CFLAGS)</span> -c <span class="hljs-variable">$&lt;</span> -o <span class="hljs-variable">$@</span><span class="hljs-meta"><span class="hljs-meta-keyword">.PHONY</span>:clean</span><span class="hljs-section">clean:　</span>    rm -r *.o <span class="hljs-variable">$(TARGET)</span></code></pre><p>参考:</p><p>&lt;跟我一起写 Makefile&gt; 陈皓</p>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux基础知识</title>
    <link href="/2018/08/17/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2018/08/17/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p>Linux 一些最最最基本的常识</p><a id="more"></a><h4 id="1-GNU-vs-BSD"><a href="#1-GNU-vs-BSD" class="headerlink" title="1. GNU vs BSD"></a>1. GNU vs BSD</h4><h5 id="典型的类-unix-操作系统包括两个版本："><a href="#典型的类-unix-操作系统包括两个版本：" class="headerlink" title="典型的类 unix 操作系统包括两个版本："></a>典型的类 unix 操作系统包括两个版本：</h5><ul><li>BSD 版本（ BSDs &amp; Mac OS）</li><li>GNU 版本（Linux）</li></ul><h5 id="Linux内核-vs-发行版"><a href="#Linux内核-vs-发行版" class="headerlink" title="Linux内核 vs 发行版"></a>Linux内核 vs 发行版</h5><p>​        linux内核是一种开放源码的操作系统，提供硬件抽象层、硬盘及文件系统控制及多任务功能的系统核心程序。<br>​        linux发行版基于linux内核源码，将Linux系统的内核与外围实用程序、软件和文档包装起来，并提供一些系统安装界面和系统配置、设定与管理工具，就构成了一种发行版本(distribution)。</p><p>各种发行版可以主要分为两大系统：</p><ul><li>以 RPM 方式安装软件的系统，包括Red Hat， Fedora， SuSE 等。</li><li>以 Debian 的 dpkg方式安装的软件的系统，包括 Debian， Ubuntu，B2D 等。</li></ul><h4 id="2-文件的目录"><a href="#2-文件的目录" class="headerlink" title="2. 文件的目录"></a>2. 文件的目录</h4><pre><code class="hljs shell">/              根目录├── bin     存放用户二进制文件  # ├── boot    存放内核引导配置文件  #├── dev     存放设备文件  # ├── etc     存放系统配置文件  # ├── home    用户主目录  # ├── lib     动态共享库├── lost+found  文件系统恢复时的恢复文件├── media   可卸载存储介质挂载点├── mnt     文件系统临时挂载点  # ├── opt     附加的应用程序包├── proc    系统内存的映射目录，提供内核与进程信息  # ├── root    root 用户主目录  #├── sbin    存放系统二进制文件  # ├── srv     存放服务相关数据├── sys     sys 虚拟文件系统挂载点├── tmp     存放临时文件├── usr     存放用户应用程序└── var     存放邮件、系统日志等变化文件   #</code></pre><h4 id="3-软连接和硬链接"><a href="#3-软连接和硬链接" class="headerlink" title="3. 软连接和硬链接"></a>3. 软连接和硬链接</h4><h5 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h5><p>硬链接就是同一个文件使用了多个别名，他们有共同的 inode和 data block块。硬链接可由命令 <code>ln</code> 创建硬链接：</p><pre><code class="hljs ebnf"><span class="hljs-attribute">ln oldfile newfile</span></code></pre><ul><li>只能对已存在的文件进行创建；不能对目录进行创建，只可对文件创建；</li><li>删除一个硬链接文件并不影响其他有相同 inode 号的文件。</li></ul><h5 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h5><p>软链接就是一个普通文件，只是数据块内容是另一文件的路径名的指向。软链接有着自己的 inode 号以及用户数据块。可以使用<code>ln -s</code> 创建软链接：</p><pre><code class="hljs shell">ln -s oldfile newfile</code></pre><ul><li>软链接有自己的文件属性及权限等；</li><li>可对不存在的文件或目录创建软链接；软链接可对文件或目录创建；</li><li>创建软链接时，链接计数 <strong>i_nlink</strong> 不会增加；</li><li>删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 <strong>dangling link</strong>，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。</li></ul><p><img src="/2018/08/17/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/hard_soft_link.png" alt="hard link vs soft link"></p><h4 id="4-环境变量"><a href="#4-环境变量" class="headerlink" title="4. 环境变量"></a>4. 环境变量</h4><p>查看环境变量：<code>echo $PATH</code></p><p> 将指定路径到系统路径(一次性)： <code>export PATH=$PATH:/path/to/dir</code>  </p><p>将指定路径到系统路径(长期)：</p><pre><code class="hljs shell">vim ~/.bashrcexport PATH=$PATH:/path/to/dirsource ~/.bashrc</code></pre><h4 id="5-常见的开源许可证选择"><a href="#5-常见的开源许可证选择" class="headerlink" title="5. 常见的开源许可证选择"></a>5. 常见的开源许可证选择</h4><p><img src="/2018/08/17/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/license.png" alt="License"></p><p>[参考资料]</p><ol><li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-hardandsymb-links/">https://www.ibm.com/developerworks/cn/linux/l-cn-hardandsymb-links/</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux常见问题</title>
    <link href="/2018/08/17/Linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/2018/08/17/Linux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>主要用来记录一些 ubuntu(linux) 使用过程中碰到的问题</p><a id="more"></a><h4 id="1-如何挂载磁盘"><a href="#1-如何挂载磁盘" class="headerlink" title="1. 如何挂载磁盘"></a>1. 如何挂载磁盘</h4><p>（１） 找到未分配的磁盘，　这里是　<code>/dev/sdb</code></p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> sudo fdisk -l  <span class="hljs-comment"># 找到未分配的磁盘</span></span>Disk /dev/sdb: 1.8 TiB, 2000398934016 bytes, 3907029168 sectorsUnits: sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 4096 bytesI/O size (minimum/optimal): 4096 bytes / 4096 bytesDisklabel type: dosDisk identifier: 0x76738fb3</code></pre><p>（２）对该磁盘使用fdisk 命令建立分区:</p><pre><code class="hljs shell">sudo fdisk /dev/sdb<span class="hljs-meta">#</span><span class="bash"> m -&gt; n -&gt; 一路回车　－&gt; w(保存退出)</span><span class="hljs-meta">$</span><span class="bash"> sudo fdisk -l <span class="hljs-comment">#　此时可以发现设备</span></span>Device     Boot Start        End    Sectors  Size Id Type/dev/sdb1        2048 3907029167 3907027120  1.8T 83 Linux</code></pre><p>（３）格式化分区，　并建立文件系统</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> sudo mkfs -t ext4 /dev/sdb1  <span class="hljs-comment"># -t　指定文件系统格式</span></span></code></pre><p>（４）挂载磁盘到指定位置</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> mount /dev/sdb1 /home/data/</span><span class="hljs-meta">#</span><span class="bash"> 区分 sdb和sdb1, sdb表示磁盘，　sdb1则表示该磁盘上的分区</span></code></pre><h4 id="2-如何查询端口所运行的程序"><a href="#2-如何查询端口所运行的程序" class="headerlink" title="2. 如何查询端口所运行的程序"></a>2. 如何查询端口所运行的程序</h4><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> sudo netstat -antp | grep 7000</span>tcp6       0      0 :::7000                 :::*                    LISTEN      12464/frps      <span class="hljs-meta">$</span><span class="bash"> ps 12464</span>  PID TTY      STAT   TIME COMMAND12464 pts/0    Sl     0:00 ./frps<span class="hljs-meta">$</span><span class="bash"> lsof -i:7000   <span class="hljs-comment"># lsof:list open files -&gt; -i </span></span>COMMAND   PID   USER   FD   TYPE  DEVICE SIZE/OFF NODE NAMEfrps    12464 ubuntu    3u  IPv6 7542760      0t0  TCP *:afs3-fileserver (LISTEN)<span class="hljs-meta">$</span><span class="bash"> ps -fe | grep 12464</span>ubuntu   12464  6446  0 00:29 pts/0    00:00:00 ./frpsubuntu   12707  6446  0 00:32 pts/0    00:00:00 grep --color=auto 12464</code></pre><h4 id="3-gdm3、lightdm-和-kdm-的认识"><a href="#3-gdm3、lightdm-和-kdm-的认识" class="headerlink" title="3. gdm3、lightdm 和 kdm 的认识"></a>3. gdm3、lightdm 和 kdm 的认识</h4><p>Q:  当我的 win10/mac 电脑想要控制 ubuntu 电脑时，一切操作无误的情况下，在点击 “远程协助” 按钮时，进去后过一会儿就会出现“连接已断开”的提示。<br>S： 在打开向日葵客户端的情况下，打开命令 ubuntu 行窗口</p><pre><code class="hljs shell">sudo apt-get updatesudo apt-get upgradesudo install lightdm</code></pre><p>重启Ubuntu系统即可远程成功</p><p>R： 了解一下gdm3、lightdm、kdm</p><p>维基百科：显示管理器向用户显示登录屏幕。 当用户成功输入用户名和密码的有效组合时，会话开始。</p><ul><li>gdm3 是 gdm的继承者，它是GNOME显示管理器。 更新的gdm3 使用了最小的gnome-shell 版本，并提供了与GNOME3会话相同的外观和感觉。</li><li>lightDM，即：Light Display Manager，是一个全新的、轻量的Linux桌面的桌面显示管理器</li><li>kdm 是 kde 管理器的显示。 但在 KDE5中，它被否决为 SDDM，它更适合作为显示管理器，因此在默认情况下，它是在屏幕。</li></ul><p>简单理解，这三个只是不同版本的显示管理器而已，当你的 ubuntu 系统安装了多个显示管理器时，(以 lightdm 切换到 gdm3 为例）可以用 <code>sudo dpkg-reconfigure gdm3</code> 来进行切换。</p><h4 id="4-xrandr-使用"><a href="#4-xrandr-使用" class="headerlink" title="4. xrandr 使用"></a>4. xrandr 使用</h4><p>装了一个侧屏， 需要使用 xrandr 来进行相关设置：</p><ul><li><p>xrandr : 列出可用的显示设备</p><pre><code class="hljs shell">zhaozhichao@zhaozhichao-MS-7B24:~/Desktop/sany/classification$ xrandrScreen 0: minimum 8 x 8, current 3000 x 1920, maximum 32767 x 32767DP-0 connected primary 1920x1080+1080+520 (normal left inverted right x axis y axis) 598mm x 336mm   1920x1080     60.00*+   1600x900      60.00     1280x1024     75.02    60.02     1152x864      75.00     1024x768      75.03    60.00     800x600       75.00    60.32     640x480       75.00    59.94  DP-1 disconnected (normal left inverted right x axis y axis)HDMI-0 disconnected (normal left inverted right x axis y axis)DP-2 disconnected (normal left inverted right x axis y axis)DP-3 disconnected (normal left inverted right x axis y axis)DP-4 connected 1080x1920+0+0 left (normal left inverted right x axis y axis) 598mm x 336mm   1920x1080     60.00*+   1600x900      60.00     1280x1024     75.02    60.02     1152x864      75.00     1024x768      75.03    60.00     800x600       75.00    60.32     640x480       75.00    59.94  DP-5 disconnected (normal left inverted right x axis y axis)USB-C-0 disconnected (normal left inverted right x axis y axis)</code></pre></li><li><p>设置分辨率</p><pre><code class="hljs shell">xrandr --output eDP1 --mode 1280x1024_60.00</code></pre></li><li><p>双屏设置</p><pre><code class="hljs shell">xrandr --output DP-4 --left-of  DP-0 --auto // DP-4 作为 DP-0 的左屏幕显示                                              //  --left-of                                                // --right-of</code></pre></li><li><p>屏幕克隆</p><pre><code class="hljs shell">xrandr --output VGA-0 --same-as DVI-D-0 --auto</code></pre></li><li><p>设置 左旋转/右旋转/正向</p><pre><code class="hljs shell">xrandr --output DP-0 --rotate normal // left、right、normal</code></pre></li><li><p>设置主屏幕</p><pre><code class="hljs shell">xrandr --output HDMI2 --auto --primary</code></pre></li></ul><h4 id="5-U盘-硬盘-mount-故障"><a href="#5-U盘-硬盘-mount-故障" class="headerlink" title="5. U盘/硬盘 mount 故障"></a>5. U盘/硬盘 mount 故障</h4><pre><code class="hljs applescript">$ sudo mount /dev/sdb1 /mnt$MFTMirr <span class="hljs-keyword">does</span> <span class="hljs-keyword">not</span> match $MFT (<span class="hljs-built_in">record</span> <span class="hljs-number">0</span>).Failed <span class="hljs-keyword">to</span> mount &#x27;/dev/sdb1&#x27;: Input/output <span class="hljs-keyword">error</span>NTFS <span class="hljs-keyword">is</span> either inconsistent, <span class="hljs-keyword">or</span> there <span class="hljs-keyword">is</span> a hardware fault, <span class="hljs-keyword">or</span> <span class="hljs-keyword">it</span>&#x27;s aSoftRAID/FakeRAID hardware. In <span class="hljs-keyword">the</span> <span class="hljs-keyword">first</span> case <span class="hljs-built_in">run</span> chkdsk /f <span class="hljs-keyword">on</span> Windows<span class="hljs-keyword">then</span> reboot <span class="hljs-keyword">into</span> Windows twice. The usage <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> /f parameter <span class="hljs-keyword">is</span> veryimportant! If <span class="hljs-keyword">the</span> device <span class="hljs-keyword">is</span> a SoftRAID/FakeRAID <span class="hljs-keyword">then</span> <span class="hljs-keyword">first</span> <span class="hljs-built_in">activate</span><span class="hljs-keyword">it</span> <span class="hljs-keyword">and</span> mount a different device under <span class="hljs-keyword">the</span> /dev/mapper/ directory, (e.g./dev/mapper/nvidia_eahaabcc1). Please see <span class="hljs-keyword">the</span> &#x27;dmraid&#x27; documentation<span class="hljs-keyword">for</span> more details.</code></pre><p>S： 利用 ntfsprogs utility 包里的工具 ntfsfix 修理一下，感觉应该是把类似链接号什么的修理好：</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> sudo ntfsfix /dev/sdb1</span>Mounting volume... FAILEDAttempting to correct errors...Processing $MFT and $MFTMirr...Reading $MFT... OKReading $MFTMirr... OKComparing $MFTMirr to $MFT... FAILEDCorrecting differences in $MFTMirr record 0...OKProcessing of $MFT and $MFTMirr completed successfully.Setting required flags on partition... OKGoing to empty the journal ($LogFile)... OKNTFS volume version is 3.1.NTFS partition /dev/sdb1 was processed successfully.</code></pre><h4 id="6-区分-profile-和-bashrc"><a href="#6-区分-profile-和-bashrc" class="headerlink" title="6. 区分 profile 和 bashrc"></a>6. 区分 profile 和 bashrc</h4><div class="table-container"><table><thead><tr><th></th><th>生效时间</th><th>针对用户</th></tr></thead><tbody><tr><td>/etc/profile</td><td>重启生效</td><td>所有用户</td></tr><tr><td>/etc/bashrc</td><td>重新打开一个 bash 生效</td><td>所有用户</td></tr><tr><td>~/.bash_profile或 ~/.profile</td><td>重启生效</td><td>当前用户</td></tr><tr><td>~/.bashrc</td><td>重新打开一个 bash 生效</td><td>当前用户</td></tr></tbody></table></div><h4 id="7-etc-ld-so-conf-与ldconfig"><a href="#7-etc-ld-so-conf-与ldconfig" class="headerlink" title="7. /etc/ld.so.conf 与ldconfig"></a>7. /etc/ld.so.conf 与ldconfig</h4><p><strong>ldconfig命令</strong> 的用途主要是在<strong>默认搜寻目录/lib和/usr/lib以及动态库配置文件/etc/ld.so.conf内所列的目录下，搜索出可共享的动态链接库（格式如lib*.so*）,进而创建出动态装入程序(ld.so)所需的连接和缓存文件</strong><br>往 <code>/lib</code> 和 <code>/usr/lib</code> 里面加东西，是不用修改 <code>/etc/ld.so.conf</code> 的，但是完了之后要调一下 <code>ldconfig</code>，不然这个 library 会找不到。<br>想往上面两个目录以外加东西的时候，一定要修改 <code>/etc/ld.so.conf</code>，然后再调用 <code>ldconfig</code>，不然也会找不到。比较常规的操作是，自己生成了一个动态链接库，然后将路径添加到 <code>/etc/ld.so.conf</code>， 然后执行 <code>ldconfig</code>。 这样就可以在系统中调用该动态链接库了。</p><h4 id="8-NVIDIA-相关软件的知识"><a href="#8-NVIDIA-相关软件的知识" class="headerlink" title="8. NVIDIA 相关软件的知识"></a>8. NVIDIA 相关软件的知识</h4><p><strong>GPU</strong>:  硬件， 主流的是 Nvidia 的 GPU(现在流行的是 RTX 2080Ti)， 深度学习本身需要大量计算。 GPU 的并行计算能力， 在过去几年里恰当了满足了深度学习的需求。 AMD 的 GPU 基本没有什么支持， 可以不用考虑。<br><strong>NVIDIA Driver</strong>: 硬件接口， 没有显卡驱动， 就不能识别 GPU 硬件， 不能调用其计算资源。<br><strong>CUDA</strong>: 是 NVIDIA 推出的只能用于自家GPU的并行计算框架。只有安装这个框架才能够进行复杂的并行计算。主流的深度学习框架也都是基于CUDA进行GPU并行加速的，几乎无一例外。<br><strong>cudnn</strong>: 针对深度卷积神经网络的加速库。<br><strong>Tensorflow、pytorch、mxnet、paddle</strong>: 在 CUDA 和 cudnn 之上的深度学习框架。</p><h4 id="9-显卡安装的知识"><a href="#9-显卡安装的知识" class="headerlink" title="9. 显卡安装的知识"></a>9. 显卡安装的知识</h4><p>(1)  <strong>硬件</strong>：插上 GPU<br>(2)  <strong>驱动</strong>:  [去官网下载对应的驱动程序]</p><p>a. 首先屏蔽 nouveau</p><pre><code class="hljs shell">sudo vim /etc/modprobe.d/blacklist-nouveau.conf</code></pre><p>在其中加入</p><pre><code class="hljs shell">blacklist nouveau</code></pre><p>b. 按照 ctrl + alt + F1 进入 tty1, 然后使用如下命令关掉 X server</p><pre><code class="hljs awk">sudo <span class="hljs-regexp">/etc/i</span>nit.d/lightdm stop</code></pre><p>c. 安装对应的驱动程序<br>d. 重启 X server</p><pre><code class="hljs shell">sudo /etc/init.d/light restart</code></pre><p>（3） <strong>CUDA &amp; cudnn</strong></p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> Download CUDA   https://developer.nvidia.com/cuda-downloads</span><span class="hljs-meta">$</span><span class="bash"> chmod a+x cuda-repo-ubuntu1804-10-1-local-10.1.168-418.67_1.0-1_amd64.deb </span><span class="hljs-meta">$</span><span class="bash"> sudo dpkg -i ./cuda-repo-ubuntu1804-10-1-local-10.1.168-418.67_1.0-1_amd64.deb </span><span class="hljs-meta">$</span><span class="bash"> sudo apt-key add /var/cuda-repo-10-1-local-10.1.168-418.67/7fa2af80.pub</span><span class="hljs-meta">$</span><span class="bash"> sudo apt-get update</span><span class="hljs-meta">$</span><span class="bash"> sudo apt-get install cuda-10-1 -y</span><span class="hljs-meta">#</span><span class="bash"> Download cudnn from https://developer.nvidia.com/cudnn</span><span class="hljs-meta">$</span><span class="bash"> sudo cp cuda/include/cudnn.h /usr/<span class="hljs-built_in">local</span>/cuda/include</span><span class="hljs-meta">$</span><span class="bash"> sudo cp cuda/lib64/libcudnn* /usr/<span class="hljs-built_in">local</span>/cuda/lib64</span><span class="hljs-meta">$</span><span class="bash"> sudo chmod a+r /usr/<span class="hljs-built_in">local</span>/cuda/include/cudnn.h /usr/<span class="hljs-built_in">local</span>/cuda/lib64/libcudnn*</span></code></pre><p>别忘记 执行以下 sudo ldconfig</p><h4 id="10-ubuntu-循环登录问题"><a href="#10-ubuntu-循环登录问题" class="headerlink" title="10. ubuntu 循环登录问题"></a>10. ubuntu 循环登录问题</h4><p>这个问题是一个很常见的问题， 我这次碰到的情况是新增加的账户不能正常登陆, 这里是由于useradd的时候没有关联到对应的/home下的文件夹所致, 处理如下:</p><p>（1）使用: <code>userdel -r 用户名</code> 删除用户</p><p>（2）使用  <code>useradd -m 用户名</code> 添加用户 -&gt;  会在/home目录下创建同名文件夹</p><p>（3）添加用户到sudoer</p><ul><li><code>sudo visudo</code></li><li>在<code>%sudo</code>行下面<code>user ALL=(ALL) ALL</code></li></ul><h4 id="11-linux-productivity-tools"><a href="#11-linux-productivity-tools" class="headerlink" title="11. linux productivity tools"></a>11. linux productivity tools</h4><p>朋友分享了一份 linux productivity tools， 用空去学习学习</p><p>参考网址为：<a href="https://news.ycombinator.com/item?id=23229241">https://news.ycombinator.com/item?id=23229241</a></p><h4 id="12-linux-开机自启动"><a href="#12-linux-开机自启动" class="headerlink" title="12. linux 开机自启动"></a>12. linux 开机自启动</h4><p><strong>方式一. 使用自带开机脚本</strong></p><p>使用 <code>/etc/rc.local</code> 文件，在 ubuntu18.04 中可以自己新建这个文件。</p><pre><code class="hljs awk">vim <span class="hljs-regexp">/etc/</span>rc.local</code></pre><p>文件的具体内容如下所示，将开机自启动命令加在 exit 0 之前。</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/sh -e</span><span class="hljs-meta">#</span><span class="hljs-meta">#</span><span class="bash"> rc.local</span><span class="hljs-meta">#</span><span class="hljs-meta">#</span><span class="bash"> This script is executed at the end of each multiuser runlevel.</span><span class="hljs-meta">#</span><span class="bash"> Make sure that the script will <span class="hljs-string">&quot;exit 0&quot;</span> on success or any other</span><span class="hljs-meta">#</span><span class="bash"> value on error.</span><span class="hljs-meta">#</span><span class="hljs-meta">#</span><span class="bash"> In order to <span class="hljs-built_in">enable</span> or <span class="hljs-built_in">disable</span> this script just change the execution</span><span class="hljs-meta">#</span><span class="bash"> bits.</span><span class="hljs-meta">#</span><span class="hljs-meta">#</span><span class="bash"> By default this script does nothing.</span>exit 0</code></pre><p>修改执行权限即可</p><pre><code class="hljs shell">chmod +x /etc/rc.local</code></pre><p><strong>方式二. 添加开机脚本</strong></p><p>(1) 在　<code>/etc/init.d/</code> 下新建一个文件 auto_start.sh，　内容如下所示，讲待执行命令填写在 exit 0 之前。　</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash  </span><span class="hljs-meta">#</span><span class="bash"> <span class="hljs-built_in">command</span> content      </span>exit 0</code></pre><p>(2) 更改脚本权限:</p><pre><code class="hljs shell">sudo chmod +x auto_start.sh</code></pre><p>(3) 将脚本添加到启动脚本, 执行如下指令即可，在这里90表明一个优先级，越高表示执行的越晚。</p><pre><code class="hljs shell">cd /etc/init.d/  sudo update-rc.d auto_start.sh defaults 90</code></pre><p>Note:　可以使用如下命令移除开机脚本：</p><pre><code class="hljs shell">sudo update-rc.d -f new_service.sh remove</code></pre><h4 id="13-NVIDIA-常见命令"><a href="#13-NVIDIA-常见命令" class="headerlink" title="13. NVIDIA 常见命令"></a>13. NVIDIA 常见命令</h4><h6 id="nvidia-smi"><a href="#nvidia-smi" class="headerlink" title="nvidia-smi"></a>nvidia-smi</h6><p>在进行深度学习实验时，GPU 的实时状态监测十分有必要。今天详细解读一下 <code>nvidia-smi</code> 命令。</p><pre><code class="hljs shell">Fri Aug  2 10:10:08 2019       +-----------------------------------------------------------------------------+| NVIDIA-SMI 410.48                 Driver Version: 410.48                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce RTX 208...  Off  | 00000000:01:00.0  On |                  N/A || 31%   43C    P8    12W / 250W |    223MiB / 10981MiB |      4%      Default |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID   Type   Process name                             Usage      ||=============================================================================||    0      1614      G   /usr/lib/xorg/Xorg                            14MiB ||    0      4804      G   /usr/lib/xorg/Xorg                           207MiB |+-----------------------------------------------------------------------------+</code></pre><p>上图是服务器上 GeForce GTX 1080 Ti 的信息，下面一一解读参数。 上面的表格中的信息与下面的四个框的信息是一一对应的：</p><p><strong>GPU</strong>：GPU 编号；            <strong>Name</strong>：GPU 型号；  <strong>Persistence-M</strong>：持续模式的状态。<br><strong>Fan</strong>：风扇转速(0~100%)  <strong>Temp</strong>：温度(摄氏度)  <strong>Perf</strong>：性能状态，从P0(小)到P12(大)　<strong>Pwr:Usage/Cap</strong>：能耗</p><p><strong>Bus-Id</strong>：GPU总线　　　　<strong>Disp.A</strong>：Display Active，表示GPU的显示是否初始化；<br><strong>Memory Usage</strong>：显存使用率； </p><p><strong>Volatile GPU-Util</strong>：浮动的GPU利用率　　　<strong>Uncorr. ECC</strong>：Error Correcting Code，错误检查与纠正<br><strong>Compute M</strong>：compute mode，计算模式。</p><p><strong>下方的 Processes 表示每个进程对 GPU 的显存使用率</strong></p><h6 id="nvidia-smi-L"><a href="#nvidia-smi-L" class="headerlink" title="nvidia-smi -L"></a>nvidia-smi -L</h6><p>第二个命令：<code>nvidia-smi -L</code>, 该命令用于列出所有可用的 NVIDIA 设备信息。</p><h6 id="watch-n1-nvidia-smi"><a href="#watch-n1-nvidia-smi" class="headerlink" title="watch -n1 nvidia-smi"></a>watch -n1 nvidia-smi</h6><p>每1秒检查一次GPU的使用情况</p><h6 id="查看CUDA-和-cudnn-版本信息"><a href="#查看CUDA-和-cudnn-版本信息" class="headerlink" title="查看CUDA　和 cudnn　版本信息"></a>查看CUDA　和 cudnn　版本信息</h6><p>查看 CUDA 版本：</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat /usr/<span class="hljs-built_in">local</span>/cuda/version.txt</span>CUDA Version 10.0.130</code></pre><p>也可以使用如下命令:</p><pre><code class="hljs shell">nvcc --version</code></pre><p>查看 CUDNN 版本：</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat /usr/<span class="hljs-built_in">local</span>/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</span>rep CUDNN_MAJOR -A 2<span class="hljs-meta">#</span><span class="bash">define CUDNN_MAJOR 7</span><span class="hljs-meta">#</span><span class="bash">define CUDNN_MINOR 5</span><span class="hljs-meta">#</span><span class="bash">define CUDNN_PATCHLEVEL 0</span>--<span class="hljs-meta">#</span><span class="bash">define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)</span><span class="hljs-meta">#</span><span class="bash">include <span class="hljs-string">&quot;driver_types.h&quot;</span></span></code></pre>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu常见的软件安装方式</title>
    <link href="/2018/06/17/ubuntu%E5%B8%B8%E8%A7%81%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/"/>
    <url>/2018/06/17/ubuntu%E5%B8%B8%E8%A7%81%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<p>ubuntu 一些安装命令的区分， 比如 apt-get、apt、snap、dpkg 等。</p><a id="more"></a><h4 id="1-apt-vs-apt-get"><a href="#1-apt-vs-apt-get" class="headerlink" title="1. apt vs apt-get"></a>1. apt vs apt-get</h4><p>　　最常用的 Linux 包管理命令分散在 <code>apt-get</code>、<code>apt-cache</code> 和<code>apt-config</code> 这三条命令当中。<code>apt</code> 命令的引入就是<strong>为了解决命令过于分散的问题</strong>，它包括了 apt-get 命令出现以来使用最广泛的功能选项，以及 apt-cache 和 apt-config 命令中很少用到的功能。在使用 apt 命令时，用户不必再由 apt-get 转到 apt-cache 或 apt-config，而且 apt 更加结构化，并为用户提供了管理软件包所需的必要选项。</p><p><strong>简单来说就是：apt = apt-get、apt-cache 和 apt-config 中最常用命令选项的集合。</strong></p><h6 id="apt与apt-get之间的区别"><a href="#apt与apt-get之间的区别" class="headerlink" title="apt与apt-get之间的区别"></a>apt与apt-get之间的区别</h6><p>　　通过 apt 命令，用户可以在同一地方集中得到所有必要的工具，apt 的主要目的是提供一种以「让终端用户满意」的方式来处理 Linux 软件包的有效方式。</p><p>　　apt 具有更精减但足够的命令选项，而且参数选项的组织方式更为有效。除此之外，它默认启用的几个特性对最终用户也非常有帮助。例如，可以在使用 apt 命令安装或删除程序时看到进度条，apt 还会在更新存储库数据库时提示用户可升级的软件包个数。</p><p>　　如果你使用 apt 的其它命令选项，也可以实现与使用 apt-get 时相同的操作。</p><h6 id="apt和apt-get命令之间的区别"><a href="#apt和apt-get命令之间的区别" class="headerlink" title="apt和apt-get命令之间的区别"></a>apt和apt-get命令之间的区别</h6><p>​      虽然 apt 与 apt-get 有一些类似的命令选项，但它并不能完全向下兼容 apt-get 命令。也就是说，可以用 apt 替换部分 apt-get 系列命令，但不是全部。</p><div class="table-container"><table><thead><tr><th style="text-align:left">apt 命令</th><th style="text-align:left">取代的命令</th><th style="text-align:left">命令的功能</th></tr></thead><tbody><tr><td style="text-align:left">apt install</td><td style="text-align:left">apt-get install</td><td style="text-align:left">安装软件包</td></tr><tr><td style="text-align:left">apt remove</td><td style="text-align:left">apt-get remove</td><td style="text-align:left">移除软件包</td></tr><tr><td style="text-align:left">apt purge</td><td style="text-align:left">apt-get purge</td><td style="text-align:left">移除软件包及配置文件</td></tr><tr><td style="text-align:left">apt update</td><td style="text-align:left">apt-get update</td><td style="text-align:left">刷新存储库索引</td></tr><tr><td style="text-align:left">apt upgrade</td><td style="text-align:left">apt-get upgrade</td><td style="text-align:left">升级所有可升级的软件包</td></tr><tr><td style="text-align:left">apt autoremove</td><td style="text-align:left">apt-get autoremove</td><td style="text-align:left">自动删除不需要的包</td></tr><tr><td style="text-align:left">apt full-upgrade</td><td style="text-align:left">apt-get dist-upgrade</td><td style="text-align:left">在升级软件包时自动处理依赖关系</td></tr><tr><td style="text-align:left">apt search</td><td style="text-align:left">apt-cache search</td><td style="text-align:left">搜索应用程序</td></tr><tr><td style="text-align:left">apt show</td><td style="text-align:left">apt-cache show</td><td style="text-align:left">显示安装细节</td></tr></tbody></table></div><p>当然，apt 还有一些自己的命令：</p><div class="table-container"><table><thead><tr><th style="text-align:left">新的apt命令</th><th style="text-align:left">命令的功能</th></tr></thead><tbody><tr><td style="text-align:left">apt list</td><td style="text-align:left">列出包含条件的包（已安装，可升级等）</td></tr><tr><td style="text-align:left">apt edit-sources</td><td style="text-align:left">编辑源列表</td></tr></tbody></table></div><p>需要大家注意的是：apt 命令也还在不断发展， 因此，你可能会在将来的版本中看到新的选项。</p><h6 id="apt-get已弃用？"><a href="#apt-get已弃用？" class="headerlink" title="apt-get已弃用？"></a>apt-get已弃用？</h6><p>​      目前还没有任何 Linux 发行版官方放出 apt-get 将被停用的消息，至少它还有比 apt 更多、更细化的操作功能。对于低级操作，仍然需要 apt-get。</p><h6 id="我应该使用apt还是apt-get？"><a href="#我应该使用apt还是apt-get？" class="headerlink" title="我应该使用apt还是apt-get？"></a>我应该使用apt还是apt-get？</h6><p>​      既然两个命令都有用，那么我该使用 apt 还是 apt-get 呢？作为一个常规 Linux 用户，建议大家尽快适应并开始首先使用 apt。不仅因为广大 Linux 发行商都在推荐 apt，更主要的还是它提供了 Linux 包管理的必要选项。</p><p>​     最重要的是，apt 命令选项更少更易记，因此也更易用，所以没理由继续坚持 apt-get。</p><h6 id="dpkg"><a href="#dpkg" class="headerlink" title="dpkg"></a>dpkg</h6><p>dpkg是用来安装.deb文件,但不会解决模块的依赖关系,且不会关心ubuntu的软件仓库内的软件,可以用于安装本地的deb文件。</p><h6 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h6><p>最后结大家提供两点使用上的建议：</p><ul><li>apt 可以看作 apt-get 和 apt-cache 命令的子集, 可以为包管理提供必要的命令选项。</li><li>apt-get 虽然没被弃用，但作为普通用户，还是应该首先使用 apt。</li></ul><p>以上原文链接：<a href="https://www.sysgeek.cn/apt-vs-apt-get/">https://www.sysgeek.cn/apt-vs-apt-get/</a></p><h4 id="2-apt-基本命令"><a href="#2-apt-基本命令" class="headerlink" title="2. apt 基本命令"></a>2. apt 基本命令</h4><pre><code class="hljs shell">sudo apt install [xxx.deb] # 安装sudo apt --fix-broken install　　#　修复依赖<span class="hljs-meta">#</span><span class="bash"> apt update vs upgrade</span>sudo apt update　　# 只检查，不更新（已安装的软件包是否有可用的更新，给出汇总报告）sudo apt upgrade #  更新已安装的软件包sudo apt remove     # 删除已安装的软件包（保留配置文件）sudo apt purge      # 删除已安装包（不保留配置文件)，删除软件包，同时删除相应依赖软件包。                         # 如果想要彻底清理软件，　建议使用　purge 命令sudo apt clean    # 此命令会将 /var/cache/apt/archives/ 下的 所有 deb 删掉，                 # 相当于清理下载的软件安装包。sudo apt autoremove   # 删除已安装的软件包（保留配置文件），不会删除依赖软件包，且保留配置文件。（这个命令容易导致系统无法进入系统桌面, 在桌面版的Ubuntu系统下尽量不要使用</code></pre><h4 id="3-常见的软件编译安装方法"><a href="#3-常见的软件编译安装方法" class="headerlink" title="3. 常见的软件编译安装方法"></a>3. 常见的软件编译安装方法</h4><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> download</span><span class="hljs-meta">$</span><span class="bash"> git <span class="hljs-built_in">clone</span> [github/path/to/packge]</span><span class="hljs-meta">#</span><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> [package]</span><span class="hljs-meta">$</span><span class="bash"> mkdir build</span><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">cd</span> build</span><span class="hljs-meta">#</span><span class="bash"> build &amp; install</span><span class="hljs-meta">$</span><span class="bash"> cmake ..</span><span class="hljs-meta">$</span><span class="bash"> make </span><span class="hljs-meta">$</span><span class="bash"> sudo make install</span></code></pre><h4 id="４-snap"><a href="#４-snap" class="headerlink" title="４. snap"></a>４. snap</h4><p>　　Snap是Ubuntu母公司Canonical于2016年4月发布　Ubuntu16.04　时候引入的一种安全的、易于管理的、沙盒化的软件包格式，与传统的dpkg/apt有着很大的区别。Snap可以让开发者将他们的软件更新包随时发布给用户，而不必等待发行版的更新周期；　其次Snap应用可以同时安装多个版本的软件，比如安装Python2.7和Python3.3。　snap软件包一般安装在/snap目录下。</p><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> sudo snap install [snap_name]　<span class="hljs-comment">#　安装snap包</span></span><span class="hljs-meta">$</span><span class="bash"> sudo snap find [snap_name] <span class="hljs-comment">#　搜索安装的snap包</span></span><span class="hljs-meta">$</span><span class="bash"> sudo snap refresh [snap_name] <span class="hljs-comment">#　更新snap包</span></span><span class="hljs-meta">$</span><span class="bash"> sudo snap remove [snap_name] <span class="hljs-comment">#　删除 snap 包</span></span><span class="hljs-meta">$</span><span class="bash"> snap list <span class="hljs-comment">#　列出已经安装的snap包</span></span></code></pre><h4 id="5-Python-packgae-安装方式"><a href="#5-Python-packgae-安装方式" class="headerlink" title="5. Python packgae 安装方式"></a>5. Python packgae 安装方式</h4><h6 id="pip-pip3"><a href="#pip-pip3" class="headerlink" title="pip/pip3"></a>pip/pip3</h6><p>比较常见的安装python package 的方法    </p><h6 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h6><p>​    conda的包管理比较好理解了，这部分功能与pip类似。例如，如果需要安装scipy， 可以使用：<code>conda install scipy</code>。conda会从从远程搜索scipy的相关信息和依赖项目。例如，scipy 依赖于numpy，一次如果你只安装 scipy，则conda还会安装 numpy。你还可以同时安装多个包。类似 <code>conda install numpy scipy pandas</code> 的命令会同时安装所有这些包。另外还可以通过添加版本号（例如 <code>conda install numpy=1.10</code>）来指定所需的包版本。</p><p>​    Conda的大部分命令都很直观，要卸载安装包，可以使用 <code>conda remove package_name</code>。要更新安装包，可以使用 <code>conda update package_name</code>, 要更新环境中所有包，可以使用 <code>conda update -all</code>。要查看已经安装的包，可以使用 <code>conda list</code>, 最新版的conda是从site-packages文件夹中搜索已经安装的包，不依赖于pip，因此可以显示出通过各种方式安装的包。 最后，如果我们不知道要找的包的确切名称，可以尝试使用<code>conda search search_term</code> 尝试进行搜索。例如，要安装 Beatiful Soup，但是我们不清楚确切的包名称，因此可以尝试<code>conda search beatifulsoup</code>。</p><h6 id="apt-get-install-Python-package"><a href="#apt-get-install-Python-package" class="headerlink" title="apt-get install Python package"></a>apt-get install Python package</h6><p>(1) 安装python2 package</p><pre><code class="hljs shell">sudo apt-get install python-[package]</code></pre><p>(2) 安装python3 package</p><pre><code class="hljs shell">sudo apt-get install python3-[package]</code></pre><h4 id="6-apt-get-和-yum-区别"><a href="#6-apt-get-和-yum-区别" class="headerlink" title="6. apt-get 和 yum 区别"></a>6. apt-get 和 yum 区别</h4><p>一般来说著名的linux系统基本上分两大类：</p><ol><li>RedHat系列：Redhat、CentOS、Fedora等</li><li>Debian系列：Debian、Ubuntu等</li></ol><h6 id="RedHat-系列"><a href="#RedHat-系列" class="headerlink" title="RedHat 系列"></a>RedHat 系列</h6><ol><li>常见的安装包格式 rpm包,安装rpm包的命令是“rpm -参数” </li><li>包管理工具 yum </li><li>支持tar包</li></ol><h6 id="Debian系列"><a href="#Debian系列" class="headerlink" title="Debian系列"></a>Debian系列</h6><ol><li>常见的安装包格式 deb包,安装deb包的命令是“dpkg -参数” </li><li>包管理工具 apt-get </li><li>支持tar包</li></ol>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Linux_commands</title>
    <link href="/2018/06/05/Linux-commands/"/>
    <url>/2018/06/05/Linux-commands/</url>
    
    <content type="html"><![CDATA[<p>Linux 常见命令：基本文件和目录操作、文件的创建和查阅、搜索命令、磁盘的压缩和解压缩、系统信息、进程管理、用户权限与用户管理、网络传输、安装卸载、开关机、窗口管理等。</p><a id="more"></a><h4 id="1-基本文件与目录操作"><a href="#1-基本文件与目录操作" class="headerlink" title="1. 基本文件与目录操作"></a>1. 基本文件与目录操作</h4><pre><code class="hljs shell">ls    # 列出文件   [-a] 列出全部文件(包括隐藏文件)      [-l]  列出长数据串，包含属性与权限等信息      # 查看当前文件下的目录个数  find ./ | wc -lcd dir  # 切换到指定目录 cd ..   # 切换到上一级目录          cd ~    # 切换到自己的主文件夹       cd -    # 切换到刚才目录pwd    # 显示当前目录mkdir [dirname]    # 创建新文件夹      rm [file]  #  删除文件或者目录     [-r]  删除目录    [-f] 强制cp [srcfile] [dstfile]   # 复制文件         [-r] 用于复制目录  mv [srcfile] [dstfile]   # 将文件移动到指定目录，不使用 [-r] 即可移动目录，同一目录则为重命名tree . # 显示目录树     -L   指定显示最大层数  sudo apt-get install tree</code></pre><h4 id="2-文件创建与查阅"><a href="#2-文件创建与查阅" class="headerlink" title="2. 文件创建与查阅"></a>2. 文件创建与查阅</h4><pre><code class="hljs shell">touch filename #  创建新文件   cat file    # 正向查看文件全部内容     tac file    # 反向查看文件全部内容    [-n] 带行号显示文件head -n file  # 查看文件前n行      tail -n file  # 查看file的后n行less file   # 按页查看文件[Page Down]    下翻一页  [Page Up]  上翻一页    /  向下查询   ?  向上查询   q 退出more file  # 按页查看文件 [Enter]   向下一行    [Space]向下一页    q退出 /查询    :f   显示文件名和当前行数</code></pre><h4 id="3-搜索命令"><a href="#3-搜索命令" class="headerlink" title="3. 搜索命令"></a>3. 搜索命令</h4><pre><code class="hljs shell">locate [filename]    # 系统全局范围内定位文件,  从/var.lib/mlocate数据库中查找文件，                     # 但是该数据库每天更新一次，所以可以首先使用sudo updatedb更新一下数据库，                     # 才能查询最近的文件        whereis [commands]    搜索命令位置(命令+帮助文档)   which  搜索命令位置(命令+别名)find  [search_file]  [search_condition]      搜索文件，应该避免大范围搜索<span class="hljs-meta">#</span><span class="bash"> 结合通配符使用： * 任意内容 ? 任意一个字符 []    任意一个[]内的内容 </span>grep [search_string]  [search_file]     -v 反向搜索  -i 忽略大小写</code></pre><h4 id="4-磁盘与压缩-解压缩命令-F"><a href="#4-磁盘与压缩-解压缩命令-F" class="headerlink" title="4. 磁盘与压缩/解压缩命令 [F]"></a>4. 磁盘与压缩/解压缩命令 [F]</h4><h5 id="1-查看磁盘空间"><a href="#1-查看磁盘空间" class="headerlink" title="(1) 查看磁盘空间"></a>(1) 查看磁盘空间</h5><pre><code class="hljs shell">du -h --max-depth=1 #　显示当前目录磁盘占用, --max-depth=1 显示级别df -h  # 检查linux服务器的文件系统的磁盘空间占用情况<span class="hljs-meta">#</span><span class="bash"> -h 以人们较易读的容量格式 (G/M) 显示</span></code></pre><h5 id="2-压缩与解压缩"><a href="#2-压缩与解压缩" class="headerlink" title="(2) 压缩与解压缩"></a>(2) 压缩与解压缩</h5><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> .zip</span>zip  压缩文件名.zip  源文件   # 压缩 zip 文件  [-r] 压缩目录unzip 压缩文件.zip   # 解压<span class="hljs-meta">#</span><span class="bash"> .tar.gz</span>tar -zcvf file.tar.gz 源目录  压缩  [-c] 打包  [-v] 显示过程 [-f] 指定打包后的文件名tar -zxvf file.tar.gz    解压<span class="hljs-meta">#</span><span class="bash"> .tar.bz2</span>tar -jcvf file.tar.gz 源目录   压缩  [-c] 打包  [-v] 显示过程 [-f] 指定打包后的文件名tar -jxcf file.tar.gz   解压</code></pre><h4 id="5-系统信息"><a href="#5-系统信息" class="headerlink" title="5. 系统信息"></a>5. 系统信息</h4><h5 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h5><pre><code class="hljs shell">date   #  显示当前时间和日期    cal   # 显示当月日历       uptime  # 显示系统开机时间</code></pre><h5 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h5><pre><code class="hljs shell">lsb_release [-a]    # 查看linux 版本   uname   [-a]  # 查看内核版本  last # 查看登录信息whoami   # 查看当前用户名lsof  # 列出进程调用或者打开的文件信息vmstat [刷新延时  刷新次数]  # 查看系统资源 w # 查看用户登录信息</code></pre><h5 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h5><pre><code class="hljs shell">cat /proc/cpuinfo     #  查看CPU 信息  cat /proc/meminfo     # 查看内存信息df   # 显示磁盘占用情况    [-h] 按照人们常见的 KB,MB,GB 格式显示du   # 显示目录空间占用情况    [-h] 按照人们常见的 KB,MB,GB 格式显示   [--max-depth]  指定显示目录深度nvidia-smi  #  显示nvidia 显卡的运行情况</code></pre><h4 id="6-进程管理"><a href="#6-进程管理" class="headerlink" title="6. 进程管理"></a>6. 进程管理</h4><pre><code class="hljs shell">ps    # 显示当前活动进程   [aux]  以BSD系统格式显示  [-ef] 以linux标准格式显示top    # 显示正在运行的进程  kill pid   # 杀死进程id  [-9]  强制杀死killall [进程名]  # 按照进程名杀死进程    pkill [进程名]  # 按照进程名杀死进程kill %[job num]  # 按照工作号杀死进程bg     # 列出已停止或者后台的进程       fg     # 将最近的作业带到前台   fg  n  # 将作业n带到前台 [command] &amp;  #  把命令放入后台，并在后台执行  jobs  # 显示后台进程[command];[Enter];[ctrl] + z  # 把命令放在后台，并暂停</code></pre><h4 id="7-文件权限与用户管理-F"><a href="#7-文件权限与用户管理-F" class="headerlink" title="7. 文件权限与用户管理  [F]"></a>7. 文件权限与用户管理  [F]</h4><h5 id="1-更改文件权限-："><a href="#1-更改文件权限-：" class="headerlink" title="(1) 更改文件权限 ："></a>(1) 更改文件权限 ：</h5><pre><code class="hljs shell">chmod [u|g|o][+|-|=][r|w|x]   file|dir    chmod octal file|dir<span class="hljs-meta">#</span><span class="bash"> u 用户    g  所属群组   o 其他      r=<span class="hljs-built_in">read</span>(4)     w=write(2)      x=execute(1)</span></code></pre><h5 id="2-用户和用户组管理"><a href="#2-用户和用户组管理" class="headerlink" title="(2) 用户和用户组管理"></a>(2) 用户和用户组管理</h5><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> user</span>useradd -m username   # 新建用户   [-m] 建立用户家目录passwd username       # 为新建用户设置密码su [username]         # 切换用户， 缺省则为 root 用户userdel -r username   # 删除用户  [-r] 删除用户家目录more /etc/passwd  # 查看所用用户及其权限</code></pre><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> groups</span>groups                           # 查看用户所属于的组usermod -G groupNmame username   # 将用户加入到组usermod -g groupName username    # 变更用户所属的根组more /etc/group  # 查看所有用户组及其权限</code></pre><pre><code class="hljs shell">chown username dirOrFile  # 更改文件的拥有者   -R 文件夹</code></pre><h5 id="3-环境变量"><a href="#3-环境变量" class="headerlink" title="(3) 环境变量"></a>(3) 环境变量</h5><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> bashrc与profile都用于保存用户的环境信息</span><span class="hljs-meta">#</span><span class="bash"> profile只能在登入的时候执行一次；</span><span class="hljs-meta">#</span><span class="bash"> bashrc 在每次执行 <span class="hljs-built_in">source</span> 时都会使用它一次</span>source ~/.bashrc</code></pre><h4 id="8-网络传输-F"><a href="#8-网络传输-F" class="headerlink" title="8. 网络传输 [F]"></a>8. 网络传输 [F]</h4><pre><code class="hljs shell">netstat         # 查看网络状态 -t TCP 端口  -u UDP 协议端口   -l 在监听状态  -a 所有端口lsof -i:[Port]  # 列出端口占用情况ipconfig        # 查看与配置网络状态route -n        # 查看路由状态traceroute IP    # 探测前往IP的路由路径ssh [-P port] user@hostname    # 以user用户身份连接到 hostname, 端口为 portwget file  # 下载file          -c 表示断点续传  -o 指定日志文件scp  -r  src/path   dst/path     #  下载和上传文件或目录   -P 端口host domain # domain -&gt; IPhost IP # IP -&gt; domainping host    #   探测指定IP或者域名的网络状况   -c 指定次数</code></pre><h4 id="9-安装卸载"><a href="#9-安装卸载" class="headerlink" title="9. 安装卸载"></a>9. 安装卸载</h4><h5 id="源代码安装"><a href="#源代码安装" class="headerlink" title="源代码安装"></a>源代码安装</h5><pre><code class="hljs shell">./configure # 软件配置和检查make # 编译make install   # 安装</code></pre><h5 id="二进制包安装-：-apt-get-ubuntu-deb-package"><a href="#二进制包安装-：-apt-get-ubuntu-deb-package" class="headerlink" title="二进制包安装 ： apt-get (ubuntu - deb package)"></a>二进制包安装 ： apt-get (ubuntu - deb package)</h5><pre><code class="hljs shell">apt-get install [package_name]      使用 apt-get安装包apt-get remove [package_name]    使用 apt-get卸载包</code></pre><h5 id="秘钥生成"><a href="#秘钥生成" class="headerlink" title="秘钥生成"></a>秘钥生成</h5><pre><code class="hljs shell">ssh-keygen -f key_name   -C &quot;description&quot;</code></pre><h4 id="11-常见的开关机命令"><a href="#11-常见的开关机命令" class="headerlink" title="11. 常见的开关机命令"></a>11. 常见的开关机命令</h4><h5 id="关机命令"><a href="#关机命令" class="headerlink" title="关机命令"></a>关机命令</h5><pre><code class="hljs shell">shutdown -h now   # 关机（保存当前正在运行的程序，相对安全）✨<span class="hljs-meta">#</span><span class="bash"> 其它： </span>halt         poweroff        init 0</code></pre><h5 id="重启命令"><a href="#重启命令" class="headerlink" title="重启命令"></a>重启命令</h5><pre><code class="hljs shell">shutdown -h now      # 重启 (保存当前正在运行的程序，相对安全)  ✨rebootinit 6</code></pre><h5 id="退出登录："><a href="#退出登录：" class="headerlink" title="退出登录："></a>退出登录：</h5><pre><code class="hljs shell">logout  # 建议每次离开服务器的时候退出登录 ✨</code></pre><h4 id="12-窗口管理命令"><a href="#12-窗口管理命令" class="headerlink" title="12.  窗口管理命令"></a>12.  窗口管理命令</h4><h5 id="标签管理"><a href="#标签管理" class="headerlink" title="标签管理"></a>标签管理</h5><pre><code class="hljs shell">[Ctrl] + [Shift]  + T   #  新建一个ternimal 标签 [Ctrl] + [Shift] + W    #  关闭 terminal 标签 Ctrl + PD / Ctrl + PU   #  切换 terminal 标签页 Alt+n   #   切换到标签页n</code></pre><h5 id="窗口管理"><a href="#窗口管理" class="headerlink" title="窗口管理"></a>窗口管理</h5><pre><code class="hljs shell">Ctrl + Shift + N    # 新建terminal窗口Ctrl + shift + Q     # 关闭 terminal 窗口  Alt + Tab    # 在窗口之间切换F11    # 窗口全屏(exit 退出)</code></pre><h4 id="13-其它"><a href="#13-其它" class="headerlink" title="13. 其它"></a>13. 其它</h4><h5 id="1-常见的热键"><a href="#1-常见的热键" class="headerlink" title="(1) 常见的热键"></a>(1) 常见的热键</h5><pre><code class="hljs shell">[Ctrl] + c  # 停止当前命令     [Ctrl] + d  # 注销当前会话     [Ctrl]+z   # 结束交互  [↑]         # 重复上一条命令         [Tab]       # 命令补齐/文件补齐</code></pre><h5 id="2-帮助命令："><a href="#2-帮助命令：" class="headerlink" title="(2) 帮助命令："></a>(2) 帮助命令：</h5><pre><code class="hljs shell">man [cmd]  # 查询命令command的说明文档   [n]  指定分类  -k 关键字[command] --help info [cmd]whatis [cmd] # 简要说明命令的作用which [cmd] # 查看程序的binary文件所在路径whereis [cmd] # 查看程序的搜索路径sudo ldconfigsource history  # 查看历史记录</code></pre><h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 重定向</span><span class="hljs-meta">&gt;</span><span class="bash">   <span class="hljs-comment"># 标准输出重定向(覆盖)  </span></span><span class="hljs-meta">2&gt;</span><span class="bash">  <span class="hljs-comment"># 标准错误输出重定向(覆盖)   </span></span><span class="hljs-meta">&gt;</span><span class="bash">&gt;  <span class="hljs-comment"># 标准输出重定向(追加) </span></span><span class="hljs-meta">2&gt;</span><span class="bash">&gt; <span class="hljs-comment"># 标准错误输出重定向(追加) </span></span>[command] &gt;&gt; [file1] 2&gt;&gt; [file2] # 将正确输出追加到file1，错误输出追加到file2<span class="hljs-meta">#</span><span class="bash"> 多命令顺序执行:     </span>;  # 无关联顺序执行   ;        与  &amp;&amp;        或  ||&amp;&amp; # 与||  # 或|   # 将命令1的正确输出作为命令2 的输入</code></pre><p>通用的参数</p><pre><code class="hljs shell">-a  # 所有 all    -l  # 长格式 long-r  # 递归  recursive-h  # 人类可读 human-t  # 类型 type</code></pre><p>参考资料：</p><ol><li><p><a href="https://fosswire.com/post/2007/08/unixlinux-command-cheat-sheet/">Linux Command cheatsheet</a></p></li><li><p><a href="http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html">http://linuxtools-rst.readthedocs.io/zh_CN/latest/tool/index.html</a></p></li><li><p><a href="https://github.com/chassing/linux-sysadmin-interview-questions">https://github.com/chassing/linux-sysadmin-interview-questions</a></p></li><li><p><a href="http://www.imooc.com/course/programdetail/pid/45">http://www.imooc.com/course/programdetail/pid/45</a></p></li><li><p><a href="http://billie66.github.io/TLCL/book/">http://billie66.github.io/TLCL/book/</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>git</title>
    <link href="/2018/06/01/Git-usage/"/>
    <url>/2018/06/01/Git-usage/</url>
    
    <content type="html"><![CDATA[<p>Git 基本用法</p><a id="more"></a><h3 id="1-安装和配置"><a href="#1-安装和配置" class="headerlink" title="1. 安装和配置"></a>1. 安装和配置</h3><pre><code class="hljs shell">sudo apt-get install git  # 安装 git</code></pre><pre><code class="hljs shell">git config --global user.name &quot;Your Name&quot; # 设置用户名git config --global user.email &quot;email@example.com&quot;  # 设置 email<span class="hljs-meta">#</span><span class="bash">  --global 表示系统用户级别，保存于  ~/.gitconfig   </span><span class="hljs-meta">#</span><span class="bash">  缺省则为项目级别/仓库级别， 保存于当前目录下的　.git/config</span></code></pre><pre><code class="hljs shell">ssh-keygen -t rsa -b 4096 -C &quot;your_email@domain.com&quot; <span class="hljs-meta">#</span><span class="bash"> 生成秘钥对， 公钥放git, 私钥放本地(一般放置在 ~/.ssh)</span></code></pre><h3 id="2-基本用法"><a href="#2-基本用法" class="headerlink" title="2. 基本用法"></a>2. 基本用法</h3><p><img src="/2018/06/01/Git-usage/git1.jpg" alt></p><p>基本的概念：</p><p><strong>HEAD</strong>: 在 Git 中，HEAD指针是一个指向你正在工作中的本地分支的指针。</p><p><strong>master</strong>：分支并不是一个特殊分支。 它就跟其它分支完全没有区别。 之所以几乎每一个仓库都有 master 分支，是因为 git init 命令默认创建它，并且大多数人都懒得去改动它。<br><strong>origin</strong>：是当你运行 git clone 时默认的远程仓库名字。</p><p><strong>Workspace</strong>：工作区                                               <strong>Index / Stage</strong>：暂存区<br><strong>Repository</strong>：仓库区（或本地仓库）                    <strong>Remote</strong>：远程仓库</p><pre><code class="hljs shell">git init  # 当前目录下会自动生成一个.git的目录，用来跟踪管理版本库</code></pre><pre><code class="hljs shell">git add &lt;filename&gt; # 添加文件git rm &lt;filename&gt;  # 删除文件   -r 删除文件夹git commit -m &quot;wrote a commit msg&quot;  #　从暂存区提交到本地仓库git rm --cached &lt;filename&gt;  # 舍弃暂存区内容git push origin master #　从本地仓库推送到远程仓库</code></pre><pre><code class="hljs shell">git clone /path/to/repository  # 创建一个远程仓库的本地克隆版本git clone usename@host:/path/to/repository # 远程服务器上的仓库git checkout -- &lt;filename&gt;  # 替换本地改动，　将仓库中的文件替换掉工作目录中的文件git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 　# 取回远程主机某个分支的更新，再与本地的指定分支合并</code></pre><pre><code class="hljs shell">git status  # 显示工作目录和暂存区的状态（显示所在分支、工作区和暂存区的状态）</code></pre><h3 id="3-版本回退和前进"><a href="#3-版本回退和前进" class="headerlink" title="3. 版本回退和前进"></a>3. 版本回退和前进</h3><pre><code class="hljs shell">git log # 查看提交历史(包括　ID, author, data等信息)  ＃　--pretty=oneline  一条日志只显示一行    --online 更加简洁的方式显示git reflog # 显示版本移动步数 HEAD@&#123;移动到当前版本需要的步数&#125;</code></pre><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 版本回退与前进</span>git reset --hard Index_value # 基于索引值 进行版本回退和前进<span class="hljs-meta">#</span><span class="bash"> --soft 仅仅在本地库移动 HEAD 指针  　　</span><span class="hljs-meta">#</span><span class="bash"> --mixed 在本地库移动 HEAD 指针， 并重置暂存区</span><span class="hljs-meta">#</span><span class="bash"> --hard 在本地库移动HEAD 指针，并重置暂存区和工作区</span>git reset --hard HEAD # 舍弃工作区和暂存区的修改，直接用本地库替换</code></pre><pre><code class="hljs shell">git diff filename # 默认比较的是工作区和暂存区git diff [HEAD] filename # 比较工作区和本地库[HEAD]，可以通过修改[HEAD]与历史记录进行比较</code></pre><h3 id="4-分支管理"><a href="#4-分支管理" class="headerlink" title="4. 分支管理"></a>4. 分支管理</h3><p><img src="/2018/06/01/Git-usage/gitflow.png" alt></p><p>其中涉及到的主要分支类型有：</p><ul><li><p><strong>master分支</strong>，即主分支。任何项目都必须有个这个分支。<strong>对项目进行tag或发布版本等操作，都必须在该分支上进行</strong>。</p></li><li><p><strong>develop分支</strong>，即开发分支，<strong>从master分支上检出</strong>。<strong>团队成员一般不会直接更改该分支，而是分别从该分支检出自己的feature分支，开发完成后将feature分支上的改动merge回develop分支</strong>。<strong>同时release分支由此分支检出</strong>。</p><pre><code class="hljs shell">git branch develop   # 从当前分支上新建develop分支git checkout develop    # 检出develop分支<span class="hljs-meta">#</span><span class="bash"> ... 此处可进行功能开发，并add和commit到develop分支</span>git push origin develop    # 推送develop分支到远端的origin</code></pre></li><li><p><strong>release分支</strong>，即发布分支，<strong>从develop分支上检出,该分支用作发版前的测试，可进行简单的bug修复</strong>。如果bug修复比较复杂，可merge回develop分支后由其他分支进行bug修复。此分支测试完成后，需要同时merge到master和develop分支上。</p></li><li><p><strong>feature分支</strong>，即功能分支，<strong>从develop分支上检出。团队成员中每个人都维护一个自己的feature分支，并进行开发工作，开发完成后将此分支merge回develop分支</strong>。此分支一般用来开发新功能或进行项目维护等。</p><pre><code class="hljs shell">git clone /path/to/repositorygit checkout develop　# 检出 develop分支git checkout -b feature-hu develop    # 从develop分支新建并检出feature分支... # 这里可以进行一些功能开发，并不断的add和commitgit checkout develop    # 切换回develop分支git pull origin develop    # 更新远端代码，看develop分支是否有更新（无更新）git checkout feature-hu    # 切换回feature分支git rebase develop    # 合并develop分支到feature分支，并解决冲突（无冲突）git checkout develop    # 切换回develop分支git merge --no-ff feature-hu    # 合并feature分支到develop分支git push origin develop   # 推送develop分支到远端</code></pre></li><li><p><strong>fix分支</strong>，即补丁分支，<strong>由develop分支检出，用作bug修复</strong>，bug修复完成需merge回develop分支，并将其删除。所以该分支属于临时性分支。</p></li><li><p><strong>hotfix分支</strong>，即热补丁分支。和fix分支的区别在于，<strong>该分支由master分支检出，进行线上版本的bug修复</strong>，修复完成后merge回master分支，并merge到develop分支上，merge完成后也可以将其删除，也属于临时性分支。</p><pre><code class="hljs shell">git checkout master    # 切换回master分支git checkout -b hotfix master    # 新建hotfix分支，并切换到该分支......                 # 做一些bug修复工作git checkout master    # 切换回master分支git merge --no-ff hotfix    # 合并hotfix分支，此时bug已被修复（无冲突）git tag v0.2.1    # 新建tag v0.2git push origin master    # 推送master分支代码到远端git push origin --tags    # 推送tag到远端</code></pre></li></ul><p>常见分支管理命令小结：</p><pre><code class="hljs shell">git branch -v  # 查看分支git branch &lt;branch_name&gt;   # 从当前分支新建一个分支git checkout &lt;branch_name&gt;   # 切换到指定分支git checkout -b &lt;branch_name&gt;  # 新建分支并切换到该分支 <span class="hljs-meta">#</span><span class="bash"> git checkout -b = git branch + git checkout</span>git checkout -d &lt;branch_name&gt; # 删除指定分支git push &lt;origin&gt; &lt;branch_name&gt; # 推送某个分支到远程仓库</code></pre><pre><code class="hljs nginx"><span class="hljs-attribute">git</span> merge --<span class="hljs-literal">no</span>-ff &lt;branch_name&gt; <span class="hljs-comment"># 将指定分支合并到当前分支</span>git rebase   <span class="hljs-comment"># </span></code></pre><pre><code class="hljs shell">git tag v0.2 # 为当前分支打 taggit push origin --tags # 将tag推送到远程仓库</code></pre><p><strong>如何解决冲突</strong></p><pre><code class="hljs vala"><span class="hljs-meta"># 解决冲突</span><span class="hljs-meta"># step 1: 手动修改冲突文件</span><span class="hljs-meta"># step 2： git add filename</span><span class="hljs-meta"># step 3: git commit -m &quot;commit message&quot;</span></code></pre><h3 id="5-远程操作"><a href="#5-远程操作" class="headerlink" title="5. 远程操作"></a>5. 远程操作</h3><p><img src="/2018/06/01/Git-usage/git5.png" alt></p><h5 id="团队内部协作："><a href="#团队内部协作：" class="headerlink" title="团队内部协作："></a>团队内部协作：</h5><pre><code class="hljs shell">git remote add origin https://xxxx.xxxx.xxxx.xxxx  # 指定远程库的别名git push -u 远程库名称 本地库名称git clone https://xxxx.xxxx.xxxx.xxxx   # clone 到本地库git fetch [远程地址别名][远程分支名]  #git merge [远程地址别名/远程分支名] git pull <span class="hljs-meta">#</span><span class="bash"> git fetch是将远程主机的最新内容拉到本地，用户在检查了以后决定是否合并到工作本机分支中。</span><span class="hljs-meta">#</span><span class="bash"> 而 git pull 则是将远程主机的最新内容拉下来后直接合并，</span><span class="hljs-meta">#</span><span class="bash"> 即：git pull = git fetch + git merge</span></code></pre><h5 id="跨团队协作："><a href="#跨团队协作：" class="headerlink" title="跨团队协作："></a>跨团队协作：</h5><p>需要在代码托管中心完成<code>fork</code>、<code>pull request</code>、 <code>审核</code>、<code>merge</code> 等操作</p><p><img src="/2018/06/01/Git-usage/git6.png" alt></p><h3 id="6-安装-GitLab"><a href="#6-安装-GitLab" class="headerlink" title="6. 安装 GitLab"></a>6. 安装 GitLab</h3><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 安装</span><span class="hljs-meta">$</span><span class="bash"> curl -sS http://packages.gitlab.com.cn/install/gitlab-ce/script.deb.sh | sudo bash</span><span class="hljs-meta">$</span><span class="bash"> sudo apt-get install gitlab-ce</span><span class="hljs-meta">#</span><span class="bash"> 配置</span><span class="hljs-meta">$</span><span class="bash"> gitlab-ctl reconfigure </span><span class="hljs-meta">#</span><span class="bash"> 启动</span><span class="hljs-meta">$</span><span class="bash"> gitlab-ctl start </span><span class="hljs-meta">#</span><span class="bash"> 在浏览器输入对应的IP地址即可访问gitlab后台，可能需要关闭防火墙</span><span class="hljs-meta">#</span><span class="bash"> （1）对root用户设置密码</span><span class="hljs-meta">#</span><span class="bash"> （2）登陆：用户名默认为root  </span><span class="hljs-meta">#</span><span class="bash"> （3）在后台进行添加用户等操作、设置密码等操作</span></code></pre><h3 id="7-其他"><a href="#7-其他" class="headerlink" title="7. 其他"></a>7. 其他</h3><p>（1） 如何设置不被追踪的文件<br>     有些文件是不想被追踪的， 可以修改  <code>.git/info/exclude</code> 文件， 以 # 开头，添加规则即可。</p><p>（2）server certificate verification failed. CAfile:/etc/ssl/certs/ca-certificates.crt CRLfile: none</p><pre><code class="hljs shell">export GIT_SSL_NO_VERIFY=1</code></pre><h3 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a>8. 参考资料</h3><ul><li><p>git 简明指南  <a href="https://rogerdudler.github.io/git-guide/index.zh.html">https://rogerdudler.github.io/git-guide/index.zh.html</a></p></li><li><p>git-scm-zh: <a href="https://git-scm.com/book/zh/v2">https://git-scm.com/book/zh/v2</a></p></li><li>常见　UI 界面: <a href="https://www.sourcetreeapp.com/">SourceTree</a>      <a href="https://tortoisegit.org/">tortoisegit</a>     <a href="https://www.git-tower.com/mac">Tower</a></li><li>gitflow <a href="https://nvie.com/posts/a-successful-git-branching-model/">https://nvie.com/posts/a-successful-git-branching-model/</a></li><li><p>gitflow 备忘清单 <a href="https://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html">https://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html</a></p></li><li><p>互动式学习git的网站：　<a href="https://learngitbranching.js.org/">https://learngitbranching.js.org/</a></p></li><li>图解git:  <a href="https://my.oschina.net/xdev/blog/114383">https://my.oschina.net/xdev/blog/114383</a></li><li>git magic: <a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/intl/zh_cn/index.html">http://www-cs-students.stanford.edu/~blynn/gitmagic/intl/zh_cn/index.html</a></li><li>github help: <a href="https://help.github.com/en">https://help.github.com/en</a></li><li>本地搭建Git： <a href="https://about.gitlab.com/">GitLab</a> 和　<a href="https://github.com/gogs/gogs">dashboard</a></li><li><a href="https://zhuanlan.zhihu.com/p/23478654">图文详解如何利用Git+Github进行团队协作开发</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Facenet细节剖析</title>
    <link href="/2018/04/13/Facenet/"/>
    <url>/2018/04/13/Facenet/</url>
    
    <content type="html"><![CDATA[<p>paper facenet &amp; mobilefacenet 实现细节剖析</p><a id="more"></a><h3 id="人脸识别项目-细节剖析"><a href="#人脸识别项目-细节剖析" class="headerlink" title="人脸识别项目 细节剖析"></a>人脸识别项目 细节剖析</h3><h5 id="1-图片输入的大小是多少？最后的-embedding-是多少？-为什么？"><a href="#1-图片输入的大小是多少？最后的-embedding-是多少？-为什么？" class="headerlink" title="1. 图片输入的大小是多少？最后的 embedding 是多少？ 为什么？"></a>1. 图片输入的大小是多少？最后的 embedding 是多少？ 为什么？</h5><p>图片输入大小设置为 160x160。why？ 随着图片分辨率的增大，验证集的准确率会上升，但是对应的运算量也会显著上升。160 是一个相对合适的分辨率大小。</p><p>(facenet 原论文尝试了 40x40, 80x80, 112x112, 160x160, 256x256)</p><p>embedding 的大小为 128， 实验测得，当超过 128 时候，验证集的准确率已经没有上升，反而有所下降。(64 -&gt; 128 -&gt; 256 -&gt; 512)。why？ 128D向量拥有足够的容量hold 住大规模的人脸数据集(百万人脸级别)， 并且相对紧凑。</p><h5 id="2-基本原理"><a href="#2-基本原理" class="headerlink" title="2. 基本原理"></a>2. 基本原理</h5><p>选取三元组(anchor, pos, neg)，其中，x和p是同一类，x和n是不同类。那么学习的过程就是学到一种表示，对于尽可能多的三元组，使得anchor和pos的距离，小于anchor和neg的距离</p><h5 id="3-主干网络："><a href="#3-主干网络：" class="headerlink" title="3. 主干网络："></a>3. 主干网络：</h5><p>原始论文中使用的是 googlenet、github上的facenet使用的 inception resnet v1、mobilefacenet 使用的是 mobilenet v2</p><h6 id="1-GoogleNet"><a href="#1-GoogleNet" class="headerlink" title="(1) GoogleNet"></a>(1) GoogleNet</h6><p>原论文中使用的是 GoogleNet， Googlenet 的主要涉及在于以下几点：</p><ul><li>Inception Module中包含3种不同尺寸的卷积和1个最大池化，增加了网络对不同尺度的适应性。</li></ul><p>第一个分支对输入进行 1x1卷积，<strong>1x1卷积可以跨通道组织信息，提高网络的表达能力，同时可以对输出通道升维和降维</strong>。</p><p>第二个分支先使用了 1x1 卷积，然后连接 3x3 卷积，相当于进行两次特征变换。</p><p>第三个分支和第二个分支类似，先是使用了1x1 的卷积，然后连接 5x5 的卷积。</p><p>最后一个分支则是3x3 最大池化后直接使用1x1卷积。</p><p>Inception Module 的4个分支在最后通过一个聚合操作合并。</p><ul><li>去除了最后的全连接层，用全局平均池化层来取代它。</li></ul><h6 id="2-Mobilenet-v2"><a href="#2-Mobilenet-v2" class="headerlink" title="(2) Mobilenet v2"></a>(2) Mobilenet v2</h6><p>另一篇论文则使用了 mobilenetv2 (输入变成112) 结构作为主要网络：主要修改点如下所示：</p><ul><li><p>Inception 结构替换为 mobilenet v2 结构：</p><p>mobilenet 的结构要点：（1）skip-connection 跳层连接 (2) 将传统卷积分解为逐通道卷积(先进行逐通道卷积但是通道之间不相加，然后使用1x1 卷积对通道进行整合), 并在前面加一个1x1 的卷积进行升维。(3) 将最后的 ReLU 替换为 Linear(非线性在高维有溢出，但是在低维不如线性好) </p></li><li><p>用全局可分离卷积替代原有的全局池化层。why? 特征图上的中心点的感受野和边角的感受野是不同的，中心点的感受野包括了完整的图片，边角点的感知域却只有部分的图片， 不应该视为同等重要。这样会导致性能的下降。</p></li><li><p>使用 arcface 替换掉 triplet 损失函数。 </p></li><li><p>小细节：通道扩张倍数变小(facenet 是 1024， mobilenets 则是 512)；使用prelu代替relu；使用batch Normalization。</p></li></ul><h5 id="4-预处理工作："><a href="#4-预处理工作：" class="headerlink" title="4. 预处理工作："></a>4. 预处理工作：</h5><p>(1) 数据集的整理和清洗(DDM 智能猫眼[大约10W张，6千人的样子-&gt; 猫眼300台，每台20人]的真实数据 和 CASIA 人脸数据)</p><ul><li>类间过滤： 清洗掉距离与类中心小于0.5 的负样本(对一个类别，先计算类中心，然后用所有样本，与其进行比较)</li><li><p>图片的过滤：将经过人脸检测(MTCNN/FaceBoxes) 返回的人脸置信度 小于 0.75 的图片直接过滤掉</p></li><li><p>按图像数量阈值进行数据划分(人脸低于10张的过滤掉)</p></li><li>类间距离问题：有些可能是名字重合的，找出来合并在一起</li></ul><p>(2) 人脸识别前的处理：</p><ul><li><p>人脸对齐？可以有也可以没有，影响不是很大 how?( 通过仿射变换将原本的五个landmark缩放旋转到固定的位置)</p><pre><code class="hljs python"><span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> transform <span class="hljs-keyword">as</span> trans<span class="hljs-comment"># src</span>src = np.array([  [<span class="hljs-number">30.2946</span>, <span class="hljs-number">51.6963</span>],  [<span class="hljs-number">65.5318</span>, <span class="hljs-number">51.5014</span>],  [<span class="hljs-number">48.0252</span>, <span class="hljs-number">71.7366</span>],  [<span class="hljs-number">33.5493</span>, <span class="hljs-number">92.3655</span>],  [<span class="hljs-number">62.7299</span>, <span class="hljs-number">92.2041</span>] ], dtype=np.float32 )<span class="hljs-keyword">if</span> image_size[<span class="hljs-number">1</span>]==<span class="hljs-number">112</span>:  src[:,<span class="hljs-number">0</span>] += <span class="hljs-number">8.0</span>  <span class="hljs-comment"># dst</span>dst = landmark.astype(np.float32)tform = trans.SimilarityTransform()tform.estimate(dst, src)M = tform.params[<span class="hljs-number">0</span>:<span class="hljs-number">2</span>,:]<span class="hljs-comment"># warpAffine</span>warped = cv2.warpAffine(img, M, (image_size[<span class="hljs-number">1</span>],image_size[<span class="hljs-number">0</span>]), borderValue = <span class="hljs-number">0.0</span>)</code></pre></li><li><p>模糊过滤？（将检测出来的人脸使用拉普拉斯做卷积运算，然后计算方差， 将方差小于 400 过滤掉)</p></li><li>人脸置信度，这里设置置信度0.8，人脸置信度太小可能不是人脸，直接过滤掉。</li><li>对图片进行标准化处理：(x-均值)/标准差</li></ul><h5 id="5-后处理-如何进行分类？"><a href="#5-后处理-如何进行分类？" class="headerlink" title="5. 后处理(如何进行分类？)"></a>5. 后处理(如何进行分类？)</h5><p>facenet 使用欧式距离来度量是否是一个人。使用十折交叉验证，我们设定阈值为 1.24。</p><p>mobilenet 使用相似性余弦度量：阈值设定为 0.7。</p><p><img src="/2018/04/13/Facenet/3.png" alt="3"></p><h5 id="6-参数调整：-没有怎么调整参数，-使用默认参数，替换掉了数据集而已"><a href="#6-参数调整：-没有怎么调整参数，-使用默认参数，替换掉了数据集而已" class="headerlink" title="6. 参数调整：(没有怎么调整参数， 使用默认参数，替换掉了数据集而已)"></a>6. 参数调整：(没有怎么调整参数， 使用默认参数，替换掉了数据集而已)</h5><ul><li><p>优化器：<code>RMSProp</code></p><pre><code class="hljs apache"><span class="hljs-attribute">tf</span>.train.RMSPropOptimizer(learning_rate, decay=<span class="hljs-number">0</span>.<span class="hljs-number">9</span>, momentum=<span class="hljs-number">0</span>.<span class="hljs-number">9</span>, epsilon=<span class="hljs-number">1</span>.<span class="hljs-number">0</span>)</code></pre></li><li><p>初始学习率：0.1</p></li><li><p>学习率下降方式：exponential_decay</p><pre><code class="hljs yaml"><span class="hljs-comment"># Learning rate schedule: Maps an epoch number to a learning rate</span><span class="hljs-attr">0:</span>  <span class="hljs-number">0.1</span>  <span class="hljs-comment"># 初始学习率</span><span class="hljs-attr">300:</span> <span class="hljs-number">0.01</span><span class="hljs-attr">400:</span> <span class="hljs-number">0.001</span><span class="hljs-attr">1000:</span> <span class="hljs-number">0.0001</span></code></pre></li><li><p>margin α=0.2</p></li></ul><h5 id="7-why-facenet-？"><a href="#7-why-facenet-？" class="headerlink" title="7. why facenet ？"></a>7. why facenet ？</h5><ul><li><p>softmax不直接，(三元组直接优化距离)，因⽽而性能也不不好。 softmax产⽣生的特征表示向量量都很⼤大，⼀一般超过1000维。 </p></li><li><p>faceNet并没有像DeepFace和DeepID那样需要对⻬。 </p></li><li><p>faceNet得到最终表示后不不⽤用像DeepID那样需要再训练模型进⾏分类，直接计算距离就好了了，简单⽽而有效。 </p></li></ul><h5 id="8-模型的大小："><a href="#8-模型的大小：" class="headerlink" title="8. 模型的大小："></a>8. 模型的大小：</h5><p>线上模型： model_size:  (Inception resnet v2： 186M)      Param：7.5M   </p><p>线下模型：(手机端) model_size:  4.1M       param:  0.99M       </p><h5 id="8-训练技巧"><a href="#8-训练技巧" class="headerlink" title="8. 训练技巧"></a>8. 训练技巧</h5><ul><li>三元组的选择<pre><code>     在一个minibatch中，我们根据当时的 embedding，选择一次三元组，在这些三元组上计算triplet-loss,  再对embedding进行更新，不断重复，直到收敛或训练到指定迭代次数。</code></pre></li></ul>]]></content>
    
    
    <categories>
      
      <category>基本方向</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hexo_blog_issue</title>
    <link href="/2018/03/04/Hexo-blog-issue/"/>
    <url>/2018/03/04/Hexo-blog-issue/</url>
    
    <content type="html"><![CDATA[<p>Hexo 部署、配置、修改等常见问题记录</p><a id="more"></a><h4 id="1-写文章、发布文章"><a href="#1-写文章、发布文章" class="headerlink" title="1. 写文章、发布文章"></a>1. 写文章、发布文章</h4><pre><code class="hljs shell">hexo new post article_title    # 新建一篇文章<span class="hljs-meta">#</span><span class="bash"> 编辑 [root]\<span class="hljs-built_in">source</span>\_posts 下的markdown文件</span>hexo g   # 生成静态网页hexo s   # 本地预览效果hexo d   # 上传到github</code></pre><p>文章开头的配置如下所示</p><pre><code class="hljs markdown">title: 标题catalog: 是否显示段落目录date: 文章日期subtitle: 子标题header-img: 顶部背景图片top: 是否置顶tags: 标签categories: 分类</code></pre><h4 id="2-添加图片"><a href="#2-添加图片" class="headerlink" title="2.  添加图片"></a>2.  添加图片</h4><ol><li><p>修改配置文件，把主页配置文件 <strong>_config.yml</strong> 里的 <strong>post_asset_folder</strong>:这个选项设置为<strong>true</strong>。</p></li><li><p>安装可以上传本地图片的插件， <code>npm install hexo-asset-image --save</code>。此时运行<code>hexo n &quot;xxxx&quot;</code>来生成md博文时，<strong>/source/_posts</strong> 文件夹内除了 <strong>xxxx.md</strong> 文件还有一个同名的文件夹。</p></li><li><p>将图片放在 <strong>xxxx</strong> 这个文件夹中，在xxxx.md中使用markdown的格式引入图片：</p><pre><code class="hljs markdown">![<span class="hljs-string">title</span>](<span class="hljs-link">xxxx/img_name.jpg</span>)</code></pre></li><li><p>修改 <code>/node_modules/hexo-asset-image/index.js</code> ， 替换为如下代码:</p><pre><code class="hljs js"><span class="hljs-meta">&#x27;use strict&#x27;</span>;<span class="hljs-keyword">var</span> cheerio = <span class="hljs-built_in">require</span>(<span class="hljs-string">&#x27;cheerio&#x27;</span>);<span class="hljs-comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">getPosition</span>(<span class="hljs-params">str, m, i</span>) </span>&#123;  <span class="hljs-keyword">return</span> str.split(m, i).join(m).length;&#125;<span class="hljs-keyword">var</span> version = <span class="hljs-built_in">String</span>(hexo.version).split(<span class="hljs-string">&#x27;.&#x27;</span>);hexo.extend.filter.register(<span class="hljs-string">&#x27;after_post_render&#x27;</span>, <span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">data</span>)</span>&#123;  <span class="hljs-keyword">var</span> config = hexo.config;  <span class="hljs-keyword">if</span>(config.post_asset_folder)&#123;    <span class="hljs-keyword">var</span> link = data.permalink;<span class="hljs-keyword">if</span>(version.length &gt; <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">Number</span>(version[<span class="hljs-number">0</span>]) == <span class="hljs-number">3</span>)   <span class="hljs-keyword">var</span> beginPos = getPosition(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>;<span class="hljs-keyword">else</span>   <span class="hljs-keyword">var</span> beginPos = getPosition(link, <span class="hljs-string">&#x27;/&#x27;</span>, <span class="hljs-number">3</span>) + <span class="hljs-number">1</span>;<span class="hljs-comment">// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span><span class="hljs-keyword">var</span> endPos = link.lastIndexOf(<span class="hljs-string">&#x27;/&#x27;</span>) + <span class="hljs-number">1</span>;    link = link.substring(beginPos, endPos);    <span class="hljs-keyword">var</span> toprocess = [<span class="hljs-string">&#x27;excerpt&#x27;</span>, <span class="hljs-string">&#x27;more&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>];    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">var</span> i = <span class="hljs-number">0</span>; i &lt; toprocess.length; i++)&#123;      <span class="hljs-keyword">var</span> key = toprocess[i];       <span class="hljs-keyword">var</span> $ = cheerio.load(data[key], &#123;        ignoreWhitespace: <span class="hljs-literal">false</span>,        xmlMode: <span class="hljs-literal">false</span>,        lowerCaseTags: <span class="hljs-literal">false</span>,        decodeEntities: <span class="hljs-literal">false</span>      &#125;);      $(<span class="hljs-string">&#x27;img&#x27;</span>).each(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)</span>&#123;<span class="hljs-keyword">if</span> ($(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>))&#123;<span class="hljs-comment">// For windows style path, we replace &#x27;\&#x27; to &#x27;/&#x27;.</span><span class="hljs-keyword">var</span> src = $(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>).replace(<span class="hljs-string">&#x27;\\&#x27;</span>, <span class="hljs-string">&#x27;/&#x27;</span>);<span class="hljs-keyword">if</span>(!<span class="hljs-regexp">/http[s]*.*|\/\/.*/</span>.test(src) &amp;&amp;   !<span class="hljs-regexp">/^\s*\//</span>.test(src)) &#123;  <span class="hljs-comment">// For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed.</span>  <span class="hljs-comment">// In addition, to support multi-level local directory.</span>  <span class="hljs-keyword">var</span> linkArray = link.split(<span class="hljs-string">&#x27;/&#x27;</span>).filter(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)</span>&#123;<span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span>;  &#125;);  <span class="hljs-keyword">var</span> srcArray = src.split(<span class="hljs-string">&#x27;/&#x27;</span>).filter(<span class="hljs-function"><span class="hljs-keyword">function</span>(<span class="hljs-params">elem</span>)</span>&#123;<span class="hljs-keyword">return</span> elem != <span class="hljs-string">&#x27;&#x27;</span> &amp;&amp; elem != <span class="hljs-string">&#x27;.&#x27;</span>;  &#125;);  <span class="hljs-keyword">if</span>(srcArray.length &gt; <span class="hljs-number">1</span>)srcArray.shift();  src = srcArray.join(<span class="hljs-string">&#x27;/&#x27;</span>);  $(<span class="hljs-built_in">this</span>).attr(<span class="hljs-string">&#x27;src&#x27;</span>, config.root + link + src);  <span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info(<span class="hljs-string">&quot;update link as:--&gt;&quot;</span>+config.root + link + src);&#125;&#125;<span class="hljs-keyword">else</span>&#123;<span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info(<span class="hljs-string">&quot;no src attr, skipped...&quot;</span>);<span class="hljs-built_in">console</span>.info&amp;&amp;<span class="hljs-built_in">console</span>.info($(<span class="hljs-built_in">this</span>));&#125;      &#125;);      data[key] = $.html();    &#125;  &#125;&#125;);</code></pre></li><li><p>检查 <code>_config.yml</code> 文件， 是否修改了对应的 URL：</p><pre><code class="hljs yaml"><span class="hljs-comment"># URL</span><span class="hljs-comment">## If your site is put in a subdirectory, set url as &#x27;http://example.com/child&#x27; and root as &#x27;/child/&#x27;</span><span class="hljs-attr">url:</span> <span class="hljs-string">https://polariszhao.github.io/</span>  <span class="hljs-comment"># 修改为对应的 URL</span></code></pre></li></ol><p><img src="/2018/03/04/Hexo-blog-issue/lena.bmp" alt="test_img"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>issue</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
