

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhichao zhao">
  <meta name="keywords" content="">
  <title>pytorch加速 - 假欢畅 又何妨 无人共享</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 60vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>假欢畅，又何妨，无人共享</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      <div class="container nopadding-md">
        <div class="py-5" id="board"
          >
          
          <div class="container">
            <div class="row">
              <div class="col-12 col-md-10 m-auto">
                

<div class="page-content">
  <p>Pytorch 加速方案</p>
<a id="more"></a>
<h3 id="1-数据"><a href="#1-数据" class="headerlink" title="1. 数据"></a>1. 数据</h3><h5 id="0-dataloader"><a href="#0-dataloader" class="headerlink" title="(0) dataloader"></a>(0) dataloader</h5><ul>
<li>num_workers与batch_size调到合适值，并非越大越快（注意后者也影响模型性能）(需要在实验中找到最快的取值)</li>
<li>eval/test时shuffle=False</li>
<li>内存够大的情况下，dataloader的<strong>pin_memory</strong>设为True。对特别小的数据集如 MNIST 设置 <code>pin_memory=False</code>  反而更快一些。</li>
</ul>
<h5 id="1-预处理提速"><a href="#1-预处理提速" class="headerlink" title="(1) 预处理提速"></a>(1) 预处理提速</h5><ul>
<li>尽量减少每次读取数据时的预处理操作，可以考虑把一些固定的操作，例如 resize ，事先处理好保存下来，训练的时候直接拿来用</li>
<li><p>Linux上将预处理搬到GPU上加速：</p>
</li>
<li><ul>
<li><strong>NVIDIA/DALI</strong> ：<a target="_blank" rel="noopener" href="https://github.com/NVIDIA/DALI">https://github.com/NVIDIA/DALI</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/tanglang96/DataLoaders_DALI">https://github.com/tanglang96/DataLoaders_DALI</a></li>
</ul>
</li>
<li><p>数据预取：prefetch_generator（<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/80695364">方法</a>）让读数据的worker能在运算时预读数据，而默认是数据清空时才读</p>
</li>
</ul>
<h5 id="2-IO-提速"><a href="#2-IO-提速" class="headerlink" title="(2) IO 提速"></a>(2) IO 提速</h5><ul>
<li><p>使用更快的图片处理：</p>
</li>
<li><ul>
<li><strong>opencv 一般要比 PIL 要快</strong></li>
<li>对于jpeg读取，可以尝试 <strong>jpeg4py</strong></li>
<li>存 <strong>bmp</strong> 图（降低解码时间）</li>
</ul>
</li>
<li><p><strong>小图拼起来存放（降低读取次数）：对于大规模的小文件读取，建议转成单独的文件，可以选择的格式可以考虑</strong>：TFRecord（Tensorflow）、recordIO(recordIO)、hdf5、 pth、n5、lmdb 等等（<a target="_blank" rel="noopener" href="https://github.com/Lyken17/Efficient-PyTorch#data-loader）">https://github.com/Lyken17/Efficient-PyTorch#data-loader）</a></p>
</li>
<li><ul>
<li><strong>TFRecord</strong>：<a target="_blank" rel="noopener" href="https://github.com/vahidk/tfrecord">https://github.com/vahidk/tfrecord</a></li>
<li>借助 <strong>lmdb 数据库格式</strong>：</li>
</ul>
</li>
<li><ul>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Fangyh09/Image2LMDB">https://github.com/Fangyh09/Image2LMDB</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/P_LarT/article/details/103208405">https://blog.csdn.net/P_LarT/article/details/103208405</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/lartpang/PySODToolBox/blob/master/ForBigDataset/ImageFolder2LMDB.py">https://github.com/lartpang/PySODToolBox/blob/master/ForBigDataset/ImageFolder2LMDB.py</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Lyken17/Efficient-PyTorch">https://github.com/Lyken17/Efficient-PyTorch</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="3-借助硬件"><a href="#3-借助硬件" class="headerlink" title="(3)　借助硬件"></a>(3)　借助硬件</h5><ul>
<li>借助内存：<strong>直接载到内存里面，或者把把内存映射成磁盘好了</strong></li>
<li>借助固态：把读取速度慢的机械硬盘换成 <strong>NVME 固态</strong>吧～</li>
</ul>
<h5 id="4-训练策略"><a href="#4-训练策略" class="headerlink" title="(4) 训练策略"></a>(4) 训练策略</h5><ul>
<li><p>在训练中使用<strong>低精度（FP16 甚至 INT8 、二值网络、三值网络）表示取代原有精度（FP32）表示</strong></p>
</li>
<li><ul>
<li>NVIDIA/Apex：</li>
</ul>
</li>
<li><ul>
<li><ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/100135729">https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/100135729</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/nvidia/apex">https://github.com/nvidia/apex</a></li>
</ul>
</li>
</ul>
</li>
<li><p>使用分布式训练　DDP 或者 horovod</p>
</li>
</ul>
<h5 id="5-代码层面"><a href="#5-代码层面" class="headerlink" title="(5) 代码层面"></a>(5) 代码层面</h5><ul>
<li><code>torch.backends.cudnn.benchmark = True</code></li>
<li>Do numpy-like operations on the GPU wherever you can</li>
<li>Free up memory using<code>del</code>     用<code>del</code>及时删除不用的中间变量，节约GPU存储。</li>
<li>Avoid unnecessary transfer of data from the GPU</li>
<li>Use pinned memory, and use non_blocking=False to parallelize data transfer and GPU number crunching</li>
</ul>
<h3 id="2-model"><a href="#2-model" class="headerlink" title="2. model"></a>2. model</h3><ol>
<li><p>用<strong>float16</strong>代替默认的float32运算（<a href="https://link.zhihu.com/?target=https%3A//github.com/huggingface/transformers/blob/dad3c7a485b7ffc6fd2766f349e6ee845ecc2eee/examples/run_classifier.py">方法参考</a>，搜索”fp16”可以看到需要修改之处，包括model、optimizer、backward、learning rate）</p>
</li>
<li><p><strong>优化器</strong>以及对应参数的选择，如learning rate，不过它对性能的影响似乎更重要【占坑】</p>
</li>
<li><p>少用循环，多用<strong>向量化</strong>操作</p>
</li>
<li><p>经典操作尽量用别人优化好的<strong>库</strong>，别自己写</p>
</li>
<li><p>数据很多时少用append，虽然使用很方便，不过它每次都会重新分配空间？所以数据很大的话，光一次append就要几秒（测过），可以先分配好整个容器大小，每次用索引去修改内容，这样一步只要0.0x秒</p>
</li>
<li><p>固定对模型影响不大的部分参数，还能节约显存，可以用 detach() 切断反向传播，注意若仅仅给变量设置 required_grad=False 还是会计算梯度的</p>
</li>
<li><p>eval/test 的时候，加上 model.eval() 和 torch.no_grad()，前者固定 batch-normalization 和 dropout 但是会影响性能，后者关闭 autograd</p>
</li>
<li><p>提高程序<strong>并行度</strong>，例如 我想 train 时对每个 epoch 都能 test 一下以追踪模型性能变化，但是 test 时间成本太高要一个小时，所以写了个 socket，设一个127.0.0.1 的端口，每次 train 完一个 epoch 就发个UDP过去，那个进程就可以自己 test，同时原进程可以继续 train 下一个 epoch（对 这是自己想的诡异方法hhh）</p>
</li>
<li><p>torch.backends.cudnn.benchmark设为True，可以让cudnn根据当前训练各项config寻找优化算法，但这本身需要时间，所以input size在训练时会频繁变化的话，建议设为False</p>
</li>
<li><p>使用<code>inplace</code>操作可节约 GPU 存储，如</p>
<pre><code class="hljs ini"><span class="hljs-attr">x</span> = torch.nn.functional.relu(x, inplace=<span class="hljs-literal">True</span>)</code></pre>
</li>
<li><p>减少CPU和GPU之间的数据传输。例如， 如果你想知道一个 epoch 中每个 mini-batch 的 loss 和准确率，先将它们累积在 GPU 中等一个 epoch 结束之后一起传输回 CPU 会比每个 mini-batch 都进行一次 GPU 到 CPU 的传输更快。</p>
</li>
<li><p>使用半精度浮点数<code>half()</code>会有一定的速度提升，具体效率依赖于GPU型号。需要小心数值精度过低带来的稳定性问题。时常使用 <code>assert tensor.size() == (N, D, H, W)</code>作为调试手段，确保张量维度和你设想中一致。</p>
</li>
<li><p>除了标记 y 外，尽量少使用一维张量，使用n*1的二维张量代替，可以避免一些意想不到的一维张量计算结果。</p>
</li>
<li><p>统计代码各部分耗时</p>
</li>
</ol>
<pre><code class="hljs python"><span class="hljs-keyword">with</span> torch.autograd.profiler.profile(enabled=<span class="hljs-literal">True</span>, use_cuda=<span class="hljs-literal">False</span>) <span class="hljs-keyword">as</span> profile:
    ...
    print(profile)</code></pre>
<p>或者在命令行运行：</p>
<pre><code class="hljs css"><span class="hljs-selector-tag">python</span> <span class="hljs-selector-tag">-m</span> <span class="hljs-selector-tag">torch</span><span class="hljs-selector-class">.utils</span><span class="hljs-selector-class">.bottleneck</span> <span class="hljs-selector-tag">main</span><span class="hljs-selector-class">.py</span></code></pre>

</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>









  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "pytorch加速&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>






















</body>
</html>
