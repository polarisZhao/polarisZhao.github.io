

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhichao zhao">
  <meta name="keywords" content="">
  <title>quantizing - 假欢畅 又何妨 无人共享</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>假欢畅，又何妨，无人共享</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-11-13 15:02" pubdate>
        November 13, 2020 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.4k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      30
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">quantizing</h1>
            
            <div class="markdown-body" id="post-body">
              <p>​        量化， 也被称为定点化、离散化，是指用低精度整数来近似表示浮点数(权重和偏置)的方法。 在量化之后，可以在特定的硬件平台上使用特定的指令集对其加速， 另外，由于存储位宽的减小，模型的体积也会显著减小。常见的量化方案可以分为二值量化、三值量化、低比特量化(介于2-8bit之间) 和 int8 量化。</p>
<h4 id="1-二值量化"><a href="#1-二值量化" class="headerlink" title="1. 二值量化"></a>1. 二值量化</h4><p><strong>Binary Weight</strong> (只对权重进行二值化)</p>
<p>🌟 [BinaryConnect] BinaryConnect: Training Deep Neural Networks with binary weights during propagations</p>
<p>🌟 [BWN]  Binary-Weights-Networks</p>
<p><strong>Binary Weight &amp; activation</strong> (对权重和激活都进行二值化)</p>
<p>🌟 [BNN] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1602.02830.pdf">Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1</a></p>
<p>🌟 [XNOR Net] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.05279.pdf">XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</a></p>
<p> [ABCNet] Towards Accurate Binary Convolutional Neural Network by Xiaofan Lin, Cong Zhao, and Wei Pan.</p>
<p> [Bi-Real Net] Enhancing the Performance of 1bit CNNs with Improved Representational Capacity and Advanced Training Algorithm</p>
<p> [HORQ]Performance Guaranteed Network Acceleration via High-Order Residual Quantization</p>
<h4 id="2-三值量化"><a href="#2-三值量化" class="headerlink" title="2. 三值量化"></a>2. 三值量化</h4><p>🌟 [TWN] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1605.04711.pdf">Ternary weight networks</a></p>
<p>[TNN] Ternary Neural Networks for Resource-Efficient AI Applications </p>
<p>[TTQ] Trained Ternary Quantization </p>
<h4 id="3-低比特量化-2bit-8bit"><a href="#3-低比特量化-2bit-8bit" class="headerlink" title="3. 低比特量化 2bit - 8bit"></a>3. 低比特量化 2bit - 8bit</h4><p>🌟 [DOREFA-NET] DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients</p>
<p>上述方案的对比</p>
<p><img src="/2020/11/13/quantizing/2.png" srcset="/img/loading.gif" style="zoom:50%;"></p>
<p>🌟  [ACIQ] </p>
<p>🌟  [AdaRound]   高通 4-bit 量化</p>
<h4 id="4-int8-量化"><a href="#4-int8-量化" class="headerlink" title="4. int8 量化"></a>4. int8 量化</h4><p>int8 方案按照量化的时机可以分为感知量化 (Quantization Aware Training, QAT) 和训练后量化 (Post Training Quantization，PTQ)。 在此的重点关注于训练后量化， 因为其不需要记性 fine-tune， 方便再工业界进行落地使用。</p>
<ul>
<li><p>感知量化， 是在训练过程中对量化进行建模以确定量化参数， 它能够保持较高精度。 该解决方案由 google 提出并将其应用于 tensorflow， 见于论文 Quantizing deep convolutional networks for efficient inference: A whitepaper。</p>
</li>
<li><p>对于训练后量化， 则是使用对训练生成的模型直接进行映射。该方法精度损失稍大但是不需要重新训练可以快速得到量化模型。常见的解决方案有四种：max-max、KL、admm、easyquant。 其中 KL 方案由 nvidia 提出，是现在主流的 int8 量化方案。在此我们列出国内开源的前向推导框架的量化实现情况:</p>
<p>|                    | max-max | KL   | admm | easy quant |<br>| ————————— | ———- | —— | —— | ————— |<br>| ncnn(Tencent)      | Y       | Y    |      | Y(第三方)  |<br>| TNN(Tencent)       | Y       | Y    |      |            |<br>| MNN(Alibaba)       | Y       |      | Y    |            |<br>| Paddle lite(Baidu) | Y       | Y    |      |            |</p>
</li>
</ul>
<h5 id="4-1-max-max"><a href="#4-1-max-max" class="headerlink" title="4.1 max-max"></a>4.1 max-max</h5><p>​        首先求出一个layer 的激活值范围， 将绝对值的最大值作为阈值， 把这个范围按照比例映射到 -127 到 128 的范围内, 如下左图所示。 其 fp32 和 int8 的转换公式为:</p>
<pre><code class="hljs lisp">FP32 Tensor (<span class="hljs-name">T</span>) = scale_factor(<span class="hljs-name">sf</span>) * <span class="hljs-number">8</span>-bit Tensor(<span class="hljs-name">t</span>) + FP32_bias (<span class="hljs-name">b</span>)</code></pre>
<p>  通过实验得知，bias值去掉对精度的影响不是很大，因此我们直接去掉, 所以该公式可以简化为:</p>
<pre><code class="hljs excel"><span class="hljs-built_in">T</span> = sf * <span class="hljs-built_in">t</span></code></pre>
<p>该方案存在一个问题： 不饱和， 即通常在正负上会有一些量化值未被利用， 且会产生较大的精度损失。</p>
<p><img src="/2020/11/13/quantizing/tensorrt_qua.png" srcset="/img/loading.gif" style="zoom:35%;"></p>
<p>！ 注意区分一下 min-max 和 max-max。 前者是将最大值和最小值映射到对应区间， 而后者是找到取最大值和最小值的绝对值。 tensorflow lite 的训练后量化过程是采用的 min-max 方式。</p>
<h5 id="4-2-KL"><a href="#4-2-KL" class="headerlink" title="4.2 KL"></a>4.2 KL</h5><p>​        针对非饱和映射精度损失的问题，TensorRT 提出了非饱和映射， 即选取一个阈值 T ，然后将 -|T|~|T| 之间的值映射到 -127 到 128 这个范围内。这样确定了阈值 T 之后，其实也能确定 scale，一个简单的线性公式是: <code>Scale = T/127</code>。 量化的核心就是找到这个阈值 T。 那么问题来了，T 应该取何值?  其基本流程如下:</p>
<p>​    (a) 选取不同的 T 阈值进行量化, 将 P(fp32) 映射到 Q(int8)。</p>
<p>​    (b) 将 Q(int8) 反量化到 P(fp32) 一样长度，得到分布 Q_expand；</p>
<p>​    (c) 计算 P 和 Q_expand 的相对熵( KL 散度)，然后选择相对熵最少的一个，也就是跟原分布最像的一个,  从而确定Scale。</p>
<p>​        其中的 KL 散度可以用来描述P、Q两个分布的差异<strong>。</strong>散度越小，两个分布的差异越小，概率密度函数形状和数值越接近。这里的所有分布、计算，都是离散形式的。分布是以统计直方图的方式存在，KL散度公式如下：</p>
<p><img src="/2020/11/13/quantizing/kl.png" srcset="/img/loading.gif" style="zoom:50%;"></p>
<p>​        从上式中我们还发现一个问题：KL 散度计算公式要求 P、Q 两个统计直方图长度一样（也就是 bins 的数量一样）。Q 一直都是 -127～127；可是 P 的数量会随着 T 的变化而变化。那这怎么做 KL 散度呢？</p>
<p>ncnn 的做法是将 Q 扩展到和 P 一样的长度，下面举个例子( NVIDIA PPT 中的例子)：</p>
<pre><code class="hljs python">P = [<span class="hljs-number">1</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">3</span> <span class="hljs-number">5</span> <span class="hljs-number">3</span> <span class="hljs-number">1</span> <span class="hljs-number">7</span>]     // fp32 的统计直方图，T=<span class="hljs-number">8</span> 
// 假设只量化到两个 bins，即量化后的值只有 <span class="hljs-number">-1</span>/<span class="hljs-number">0</span>/+<span class="hljs-number">1</span> 三种 
Q = [<span class="hljs-number">6</span>, <span class="hljs-number">16</span>]  // P 和 Q 现在没法做 KL 散度，所以要将 Q 扩展到和 P 一样的长度 
Q_expand=[<span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">6</span>/<span class="hljs-number">3</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>, <span class="hljs-number">16</span>/<span class="hljs-number">4</span>]=[<span class="hljs-number">2</span> <span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">2</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span> <span class="hljs-number">4</span>] // P 中有 <span class="hljs-number">0</span> 时不算在内 
D = KL(P||Q_expand)  // 这样就可以做 KL 散度计算了</code></pre>
<p>​    这个扩展的操作，就像图像的上采样一样，将低精度的统计直方图(Q)，上采样的高精度的统计直方图上去(Q_expand)。由于 Q 中一个 bin 对应P中的 4 个bin，因此在 Q 上采样的 Q_expand 的过程中，所有的数据要除以4。另外，在计算 fp32 的分布 P 时，被 T 截断的数据，是要算在最后一个 bin 里面的。</p>
<p>TNN int8 量化方案代码位置  <a target="_blank" rel="noopener" href="https://github.com/Tencent/TNN/tree/master/tools/quantization">https://github.com/Tencent/TNN/tree/master/tools/quantization</a></p>
<h5 id="4-3-admm"><a href="#4-3-admm" class="headerlink" title="4.3 admm"></a>4.3 admm</h5><p>admm 算法由 阿里巴巴提出， 应用在 MNN之中。 ADMM 算法是从优化的角度出发，来保证编码前后数据尽可能相似的方法。</p>
<p>首先我们定义一个分段函数 $E(x)$ 如下所示,  则 int8 的求解过程可以表示为 $E(\frac{X}{s})$</p>
<script type="math/tex; mode=display">
E(x) = \left \{
\begin{aligned}
x &= round(x), abs(x) < 2^8 \\
x &= 2^8 - 1, abs(x) > 2^8 
\end{aligned}
\right.</script><p>可以定义一个目标函数来衡量反量化之后的数据和原数据的“距离”。 这里选择度量 D 为 L2 度量， 则目标函数可以记为：</p>
<script type="math/tex; mode=display">
L = ||s \cdot E(\frac{X}{s}) - X||^2</script><p>对其进行求导， 可得:</p>
<script type="math/tex; mode=display">
\frac{\partial{L}}{\partial s} = E(\frac{X}{S})[s \cdot E(\frac{X}{s}) - X]</script><p>得到目标函数关于 $s$ 的导数公式以后， 该问题转化为求解 $L$ 关于 $s$ 的导数为 0 的数学问题。 论文采用了 admm 的思想：首先固定 E 中的变量 s，进行 s 值的求解；再通过求解后的 s 去估计 E 的值，如此反复直到 s 值收敛到最优。于是上述的式子要弱化为如下公式： </p>
<script type="math/tex; mode=display">
\frac{\partial{L}}{\partial s} = E(\frac{X}{s_k})[s_{k+1} \cdot E(\frac{X}{s_k}) - X] = 0</script><p>所以， 迭代的过程也就变成了交替求解如下两个公式的过程:</p>
<script type="math/tex; mode=display">
\left \{
\begin{aligned}
& s_{k+1} = \frac{X}{ E(\frac{X}{s_k})}, \\
& E(\frac{X}{s_k})
\end{aligned}
\right.</script><p>MNN 中 admm 算法的实现： <a target="_blank" rel="noopener" href="https://github.com/alibaba/MNN/blob/master/tools/quantization/quantizeWeight.cpp">https://github.com/alibaba/MNN/blob/master/tools/quantization/quantizeWeight.cpp</a></p>
<h5 id="4-4-easyquant"><a href="#4-4-easyquant" class="headerlink" title="4.4 easyquant"></a>4.4 easyquant</h5><p>github 主页: <a target="_blank" rel="noopener" href="https://github.com/deepglint/EasyQuant">https://github.com/deepglint/EasyQuant</a></p>
<p>原始的卷积输出结果可以表示为:</p>
<script type="math/tex; mode=display">
Q_l = A_l * W_l</script><p>其中，A 表示网络层的输入， W 表示网络层的参数。</p>
<p>如果用 $Q$ 表示量化操作，量化层输出再反量化的结果可以表示如下， 其中 $S$ 表示 scale 值。</p>
<script type="math/tex; mode=display">
\hat{O}_l = \frac{Q(A_l, S^a_l) * Q(W_l. S^w_l)}{S_l^a \cdot S_l^w}</script><p>easyquant 将其看做一个优化问题， 优化目标为量化前的输出和反量化之后的输出的余弦距离。数学表达式为:</p>
<script type="math/tex; mode=display">
max_{s_l} \frac{1}{N} \sum_{i=1}^{N} cos(Q_l^i, \hat{Q_l^i}) \\
s.t. S_l \in R^+</script><h5 id="4-5-GDFQ-和-ZeroQ"><a href="#4-5-GDFQ-和-ZeroQ" class="headerlink" title="4.5 GDFQ 和 ZeroQ"></a>4.5 GDFQ 和 ZeroQ</h5><p>​        结合 GAN 网络实现生成数据，实现 data-free。 然后结合知识蒸馏（teacher model 为高精度网络， student model 为量化网络）来实现网络的量化。</p>
<p>​    ·</p>
<h4 id="5-int8-实际应用"><a href="#5-int8-实际应用" class="headerlink" title="5. int8 实际应用"></a>5. int8 实际应用</h4><p>关于量化之后，如何使用的问题，有两种解决方案：</p>
<ul>
<li><p>混合 fp32/int8 推理: 该解决方案引入 Quantize 和 Dequantize 两个操作。在进行卷积操作前，将权重和输入进行 Quantize 为 int8，然后使用 int8 进行卷积，最后将结果  Dequantize 为 float32。这种方案并不需要所有的算子(operator) 都支持量化，但是由于需要数据的 Quantize 和 Dequantize，降低了网络的推理速度。一般而言， 对于权重量化采用 kl量化 或者 easyquant 量化，而对于激活(输入和输出) 的量化可以采用 max-max 量化 。</p>
<p><img src="/2020/11/13/quantizing/q1.png" srcset="/img/loading.gif" title="混合fp32/int8推理" style="zoom:50%;"></p>
</li>
<li><p>纯 int8 推理：将网络整体转换为 int8 格式，因此在推理期间没有高低精度数据的转换，因此推理速度更快。但是该解决方案要求算子(Operator) 都支持量化，因为运算符之间的数据流是 int8。对于尚未支持的那些，降级到混合 fp32/int8 推理。 </p>
<p><img src="/2020/11/13/quantizing/q2.png" srcset="/img/loading.gif" title="纯int8推理" style="zoom:50%;"></p>
</li>
</ul>
<h4 id="6-ncnn-量化工具的使用"><a href="#6-ncnn-量化工具的使用" class="headerlink" title="6. ncnn 量化工具的使用"></a>6. ncnn 量化工具的使用</h4><p>(1)  Optimization graphic</p>
<pre><code class="hljs smali"><span class="hljs-keyword">.</span>/ncnnoptimize mobilenet-fp32.param mobilenet-fp32.bin mobilenet-nobn-fp32.param mobilenet-nobn-fp32.bin</code></pre>
<p>(2) Create the calibration table file</p>
<pre><code class="hljs angelscript">./ncnn2table --param mobilenet-nobn-fp32.param --bin mobilenet-nobn-fp32.bin --images images/ --output mobilenet-nobn.table --mean <span class="hljs-number">104</span>,<span class="hljs-number">117</span>,<span class="hljs-number">123</span> --norm <span class="hljs-number">0.017</span>,<span class="hljs-number">0.017</span>,<span class="hljs-number">0.017</span> --size <span class="hljs-number">224</span>,<span class="hljs-number">224</span> --thread <span class="hljs-number">2</span></code></pre>
<p>(3) Quantization</p>
<pre><code class="hljs stylus">./ncnn2int8 mobilenet-nobn-fp32<span class="hljs-selector-class">.param</span> mobilenet-nobn-fp32<span class="hljs-selector-class">.bin</span> mobilenet-int8<span class="hljs-selector-class">.param</span> mobilenet-int8<span class="hljs-selector-class">.bin</span> mobilenet-nobn.table</code></pre>
<h4 id="7-参考资料"><a href="#7-参考资料" class="headerlink" title="7. 参考资料"></a>7. 参考资料</h4><p>[1] <a target="_blank" rel="noopener" href="https://me.csdn.net/sinat_31425585">https://me.csdn.net/sinat_31425585</a></p>
<p>[2] <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/c_1064124187198705664">https://zhuanlan.zhihu.com/c_1064124187198705664</a></p>
<p>[3] <a target="_blank" rel="noopener" href="https://github.com/BUG1989/caffe-int8-convert-tools">https://github.com/BUG1989/caffe-int8-convert-tools</a></p>
<p>[4] <a target="_blank" rel="noopener" href="https://github.com/Tencent/ncnn/wiki/quantized-int8-inference">Tencent/ncnn</a></p>
<p>[5] Nvidia solution： Szymon Migacz. 8-bit Inference with TensorRT</p>
<p>[6] Google solution：Quantizing deep convolutional networks for efficient inference: A whitepaper</p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/DL-Deploy/">DL_Deploy</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/11/15/lightweight-cnn-architecture-design/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">lightweight-cnn-architecture-design</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/10/21/principles-of-detection-network-design/">
                        <span class="hidden-mobile">principles-of-detection-network-design</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "quantizing&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
