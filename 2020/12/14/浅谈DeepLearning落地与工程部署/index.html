

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="zhichao zhao">
  <meta name="keywords" content="">
  <title>浅谈DeepLearning落地与工程部署 - 假欢畅 又何妨 无人共享</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/tomorrow.min.css" />
    
  

  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>假欢畅，又何妨，无人共享</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-12-14 13:49" pubdate>
        December 14, 2020 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      2.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      23
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">浅谈DeepLearning落地与工程部署</h1>
            
            <div class="markdown-body" id="post-body">
              <p>浅谈 Deep Learning 落地与工程部署问题</p>
<a id="more"></a>
<h4 id="一-概述"><a href="#一-概述" class="headerlink" title="一. 概述"></a>一. 概述</h4><ol>
<li>软件: 模型的的压缩加速： 轻量级架构设计、剪枝、量化、低秩分解、蒸馏</li>
<li>框架层面<br>（1）算子的优化(conv 实现)、 图优化( DAG、op 融合)、不同精度的推理( fp16、int8、混合精度)<br>（2）内存优化、Cache 命中、SIMD、多线程、并行计算 (openmp &amp; cuda &amp; sse)<br>（3）代码层：循环展开、汇编<br>（4）平台层：arm、gpu、cpu、x86、npu </li>
<li>编译器：TVM 和 MLIR</li>
<li>硬件： 硬件设计</li>
</ol>
<h4 id="二-常用模型压缩与加速方法"><a href="#二-常用模型压缩与加速方法" class="headerlink" title="二. 常用模型压缩与加速方法"></a>二. 常用模型压缩与加速方法</h4><p>（1）轻量级网络设计与搜索</p>
<ul>
<li>设计轻量化的网络架构，如 mobilenet 、shufflenet、ghostnet 等</li>
<li>使用 NAS 搜索较为高效的网络结构</li>
<li>模型蒸馏：使用复杂模型( teacher )去训练另一个轻量化的网络(student model)</li>
</ul>
<p>（2）网络的压缩技术（常见的手段包括： 剪枝、稀疏化、量化）</p>
<ul>
<li>在训练时使用稀疏约束（加入权重的稀疏正则项，引导模型的大部分权重趋向于0），然后在完成训练后，剪去滤波器上的这些权重较低的节点 。</li>
<li>量化：模型量化是指权重或激活输出可以被聚类到一些离散、低精度(reduced precision) 的数值点上。常见的有二值网络、三值网络、int8 量化。</li>
</ul>
<h4 id="三-常见的推理框架"><a href="#三-常见的推理框架" class="headerlink" title="三. 常见的推理框架"></a>三. 常见的推理框架</h4><p>​        一般会提供模型优化和推断引擎两个模块。模型优化模块用于将给定的模型转化为标准的 Intermediate Representation (IR) ，并对模型优化。推断引擎 (Inference Engine) 则会根据特定的硬件进行算子的优化，以实现高效的前向推导。 </p>
<ul>
<li><p>国外：</p>
<ul>
<li>google：tf-lite    <a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/performance/post_training_quantization">https://www.tensorflow.org/lite/performance/post_training_quantization</a></li>
<li>facebook：caffe2  + qnnpack: <a target="_blank" rel="noopener" href="https://github.com/pytorch/QNNPACK">https://github.com/pytorch/QNNPACK</a></li>
<li>intel： <strong>open-vino(for intel CPU)</strong>  <a target="_blank" rel="noopener" href="https://software.intel.com/en-us/openvino-toolkit">https://software.intel.com/en-us/openvino-toolkit</a></li>
<li>apple： core ml</li>
<li>nvidia： <strong>TensorRT(for nvidia GPU)</strong></li>
</ul>
</li>
<li><p>国内：</p>
<ul>
<li>腾讯：<strong>ncnn -&gt; TNN(for arm chip)</strong>  <a target="_blank" rel="noopener" href="https://github.com/Tencent/ncnn">https://github.com/Tencent/ncnn</a></li>
<li>阿里： mnn  <a target="_blank" rel="noopener" href="https://github.com/alibaba/MNN">https://github.com/alibaba/MNN</a></li>
<li>百度： paddlelite  <a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Paddle-Lite">https://github.com/PaddlePaddle/Paddle-Lite</a></li>
<li>小米：mace  <a target="_blank" rel="noopener" href="https://github.com/XiaoMi/mace">https://github.com/XiaoMi/mace</a></li>
</ul>
</li>
<li><p>其他</p>
<ul>
<li>TVM: <a target="_blank" rel="noopener" href="https://github.com/dmlc/tvm">https://github.com/dmlc/tvm</a></li>
<li>TC: TensorComprehensions</li>
<li>onnx: <a target="_blank" rel="noopener" href="https://github.com/onnx/onnx">https://github.com/onnx/onnx</a></li>
</ul>
</li>
</ul>
<p>ps：MLIR（MachineLearning Intermediate Represent）深度学习中间表示已经越来越受重视，但是最大的问题是众多的框架无法统一 IR，前途漫漫（参见 ONNX 项目）。</p>
<p>目前做 MLIR 比较出色的包括（这些 IR 都仅限这些框架自己内部使用）：MLIR(<a target="_blank" rel="noopener" href="https://github.com/tensorflow/mlir)、TVM、XLA">https://github.com/tensorflow/mlir)、TVM、XLA</a></p>
<h4 id="四、硬件发展"><a href="#四、硬件发展" class="headerlink" title="四、硬件发展"></a>四、硬件发展</h4><p>各类硬件的发展都离不开芯片制程、核心数量、指令架构优化三个主要方向</p>
<p><strong>2.1 服务器端硬件分类</strong></p>
<p>x86_64 CPU、<strong>NVIDIA GPU</strong>、服务器 NPU</p>
<p><strong>2.2 移动端硬件分类</strong></p>
<p><strong>ARM CPU</strong>、ARM GPU（Adreno、mali系列）、移动端NPU、NVIDIA Jeston系列、<strong>Apple 家的芯片（自家GPU、NPU）</strong> </p>
<p> <strong>2.3 其他</strong></p>
<p> DSP、<strong>FPGA</strong>、外接式加速设备，各种云平台形式的部署</p>
<h4 id="五-一些基本的问题"><a href="#五-一些基本的问题" class="headerlink" title="五. 一些基本的问题"></a>五. 一些基本的问题</h4><h5 id="1-工程上对卷积操作如何进行优化的？"><a href="#1-工程上对卷积操作如何进行优化的？" class="headerlink" title="1. 工程上对卷积操作如何进行优化的？"></a>1. 工程上对卷积操作如何进行优化的？</h5><p><strong>目前，卷积的计算大多采用间接计算的方式，主要有以下几种实现方式</strong>：</p>
<ul>
<li>滑窗机制。这种方法是最直观最简单的方法。 但是，该方法不容易实现大规模加速，因此，通常情况下不采用这种方法（但是也不是绝对不会用，在一些特定的条件下该方法反而是最高效的）</li>
<li>im2col + GEMM。 caffe/MXNet等很多框架中都使用了这种计算方式，原因是将问题转化为矩阵乘法后可以方便的使用很多矩阵运算库(如MKL、openblas、Eigen等)。</li>
<li>FFT变换。 时域卷积等于频域相乘，因此可将问题转化为简单的乘法问题。傅里叶变换和快速傅里叶变化是在经典图像处理里面经常使用的计算方法，但是，在 ConvNet 中通常不采用，主要是因为在 ConvNet 中的卷积模板通常都比较小，例如 3×3 等，这种情况下，FFT 的时间开销反而更大，所以很少在CNN中利用FFT实现卷积。</li>
<li>Winograd：快速卷积算法，针对不同大小的卷积核进行优化，减少计算中的乘法运算次数，提升运行速度。-&gt; 大部分的前向推导框架都实现了 winograd算法。</li>
<li>MEC：改进了 im2col+GEMM 算法</li>
</ul>
<h5 id="2、算法底层加速相关的技术"><a href="#2、算法底层加速相关的技术" class="headerlink" title="2、算法底层加速相关的技术"></a>2、算法底层加速相关的技术</h5><p><strong>代码层级：</strong>图优化(conv + bn + relu 融合)、卷积计算方式优化（im2col + gemm、winograd、FFT）、尽量避免乘法和除法运算（使用位移、加减法运算替代）、精简代码减少不必要的运算、循环优化、高效存储(CSR)等</p>
<p><strong>汇编优化：</strong>并非汇编代码的效率一定比 C 快，如果 C 程序写的足够好，则编译器生成的汇编可能质量会更高，只是针对特定场景下的情况编译器的优化可能还赶不上高效优化后的手写汇编，因此 ncnn、MNN 都采用了汇编实现算子，但是 TVM 针对 CPU 的代码生成并不是生成的汇编，但是对生成的 LLVM IR 做了很多的优化，目前基本上在 ARM 上已经与 ncnn、MNN 的性能相当了。</p>
<p><strong>硬件层级：</strong>SIMD（单指令多数据类指令如NEON，SSE），Cache 优化，内存复用（内存优化以及内存池，但要避免程序内存占用过大），多线程（并行计算），访存优化（内存对齐，内存重排提高cache命中率）</p>
<p><strong>计算库或加速接口：</strong>cuda+cudnn、OpenGL、OpenCL、Vulkan</p>
<h5 id="3-为什么-mobilenet-理论上速度很快，工程上并没有特别大的提升？"><a href="#3-为什么-mobilenet-理论上速度很快，工程上并没有特别大的提升？" class="headerlink" title="3. 为什么 mobilenet 理论上速度很快，工程上并没有特别大的提升？"></a>3. 为什么 mobilenet 理论上速度很快，工程上并没有特别大的提升？</h5><p>(1) 硬件相关：GPU 偏重于并行、CPU 侧重于侧重于串行。很多细粒度的操作没法很好的并行。</p>
<p>(2) 和对应的 DL 框架实现细节有关：没有对 dw 和 pw 算子进行优化，比如访存次数、cache miss 较多等。</p>
<p>(3) 参数量和计算量：设计衡量的指标是 FLOPS、而不是时间。很多 element-wise 操作以及细粒度操作会增加推导时间。</p>
<h5 id="4-知识蒸馏的原理及其思路"><a href="#4-知识蒸馏的原理及其思路" class="headerlink" title="4. 知识蒸馏的原理及其思路"></a>4. 知识蒸馏的原理及其思路</h5><p>​    基本思想: 蒸馏模型采用的是迁移学习， 通过采用预先训练好的教师模型( teacher model) 的输出作为监督信号去训练另外一个轻量化的网络( student model ) 。从而实现将复杂网络(老师模型)的知识迁移到小网络(学生模型) 中， 提高小网络的精度。常见的蒸馏方案有两种：</p>
<p><img src="/2020/12/14/%E6%B5%85%E8%B0%88DeepLearning%E8%90%BD%E5%9C%B0%E4%B8%8E%E5%B7%A5%E7%A8%8B%E9%83%A8%E7%BD%B2/5.png" srcset="/img/loading.gif" alt="img" style="zoom:35%;"></p>
<ul>
<li>用老师学习到的 soft label 来指导学生模型</li>
</ul>
<p>​        使用复杂的网络作为 teacher 模型去监督训练一个参数量和运算量更少的 student 模型。teacher 模型可以是一个或者多个提前训练好的高性能模型。student 模型的训练有两个目标：<strong>一个是原始的目标函数，为 student 模型输出的类别概率和 label 的交叉熵</strong>，记为 hard-target；另一个是 <strong>student 模型输出的类别概率和 teacher 模型输出的类别概率的交叉熵</strong>，记为soft target，这两个loss加权后得到最终的训练loss，共同监督studuent模型的训练。 </p>
<p>参考论文：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1503.02531.pdf">Distilling the Knowledge in a Neural Network</a></p>
<ul>
<li>用老师学习到的学习方法来指导学生模型</li>
</ul>
<p>​     该方法用小模型去拟合大模型不同层特征之间的转换关系，其用一个 FSP 矩阵（特征的内积）来表示不同层特征之间的关系，<strong>大模型和小模型不同层之间分别获得多个 FSP 矩阵，然后使用 L2 loss 让小模型的对应层 FSP 矩阵和大模型对应层的 FSP 矩阵尽量一致</strong>，具体如下图所示。这种方法的优势，通俗的解释是，比如将蒸馏类比成 teacher（大模型）教 student（小模型）解决一个问题，传统的蒸馏是直接告诉小模型问题的答案，让小模型学习，而<strong>学习 FSP 矩阵是让小模型学习解决问题的中间过程和方法，因此其学到的信息更多</strong>。</p>
<p><img src="/2020/12/14/%E6%B5%85%E8%B0%88DeepLearning%E8%90%BD%E5%9C%B0%E4%B8%8E%E5%B7%A5%E7%A8%8B%E9%83%A8%E7%BD%B2/7.png" srcset="/img/loading.gif" alt="img" style="zoom:50%;"></p>
<p>参考论文：<a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf">A Gift from Knowledge Distillation: Fast Optimization, Network Minimization and Transfer Learning</a></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/DL-Deploy/">DL_Deploy</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/12/14/quantizing/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">quantizing</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/12/14/network-pruning/">
                        <span class="hidden-mobile">network-pruning</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>







  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "浅谈DeepLearning落地与工程部署&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.staticfile.org/mathjax/3.0.5/es5/tex-svg.js" ></script>

  
















</body>
</html>
